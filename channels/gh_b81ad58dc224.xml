<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[机器之心SOTA模型]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[机器之心SOTA模型公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_b81ad58dc224.jpg</url>
      

      <title>gh_b81ad58dc224</title>
      

    </image>
    






    <item>
      <title><![CDATA[今日开源（2024-12-13）：文档解析评估基准OmniDocBench，含文本段落、标题、表格等元素的定位信息，提供模块代码]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkwBRwvMWo2wljI0ZYQUlibbbhbGC2hlM1fbayuSXxkrGlpynDZibxia7AgXyNKCJJS2eIIkZbQLGlcpg/640?wxtype=jpeg&amp;wxfrom=0"/><p>🛠️框架平台、必备工具①项目：OmniDocBench★OmniDocBench是一个用于评估多样化文档解析的基准，适用于真实世界场景。该项目涵盖了多种文档类型、版面类型和语言类型，提供丰富的标注信息</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247497195&amp;idx=1&amp;sn=05abd76af8ab2cbc5d7d29d300517d8e&amp;chksm=c0efddc0415024c08bf217621f57deae52692455f9a8ac8c1d36c548cd036f0fe2626b5a9152&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 13 Dec 2024 10:08:46 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[今日开源（2024-12-12）：多模态大模型Maya，基于LLaVA框架，8B参数，指令微调扩展至支持8种语言]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkwPHbjAob3qevqF6lvzO7SHKzlu0xsRLL1OvovO3cF0f7pf1TWAYtcdlEdN88IkISU8HPib3q5FmEw/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Maya★Maya是一个经过指令微调的多语言多模态模型，旨在扩展多模态能力至八种语言，强调数据质量和文化敏感性。基于LLaVA框架，Maya包含一个新创建的预训练数据集，支持多语言和</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247497183&amp;idx=1&amp;sn=17c018355adb9b2865057acd210c6081&amp;chksm=c042a5d6db4c4eb26ac65e166a2bcab4922ac6620162f426ace4c17fac7101ddc189e23c9c82&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 12 Dec 2024 10:20:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[今日开源（2024-12-11）：书生·万象InternVL 2.5开源，1B到78B参数，链式推理技术提升性能媲美GPT-4o]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkzFW1tZH0AD4pxRjBVK0Ue7YUicyshBhPaJBTGe9MibQLy5N9icmFia4nIYybN2Zsib4nWh8EFoRAstj5w/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：InternVL 2.5★InternVL 2.5 是一个先进的多模态大语言模型系列，基于 InternVL 2.0 构建，保持其核心模型架构，同时在训练和测试策略以及数据质量方面进</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247497173&amp;idx=1&amp;sn=93486372221473fa7f485abe091a6a63&amp;chksm=c076145cc7df25d46782dbd8dc7ba96f10dfc39e94cb506f0f08213fd266eb161e29640f3bfb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 11 Dec 2024 10:04:52 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[今日开源（2024-12-10）：智源发布3D生成模型See3D，1600万互联网视频训练学习，无须几何注释的视觉内容驱动]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkxFaukY2FR0QFAum1yubiadMknYZibI7icEVrJyk6vgviaZnqcRjFrVguqMkBOCBvfyomlDcicht7uyfcw/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：See3D★See3D是一个视觉条件多视角扩散模型，旨在通过大规模互联网视频进行开放世界3D创建。该模型通过观察视频数据中的视觉内容来获取3D知识，利用自动化数据筛选管道过滤多视角不</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247497163&amp;idx=1&amp;sn=ee4ff4247ebe4383369859b1d4831424&amp;chksm=c03b55f76ce27a82d9c6e556a42642b38034e374b6a84693bd2d0425c17a0ca1c7d734bc2b90&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 10 Dec 2024 10:03:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[今日开源（2024-12-09）：Meta开源Llama3.3专注文本生成，70B媲美405B性能，支持8种语言、128k上下文]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDky46ibiaDkwPpOl085OGW8JMM3vibhNsXgv86VS0uGR9XE7tq7A9FzGUBWhzicZ6htmWQuhQwBgUphtzw/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Llama 3.3★Llama-3.3-70B-Instruct是由Meta开发的大型语言模型，专注于文本生成任务，对8种语言的全面支持。Llama 3.3采用优化的transfor</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247497153&amp;idx=1&amp;sn=0a7bc26cb4d676f4da7473d0deb2acfd&amp;chksm=c025734a7eed4e33245cdc98e78114d0034dcae30a61538392c432c7c3b4e43945bb918f6b1d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 09 Dec 2024 10:12:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[今日开源（2024-12-06）：谷歌新一代视觉语言模型PaliGemma 2，从3B到28B，结合Gemma 2 文本解码器]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkzNzwrM9qaicwzXx4pUywZopzH5d8LaLaEZ7HBicKHPxZJvapuSuZFqJ2y2zCHNPfLISODOpjFPbHbA/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：PaliGemma 2★PaliGemma 2 是 Google 推出的新一代视觉语言模型，结合了强大的 SigLIP 图像编码器和 Gemma 2 文本解码器。该模型提供了 3B、</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247497131&amp;idx=1&amp;sn=0dc1d5d382fe53ba58c2106ba022bb2f&amp;chksm=c055c685fb6ebdfc56938cd3230b53c81ca67f0c0cda6ed803601d897aae44a2c5a22b4af879&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 06 Dec 2024 10:02:58 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
