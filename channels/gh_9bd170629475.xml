<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[夕小瑶科技说]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[夕小瑶科技说公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_9bd170629475.jpg</url>
      

      <title>gh_9bd170629475</title>
      

    </image>
    




















    <item>
      <title><![CDATA[Claude 官方发布《Agent 构建指南》，附 PDF 下载]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qHhFZGkVyBjeI6icFfiaTHqCflzrnbg799I4GnOVGCo1GaCs6awf6B5jBDUe9nib5R2L9KBCfrQhTl6w/640?wxtype=jpeg&amp;wxfrom=0"/><p>简单才是王道，Anthropic 的智能体开发的“反直觉”法则Anthropic 最新发布了一篇关于 Agent 的博客文章，得出了一个引人深思的结论：AI 开发的未来，在于“Less is More</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247600714&amp;idx=1&amp;sn=0f1fae17b257f401f47db73771366992&amp;chksm=96330e17a4c925cce1e7f25ad70bd5b09b299bd35844205d0cedc77f08a0a7d64cf9013109e5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 22 Dec 2024 08:58:45 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[哈佛华人创办的 AI 搜索引擎，提出了 AI 搜索赛道的 Scaling Law]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qHhFZGkVyBjeI6icFfiaTHqCfGickdc9ibTkNZNNZ6IcQCRHcldWt7r0ByCz6bLIUx2byDLyKAriay8ofQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>“当人类使用 AI 作为入口，搜索引擎的消费者将只剩下 AI”不像西部世界的 AI 那么智能，现在的 AI 经常没办法满足我的小众需求。我开始以为是模型能力的问题，但是试用了各家的 AI 发现它们都因</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247600714&amp;idx=2&amp;sn=e1ea19b71a6a3bdfc7b581e1ab2692ea&amp;chksm=96c81096d883b3dd924addac76f1747a1404cfc7ba5375101043277a4e3cc00b152456832f4b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 22 Dec 2024 08:58:45 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[o3 发布了，摔碎了码农的饭碗]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qERDqfFk6PXYZ9lMCrScavibwENr6vnPobS201iaYuQSBut2ZaYLMYuKdcia4KA1SAr3yXouaUyEBn4g/640?wxtype=jpeg&amp;wxfrom=0"/><p>OpenAI 连续 12 天的直播，已经全部落下帷幕。如本文标题，没想到，最后一天直播的核心内容竟然是 o3，以及 o3 mini 的预告。为什么不是 o2？因为为了避免版权纠纷，OpenAI 放弃了</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247600616&amp;idx=1&amp;sn=655bce42833fd5634fe263dbdf8fc660&amp;chksm=96b8a2339ab50e6aea12a610636ae69dbd74fcaf9354b8b33f817c4c86a622e63c6f1d2a509d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 20 Dec 2024 21:43:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[我用扣子，把夕小瑶做成了表情包！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qERDqfFk6PXYZ9lMCrScavibb7icJQ1N41CJ9vWxAAicQdPOeAiblTmBQFm3d6ZUPeLPNMDsnulcPFyLg/640?wxtype=jpeg&amp;wxfrom=0"/><p>自从前段时间更新了文章版面后，就经常有家人在 Family 群里夸——然后就会有人疯狂追问这是不是用 ai 做的——众所周知，由于夕小瑶太穷，请不起专业的设计师，但由于自身 AI 能力过硬，所以必然要</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247600546&amp;idx=1&amp;sn=933cb3d5693bee90c43856d6523a5444&amp;chksm=96fdafca6e6b4e2e573552a641236f2472dce8db9cc8aee340ffabc3f505fd6cac3b004ca6df&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 20 Dec 2024 08:09:55 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[谷歌版o1模型发布了，脚踢o1满血版，登顶榜单第一，速度起飞]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qERDqfFk6PXYZ9lMCrScavib6jVOTEEAl6Jia9f0lVwBfy48QbqaiaCSTS6AEFFvIj9AXibt2vb50ibvuA/640?wxtype=jpeg&amp;wxfrom=0"/><p>家人们，就在 OpenAI 发布会的两小时前，谷歌 Deepmind 团队成员发了一个很抽象的预告：这个表情，是要出推理模型的节奏吗？！我还没搞明白发生了什么的时候，我发现 Family 群里已经有家</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247600485&amp;idx=1&amp;sn=b7a740893fb2893b995e6a183124e3e8&amp;chksm=96db9170f5f00f44cc7c32d863af16bc3a5bb416eef976ca00e3f960e24e5cd32dddc4e5663a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 20 Dec 2024 03:42:29 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[GPT、CLIP之父Alec Radford确认离开OpenAI！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qERDqfFk6PXYZ9lMCrScavibeZsqFf0fmzPv6Uasq8iarWzhGm6BPfXOAttkTUiaXRsUOwAG3CgdTksw/640?wxtype=jpeg&amp;wxfrom=0"/><p>家人们家人们！事越大字越少！大 Shock！根据 The information 报道，OpenAI 的研究员，GPT 之父 Alec Radford 昨天开始后在同事圈内宣布，他将离职以独立进行研究</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247600443&amp;idx=1&amp;sn=42abc78c23b199a2ffeb1b77150d5c9c&amp;chksm=96eeff0c785c6ec6c67391b7ba249549a179abc35a192491797174c3c7ecf9b33a594757d014&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 20 Dec 2024 03:05:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Anthropic 发现了一种 AI 越狱方法，安全护栏崩塌，文本视觉语音全部沦陷]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qFFVlav2oaSaBYJfrXC6e1XHYmyibwvS6Q30y0NvUyiaHIp7Zz8nr9qhqCzNX2zN3m4SFZRjGbazmow/640?wxtype=jpeg&amp;wxfrom=0"/><p>今年以来，Best-of-N (BoN) 方法火爆 LLM 圈子，例如 Google DeepMind 提出 BoND (Distillation) 做 RLHF、DeepMind 提出改进 BoN </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247600422&amp;idx=1&amp;sn=5a8fb57b697a7f21e90c428ab89dc833&amp;chksm=96c3003a1e2aa73bfb93c88fd790a5da4fa9cefc579896e7586e89a7f6dcdfd227dbf8d9cb69&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 19 Dec 2024 08:30:56 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[视觉 LLM 开源的疯狂月！阿里 Qwen、腾讯混元、谷歌等连续开源重磅模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qFFVlav2oaSaBYJfrXC6e1XIGelzM3QaCbCkTN2DNF9IPLktzwyJnAUj2sfKscCGZInKBVTcstpRA/300?wxtype=jpeg&amp;wxfrom=0"/><p>2024 年 12 月真的太疯狂了，首先是闭源的视觉模型接连重磅发布——前有《智谱 GLM-4V-Flash API 发布即免费》、《Gemini2.0 实时全模态炸场》、《GPT-4o 视频通话对波</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247600422&amp;idx=2&amp;sn=d276b048effb2183633af00778d48ac2&amp;chksm=969c788d702e7a4452b9fcbdfef40a70f1a061789831ffa60cee28eda6544169ec9a4c10523b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 19 Dec 2024 08:30:56 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OpenAI发布会：o1满血版API上线，4o实时语音API打骨折]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qHicn69lTo7BHWKT7icL0xahqicicvn28M4euA9Hzve8yIGZsnwzoR2uFBvwaiau8m85hxr1WNIX257iatg/640?wxtype=jpeg&amp;wxfrom=0"/><p>OpenAI 预告说，Day9 是属于开发者的一天。所以我早早的搬着小板凳来看直播了~果然，今天直播放了大活：满血版 o1 开放 API 调用更新实时对话 API；价格打骨折数个小更新：偏好微调、SD</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247600348&amp;idx=1&amp;sn=74e908a6780be0eac3fdbc6c5f7d4909&amp;chksm=96205ae8a479fc921fe2d34c239a11bbf56145061bdea17db758ff1f3c6297d3a71355619488&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Dec 2024 01:18:57 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[锤爆Sora，尺度最大，谷歌发布最强视频模型Veo2，叫板海螺可灵]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qEevycmAPIWMOdMjIoLXDZ82AEIXmJa5Z9nkxEgUiaF6qZtDcEp7swnF24Qx4MLV2EIvLaKTpdkKVw/640?wxtype=jpeg&amp;wxfrom=0"/><p>之前，OpenAI 一直狙击谷歌的新产品。现在，这个回旋镖打回来了。谷歌昨晚在 OpenAI 发布会之前，发布了两个重量级更新，一个是最先进的视频生成模型 Veo 2，一个是文生图模型 Imagen-</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247600316&amp;idx=1&amp;sn=03b4b775da6a4870f30c27a640208cd2&amp;chksm=96bf21772b4fa57f6c9697e9fca79119134d35bf4cfe2009d8f8e3ed7a7c5391fbb27562831e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 17 Dec 2024 05:40:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DeepSeek 怒抢视觉对话王座！DeepSeek-VL2 发布即开源，技术全公开]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qEevycmAPIWMOdMjIoLXDZ8z1gdDGoRsR7x5Wxiaku3xh2B2ibkcMZgiarEtpPkVOiawLTMDFnoXp671Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近视觉模型真的卷疯了...前有《智谱 GLM-4V-Flash API 发布即免费》、《Gemini2.0 实时全模态炸场》、《GPT-4o 视频通话对波 Gemini》、《无问芯穹全模态端侧模型开</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247600316&amp;idx=2&amp;sn=119e2d2d2737278c07de1a2b9a4ac39c&amp;chksm=96874abdac3d0dccab558eba8f1db7a4612bdb2471b4044541a4d4ab744f76c9c8ec9d677a47&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 17 Dec 2024 05:40:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Kimi视觉思考模型刚上线，就跟海螺和豆包干了一架，开局即王炸]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qGLkicQw1197Mr3RRyviaXEpibX92icaz28VPktIHzKWJJ29E4GlcGib7yrJIsHdSKv8QANtTiazs5pibic5w/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天早上 11 点刚睡醒，我就看到 Kimi 的官方公众号发了一篇推文——《Kimi 发布视觉思考模型 k1，多项理科测试行业领先》好家伙，最近大家怎么齐刷刷的卷起来视觉模型了。前有《智谱 GLM-4</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247600206&amp;idx=1&amp;sn=7c72a2d3f265110af3907888a671fe67&amp;chksm=969aba744d3a3314ecc2924ebeb18814ec3ef2b58eaa43292273d1fb30d5b18beca88729b126&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 16 Dec 2024 13:14:13 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[最强的全模态理解端模型开源，这个轻巧的小模型不仅多基准登顶，推理速度最高还能领先300%]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qGLkicQw1197Mr3RRyviaXEpibibFsicWO5oA5HVEyAKhX5ZsvF24tOhq5NYzq8YDdTD55elTsO7mKeibOQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>这可能是目前最强的开源全模态理解端模型了。今天，无问芯穹宣布正式开源全球首个端侧全模态理解模型 Megrez-3B-Omni，同步开源的还有它的纯语言版本模型 Megrez-3B-Instruct。M</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247600071&amp;idx=1&amp;sn=05c62bcf139d6bf7ab42b2375d3a28ca&amp;chksm=961695e801ca351693439512e158163be8f12b3ac7ba15efddadde14f12d07f1ca89a4f5e622&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 16 Dec 2024 05:46:17 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[预训练卷到头了，推理却是一片蓝海]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qGLkicQw1197Mr3RRyviaXEpibeSUibMkdFMpuNZWgyMxiab7gia76kocHFumlngBgqlOQLQfgoicJNs079A/300?wxtype=jpeg&amp;wxfrom=0"/><p>就在刚刚结束的 NeurIPS 2024 上，OpenAI 前首席科学家、联合创始人 Ilya 提到“预训练即将终结”，“接下来将是超级智能：agent、推理、理解和自我意识。”从商业价值的角度看，尽</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247600071&amp;idx=2&amp;sn=0cd28d89e585e5b0af12513a85270eee&amp;chksm=96e393da6325ed9bce1986862da9822df9aa273792ed0709ec460824401594e23c64b364ea2b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 16 Dec 2024 05:46:17 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[发现一个好玩的AI播客生成工具，嗯嗯啊啊实在太像人了...]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qGLkicQw1197Mr3RRyviaXEpibOnRdeH0AXPRzx4mfibRLbMArcbTURVeDvLVDHTAq5auAgT9ib16chGnQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>经常读咱们文章的小伙伴们，你们是否觉得文字的方式有些枯燥了呢？没关系，这里我制作了本文的一期播客，欢迎收听！还有爱好写作或者喜欢听播客的朋友们，你们是否想过做一档属于自己的播客，但又无从下手呢？没关系</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247600071&amp;idx=3&amp;sn=83b5e55a657aec9b8174dfa7def290c4&amp;chksm=96e2cbff56a04ab5fd1febb29111d42b4a863d5a86d575e0da45e89a2ec2dab852a9797421ed&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 16 Dec 2024 05:46:17 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OpenAI 计划推出 2000 美金/月的会员，疑似博士级智能体的人类替代品，我看懵了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qEyia2vRUibJFIhgliaicWUxtiaGEecIu4Yib8RDbkE2CBXljMd8kTx6bcIL7xC4h08fw00n1U9djelvqog/640?wxtype=jpeg&amp;wxfrom=0"/><p>家人们，我真的看不懂了。根据几个小时前的彭博社报道[1]，OpenAI 首席财务官 Sarah Friar 表示，其公司正在为其 AI 产品每月 2000 美元的订阅敞开大门，并且由于其具备“博士级智</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247599900&amp;idx=1&amp;sn=9f8cf7bd1ea8a521dada7fccc3547180&amp;chksm=96b75e7cc5f1a36261fcd549f834d07cc40ea503db9f54c1393b37cb12423cd4d6e319d0313a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 15 Dec 2024 18:03:07 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[发现了一个免费的开源实时语音框架，响应超快超自然，支持多语言和实时打断]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qEyia2vRUibJFIhgliaicWUxtiaGak6eYO5VrBicWX979ODptUVeqTTwMbF1Syib0amDib8mznic44AwuaQr7A/640?wxtype=jpeg&amp;wxfrom=0"/><p>“它前进着，又跨过了新的一级台阶，耳边仿佛传来由远及近的低语：前方，即是世界。”大家好，我是含萧。前几天 OpenAI 的发布属实有点雷声大雨点小，o1 之后发布的都是大家已知的功能，许多 canva</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247599790&amp;idx=1&amp;sn=2ca12744a94c081c1a7ad6516b2f7fc6&amp;chksm=969ac026c4237b8fd5f05394ce3abcafccbee5e718bbdcf766eadc5be66f73b707facdf7a1ea&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 15 Dec 2024 12:31:36 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
