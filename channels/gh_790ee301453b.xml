<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[学术头条]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[学术头条公众号]]></description>
    

    <language>zh-cn</language>
    








    <item>
      <title><![CDATA[清华、智谱AI团队：Loss才是涌现的关键，而非模型参数｜论文分享]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5qv5QsBmI9CsVryvREKQhQAticIxCbKRphpc2PWthXWtsEXia1DFbgQxHlQpVkW1EKu3TuOAerjFALYPvensgRVw/640?wxtype=jpeg&amp;wxfrom=0"/><p>文章来源：GLM大模型作者：GLM技术团队大语言模型中的涌现能力（Emergent Ability）研究指出，伴随着模型参数的增大会出现能力涌现。但过去的观察却发现：1）小模型也可以在涌现出的能力上有</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247585700&amp;idx=1&amp;sn=d0bbc6798034270197e45b09e383a9aa&amp;chksm=ce46f33b29738e1a2cb604f09b685b14d63d90ab22a71f5d28d46a664e9c81c52d3c9b5b3c92&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 21 Apr 2024 00:28:30 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[只用0.5天，训练一个15亿参数小模型；谷歌推出新型Transformer架构｜大模型周报]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5qv5QsBmI9CsVryvREKQhQAticIxCbKRpNALicFgdRTQkhcB0RHjibJ6icwRBKSzRd6Ib1C6ffvwCia3uiatPlzZ0clw/640?wxtype=jpeg&amp;wxfrom=0"/><p>本周值得关注的大模型 / AIGC 前沿研究：只需半天，训练一个 15 亿参数小模型Megalodon：具有无限文本长度的高效 LLM 预训练和推理Melodist：实现包含人声和伴奏的可控文生歌曲模</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247585633&amp;idx=1&amp;sn=d748afa375fcbec19acf483697f90504&amp;chksm=ce271020e7ccee1100ecf5dcf3bf37f549940f3cef1c546328bc490660af8007c40e88afde5a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 20 Apr 2024 00:24:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[刚刚，全球最强开源大模型 Llama 3 发布：使用 15T 数据预训练，最大模型参数将超 4000 亿]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5qv5QsBmI9AgLYMoZuAUcsTAS7lHPN0bnhfxspcwlzVyT3ic6Q00EKf5qBP0grg8rJP6HNSVn6eNL0FBibL92tnw/640?wxtype=jpeg&amp;wxfrom=0"/><p>就在刚刚，Meta 发布了其最先进开源大型语言模型的下一代产品——Llama 3。据介绍，Llama 3 在 24K GPU 集群上训练，使用了 15T 的数据，提供了 8B 和 70B 的预训练和指</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247585583&amp;idx=1&amp;sn=69234e42acce877ac4e710ad20046453&amp;chksm=ce9ce0254313a56e629fbc00f42c24a67558edbef4c348c8e5ffdcc7ccb5b461e0be45655bd9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 18 Apr 2024 17:48:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[重磅！清华大学基础模型研究中心发布《SuperBench大模型综合能力评测报告》]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5qv5QsBmI9AgLYMoZuAUcsTAS7lHPN0bicA4FyMibjVAQaPOpibqicg1UjHPbjdEXLRiaR27A1ZdO5bdcpPZOO1iaF4Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>在 2023 年的“百模大战”中，众多实践者推出了各类模型，这些模型有的是原创的，有的是针对开源模型进行微调的；有些是通用的，有些则是行业特定的。如何能合理地评价这些模型的能力，成为关键问题。尽管国内</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247585558&amp;idx=1&amp;sn=2cffbc89df85ad63f2ed514e807c28ec&amp;chksm=cecf3eea0824fb9caa7c2ed5a9c950082320aac623e54a6ae323bf6ad308e37bc519bbc17dbd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 18 Apr 2024 06:05:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[刚刚，李飞飞团队发布《2024年人工智能指数报告》：10大趋势，揭示AI大模型的“喜”与“忧”]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5qv5QsBmI9CnSLPINZhzP9EJztuibEAMSwicaRWWU4stjic6ticw1OVnvK4efkRjUk62cV6waOrSMZHqbwFSCRmT1Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>刚刚，由李飞飞联合领导的斯坦福大学以人为本人工智能研究所（Stanford HAI）发布了《2024 年人工智能指数报告》（Artificial Intelligence Index Report 2</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247585382&amp;idx=1&amp;sn=b36285447eec24ab552f0b150e79425e&amp;chksm=cee42db378340b0b6c9482c0f59fa763f23c59560557883a63ba92672b6eb1bebb20b5a61f5c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 15 Apr 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[陶哲轩力荐、亲自把关：AI for Math照这个清单学就对了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5qv5QsBmI9CnSLPINZhzP9EJztuibEAMSdYQw10o49UdK4sF96aicdrk6S6ua94lnk8FP5Vw0fqnKQ8uco95kA0g/640?wxtype=jpeg&amp;wxfrom=0"/><p>内容来自机器之心编辑：陈萍在 AI for Math 领域，如果你一直找不到合适的资源，这份清单或许会有帮助。刚刚，著名数学家陶哲轩的个人博客又更新了，这次他们整理了一份有用的资源列表，该资源专注于 </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247585315&amp;idx=1&amp;sn=f2f21665ddeff23aee374158b935bf0a&amp;chksm=ce6b7cbfe56261e01db5e6a5b5696d16d3dd8118b815e95f982dc8e94913ab765a6d1982a066&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 15 Apr 2024 11:07:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[仅用10万美元！MIT训了一个Llama2级的大模型；谷歌提出无限上下文Transformer｜大模型周报]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5qv5QsBmI9ByNvksQYcT6POY3YXBZCfuqgZfN2m3ELZviaiaU6IB4yUJ6nq33IlAM1icv89phABxURluGicv9XwaJA/640?wxtype=jpeg&amp;wxfrom=0"/><p>本周值得关注的大模型 / AIGC 前沿研究：超越 Transformer：Google DeepMind 提出高效开放语言模型仅用 10 万美元！MIT 训了一个 Llama2 级的大模型英伟达推出</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247585272&amp;idx=1&amp;sn=cbf88d4df1d4e5d6fb7a1b86bf7a52d3&amp;chksm=ce52f09bbe95ca86233e977f79aec01e8b3e8126e1a34caa4441e67378cdab2fac76fb41c9ca&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 13 Apr 2024 00:24:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[清华“太极”光芯片登上Science：首创分布式广度智能光计算架构，或为大模型训练推理提供算力支撑]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5qv5QsBmI9ByNvksQYcT6POY3YXBZCfuVkuZk1hkIsnkk6LzsFjUrWSEjp0Re1gtGPA1eyOZxKUfbVia9JeoF2g/640?wxtype=jpeg&amp;wxfrom=0"/><p>在迈向通用人工智能（AGI）的道路上，不断增加的计算性能和能源需求，已成为业内构建更强大大模型的主要限制和亟需解决的难题。而光芯片，作为一种创新型技术，以其独特的光速处理能力和低能耗特性，被寄予厚望。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247584724&amp;idx=1&amp;sn=e46f6f9be5a0789863551e4399bf73da&amp;chksm=ce30f9df00226bcd91c59c8f3108d1fb3cab7ac8611deb49a78524a462feb45d04d338f267df&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 12 Apr 2024 08:59:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
