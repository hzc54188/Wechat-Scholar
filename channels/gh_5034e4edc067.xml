<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    



























    <item>
      <title><![CDATA[软科中国大学专业排名——计算机科学与技术]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIz047H3EoCLJw9b7D030vDlB7scCfDGcZwPGhxltbEPedZEcDia5xfw2648oCCWWlxxnWic0qokRtQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>转载自 | 软科2024年6月13日，高等教育专业评价机构软科今日正式发布“2024软科中国大学专业排名”，排名包括810个专业，涉及93个专业类、12个专业门类。软科中国大学专业排名是迄今为止覆盖专</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443445&amp;idx=1&amp;sn=ff06ad442c2f193d1c8f7941ab8b9813&amp;chksm=bff2db332088660b35ecc8d2430e98da5863358ab7ced5819ce7e6f72a97fb5820dd02baf53b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 08 Jul 2024 13:36:18 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[厦门大学首发多模态阅读理解新任务： 图文深度融合数据集VEGA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIz047H3EoCLJw9b7D030vDxa2PVj0JqCvjdDZCAoIJd1prLqJe5ibgT4sHEKLFDsy4YtgOp5qDfAQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>介绍多模态大型语言模型（MLLMs）的高速发展彰显了其在处理图文信息方面的强大潜力。然而，目前的多模态模型和方法主要集中于处理基础视觉问答（VQA）任务，这些任务通常只涉及与问题强相关的有限图片和文本</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443445&amp;idx=2&amp;sn=0b62d999d47fe406176cb04be3e6a9c8&amp;chksm=bf5a819343395a19dd77ba449dffff892ba7f5ff549af7706ec6d9369a6b736b3face3624e7c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 08 Jul 2024 13:36:18 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[ACL 2024 ｜“我的回答是C": 在指令微调语言模型中，第一个token概率与文本答案不匹配]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ibj1ATvtMaloVF1UDcibu7UY3Pl5YvpxDW0YNY3ZnrDnKUK6uV3nRJWom5ZQXPyibh9URB3sibAuDkejVTYWCjajVQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文分享慕尼黑大学Prof. Barbara Plank 团队与意大利Bocconi大学团队合作的一篇ACL 2024 Findings 文章：《"My Answer is C": First-Tok</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443445&amp;idx=3&amp;sn=4e2d93c30f50996f9109af6c7e913f1d&amp;chksm=bfbbb08423bcc3fc21dd3222b5c3ec4e8eea566a531ce2e2e2f7d0ac2904f60e744e24b025a9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 08 Jul 2024 13:36:18 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【RAG】GraphRAG开源：查询聚焦摘要的图RAG方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGDoSiaibBWvebGtNxiakmr35fvNBnLjJjHKoHLVMjsFsPpFawsPiac346o5FTP5jw56m18b97JUPTibwZQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言传统的 RAG 方法在处理针对整个文本语料库的全局性问题时存在不足，例如查询：“数据中的前 5 个主题是什么？”对于此类问题，是因为这类问题本质上是查询聚焦的摘要（Query-Focused Su</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443445&amp;idx=4&amp;sn=8b78308fe80085f5f65ca2cb4b25ca1e&amp;chksm=bf58d6804d7d7b31e3b89c12efb112c0cc228b7ccff91cc1da7bc977bfa46858ab35c4618b76&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 08 Jul 2024 13:36:18 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[序列建模中Next Item Prediction的代表性工作]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/dcUv9UF2OUXVlnkmnpiaL95NEkcib2SWJerWFbeI9RFbh6X2SSMyuUYrxXGnA6z2vD7hoMMEzKr3M32QpNnzDPwg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Next Item Prediction任务是序列推荐系统中的一个基础任务，根据用户的历史浏览行为item序列，预测用户下一个感兴趣的item。今天这篇文章，给大家梳理一下近几年来，Next Item</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443445&amp;idx=5&amp;sn=2405f5fb74e79df2b11ada0b75a46297&amp;chksm=bf3865df61e14fa7c1a42fc9957a034c74b2eae9d35739f2e88687c3ec340ef826e05eb9c406&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 08 Jul 2024 13:36:18 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[大语言模型修炼三部曲]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>周末做了一个合集，将李宏毅老师生成式AI导论 2024第6、7、8讲放在了一起：大型语言模型修炼史三部曲，推荐一下，讲得很有意思！</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443416&amp;idx=1&amp;sn=d8b7a93ace36ab5cf73f26e5c4ac375d&amp;chksm=bf723d37ef6e6b8ecd15352b84ce012df06c14e57019b97f8b7d8a7fb63a8e229e1c9c0fae71&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 07 Jul 2024 15:03:07 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[团队准备解散了。。。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSISP2AyqVAgedib23XEqXbayJ0Gc5r2fwym8ZlM7DVZA38Akric9t0kd0icWKDhWL7FGibvloXUuia6UdQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>周末看到一个非常有意思的讨论，是关于如何带好团队的问题。讨论的大致话题是：如何才能把团队给带散？大家有没有经历过自己把团队带散的案例？或者说有没有看到过相关的案例？核心的关键点在哪几个？初看这个问题，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443410&amp;idx=1&amp;sn=dfbdda5543d90cb92dfe953f0a8b2d75&amp;chksm=bff0880d62a91f4a958298e0930240c90b1822ba8bbe2d33dd8ebba72812df2ef81084fcd993&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 06 Jul 2024 12:30:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[文末赠书！上市一个月，多次重印的断货王，国际版统计教材实至名归！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSISP2AyqVAgedib23XEqXbaypsQkIibiaMeRpoVYwkvPrWEI3EsEEeIEW7gCmcbMIiccw5ze5tQPII5Tg/300?wxtype=jpeg&amp;wxfrom=0"/><p>--文末赠书--最近，《基础统计学（第14版）（双色）》这本书可真是卖爆了！上市一个月，重印了好几次，多次在各大平台卖断货，读者群里小伙伴想要再买一本送人，结果买不到，急得不行！偷偷说一句，京东现在已</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443410&amp;idx=2&amp;sn=b790dd2f17d87c1226f42444aa648cb4&amp;chksm=bfbddc24d84afba3100c233b18a0dc91a8d5b1c954cd0677804a21087211d6d78f13bc300baf&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 06 Jul 2024 12:30:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大语言模型的前世今生：万字长文完整梳理所有里程碑式大语言模型（LLMs）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icohvnWHDnYrXsEvjBbpNksQtIPZAaO6ZIjFUWJRud2YeG0ibVEWkfEvgnrzZHO9ZwORjqCxrowASh5A/300?wxtype=jpeg&amp;wxfrom=0"/><p>链接：https://zhuanlan.zhihu.com/p/691719636本篇博客全面汇总了大型语言模型（LLMs）。从早期的预训练神经语言模型开始，探讨了它们的起源和发展。重点讨论了Tran</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443410&amp;idx=3&amp;sn=eed3bd9b06513441dae43055e1beb96e&amp;chksm=bf35c3ae3fd79a74b7b162adff116ce3e4dcf768ce8e8676000bf4cda5683252a393877ec866&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 06 Jul 2024 12:30:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解大模型计算加速系列：分离式推理架构1，从DistServe谈起]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkOoxD4ssXHzz3QZ2mt7n7j2dukZxAtT7naiboglFuicQhicqS8H9PuNSDNQQbmc5MTxmNhJA6DKRhibzA/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，最近Kimi开源了它的推理架构Mooncake的技术报告，让分离式推理架构的关注度一下升了起来。所以在这个系列中，我打算写一写关于分离式推理架构的一些有趣的优化知识。对于这个架构，我之前也只是</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443410&amp;idx=4&amp;sn=6b1ce66bf5b123d6366b7a8765dc906e&amp;chksm=bff3dcb37b43d5b59b475845d8c9c8eb4dcba8d6e2230310c4fdf023cda8ef7272832107789a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 06 Jul 2024 12:30:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ACL 2024 | GNNavi：用图神经网络引导大模型的信息流动]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ibj1ATvtMaloygLIoQngde37ZT9ZFmPBDEEcVm9VGdjB3wVcsibITYK1noMjG8Uono69NYocAMNWYfJ1O0kZuuPw/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文分享慕尼黑大学Prof. Hinrich Schütze 团队与德累斯顿工业大学团队合作的一篇ACL 2024 Findings 长文：《GNNAVI: Navigating the Inform</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443410&amp;idx=5&amp;sn=659c2a02a0517bd4ec62d6e6475b5092&amp;chksm=bf112807dbfdc787aa49015811fad3c1e99f9990e075d6df0a662ac51c9b4c99bc7bd5596970&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 06 Jul 2024 12:30:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[微调神器LLaMA-Factory官方保姆级教程来了，从环境搭建到模型训练评估全覆盖]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJCA8cA2rBib1tF7DyZbVWu5t5usEo3Jb4QBV6rqssnApUSSjWUKgfAtkklf7kZ3vsNp9hpBeTQFFw/640?wxtype=jpeg&amp;wxfrom=0"/><p>编者注：之前一直用firefly做微调，最近切换到LLaMA-Factory，发现不但简单易用，而且非常全面，有点相见恨晚的感觉。使用过程中我主要参考2个文档，一个是github上的官方中文文档：ht</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443386&amp;idx=1&amp;sn=b343ab9a3c2bd69d2becbbe5325e8baa&amp;chksm=bf78e61b69963ccd6cce5c5477f8d2ac2b3cf09bd4acacfffa8e7941ed5e289e6b19a0809e84&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 04 Jul 2024 15:05:12 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[月之暗面kimi底层推理系统方案揭秘（二）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuzTPgLmqFBkHXb6l9ohia8p3e82XibUxRJ2yDolpwIlX6HLAc9B4eoZX4ibGf8icR0NY4l2uG6AXT7GBQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>既上一篇许欣然的月之暗面kimi底层推理系统方案揭秘，本篇继续。作者分享在知乎上引起了广泛讨论，很多system方向的大佬炸出来了，本文根据作者清华助理教授zhangmingxing的一些分享整理，欢</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443386&amp;idx=2&amp;sn=5f9025450f3012c096900a2ef21155a3&amp;chksm=bf9375f32602079c91b2f6852c4b6f94124cbd4780c57b2e17a4f556bb1bd5f970ab43fac75f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 04 Jul 2024 15:05:12 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[京东招聘LLM+Rec研究型实习生]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJCA8cA2rBib1tF7DyZbVWu5ibmY5bdWFb6neCjPPibIudjoZqdftr7iaf8bYME5dIsrbvsIdRTvmibvibg/300?wxtype=jpeg&amp;wxfrom=0"/><p>京东招聘LLM+Rec研究型实习生（北京）【团队介绍】我们属于京东零售推荐算法团队，负责京东集团推荐平台的算法工作，在这里，有业内一流的推荐算法专家带领团队探索最新前沿技术，有来自国内外大厂的技术精英</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443386&amp;idx=3&amp;sn=2922291d21fa5cd41173b5746614d46e&amp;chksm=bf0703be5cf98a48f7ad60ff3a437bcb0fd008efc808b43ef1a156c9e31ae62e0ecbb590b104&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 04 Jul 2024 15:05:12 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[搜索广告召回技术在美团的实践]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/hEx03cFgUsWxbsG8O3HaXCTnqicV2tg7r39ibbGPNDxhp8r4yDNssrZ3TOLPGRib5UHjqvibkopUuDaJfzokM9tlVQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>内容整理自美团技术沙龙第81期《美团在广告算法领域的探索及实践》（B站视频）。本文首先介绍了美团搜索广告的三个阶段：多策略关键词挖掘、分层召回体系、生成式召回；然后重点介绍了生成式关键词召回、多模态生</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443386&amp;idx=4&amp;sn=efe2e79e55525c724729f1328366aeea&amp;chksm=bf6bf6a4d9747b696ad0d40720483e1fed40ec63f224b895ba40e9e7418721359c6e55cbf0e2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 04 Jul 2024 15:05:12 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[GLM4报告的一些技术点]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW467tjNeS9lhrypUtodbKDjjjUKzDcwK4IDLnicGY0Z8zicGCyre7BnPnJzG0Oc19Kws0xbHbnicY7KvxA/300?wxtype=jpeg&amp;wxfrom=0"/><p>智谱的GLM系列模型在中文领域一直是比较受关注的，特别是最新的GLM-4，个人在使用体验上，感觉已经可以满足大部分日常需求。最近智谱开源了GLM-4-9B，也发了相关的技术报告，总结了整个系列从预训练</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443386&amp;idx=5&amp;sn=0d6f805e4213a29eb325f4629954b8e3&amp;chksm=bf85635d91eb53cff937ba4702f0aba11d7d62368a54526237b06092be2e8f04211406bd6b75&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 04 Jul 2024 15:05:12 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[博士第五年，我还没有找到论文创新点?]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL3K3oMA2Qkibu6LSBpQdl4bTKME60vlKso2PYDx6UeuGs2ANsZL9V2MuoKhpicG9WfMCsOZLtu9guw/640?wxtype=jpeg&amp;wxfrom=0"/><p>写论文之初最难的是找到一个不错的idea，这是非常重要的。因为如果你有idea的话写起来其实挺快的。主要是多看领域内顶刊文章，模仿别人文献的框架和写作思路，找几篇文献一段一段的模仿写作各个部分！但是说</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443367&amp;idx=1&amp;sn=b0a79daba2389b76935019f0a2951e62&amp;chksm=bfa94aebc978a42fda0cfbd2e329543a7876647671248d259b36dad207fb85c2ac324218f334&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 03 Jul 2024 02:10:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[详解这一年多模态视觉-语言大模型的架构演进]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJBjALrmcKhJBOkDNCr72ibPA10NpmW55To8GTQgGIy0kA5KjXOWJDJic3hDtn9IickmflOqCdo5uSrg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：Dreamweaver，SJTU × AIGC/LLM，腾讯公司 · 多模态应用研究 (实习)声明：本文只做分享，版权归原作者来源：青稞AI原文：https://zhuanlan.zhihu.c</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443367&amp;idx=2&amp;sn=af2e4e8d80c51f4fd2ea2c46127ee979&amp;chksm=bf513a559f5093411ce32bcc8b199100836fab5309fbc5a75fcc0390ad065cace660837dc84c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 03 Jul 2024 02:10:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[幻方&amp;深度求索DeepSeek 核心岗位实习生招募]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJBjALrmcKhJBOkDNCr72ibPMRdouxRKicbu5EibthoSgibaKAIEEvbGCB5OM8VbG0fFdmUNPNzcGBcWw/300?wxtype=jpeg&amp;wxfrom=0"/><p>幻方&amp;深度求索DeepSeek 核心岗位招募公司简介：我们相信大模型是科研 + 工程 + 组织的优雅艺术。我们正在寻找并长期培养优秀的 AI 人才，与我们一起进行高水平的科学研究和工程实践。如果你对人</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443367&amp;idx=3&amp;sn=77787c5941aeb9b8267df60245883144&amp;chksm=bff07fe51acae9c779438fcf3b4815fa4b0a39bc828f9f18eeaebe5207ec89c3396b756d8a6e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 03 Jul 2024 02:10:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[成本10w刀的JetMoE]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW4679JTaaic8JeQ9vIJWaa0ibc1ryjVC2NicdKjNZicjHicrjVDiaJTx6wZvoyibgs41EoDrZ7fTL0YicSbOc5g/300?wxtype=jpeg&amp;wxfrom=0"/><p>JetMoE是由MIT、Princeton等几个学术机构发布的MoE模型，其总参数量为8B，激活参数量为2B。训练JetMoE的总花费约为10w美元，而JetMoE在各个benchmark上都有不错的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443367&amp;idx=4&amp;sn=ce0fe297f2f07c8d24023b7fa8ffeef5&amp;chksm=bf84ba967d50eafed8d10a19021863bf46fc1529554306cc8cdebd050b967ed195960e38df0c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 03 Jul 2024 02:10:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[再读deformable detr，还有多少细节是你不知道的]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkMT6icFF1npz4SMWfTwKIczgFH2Nsx5icQGNmFSJW32GVYbrFOVg95soRhuoTE80XZYy86kcRhbvaTQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，今天来写写基于Transformer架构的端到端检测模型：Deformable Detr。如果你也读过Deformable Detr的论文和代码，你可能会发现相比于原生detr，它确实不好理解</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443367&amp;idx=5&amp;sn=25a76d14c1f485d6935d9b72edc59956&amp;chksm=bf6e8717d2c4f1163572c89292d1eff276c9917650ebf6618f63e7824b8d0a6b6e38fe9304b2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 03 Jul 2024 02:10:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多模态大模型，彻底爆发了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIN3EPicAEiay4NMTKLS5LmMlVhbxdeialTPB6YU5AqeAfoXkQWdux0Z3nL952jlticKEyvKBSaundoog/640?wxtype=jpeg&amp;wxfrom=0"/><p>自从ChatGPT和其他大语言模型的出现，人工智能领域发生了巨大变革，尤其是视觉语言多模态大模型的研究和应用。（文末有顶会idea分享）这次我将重要的多模态大模型资料包括670篇多模态大模型论文、14</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443346&amp;idx=1&amp;sn=f2a84c47b26c70dce11b6eca26f27da4&amp;chksm=bfe57433dae36516a124e79449e960913e1565a0989fbb8f1db8bdb8cba237a67cc2f2ee8a19&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 02 Jul 2024 02:09:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型训练十戒]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuwh5Oh4u8kQEV0Q7GBicSdkwOl08M4a3GKJG5fIw99YztD05JIW2XY9QibLCGWo5BCqTAf49dMibNwYw/300?wxtype=jpeg&amp;wxfrom=0"/><p>注：之前发过一个简洁版：大模型微调十诫，这篇算是一个带原始信息比较完整的版本今天看到一个很有意思的东西，言简意赅，字字玑珠。加了注解，与大家分享。新造的LLM，感谢尊者开悟～1.切勿微调（Thou S</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443346&amp;idx=2&amp;sn=e39328797b18f786760e44a5cc909a0b&amp;chksm=bfbcae1db57d1cbc67cd3d5eb98d6ff2d1ecdd038a188341141f834eca704bd92d543b831a52&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 02 Jul 2024 02:09:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型上下文长度扩展中的检索增强技术简述]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/58FUuNaBUjodxT3b8OjYSyFMPZCrgIFzesXshZtW7um11xlfu9zYzx1x3DibodY9eZXgGiaeoiaJdSI2dln1SdMMw/300?wxtype=jpeg&amp;wxfrom=0"/><p>笔记作者：刘议骏，徐阳出处：哈工大SCIR背景介绍基于Transformer的语言模型在众多自然语言处理任务上都取得了十分优异的成绩，在一些任务上已经达到SOTA的效果。但是，经过预训练后，模型能够较</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443346&amp;idx=3&amp;sn=80005f3bd3c1c8280744450af0d41ce3&amp;chksm=bfd4eba5f825129dea86fd7f3e66411dc05935e477728c81793e62b72ac28d9c1cf2c3a8b53c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 02 Jul 2024 02:09:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[XTR检索模型简介]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BAVX0pafImmXiafibfaV7VlKohmeynS9SZlsjwTtJRhZKGfDO7GmVib2VLTOFpr9iboTWroRIjOkxkqMOTCv05CicyQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前写过深度检索模型的介绍：# 深度文本检索模型：DPR, PolyEncoders, DCBERT, ColBERT，今天来看看DeepMind在NeurIPS 2024上的文章，对多向量检索模型（</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443346&amp;idx=4&amp;sn=10345ddd1f22274b44672700489bbacb&amp;chksm=bf72a0e61ccf837a44965f90a8597374f6fe6e46fd9716ab32fbf03aee5b2d1aa28a138620c4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 02 Jul 2024 02:09:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[BigCodeBench: 继 HumanEval 之后的新一代代码生成测试基准]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2r0KXvibdsDP6u1bDzDMhH7NmezMNkQ17X06LEu6VhicibZibeuj6QmxpXzrjBEGunQ3tyibunvCdWibJBg/300?wxtype=jpeg&amp;wxfrom=0"/><p>HumanEval是一个用于评估大型语言模型 (LLM) 在代码生成任务中的参考基准，因为它使得对紧凑的函数级代码片段的评估变得容易。然而，关于其在评估 LLM 编程能力方面的有效性越来越多的担忧，主</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443346&amp;idx=5&amp;sn=9b02993c12a94ebaeb374dade1368ecc&amp;chksm=bf5cde8835936adccd432a365eca4bf68f1ff650ab4dae893badcc28ba2c633de704c238ca16&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 02 Jul 2024 02:09:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024 年了，你的长文本训练数据真的够长吗？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIN3EPicAEiay4NMTKLS5LmMluhANuzdTiaia89zJqJyZwf2xUnSMrC6XQka3g4mQXibTPmdnxcx9k1uww/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文标题：Long Context is Not Long at All: A Prospector of Long-Dependency Data for Large Language Models</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443336&amp;idx=1&amp;sn=009f49aeee7e4f4cc5903bf85d2d641a&amp;chksm=bf7a38571daaeb6049c5f3ed8b26df73bbfd99269f1a5a402c61049b7b9d910907493909840d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Jul 2024 14:01:28 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[月之暗面kimi底层推理系统方案揭秘]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuxe5SBIw9qaAr5TDcgtpiaFBaWrEaiczwSogfnx8akps5MN7fibOcQ3F41DuibrT6ezpvvQG9SnGLxGxw/300?wxtype=jpeg&amp;wxfrom=0"/><p>太长不看版（作者大佬自己的在知乎碎碎念）：本论文与很多 Prefill/Decoding 分离的论文不同的是，这套方案已经在大规模集群上进行几个月的验证并证明了方案的有效性。目前这套系统承载了 Kim</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443336&amp;idx=2&amp;sn=ff8a2773a5bb2bbbd2722babf6ef2bb6&amp;chksm=bfa22c96eef8708ae399c328d640ec528c54e41143980fea519e1dbad905081419813f85d588&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Jul 2024 14:01:28 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Hugging Face Accelerate 两个后端的故事：FSDP 与 DeepSpeed]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2q4zkWrSBs9FJnBuEVmExTheMebSct2qta6dqg8hlaqiaIOs7nWZQ8P2F2Pc7GwHMQPfnh7FxjeEwg/300?wxtype=jpeg&amp;wxfrom=0"/><p>社区中有两个流行的零冗余优化器 (Zero Redundancy Optimizer，ZeRO)算法实现，一个来自DeepSpeed，另一个来自PyTorch。Hugging FaceAccelera</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443336&amp;idx=3&amp;sn=5972bcf2e987b2c2b4e424dc1348e7fe&amp;chksm=bf156a5fe0043ddb743f9e9b2c910a81e81d6d4ebc83c017ea8c5b707ff2359b8f0d56423478&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Jul 2024 14:01:28 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Multi-task Hybrid Loss Training：因地制宜，充分利用数据信息]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKpvTic1FcPFgVHjqObjWIIrlIOibLSmPY0ibtRApXlKDjTviag7LRiamOyLF4l5ulJ4SMIsqQkkskDWn6eg/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲‍‍‍‍‍‍‍‍‍‍‍‍1 简介2 Multi-Task Hybrid Loss Training    2.1 Retrieval and Reranking Loss    2.2 STS a</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443336&amp;idx=4&amp;sn=50cc9b707353fdc001400cd192d70bc6&amp;chksm=bfe6d841966147d69de2b885bfbc190161b2f7c039db8ff8169ca3acdce25333c7dd62e6199a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Jul 2024 14:01:28 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[深度文本检索模型：DPR, PolyEncoders, DCBERT, ColBERT]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BAVX0pafImm4UvL6oG2x5VZurZKMg8vptiahHX4YFCVqBFyns9n6iaXCjvAGLlfPSU7fqqoibeOjXHk9McDzVoHtQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>文本匹配与检索是NLP中的经典问题，主要研究两个文本的主义相似度，通常用在检索系统的召回阶段。传统的召回方案如tf-idf和BM25具有速度优势，但在语义匹配方面有所欠缺。随着预训练模型的发展，使用深</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443336&amp;idx=5&amp;sn=2884c1d7434f2fc3d0d493531e67f213&amp;chksm=bf8d00a4a422b72150f3f455320b381c5af97b2c77bf3cc8406ef035a9976b5179de304c29d9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Jul 2024 14:01:28 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
