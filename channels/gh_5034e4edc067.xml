<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    


























    <item>
      <title><![CDATA[RAG在若干医疗场景的实践和思考]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GcdHgGa9nicia3XVUeha9VSTe4loibUbIkia06SJOCFv5WMuOUSGUR9CHx6CTQeicGd5Yl3rLgs0neXtZL0LVQWAH1Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>          2024年第一篇文章，讨论一下最近一段时间做llm应用的思考。元宵节，小区附近烟花很美，但是笔者写一篇文章要花一个晚上。（祝读者朋友们节日快乐哈🌹）                </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441005&amp;idx=1&amp;sn=5ae80e74498f23a3877b3072bf4fd168&amp;chksm=bfce6245bc5cf90c46f486915346d057f82eb65f39a62c8b4ac072ecddf713e34ba57f2841bb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 26 Feb 2024 10:26:04 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[来自社区的Gemma微调踩坑记录]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/fI41EfAgQvsS0nsRrxo4lO1d7OcSmsJ0DnLW8UaicXQz4QDzXiaDHsGQHibFAFfr74KLk6Dg4xfEK8rDLXiaYl4uNA/300?wxtype=jpeg&amp;wxfrom=0"/><p>越来越多人发现Gemma 难以 finetuned的现象了。今天在 Twitter 逛就看到好几个相关帖子。有些内容还挺有价值，分享给大家。下面这个老哥是 Dolphin 和 Samantha作者，应</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441005&amp;idx=2&amp;sn=4758fb24130f44d6a96fc8ab0a07d449&amp;chksm=bf0de731a0072c7d9b9ba566ce8555f67bea32f6c3cb60b938460304df3f34bff4c0f15b5059&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 26 Feb 2024 10:26:04 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[CCL24评测火热报名：中文意合图语义解析评测]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/iaNXOBvo8d77x9icz0cGnlGibs6mOpb0uUyuicvbRHQ2d8uGmyibtnib6uRPDRA2nC2CDibYRN18grSqbRWfervgiaq1ng/300?wxtype=jpeg&amp;wxfrom=0"/><p>2024中文意合图语义解析评测任务参赛邀请第二十三届中国计算语言学大会技术评测研讨会（CCL24-Eval）任务已发布，其中中文意合图首次进行公开技术评测，欢迎各位同仁报名参赛。组织单位：北京语言大学</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441005&amp;idx=3&amp;sn=002321c6a7ac1dc24a81d2af2fee3947&amp;chksm=bf204907e76665a6e25400f6e77643f343bba52421e7c881bde60d7cfae2915f7bccf92b55c6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 26 Feb 2024 10:26:04 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[ICLR2024｜Mol-Instructions: 面向大模型的大规模生物分子指令数据集]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/AicicrECaqhcOvFTVsoLITNOboIIH7lew6sN73ES6UficlFGA9WwHbrzk7AGg4CtkQ0wRjn1BYNfEXzjuUpKNLHLg/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文题目：Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models本文作者：</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441005&amp;idx=4&amp;sn=c687711123eee30aeb83189ce3a27b97&amp;chksm=bfc2aaef17326ce771ba19add74dabe85a8afb7de6100a54e35726812fca36b88ba6adb92d66&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 26 Feb 2024 10:26:04 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【急招】【社招】【一汽北京软件】自然语言处理算法工程师]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJBKE5kQaGDucibyicmu3ERUnqPPSYPBEZhCicr6diaugM6CUrzJwNg4e1sGiblc1SB7Vrff3p67GQ8xTw/300?wxtype=jpeg&amp;wxfrom=0"/><p>【急招】【社招】【一汽北京软件】自然语言处理算法工程师职位描述1. 负责人机对话系统相关算法开发、多轮对话管理功能开发，提升用户多场景使用体验2. 对用户数据进行理解、挖掘，构建高性能知识库服务，支持</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441005&amp;idx=5&amp;sn=1ab172964f75e3c3c7bf928403d700e3&amp;chksm=bffc6a8b32afad4e2a8ba38a28c70f463645aa30e0ab2de9985260cb94b6b8a099713bd42970&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 26 Feb 2024 10:26:04 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[传说OpenAI工程师必背的经典：苦涩的教训]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/aaN2xdFqa4FX8elmfCpiaOktMsR1L7PEAvCibFlicjw2TicVPMcHxhTzNCVBZAHsqzZT8mnDxMTqQn8icSMZPNpGtDw/640?wxtype=jpeg&amp;wxfrom=0"/><p>近日，流传了一份OpenAI工程师的作息时间，其中有一项就是背诵强化学习之父、加拿大计算机科学家理查德·萨顿（ Richard S. Sutton ）的经典文章《The Bitter Lesson（苦</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440984&amp;idx=1&amp;sn=803b790bf9dac65bf1b3e535f9f31916&amp;chksm=bf44d360e5e7a51d9cb451dc54913da46eb30a860e677c6e7a171058333d6a77ca2d8688551a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 24 Feb 2024 12:37:56 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[地表最强7B模型？我的Gemma体验报告]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/fI41EfAgQvtQfWibwkXMBe6n9CUWo5mDgmefnAF40zVNVwHUgOe4RMcF4mFlpxWPUHic8GE8WXzHuue98bYHrYFA/300?wxtype=jpeg&amp;wxfrom=0"/><p>昨天，也就是2024年2月22号，一早上起来就看到国内的AI公众号就热闹非凡，Google发布了他们的开源大语言模型Gemma，上Twitter也看到Jeff Dean卖力地再宣传自家的新产品：几条推</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440984&amp;idx=2&amp;sn=0690c3eabdf7e44a6cc32ee6eb3c5517&amp;chksm=bf65739e51aa407c508a46cb1e2e1c0ae6a7d837bafcfd31fe5822c4a7dd3f76a40c8335fd7b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 24 Feb 2024 12:37:56 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[上海传音控股招聘大模型应用算法工程师]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL2zibwQbrwukB1yhVKniaEZp7ibEvKq1p9I4VdkNtic6boWm73nLUhBiahK7jbgBgfDZPxuckcgzKMdibg/300?wxtype=jpeg&amp;wxfrom=0"/><p>上海传音控股招聘大模型应用算法工程师 大模型应用算法工程师岗位职责：1、结合公司业务需求，探索大语言模型(LLM)等NLP技术相关的新方法、新应用，参与大模型应用研发及业务落地；2、负责NLP模型的训</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440984&amp;idx=3&amp;sn=0247718644961a5e80fcb899e651b171&amp;chksm=bf75d068d2b478fba66e33fecfd9963c18e6aa6f09b11d9139aa88ec0e792f3d4cdc8ba484f6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 24 Feb 2024 12:37:56 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM之RAG实战 |  利用MongoDB矢量搜索实现RAG高级检索]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/N5aX12H1SickuvXDX7nadJyckicXWaNwKcIuknhmbZIia8O0ibGZjyXcpmyzFSvOlPmO917D6Wrk1yOKOEYXN4l0wg/300?wxtype=jpeg&amp;wxfrom=0"/><p>       想象一下，你是一名侦探，身处庞大的信息世界，试图在堆积如山的数据中找到隐藏的一条重要线索，这就是检索增强生成（RAG）发挥作用的地方，它就像你在人工智能和语言模型世界中的可靠助手。但即使</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440984&amp;idx=4&amp;sn=c1d002c80128e6fbb8d1f9c0c14472ea&amp;chksm=bf22a87e357846ca988a85c1ddea50815915241172af5f46542a04ae627fff5d0a4184397a5a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 24 Feb 2024 12:37:56 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[欢迎 Gemma: Google 最新推出开源大语言模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2oA5NUUIod4WezAxtMtqJmS6I5SQwe0YZtH1oVtbXdw5w4OgLmUFMV0EFWlsphicMbZzl3UloxJ3Uw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天，Google 发布了一系列最新的开放式大型语言模型 —— Gemma！Google 正在加强其对开源人工智能的支持，我们也非常有幸能够帮助全力支持这次发布，并与 Hugging Face 生态完</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440984&amp;idx=5&amp;sn=d1667386b46bb46e2bedd19bfdb665b9&amp;chksm=bfd03ee2ae0c841e838e22c23ad023126b9e51a74af93e8df086010b518a29aba7559096e86d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 24 Feb 2024 12:37:56 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[详解大模型RLHF过程（配代码解读）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfq1z11WrQogZvALeoNWZInG5RPbbcEl4k64vzXiaT8WVnicqZpmpd09xMbBLuKocD6Lg011CcAcgN8Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者丨战士金@知乎来源丨https://zhuanlan.zhihu.com/p/624589622编辑丨极市平台导读 本文结合代码详细讲解奖励模型训练和强化学习训练过程，大模型的强化学习微调过程看这</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440966&amp;idx=1&amp;sn=c6fc9ac1cfbf6fe17ce4b8fd06a520cd&amp;chksm=bfa512e0ac51542e8ce1b3febc3a10a4707a6fc5b9b0598f23a5efbbe8d898b8ba617915cc05&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 22 Feb 2024 10:51:23 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[开源大语言模型作为 LangChain 智能体]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2oicyFtkuEMSSlKHvcyIJPW06iaNAib22pibRYkCxqLzgaMhebHuWXHG0u0lkdlCxjUPl2Rzss5FJsQxQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>概要开源大型语言模型 (LLMs) 现已达到一种性能水平，使它们适合作为推动智能体工作流的推理引擎: Mixtral 甚至在我们的基准测试中 超过了 GPT-3.5，并且通过微调，其性能可以轻易的得到</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440966&amp;idx=2&amp;sn=cc6e57afa8adf35fcdbdbc4b96da6086&amp;chksm=bfb2c9b369c897993da54af9763382ffd7d3fdfe47f0fe69ba05cc2712f144eba3bd1bf2365b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 22 Feb 2024 10:51:23 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[美团大模型基座强化算法实习生]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIqo1McIromIrfgTPjqvIBMyUzXRvhjr4FeODYWZ60Ngn1o4EpUiaRibya8IIWhYfLibOGY9ZKNwjF2Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>美团大模型基座强化算法实习生（北京）岗位职责：1.参与LLM对齐技术（SFT、RLHF等）链路整体优化，包括数据探索与增强、奖励模型优化、RL策略迭代等；2.参与百亿参数以上超大模型的训练与性能优化；</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440966&amp;idx=3&amp;sn=6707193ff93a5d13621f350dc0676c10&amp;chksm=bf9bfbb35593b51c1d73bb1cb9c27d0e67463c3db49f885f680af6d356761ff65ea6668f41c6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 22 Feb 2024 10:51:23 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Sora介绍]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HIKk7OFDjoTZm8onh4ZlgpMDIAMicblWIB18wFmyyo9jyN53HCsEaZ9iauBia0wmBLy2eUyfzltjauUWYbCl79BqQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>春节假期最受关注的模型就是OpenAI release的Sora了，由于目前技术原理没有开放，且仅开放给部分用户用于测试，本文仅介绍官方技术文档所发布的信息。https://openai.com/re</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440966&amp;idx=4&amp;sn=a94bc9ede577adcd21350f38bf554474&amp;chksm=bf78c678b700f7442c1cd0ea13256e2cfdbe3dd80d55bcb01f0d9509e4e256c16fb5944222da&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 22 Feb 2024 10:51:23 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLMLingua｜您有一份prompt压缩20倍的方案请查收]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gTSf9kr5zrMdkcD3wFnpvWqiakyPRcsBt8qDIA2Ct1YJ3wdTCKx3QdzK7F9T6gLFe880UkWCVUg81kK8fRCicXyg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天分享微软公司的一篇文章，Title: LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Mode</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440966&amp;idx=5&amp;sn=2fc52fda105c79bb9e8450bd11e73577&amp;chksm=bfd8eca41aed9c79ce7613463eb373f8712ab04f2ae35479217391a1b9442336e4e6edce8a3d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 22 Feb 2024 10:51:23 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Sora 爆火，Llama 2 高调开源，大模型微调我已经上手了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLOcquMAiahpesNB5SXcmNBLQ7tbjia9TdrIZgC1oxmjWm7w31xtjl5TEhsBDFib01odOOug1iaGPibVKw/640?wxtype=jpeg&amp;wxfrom=0"/><p>如今大模型席卷AI界，已经成为所有人工智能从业者都要入局的领域。在2024开年，我系统梳理大模型学习脉络，邀请多位高校博士、国际顶会审稿人开了30节大模型课程：包含大模型理论课程、大模型论文带读、企业</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440952&amp;idx=1&amp;sn=c481f3ecccccf3990c17220483e36cf3&amp;chksm=bfd764fce8c4e65f954a8c0aafb1a5a0ef18c370b7907ec9225981888906dee25920b45c58ec&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 20 Feb 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM之RAG实战  |  在RAG管道中实现上下文压缩和过滤]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/N5aX12H1SicnxhugfOrlaZ6JT1ib3Dp5jKqtFrt805JyGv2PTlN2ZuOKFDrWVmBJYU5YUBQ6KnM9apebqjuTCiabw/300?wxtype=jpeg&amp;wxfrom=0"/><p>               在RAG中可能面临的最大问题之一是检索器应该检索什么内容？       实际使用中，检索到的上下文并不完全有用，可能检索处理较大的块中只有非常小的一部分与答案相关，还可能</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440952&amp;idx=2&amp;sn=6fc47573f209deff7d319738d3993f66&amp;chksm=bf6455618156a492066220fd68ab268a6699fa80ccc74243da43869d91dca69d2108baeaf7ff&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 20 Feb 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[前沿重器 | 综述-面向大模型的检索增强生成（RAG）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jT5Sp7MICPzCwkfYWt5KQv86sibia4QgCnV7e4borKeUMYvq5L2xHdAQ0rnBcXOu7VSiceJsLyZHAkYR0OccDuqNw/300?wxtype=jpeg&amp;wxfrom=0"/><p>RAG最近有一篇广受关注的综述，最近是花了不少时间给啃了个大概，里面提及的挺多文章其实都挺精彩的，甚至是让人兴奋的。我先把链接放上。论文：Retrieval-Augmented Generation </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440952&amp;idx=3&amp;sn=e4a17d1eac305db04dcd15b1b6a252cc&amp;chksm=bf82906d42665ffcb4a2f73eee2f341e268ddbfad3e5aecc79477c6b4a19f29717edb45ea2cb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 20 Feb 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[论文浅尝 | PanGu-Coder2: 利用排序反馈增强代码的大型语言模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GNpj5fw72EpuVAAkyhOMWqCls5a4Y4QCibN088LU5OHdFCYU87pFKIrqLddnS9ZCIMLBYmRwgcTiaWl1cZkmGCRQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>笔记整理：李晓彤，浙江大学硕士，研究方向为蛋白质与大模型链接：https://arxiv.org/pdf/2307.14936.pdf1. 动机作为大语言模型最有前途的应用之一，代码大语言模型（Cod</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440952&amp;idx=4&amp;sn=e0844f8e546e16ebc76d141f571da844&amp;chksm=bf572711708e32441bf847383c07530f8aa1c6e04a337788cd5eba83e231168b1b9ae06b12e7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 20 Feb 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLaMA 2 - 你所需要的一切资源]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2oTm4VSzmicmftwmV7x6qmnQBd9Ewxymaw6cOe5eYVSf4blqrlIicbUrjflSQkVGhCLgQGXbgPgp5zQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>摘录关于 LLaMA 2 的全部资源，如何去测试、训练并部署它。LLaMA 2 是一个由 Meta 开发的大型语言模型，是 LLaMA 1 的继任者。LLaMA 2 可通过 AWS、Hugging F</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440952&amp;idx=5&amp;sn=8c2dcc78bd184d9580d2b206854fba49&amp;chksm=bfe768ca1ce2e002bc36386634132a4d22c5e0508870aad87152d33f71d46db3edf0c1593385&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 20 Feb 2024 04:10:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
