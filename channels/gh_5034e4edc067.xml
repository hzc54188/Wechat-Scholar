<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    





















    <item>
      <title><![CDATA[Llama 405B背后的训练、对齐技术演变路径]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJNm9ibRjg92hvspnjfnnUJxRDzu5IQtX0Q0L9mVKiaWibJeWQd7AYbsxj27X6NlDJYzqH6aGOOmwVjw/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着大模型的飞速发展，在短短一年半间就有了大幅度的技术迭代更新，LoRA，QLoRA，AdaLoRa，ZeroQuant，Flash Attention，DPO等技术效果已经在工业界逐渐得到验证。过去</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443872&amp;idx=1&amp;sn=d1e12680276f9237dabe7ba80ebfa466&amp;chksm=bf252fa7a7a786644522d7fa8d68b1f1a5e153a83e5132a9a33d316b8bc01cfcc5de59d1350f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 29 Jul 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[为什么说大模型训练很难？聊聊预训练的一些经验]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL5XkL946ZRAn14LSUn6Ktxv57nAWWy5rPhzuZn6mfEEzbgLLLoOyeMbeFFBTfWOLibKQGN0unX6hg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：罗小黑，主要做NLP声明：本文只做分享，版权归原作者，青稞AI整理原文：https://www.zhihu.com/question/498271491自从Bert网络模型产数量超过3亿规模，当</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443872&amp;idx=2&amp;sn=3df3010223b426ce74c8edca121bfd54&amp;chksm=bf2a2aaa5037c579c45620a6b5fb6ddf1923e2b5d34009bb9f25dd67e02bf8f282f224484557&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 29 Jul 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Llama3.1--post-training要点一览]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW464iactcJwYsUrZcBMI7BgI5ZMbgUd9kClmXjZ5icto96sODFT3SY3u6kvBQRiak1gfl5DCjHQ5F4tSGA/300?wxtype=jpeg&amp;wxfrom=0"/><p>书接上回：Llama3.1--预训练要点一览，继续整理一下Llama-3.1中post-training的内容。在Llama-3的报告中，任何在pre-training之后发生的训练都属于post-t</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443872&amp;idx=3&amp;sn=05f2ce4a16c8228801c02e9f41d00fab&amp;chksm=bf36231f619f25b0a2e815a81b55a613f7b0ec640fdb9a21f22b9694d7b0d1c8ab147783cff8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 29 Jul 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【LLM基础知识】LLMs-Norm&amp;激活&amp;FNN层知识总结笔记v5.0]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdBbOW12YJpSibiaSgCWJB70SsNl1lwC3L5zBZpy5zkib8Ba5qpjr1Osw5MbCmJ354aicMibhQLGD6Pia8Ww/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM知识点第五篇，介绍LLM中采用的Norm方法，重点介绍LLM常用的LayerNorm，RMSNorm，DeepNorm。接着介绍ReLU，GeLU，Swish激活函数和GLU及其</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443872&amp;idx=4&amp;sn=af329c7b93a7e864bc18cc8b6b9cdd3f&amp;chksm=bfb8d5e126a88ad082efa3a86551ffe80b68742914362a23c1a0929a32df80026f36ac48d057&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 29 Jul 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[语言模型之text embedding（Decoder_only篇）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKpsGBXO4eSaJl81GYQgRZ3NyQKicfZq3vTctrGmuBGKXJKOvl22D2Lp7zXaPMicGcfRbjoF3E7P8ib5dg/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲1 简介2 任务介绍3 decoder-only    3.1 模型基底优化    3.2 注意力机制优化    3.3 Pooling方式调整    3.4 训练数据优化    3.5 训练方式</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443872&amp;idx=5&amp;sn=80d40eca682034aa6dd59a963612ae67&amp;chksm=bf78acde071fcfdcd373a1108dfee76e5802d20c914729a20bebc86610a8060d04d2883cd5ee&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 29 Jul 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[腾讯宣布全员调薪了...]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJNm9ibRjg92hvspnjfnnUJx4R42s2NzFricyXQoGqIUGDAAPpLnkJErBNSreicXhicWbCdh0zpHGtTyw/640?wxtype=jpeg&amp;wxfrom=0"/><p>7月10日，从腾讯内部人士处获悉，腾讯发布全员邮件，称将调整内部薪酬福利政策。主要内容如下：1. 校招生的房补从每月4000元调整为按15个月发放，并将其纳入月薪基数中。调整后，员工每月基本工资增加3</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443846&amp;idx=1&amp;sn=6d8272b34fe553d453cb4df0027256a7&amp;chksm=bf6791f66a2655c88a7bdc4fa5254e66b372ce89519dbba51f0cac55fbff521f5a315493d758&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 28 Jul 2024 11:25:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[赠书：《快速部署大模型，LLM 策略与实践》]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJNm9ibRjg92hvspnjfnnUJxrdzWibgBsKMHoeFib9GWaWN01qJKPjqqWEgsiaPaS9hS2gICicTrL5S7tg/300?wxtype=jpeg&amp;wxfrom=0"/><p>❝本文“如何写好提示词”节选自《快速部署大模型，LLM 策略与实践》一书提示链提示链涉及使用一个LLM的输出作为另一个LLM的输入,以完成更复杂或多步骤的任务。这是一种利用多个LLM的能力,并实现单个</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443846&amp;idx=2&amp;sn=04ccaf98ff4c97564aebb4a6f8b45320&amp;chksm=bf8b261fc726c4696bf4620ec3b7c03fc9af16174c63dd89047537b38d9af5975457f3f3ab8a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 28 Jul 2024 11:25:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[如何从Meta窃取价值百万的Scaling Law数据]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/d6902wUyyvLfeJib8wQKFH6zcM9Rial544FClvia23rLqem3jVkQoYs5cT2mBlaQV0C1cTSVme7VXKpy3s3Dcwp3Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>Surprise surprise 恭喜你被骗了，这里的一切内容都是合法且符合中国特色社会主义价值观的。背景开源皇帝meta最近推出新的开源模型llama 3.1，其中最大的模型尺寸来到了巨大的405</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443846&amp;idx=3&amp;sn=68380eeb803ce0a9a4319456a654f320&amp;chksm=bf982d028d3ba82edfa4872d27364460f83f11591199fae9a36801c46109118bb2b6c1499ea7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 28 Jul 2024 11:25:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一大堆Llama3.1-Chinese正在袭来]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5kuOUbz3AyNbp5qse4qsk9dFcK5tXRLkfWkRY8WjxSQiadlDzf5yfTxBiauzF6EiaXsDklvAItibicKFJw/300?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面Llama3.1模型已经开源，在这短短几天之内，也是出现了一些Llama3.1汉化的repo，开源社区也是相当的卷。主要是Llama3.1没有关注中文，虽然是多语言，但主要针对英语、法语、德语</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443846&amp;idx=4&amp;sn=c566979ad666e3a1f77bac9429faa205&amp;chksm=bf85f894796094c6247456e29f209c1c03e7737698529133f0f16ace864ff3dbbe7c5061af20&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 28 Jul 2024 11:25:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【推理加速】vLLM加速部署LLM重要参数]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGDTOu5v1pvJZ5c9MiaEdgSRDmib6LX2ibTdIWb2MI8Pwv4icibQLtNlqQclWPX0mHnuJXm9jkvjT3MthKA/300?wxtype=jpeg&amp;wxfrom=0"/><p>部署简单示例from vllm import LLM, SamplingParamsprompts = [    "Hello, my name is",    "The president of t</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443846&amp;idx=5&amp;sn=7c2a1989009b90e172bb8200ac64235b&amp;chksm=bfe1a6f8a76b7a206aff597db74b67a5919546925859f7ccc99fa3d396dbca9221050fd0f7a0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 28 Jul 2024 11:25:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[SEA：基于大模型的自动评审框架！模型、代码已开源]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL3KRiaSJBKA8UyseXtcercnIlmg4diaAleHfBCdoRqvmfYbdiaXiakmZNMMwEJxBibglRa1yPibdLiaZ2Eg/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文题目：Automated Peer Reviewing in Paper SEA: Standardization, Evaluation, and Analysis主页地址: https://e</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443819&amp;idx=1&amp;sn=0cd93117db8abbb0570b0782e03edb07&amp;chksm=bf14e08a522b675374bb63c1f17ad8ba07b95d23d5c9fcb2121ac82375f1562b56e9a2b0602a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 26 Jul 2024 13:50:02 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Llama3.1--预训练要点一览]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW4651pAKjjjjQMO03WGLhRbDxCqNNUtgM6wemaB4PVzNjchiaia3BdCiaO0tfoicpyqOfnhIAwjNd9fgfLQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近Llama-3.1-405B模型放出，从官方的评测结果看，已经超越了GPT-4-0125，基本达到顶尖闭源模型Claude-3.5-Sonnet和GPT-4-OMNI的水平；而更小规模的8B和70</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443819&amp;idx=2&amp;sn=14483b5c491e528ee2c5cee83891f289&amp;chksm=bf440300c6fae57c92429bd1baee89bcc7fc6a27f44f0b8fd78a43d29dbf460cd501089a898c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 26 Jul 2024 13:50:02 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[全职 深度求索DeepSeek 多模态预训练数据岗位招募]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLRc2sXVaGow0ys5HhzzzJ5Dqx7K9qPk9xrvlU1oibdyZ5A4SPQconVypR5YrDKjrak1WBJbXnwzKQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>全职 深度求索DeepSeek 多模态预训练数据岗位招募公司简介：https://www.deepseek.com/我们相信大模型是科研 + 工程 + 组织的优雅艺术。我们正在寻找并长期培养优秀的 A</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443819&amp;idx=3&amp;sn=a6cb4ee8d0d05e0561a089d73395903a&amp;chksm=bf4f8fb869231590ab3573fce5328b8fe1a679586689fc42325ef3bb22a8b505353d6a95b58b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 26 Jul 2024 13:50:02 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[为视觉语言多模态模型进行偏好优化]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2qUlEbUiaMUNyUf5iaicCfdHtJN7tR39icIhrLZJhxibmBynShZfQPszxZiaEjD4picRCasRib4PaTRiat4U2Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>训练模型使得它能够理解并预测人类偏好是一项比较复杂的任务。诸如 SFT (Supervised finetuning) 的传统的方法一般都需要耗费较大成本，因为这些算法需要对数据打上特定的标签。而偏好</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443819&amp;idx=4&amp;sn=bb87c87e799ad014a1ecc3450c8cc3fe&amp;chksm=bf5fcbffbca36f788c0e2033331f8a7556b3728a03aa77865f714c1591766879a81904cf3fea&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 26 Jul 2024 13:50:02 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ACL 2024 | 基于自我规划的自动化问答智能体学习]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/AicicrECaqhcOEW31LFpB2j61bKM9uIcxpprqhBwbGlvJenHkCrJeQo8BT06iaBG48zH3a0rSjF7p3sAgSamXN45w/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文题目：AutoAct: Automatic Agent Learning from Scratch for QA via Self-Planning本文作者：乔硕斐（浙江大学）、张宁豫（浙江大学）</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443819&amp;idx=5&amp;sn=9276a79ff04a30fb9000df19f7319272&amp;chksm=bf161f2f3a623f3006e59b7956aca7648a1b08a982ea50a2caa0453edab9fb34951236a84362&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 26 Jul 2024 13:50:02 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[浅谈Llama3.1，从结构、训练过程、影响到数据合成]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLcviay4L1dQiackaYRSH99s87hgbZFP6ic6zBZX1sD0ajb6JtQ9MfUWzblkB8Jsh4xPYfNbOdmbocsg/640?wxtype=jpeg&amp;wxfrom=0"/><p>Llama3.1系列模型的开源，真让大模型格局大震，指标上堪比最好的闭源模型比如GPT 4o和Claude3.5，让开源追赶闭源成为现实。这里给大家分享一篇俊林兄（@知乎张俊林）的一篇解读，主要对LL</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443806&amp;idx=1&amp;sn=1de5a42c127afba64f4838d3c578a66f&amp;chksm=bfa9db4e3b469b79bafa473318760bbed2bd655172ad48997d8ed56e5ce5f61fba43dfee5f1b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 25 Jul 2024 13:11:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLama 405B 技术报告解读]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuwreK2M2vvibMaCYv5mD1Wc49SCIteA4mzHqRBwzaV5wD7SlulnzQsLmQJiblBiaMVJiagWFo6hKScu9Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>果然传的消息都是真的，meta在24号凌晨发布了llama 3的405B版本，这次还是做一个技术报告解读。值得一提的是，在技术报告的开头，meta特意强调了一个 Managing complexity</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443806&amp;idx=2&amp;sn=2b7d1f7dc00fabfbf71dc57e125bb9cb&amp;chksm=bfdd47bac70d7406349905126ade9bd84bf66eb4c7322d8ac01d69e17fef6b85acd469b6f9fe&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 25 Jul 2024 13:11:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[上海人工智能实验室招聘大模型群体智能方向实习生]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLcviay4L1dQiackaYRSH99s8Cg5xTXiaA7l3rKqibLCJgQGiaGhKwZp7XdF9XSktUCcFNEvAZBGxWkibwA/300?wxtype=jpeg&amp;wxfrom=0"/><p>实习生招聘｜上海人工智能实验室招聘大模型群体智能方向实习生          l实习单位：上海人工智能实验室           l地点：上海徐汇           l岗位名称：大模型群体智能方向实</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443806&amp;idx=3&amp;sn=472154d83662ec5e441f15dea8bd583d&amp;chksm=bf82627d30996ab7153a237ec5392a0cfa5e26e7360635f448905b33ac9521ff00971edc2e3a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 25 Jul 2024 13:11:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[预训练数据处理--长度分解]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW467jyo7cNC1p5aQjb0l5pPWQSTUTIlkkjS0ZiakEp21Bu8xEwNNDv7acZnDgTJor9iagVibLic7ne6WGFQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>LLM预训练最重要的工作就是数据的准备，可以说90%的时间都在处理数据。苹果提出Dataset Decomposition，对数据按长度进行分桶，提升预训练的效率。1.预训练数据准备1.1.conca</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443806&amp;idx=4&amp;sn=b678bf4350ef262293d00ec72f29ed85&amp;chksm=bf440530b6495681902e5dcb0196c1a813b33f2a9da3a28bd7353f6f530c713ae8114c0e01db&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 25 Jul 2024 13:11:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[美团外卖AIGC视觉创意的探索与实践]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/hEx03cFgUsXicSLlh7QOFEpy6xWh7Wv84ibiaZAibhK9TM2ibKAbicdYRCQMwK728LBmyotrRXajoZweNcDn74C4kmVg/300?wxtype=jpeg&amp;wxfrom=0"/><p>不同于其他电商场景，外卖业务下大量中小商家营销能力弱，菜品图像质量差，因此在C端对菜品图利用AIGC技术进行美化存在较大的潜力。自2023年以来，美团针对智能头图展示的菜品供给利用AIGC技术进行全面</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443806&amp;idx=5&amp;sn=9c9828f907af8aa6549559992e0e4d3a&amp;chksm=bf9daa6124dddd2a541e2d0e0fca47f19416c29b303bb4bd7a7b298312e132e416d7bb3ed956&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 25 Jul 2024 13:11:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[GPT-4o炸裂登场！大模型仍是最大赢家！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIvgYwzYO97qmBRfkkPv1wz9br4RPQw75FR6Pn6j9SgkMIcJaccr5q3kVBVLNnH9RGkSxCUARWE7w/640?wxtype=jpeg&amp;wxfrom=0"/><p>从一年前ChatGPT突然爆火，到不久前文生视频大模型Sora以霸屏之势吸引全球舆论，再到OpenAI发布的王炸GPT-4o，与AI大模型相关的议题越来越多地被大众所讨论，如果说2023年的大模型风暴</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443749&amp;idx=1&amp;sn=42f6ee45b028da74a7f6c0d94224dc15&amp;chksm=bf0592850fe51ba8faa1e067df36fd29b2702d21feb03da712215e44c0738fbee307bae19d6e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 23 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024年大模型LLM还有哪些可研究细分领域？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/s7YKINJYHDDbRBlyS0HB5ib1wvuEj19dd4Og24zsWBlC94Vvf73iam0w8hibKTBAAqgj5sEbC5tzZdXW8kuCeYVdA/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：swtheking来源：知乎Pretraining部分Data Collection整个pretrain阶段最重要的部分就是数据收集，尽管OpenAI已经给我们了一套标准化的数据收集流程并也有很</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443749&amp;idx=2&amp;sn=43d05bbf11ec3d43f83fdd704baeb34b&amp;chksm=bff423f01a86941b9bf29864645e752397a6c69da4e8469ee864708840f057290f0a9dc74e6a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 23 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[从dense到MoE -- sparse upcycling]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW464KJqafZSxMgcFxyCd4r3vs1gmEdfVEr2WZu1OIeYYSeIJgDATYXUDicwjOib61m98Mnme0OvVfGChQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>目前已经有很多优秀的dense大模型，那么要通过MoE获得更强的模型，用已有的dense模型进行初始化是一个自然的想法。Google的sparse upcycling对此做了一些实验，由于实验是在20</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443749&amp;idx=3&amp;sn=c3fb9129c8d56fad741b209b21078e01&amp;chksm=bfabc9dfae3d89e4e5e40a2435a88476b69ea31aab0c39bb482e9e80853e5da82384a7cb4ed2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 23 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM基础知识】LLMs-Attention知识总结笔记v4.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdBbOW12YJpSibiaSgCWJB70SsNl1lwC3L5zBZpy5zkib8Ba5qpjr1Osw5MbCmJ354aicMibhQLGD6Pia8Ww/300?wxtype=jpeg&amp;wxfrom=0"/><p>‍【导读】：本文是LLM知识点第四篇，介绍LLM中的最重要的Attention机制，具体有Attention机制，Self-Attention，Multi-head Attention的原理和实现细节</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443749&amp;idx=4&amp;sn=fc3695180d8a3ff584cd7180d430851a&amp;chksm=bfd514001223d3fb68b7def815549f77a790544d1e787b38e651ad95de7241d100a40282f49e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 23 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ACL 2024 | 关于多语言上下文学习中示例影响的多维分析]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ibj1ATvtMalpSwjy3eOS2RDA2CIm0B42MeA6KPIPzPrNx3tUB2DYDjmQHp3Zd00RxZk9jOb4tAS1DaiaNL68CjNw/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文分享萨尔大学和慕尼黑大学团队合作的一篇ACL 2024 Findings 长文: The Impact of Demonstrations on Multilingual In-Context L</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443749&amp;idx=5&amp;sn=95cbc4557ceb1e831a39a3d146ef42cd&amp;chksm=bf77c04f25555605de05e3eef6985bdf67ee2c509ae61dc9fe3c24d0750f4997cfa8030cd362&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 23 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
