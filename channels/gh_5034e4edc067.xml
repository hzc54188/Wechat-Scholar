<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    


























    <item>
      <title><![CDATA[万字长文总结大模型微调技能图谱]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSK1J9buNHUBYtPvyMLfGkYwKusMn9IRvBaj6SZaZEj9MpDRA2icfrQ0NHuAxiaxFPNoKp8uyCZR0hGg/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着大模型的飞速发展，在短短一年间就有了大幅度的技术迭代更新，从LoRA、QLoRA、AdaLoRa、ZeroQuant、Flash Attention、KTO、PPO、DPO、蒸馏技术到模型增量学习</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442344&amp;idx=1&amp;sn=27b70415f9470597115b91863988c69b&amp;chksm=bf84cbb329edc87694dc5c11cf0c0956a330bf792bcfe1de9513e6d633f8948eb646d637c9ff&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 09 May 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[DeepSeek-V2技术解读]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/d6902wUyyvIICKyjEKgYtMsEOoP6MZamOdh0KU0pibo1Ic4cOGSH2GYqonkcI4LTDo7EMl8Lp7HFTicVJxPCABfQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>DeepSeek又带来了新的MoE模型DeepSeek-V2，总参数量2360亿，激活参数210亿，虽然离GPT4水平还差一点，但也可以说是目前开源的最强MoE模型了。并且秉承着一贯的开源精神，同时发</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442344&amp;idx=2&amp;sn=b023f892fa001a265398d1880f62d4f7&amp;chksm=bf5bc1b319550f596f858722eacb1bd5317ba99d555f7ee7306fd4c0143cfb1871f79f3eaa6b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 09 May 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[ORPO：当有监督微调遇上偏好对齐]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/vtIvcrPJjh41PuiczrGnZffujR0l3ITohx0WFvibQFqGiaSxs8YHn5FGK7zk3HKrujicL8XzYudOsDa5ok5azTdwjg/300?wxtype=jpeg&amp;wxfrom=0"/><p>大语言模型通常会有预训练、有监督微调（supervised fine-tuning, SFT）、偏好对齐（preference alignment）三个训练阶段。虽然说在很多应用场景下有监督微调就已经</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442344&amp;idx=3&amp;sn=df363e9dadeae5054d986c24566846e3&amp;chksm=bf7b2242e64e86ad52f4fda7f0c1404f137e100eb9e723a89ac0d7aabe6d8d7f7f48df6be078&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 09 May 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[全面的大模型训练、推理工具包LLMBox来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/G7ia3FZ0o0Oq2ibcQGRB20ZVaNJqOiavj1ks8zeH1xpefx8eoD3oQCS9OGbtnMcia7FlHvrNzCAhtv4xWO08kdRxvg/300?wxtype=jpeg&amp;wxfrom=0"/><p>    在2023年3月，我们发表了大语言模型综述文章《A Survey of Large Language Models》，目前已经更新到第13个版本，自上线以来受到了不少读者的关注。在几周之前，我</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442344&amp;idx=4&amp;sn=c36f1aa98d8bddbb2b40bfe0690bef38&amp;chksm=bfeba8d80ed35033cc49ebf638d2a6dcac6b2c85e9c26ad624eb266d66b4e4e2649f2117fcd0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 09 May 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[图推荐系统综述：A Survey of Graph Neural Networks for Recommender System]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/DHibuUfpZvQc3Ku0sw17D1NWNHia89a72upTOh7zFnEYSBUU4NAp4ZBlpBcbiak5umXeOzt0PQAfA7oHY7YN6JupA/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者 | twilly（已授权） https://zhuanlan.zhihu.com/p/686458569第一次整理综述，作为深入这个方向的开始。应该不如AI整理的详细全面，不过这一篇文章主要是阅</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442344&amp;idx=5&amp;sn=d49201c2295cbe581c322f27a70fc98e&amp;chksm=bfff26b2e1c0fecf7f4e9286bd1ba064b17216a96a4b8324073186c733916c831edf708eaf1f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 09 May 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[LLMBind：LLM+MoE实现多模态大一统！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSK1J9buNHUBYtPvyMLfGkYwUZSicdSfDN1HksYs5z4xibibKB4atDOf16ia1u8gJrYgbr4pBCLIOAeevw/640?wxtype=jpeg&amp;wxfrom=0"/><p>多模态大语言模型（MLLM）成为研究热点，北大投稿顶会ACM MM 2024的一篇论文，创新提出了LLMBind框架，结合大型语言模型（LLM）和专家混合（MoE）技术，通过处理多模态输入，并生成特定</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442323&amp;idx=1&amp;sn=c76e0a7e60ec3d5472f9179fb239a7d7&amp;chksm=bf021e58e4ff317cccac6f7286952126dbcb4aba9125ecf760ffb1518d734805740a248f35c7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 08 May 2024 04:29:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Unsloth x Qwen2 微调实战，提速47.32%，节省39.13%显存，最少仅需8.43GB显存]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/JrHT8u594NGjyJL2C2DJz1zTTV5o8IKjic3KLm9x7ffmG6m2Hx6W5K73ibiaTAqSxLIeVR5coycQ307N5HbfZDTjw/300?wxtype=jpeg&amp;wxfrom=0"/><p>01现状在上一篇文章「Unsloth微调Llama3-8B，提速44.35%，节省42.58%显存，最少仅需7.75GB显存」中，我们介绍了Unsloth，这是一个大模型训练加速和显存高效的训练框架，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442323&amp;idx=2&amp;sn=85f69871cb1bacc344ff3cd3c5ac6b0d&amp;chksm=bf72d97f7da41ac1275e950c86abe23f45959ffcff83077efc091862a738740b64bb4e55a378&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 08 May 2024 04:29:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[解锁大模型长上下文能力]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW464mWPic6FiacIFn4rg1vj6fQuwVicoap3QCmgLUgxiaCY7qtpuF8MEc1jvv4ECiahx4TM1TtibEoy8Z4ibow/300?wxtype=jpeg&amp;wxfrom=0"/><p>步入2024年Q2，大模型在RAG、文档对话、大模型Agent能力等方向的发展持续升温。在平时的日常生活和工作中，大模型工具提供的文档总结、文本润色、代码生成等能力已经是提高效率的必备帮手，甚至在一些</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442323&amp;idx=3&amp;sn=87d266c11ec3480a277c0235a2a8e9f8&amp;chksm=bfc528137622d29f9c06b4e8587e4966645ffcc72d3351f662732cf7d85f2842b540dd236d2f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 08 May 2024 04:29:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[4.5万字详细解读复旦NLP和米哈游最新Agent Survey]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/goiboxqfW2fY4fzRiaCwu9o1lZ3vxVL9oCJJCsl20ztAkBZiaZz51ickooebXbFSTk6Uea4fDRJSVgm6OGn5tFZcpQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：兽族机枪兵（复旦数据科学博士 ）原文地址：https://zhuanlan.zhihu.com/p/656676717笔者前言：这次的文章写了三天三夜，好哥哥好姐姐要不给个赞再走呗正好最近LLM</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442323&amp;idx=4&amp;sn=3a60f0018dac38f42b8c6f867a696345&amp;chksm=bf2700c399fbfd10a3a236e2ab0bfc0ef0fe0edb05b76a1ecf60d7badf98d0217732fbae9139&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 08 May 2024 04:29:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Llama3-chinese: 大幅改进Llama3 中文能力]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgwtLKsPKyH6XBysTicgwUCnnpicUnAP39wBsq9ntfW0m2VOXuTVMweibYwpFqWr76f6a7mWb8N9A3e1w/300?wxtype=jpeg&amp;wxfrom=0"/><p>介绍Llama3-Chinese是以Meta-Llama-3-8B为底座，使用 DORA[1] + LORA+[2] 的训练方法，在50w高质量中文多轮SFT数据 + 10w英文多轮SFT数据 + 2</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442323&amp;idx=5&amp;sn=f4af22a3e5e79a1be7a899fa7663fa89&amp;chksm=bf313ead6eddb8b2fe887cbd4a23b28d0cad9ece0746972057077c4565463f287f237cf155aa&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 08 May 2024 04:29:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[yyds! AAAI 2024等顶会论文合集出炉]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKic88K0b8qkqjgCexTIZMYhnskviaC83C5GYodtcG9LaJXtQ42Ube6YhuXricBKXAxRibGKa856YEiawg/640?wxtype=jpeg&amp;wxfrom=0"/><p>众所周知，论文是人工智能学习的基石，因为论文展示了不同方向最新的研究成果，了解并且掌握这些学习成果，会对自己写论文助力不少。这次我整理了AAAI 2024 / CVPR 2024 / ICLR 202</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442307&amp;idx=1&amp;sn=7d08172a9737b7a83495920068808759&amp;chksm=bf98e78751f2b8612bd4401d92d427ff3884281d68fc54970c72506b0438191fe897dc01ec71&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 May 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Unsloth微调Llama3-8B，提速44.35%，节省42.58%显存，最少仅需7.75GB显存]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/JrHT8u594NHHkBO6rozlzFdf9t37KHmq6qVd2X8rsZprDshcicDTwIzSiaCdgXXF4JPo4RZdLv0chYxx87ZpJWWA/300?wxtype=jpeg&amp;wxfrom=0"/><p>01前言本文主要介绍Unsloth，它可以显著提升大模型的训练速度，减少显存占用，我们将其整合到Firefly训练框架中，实现对Llama3、Llama2、Mistral、Gemma、Zephyr等模</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442307&amp;idx=2&amp;sn=8963f023b150db638ba5e4f03eb95dcb&amp;chksm=bfbb9ad12e27f75f8d8876f83f193a58f5c68c437bbb6d58c151daeb0c3735fbdb762996daa2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 May 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[SIGIR 2024 | 共现关系还是细粒度偏好？ID和模态信息解耦的会话推荐]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmxsbKeefEPuUVnQE0BkKarwblcgb9eu3MoVIlHGicYKFHuuSp3Qrgwy6gNoyyxvicO8PzoJT7aSicUg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者 | 张晓堃单位 | 大连理工大学·信息检索研究室研究方向 | 推荐系统论文题目：Disentangling ID and Modality Effects for Session-based R</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442307&amp;idx=3&amp;sn=6496d2406b12cef3854117953cdf8b90&amp;chksm=bf32708b91a6085bdd1818c4e5aa739f00afe44b1a88105fd49e38f37ef42fb187e551aa9d5e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 May 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[幻方发布全球最强MOE大模型！ DeepSeek-V2]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuw5791WahjJHRibX1R0sjat2Hv99icibOxmhxJBc0HPIzAyoPfdyYicEkiauhBQqpqjYZDENtYrd0icHDibA/300?wxtype=jpeg&amp;wxfrom=0"/><p>仓库和技术报告地址：https://github.com/deepseek-ai/DeepSeek-V21. 介绍今天，我们介绍了DeepSeek-V2，这是一个强大的专家混合（MoE）语言模型，其特</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442307&amp;idx=4&amp;sn=7c8e3822a114bc0d5ef655c3f52919c3&amp;chksm=bfd552f435b07fac3dc426f0802ae251af49f61cd959c0cfff57d038ef904e98826bfa293790&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 May 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大语言模型与推荐系统：SIGIR 2024 相关论文导览]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/G7ia3FZ0o0Oq79FEAiaalyNN6CvYs1QRGVsNEjibI4z8nPnzPicPTnuicpMLm1wQThL1hDLTZiaKPf1nsuJh89yic7DHQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>© 作者｜李炳黔机构｜中国人民大学研究方向｜大语言模型、推荐系统本文聚焦 SIGIR 2024 大语言模型结合推荐系统的相关论文，总结了当前 LLMs 在推荐任务中的使用方式。文章也同步发布在 AI </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442307&amp;idx=5&amp;sn=7d1473700819bfe1f88b07a75a366d37&amp;chksm=bff1f3c6da13dc249b1c1bdcb387dfd7e5500cd3708485d4e32e84d26ae3fb0d799dd384a6ca&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 May 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型中文微调最佳神器！"弱智吧"is all you need]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIQo0YJPl6vaCMpCR3fqJV8PINgbME3cIkNkHfz944O77YAFSSKY5QsKdgx1biczSkq6oPgIz6zVtQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（LLM）在近些年取得了重大进展，特别是在英语方面，然而，LLM 在中文指令调优方面仍然存在明显差距。不久前，一篇人工智能论文将弱智吧推上AI圈的风口浪尖，该贴吧竟然成为了最好的中文训练数</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442286&amp;idx=1&amp;sn=3ea8b35ee3958becded32d290c0fd72c&amp;chksm=bfe05f2a2753eb5949e1b2fde9e4d2684356306a845a18109314e8f21fbf524902d2ab633aed&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 May 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[我看阿里的年终奖总算发了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/icmWrEONNM8VpHVukWOfYpfakTytxWC1CEYeNwDU0K2RtrzcevAUNy8zIWEyfthCRs3h7OWOsHP0kKGCkTmyKew/300?wxtype=jpeg&amp;wxfrom=0"/><p>到4月底了，这两天看朋友圈，发现阿里的年终奖终于发了，问了问老同学，也从网上检索了不少信息，基本搞清楚了阿里今年的年终奖情况。近来来阿里一些集团对绩效等级做了较大的调整，以前的旧绩效系统中，绩效分为3</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442286&amp;idx=2&amp;sn=e010ee3c2f4f1ca54c7ad791752f7067&amp;chksm=bf7b18da0774e3bab32c182d3314de08f5beca5f36ed2f0a02fb35527684f451593bbcc79ca4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 May 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型算法题(5)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW466iaG2gu3bW8lKStyteOJmclgL83orBBRPDGnwH47bKDPRNnC7NTsuKgwuctK3nnYRnqXCKX8XPSicQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>本系列将持续整理一些LLM中关键的、细节的、值得关注的内容，持续更新~如有错漏，欢迎指正~1.使用半精度训练时，bf16和fp16格式有什么异同？二者都是占用16bit空间。fp16由1个符号位、5个</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442286&amp;idx=3&amp;sn=8154bb03d1825ef5c37babd7a866600e&amp;chksm=bf615d0e3c7fc3e4d3ee3f58f04d2bfcb63e4cbb6bb6d3a7ce5f2a0cc003ae04c526e618761f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 May 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[值得一看的大模型+生成式图分析若干任务及提示总结：兼看大模型用于文本分类体系挖掘]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/fUBU1yiaEmJia1u0l0SAvibY9ksSvXicwBHznZicbntvNPyQGpNzNMNMFtLIRiaqlg3hbVmkSOibYT8ic4BhKaN6q7zXsQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>我们来继续看看两个问题，一个是关于大模型与图分析结合有哪些任务，对应方案有哪些？另一个是如何使用大模型做文本标签生成。供大家一起参考并思考。问题1：关于大模型与图分析结合有哪些任务，对应方案有哪些？图</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442286&amp;idx=4&amp;sn=faa3d1242d5935bbc27bc9e0322b3bd6&amp;chksm=bf811fe697fdc99fb039fd442c31197d5f05ed4060ac2dfdc398f66963ebb671905c50bac3a0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 May 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[RAG已死? RAG vs Long-Context LLM]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/goiboxqfW2fY24vLibzkZaZpcPdZzWqISs3E1gx6MtDr7rFDNWhicEQNTho012BALMibXBOr1x0GRqYhMuQmd0MPlw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：lucas大叔文章链接：https://zhuanlan.zhihu.com/p/693574568导读最近，谷歌发布了最新的LLM-Gemini 1.5版本，支持处理长达10M个token的上</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442286&amp;idx=5&amp;sn=2328534391f4c5597feba98a69bae9d4&amp;chksm=bfb5a8fa0d1492987a9b4b8fb792b165bd18813ca9fddaf1f627513614b64c89a6bcc3873690&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 May 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型人才今年的薪资。。。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLqpOnzXNAlaYEBXg8P0VFaMrtkg3wfqUl7knibQMKibk1x6Y5FTcmFia02J0Zrjiaqkvr9P1QqYPWHhA/640?wxtype=jpeg&amp;wxfrom=0"/><p>「AI大模型人才培养计划」适用所有程序员2024年，AI在国内市场全面大爆发，不断涌现出新的算法、模型和应用场景，各行各业的垂类大模型应用也迎来井喷期。无论是Google、百度、阿里等互联网巨头，还是</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442271&amp;idx=1&amp;sn=a070d4252e6fe14ba73cdd93e1ebe125&amp;chksm=bfe4bf1ffc5b94c2613bb92a377739c446a61483269cce0a7f19e506481bf13626251dbabd1d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 05 May 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型时代的核心推荐技术，这本书全讲到了！文末赠书]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLhlTd4gGzgkuBN0Laf3Er2l9wVURicVKs4QCfjG7BDQOb4ttwIUNE5qsbKaxic3GfxAQdnxcJrU7xw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在当今数字化时代，推荐系统已经成为许多互联网平台的核心功能之一。无论是在线购物、音乐和视频流媒体、社交媒体，还是新闻和内容聚合，推荐系统都扮演着至关重要的角色。它们通过分析用户的历史行为和偏好，以及其</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442271&amp;idx=2&amp;sn=43ee2a8f77ef7639b7a871c5f0b3d8d6&amp;chksm=bf48d8aa558935d25a79a509426076235c2688f660a07c5faf1f5996ac262430410bb39fdcc2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 05 May 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[生存还是毁灭？大模型时代的传统对话机器人将何去何从]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ZB4VKHPZpytbSVbf4ayGY9Kx1d6iatrm4o9KQfe2lFthGwrVbm723Pm2lI5eOzMxFOOL8TIyve4pIx3IK0Bkx9w/300?wxtype=jpeg&amp;wxfrom=0"/><p> “ 在ChatGPT大火之前，对话机器人（ChatBot）是为数不多的能够为NLP领域提供商业化的产品之一。而在ChatGPT为代表的基于大语言模型的对话产品方兴未艾的今天，传统ChatBot将何去</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442271&amp;idx=3&amp;sn=f2fcad60e699e57edc915a2833971bd1&amp;chksm=bf8fc9dea09ffa2c74bc64aef97422b29d39fbfdc9a1974ee39893b709527d17c309863915b5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 05 May 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[梳理RWKV 4，5(Eagle)，6(Finch)架构的区别以及个人理解和建议]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/SdQCib1UzF3u2hl1bMwtDKFebuYby6icqEoPIdXDgP7vx2uic5C7aF42FnOhGAsXzesMPFaYYFDAk8ZibvFSzNfRww/300?wxtype=jpeg&amp;wxfrom=0"/><p>0x0. 前言RWKV系列模型的迭代速度比较快，主要是下面两篇paper：RWKV: Reinventing RNNs for the Transformer Era：https://arxiv.or</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442271&amp;idx=4&amp;sn=8f0a02873bc5b36fbce4c720e754f87b&amp;chksm=bf6f844a0e74cc65142828f5827cdd67b4e2f6cc4f331479c7e7ff9673d395b6be4ddcd28705&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 05 May 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[RAG开源项目Qanything源码阅读1-概述+服务]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jT5Sp7MICPxUykpP930GvErHBGBWKDxaIjRPYhvSpmWHkjuZfg87bQibNrHVfasNqdZErnk4tibFZDjibQKe6xCZg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近是想找一个开源的RAG项目进行进一步学习，选了这个项目：https://github.com/netease-youdao/QAnything，后续一连几篇，会分几篇，从我的角度，给大家介绍这个项</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442271&amp;idx=5&amp;sn=06675a7481c755b0af34ebaa31bfb772&amp;chksm=bf41ebeb779da063177e572a94585e28697c6e8cf2a8e98ff9dd9043a5bf0c8a79d334e483cd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 05 May 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[70后新晋中国科学院院士，任985校长！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIYtaeR8gYRpW6cGjcjGTyf45UVHkbA6QBSjbDicgpN0z8P1vHGzCHiarwYlOhOB6RU00y3HRtxueDw/640?wxtype=jpeg&amp;wxfrom=0"/><p>来源：北京理工大学、青塔日前，中央批准：姜澜同志任北京理工大学校长（副部长级）、党委副书记。查看官网发现，北京理工大学已更新现任领导班子：姜澜任校长、党委副书记。姜澜姜澜，男，汉族，1972年7月出生</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442251&amp;idx=1&amp;sn=299c92fc411665407cf6e0a8890ab026&amp;chksm=bf90d638cd76551d04d94abd140efff8c50b805d424e8c9b0d1cae639e27a4e491f3ae76d114&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 02 May 2024 04:35:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[如何在本地部署运行Llama3]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HIKk7OFDjoTn5Utelj41c2fvlmwltBOhhMfDU7Q2iczSgOZWoIodhegLW0nzJfr0ucD3djo23TEeJQa4fiboYXuA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Llama3 目前发布了8B和70B两种尺寸huggingface Llama3模型主页：https://huggingface.co/meta-llama/         Github主页：htt</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442251&amp;idx=2&amp;sn=6e7f89772865af21c5bbf23bfc39e1aa&amp;chksm=bfa81e5ffd564c61604c0f9d2a2b4661d9ea5b9eb90460d5c9963d6d641e1e4d92f0776f9e84&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 02 May 2024 04:35:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[从第一性原理看大模型Agent技术]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/goiboxqfW2fbpGOKohmTQWLmf9kxGbcGwvEwLGIvU4zmyq255TQl3JPfMmb68SZ5MnwCmcq7pvia0iav9ibSqf5Wtg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：凡心原文地址：https://zhuanlan.zhihu.com/p/662538702在大模型技术引领的革新时代浪潮中，面对纷繁复杂的相关资讯，您是否感到对这一前沿技术的核心理念尚不明晰？是</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442251&amp;idx=3&amp;sn=a8ad2eb8077cbea005bf108c74aa83e6&amp;chksm=bfee4467ee3f9ac700c6e07a205cc9433c590539eccd9d29ae336734415b7174e21ec3312385&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 02 May 2024 04:35:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Lite-LLM4Rec:大幅降低用LLM做推荐任务的耗时]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hg6UPGp0Hib6Vck4E0QMicvgsaDIckL3oDRvaibysXUKMIObLxOu5rLztNTWodxV8iaL4IAFQsMDaYUMBRmVaTfIqw/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名称: Rethinking Large Language Model Architectures
for Sequential Recommendations链接: https://arxiv.</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442251&amp;idx=4&amp;sn=53d44da2ed02848d5182bbc5bad886bb&amp;chksm=bf3ea1db1b2c3af5e318d79840ee317d1b1af3c7eabe2a77769cc10ed7f0fde1f99d0ba74584&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 02 May 2024 04:35:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM4CS：一种利用LLM提升多轮会话检索的效果的方案]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gTSf9kr5zrOEgMJ1ngZzqgOF3EsyXRedrJPjAHHeFibOCENkWXvtDBQxkZcYG7k7jNhib2ASJVUtzoeAaAfLpiaBg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天分享一篇人大的文章，大型语言模型知道您的会话上下文搜索意图（Large Language Models Know Your Contextual Search Intent: A Promptin</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442251&amp;idx=5&amp;sn=4f6d88d456ef7e952dba6beca79acddc&amp;chksm=bf6386e4d2bafca5d765ab8d4838bf23902b201ed51f222d1c453928f6913bb277977ddbf874&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 02 May 2024 04:35:20 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
