<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    































    <item>
      <title><![CDATA[GPT-o1深度揭秘 &amp; 最热门20个大模型数据集公开]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKzPhuVnIGXEon53TWIzS1ujULAB7DZhIClSg2zib8VhRpPwDb6dkASJQ2I1YVO5bKfgZky4IUibP1w/640?wxtype=jpeg&amp;wxfrom=0"/><p>上月，OpenAI 突然发布了 OpenAI o1 系列模型。按照官方技术说法，o1 在推理能力上代表了人工智能最强的水平。GPT-o1模型一大特性是突破了LLM极限，新模型能力在生物、物理比肩甚至超</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445383&amp;idx=1&amp;sn=ba6800883a40e7b2348ab3236f263539&amp;chksm=bf882a2e82ddb282bc5f007f38de816423fcfefd91dd820c1b8069775721617ecb5148306382&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 14 Oct 2024 00:50:02 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[微调大模型前，重写SFT数据？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKzPhuVnIGXEon53TWIzS1uzDv5ljZrKKNzUticpl5z8FtVqPiaU2RsEJsQxOcGL0HuW8OW8UZuiaIeQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：张义策文章地址：https://zhuanlan.zhihu.com/p/710594520Self-Distillation Bridges Distribution Gap in Langu</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445383&amp;idx=2&amp;sn=c84f3369efbc33b50dae930b1abe4db5&amp;chksm=bf3e8be0ace4d381a77216e30d46796fa061e861ef04b27a80c4d0f6dfc322837ca069ea162b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 14 Oct 2024 00:50:02 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Journey Training：o1的一次复现尝试，极长思维链的合成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajdC8WABSdnepk2A5cBM5BDFPFhDnOO03co5D8RvBJzCiao6qorKYUH2bYE4EQiaK0dxeq1zZ9IHqJw/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：啦啦啦啦（已授权）链接：https://zhuanlan.zhihu.com/p/902522340论文：O1 Replication Journey: A Strategic Progress</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445383&amp;idx=3&amp;sn=70ff02652d3f84e5417afa8ffb64aab4&amp;chksm=bf0fb62491cd6b86e220518fce854e7b40032a126427fa351f7c5a25134c08340314160bdf37&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 14 Oct 2024 00:50:02 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【LLM开源项目】LLMs-开发框架-Langchain-Tutorials-external knowledge-v4.0]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdBYEj1f5rwrMGJp0tEItiaSqug9PWn9RRSXKjVxTVOmOwjYpvAF9w3lusIia57PWtxePkNwcab3ad1g/300?wxtype=jpeg&amp;wxfrom=0"/><p>【1】构建基于SQL数据的问答系统Build a Question/Answering system over SQL datahttps://python.langchain.com/docs/tu</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445383&amp;idx=4&amp;sn=03ae0d111062f9d99abf91465c385107&amp;chksm=bf011c4e8994e0018790d72c86cfa1d193b411f67e451dd3df1eca93c4d40d04e64d7ba98d6c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 14 Oct 2024 00:50:02 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Bge-en-icl: 当in-context learning遇上了text embedding...]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKpsBj3RsWAbywuTEXdljjM4wJibyvfCKMDHEdNTVPJrNGDW1fg4kURu5HZfwtibBZejVK9cl1lic4k6Ng/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲1 简介2 方法    2.1 模型输入    2.2 Pooling策略    2.3 训练方式3 实验4 实验结论5 讨论参考文献1 简介    In-context learning作为大模</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445383&amp;idx=5&amp;sn=b4979093b0d9759309aac5981c0fcb44&amp;chksm=bf69cbc1211c69f6d480d1fe802b6afc6f62f51d04d7a2d2477f0c0568fe7143fca2a377afea&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 14 Oct 2024 00:50:02 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[现代LLM基本技术整理]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKzPhuVnIGXEon53TWIzS1uzxVQRd0aAEPaqKCs4MjO6KoDtRyubkaLiaQN85drBibfa3KQ2pDBErFw/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：hadiii，北京大学 电子信息硕士在读原文：https://zhuanlan.zhihu.com/p/713794852编辑：青稞AI0 开始之前本文从Llama 3报告出发，基本整理一些现代</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445374&amp;idx=1&amp;sn=daca2614e9baa46e8ed957b3a25bc80d&amp;chksm=bf80ef8d858fdc80c7f3e3768531358be82c2832b42a015c6182156b88d557d0bdb88cbbfbdc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 13 Oct 2024 10:55:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【文末赠书】如何构建出更好的大模型RAG系统？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKzPhuVnIGXEon53TWIzS1uN4YdeZibfF3Z4pfWGs5YgJuy2ERZ8lf7WhXRSqtGhRq9THjqgscgz9g/300?wxtype=jpeg&amp;wxfrom=0"/><p>ChatGPT爆火之后，以ChatPDF为首的产品组合掀起了知识库问答的热潮。在过去一整年中，大多数人都在完成RAG系统到高级RAG系统的迭代升级。但是技术发展是迅速的，如何深入了解RAG的发展，做出</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445374&amp;idx=2&amp;sn=2d0b6aa41a8a92e8fb929f73873595b9&amp;chksm=bfdebbfee8b33f3a886fbeae444a5bb8f3b6481321583ece833206e68791142d86e6749576f8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 13 Oct 2024 10:55:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[通义实验室招聘大模型算法专家]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKzPhuVnIGXEon53TWIzS1uB5WXQRgvxYLcoj5fq3SVd04LLuPqyt5BGPc4CjnG56vYhM38cGfoHA/300?wxtype=jpeg&amp;wxfrom=0"/><p>通义实验室-大模型算法专家团队介绍阿里巴巴通义实验室-对话智能团队 以大模型对话技术为核心，研究及应用方向包括智能客服、个性化对话、角色扮演、分身复刻、社交智能、数字人等，主要业务场景包括（1）通义晓</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445374&amp;idx=3&amp;sn=6d40dce53892ae336ee58a11a5cb6061&amp;chksm=bf32357c2fbab41cc9e61242cdfa8ebf7b392bf632436086968ca7d8a7b871c18cc7af7a7716&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 13 Oct 2024 10:55:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[全面深入解读Movie Gen技术原理(5部曲)：概述 (1)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/w3hibrVDUAib6oCdibFAwFnv0jASek0FryIwx13noW7mKsJvt5ypiaGG9H6vE3VTITKfCgFiczGBQ1iaX462OncMYcwg/300?wxtype=jpeg&amp;wxfrom=0"/><p>1. 引言2024年10月4日，Meta发布其视频生成产品Movie Gen，对标OpenAI的Sora、Runway等视频生成工具。这标志着Meta正式进入视频生成赛道，与Pika、Runway等进</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445374&amp;idx=4&amp;sn=7b17134fe47b7407c8785965fe212687&amp;chksm=bf28211f7edc8800dbb5ddfc9d6581548e678be64a6a41c3e32adff829d99976805378f7a310&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 13 Oct 2024 10:55:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[如何实现大模型Speech2Speech Dialogue？(二): LLaMa-Omni]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/vImdeGStOOcp3R0PgIMIzyr30qee7uLTrMUn4zpcp1pOILe5Vsnf0f8nFxjOoGaSBxy97zicHVXWwe3Oydm4Zqg/300?wxtype=jpeg&amp;wxfrom=0"/><p>上篇文章主要介绍了SpeechGPT和CosyVoice，本篇主要介绍下另一个端到端语音到语音方案LLaMa-Omni。NetRookie，公众号：NetRookie如何实现大模型Speech2Spe</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445374&amp;idx=5&amp;sn=5e8f3be71851076a311b3f55b108c7e1&amp;chksm=bff7055cc542fc5de4c4e6f97b216dc2c6b04a12488aae32adbe064c7286dc4447da430be702&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 13 Oct 2024 10:55:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM预训练与SFT数据配比调研]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJsJnOHTWe75WsIgwo2tv4VZYj6VfnWGwbR0ciamfgEEIjcGeAibfcccKIicwyk1d1Efo9Yia37FX2SlQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：天晴链接：https://zhuanlan.zhihu.com/p/703825827背景与目标最终目标是在 LLAMA3 模型的基础上进行继续训练与 SFT，但 LLAMA3 的数据与配比方案</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445341&amp;idx=1&amp;sn=280ea21b46e88585cb203f7be73bd6bd&amp;chksm=bf2e6bfc4f1bd081907e5a73591a950b1c4404845e5022a73d880164139c877f4270dc8ff75a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 12 Oct 2024 09:58:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OpenAI o1技术初探3：如何让模型拥有自我纠错的能力]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkOpqVjLraGbzg9n0LCX1PlGhB4mNkjqHLC9mpEgW9PSh5PRWTGerVXAkHO4ibE51v6c9yvGpHlrJCA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在这个系列之前的文章中：我们探索了o1（可能基于test-time scaling law）做的基本框架。以及框架中的一块积木（靠纯inference优化来增强逻辑推理能力，我们分别列举了“PRM+s</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445341&amp;idx=2&amp;sn=052314b8bc533b3cc7195837c407453c&amp;chksm=bff4591bf9fbdb6b29a7bff28685da4aa721596384325a293e93abd26462537b3f323d4fab4e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 12 Oct 2024 09:58:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[COLING 2025 Call for Papers: 多模态生成评估研讨会]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJsJnOHTWe75WsIgwo2tv4V1BH0Up6UpogBPhxVb8uYdr1zRlIvPKaicaAwxU1nWFTKgXY9R2Dkiafg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Call for Papers: 多模态生成评估研讨会 The First Workshop of Evaluation of Multi-Modal Generation @ COLING 2025</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445341&amp;idx=3&amp;sn=7a2641a1956981bc39e1e8cbc52fa554&amp;chksm=bf6808095642a0c8aac0502961f8abebe1ea4b9e8ee2ed9d737aa2ad42bee236b54b810bb807&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 12 Oct 2024 09:58:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CodePMP：提升LLM推理能力的可扩展偏好模型预训练]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5nbQgT8S1l4BLjrkFXxvP4ia1QDwiaa5yJdhphnkRLTF0JPOwicfGiaAZblynlrhX564ibDsTnpYU1GK0g/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：鱼汇沐  机构：中国科学院信息工程研究所 paper: https://arxiv.org/abs/2410.02229在LLM（大语言模型）的对齐训练中，尽管RLHF（基于人类反馈的强化学习）</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445341&amp;idx=4&amp;sn=faaffe2962949b2a34844610544dc06b&amp;chksm=bf06f271e05111f880f0afbe313229f36c297f9739f5bef70defb501ae99dc6697688c1261ce&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 12 Oct 2024 09:58:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM开源项目】LLMs-开发框架-Langchain-Tutorials-external knowledge-v3.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdBYEj1f5rwrMGJp0tEItiaSqug9PWn9RRSXKjVxTVOmOwjYpvAF9w3lusIia57PWtxePkNwcab3ad1g/300?wxtype=jpeg&amp;wxfrom=0"/><p>【1】构建检索增强生成（RAG）应用程序Build a Retrieval Augmented Generation (RAG) Applicationhttps://python.langchain</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445341&amp;idx=5&amp;sn=04219ba504100b20e3faeea94a57c24c&amp;chksm=bf58d0a6c00fd4d853c33211496815cc45b1256b25d6c113437d6d450114117213285e9ac80e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 12 Oct 2024 09:58:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一份MoE 可视化指南]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahHRkRw7bHSfaGqosebVZjBMpLRAgPjSou2QqLWlDJ5A2OGFv0KryGicGqic40THnJhzq9r7LAd9PKw/640?wxtype=jpeg&amp;wxfrom=0"/><p>编辑：AI椰青整理：https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mixture-of-experts在查看最新发布的L</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445323&amp;idx=1&amp;sn=c77482d38bda5c267f7212a1f0afa0db&amp;chksm=bf0f421cd1f67b10b94fcc8d997fdf1dc81d420fdfefe70946f429f2de62e4592d7a9530c276&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 10 Oct 2024 11:46:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[RoPE背后的数学想象力]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKGvADdGyKWmHJXZI8OlCHsgB9B4dw6YtO2ywog9rcrN8kVBOGP3ENFo6HRIZPEFIXia81zgHOyRlA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Polya said it well: “When you have satisfied yourself that the theorem is true, you start proving it</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445323&amp;idx=2&amp;sn=7a9458b86c5940430c834ed28252dc65&amp;chksm=bf47842271e626e0245b659c80ba4ac8b2e39c308e929764affcc51959a2211a6daa6f54915d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 10 Oct 2024 11:46:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[[社招/研究型实习生]通义实验室-角色扮演/分身复刻算法方向招聘]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKGvADdGyKWmHJXZI8OlCHstLTKWQBh8IUVvU0unyiaLW7NzpibpIQKmoIibhrrrK4GrVicISLZdhoLuQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>[社招/研究型实习生]通义实验室-角色扮演/分身复刻算法方向招聘[团队介绍]阿里巴巴通义实验室，主要负责通义系列大模型的研发和应用落地。其中对话智能团队以大模型对话技术为核心，研究及应用方向包括角色扮</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445323&amp;idx=3&amp;sn=0872378e95e42bab7239219f8af09a0e&amp;chksm=bff610f83f3c4cb1c21078e260c1d122b70d72d348d088b3369c83ed142974d7577adc0136c4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 10 Oct 2024 11:46:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024年诺贝尔化学奖官方解读：他们通过计算和AI揭示“蛋白质奥秘”]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKGvADdGyKWmHJXZI8OlCHszqN6u61oqrnLczMW6tz1Ao5vFNBQcKo47ye4R4LbFiaLWNNIQr0ibyibg/300?wxtype=jpeg&amp;wxfrom=0"/><p>长期以来，化学家们一直梦想着全面了解和掌握生命的化学工具--蛋白质。现在，这个梦想已经触手可及。Demis Hassabis 和 John M. Jumper 成功地利用人工智能预测了几乎所有已知蛋白</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445323&amp;idx=4&amp;sn=e188b0984a295cb64fef0e50e0deee22&amp;chksm=bf1dff4cd83d7009c06e635abad0091da39004d941618f30e119cc493ad16b36ee3bd1461971&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 10 Oct 2024 11:46:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多模态入门--CLIP]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW465ZwfEVEGyUkIibc0vicYcV0aTjXLptibp5kam0S5wLtl7uNxBrGlQSy9dBsvXm6celrqxYUc3THzw7g/300?wxtype=jpeg&amp;wxfrom=0"/><p>放假了，小小水一篇多模态的经典之作，CLIP。论文：《Learning Transferable Visual Models From Natural Language Supervision》时间：</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445323&amp;idx=5&amp;sn=752509cc7386fc2175424858c6c891cd&amp;chksm=bfe692ee1fe7d8d2aaa52c492abb935dc85fa73f24bc52686246bd5114f289c6ffd422a5e750&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 10 Oct 2024 11:46:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[全是细节｜大模型SFT的100个关键点]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIXM2OJMOJmibe3GicicukSzmial8iaRAtoN081OET6Nmoib8ic9C7qElia4rULgibwicMvt7DECW6MK7M4y64A/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：ybq链接：https://zhuanlan.zhihu.com/p/809229182点击底部访问原文直达这篇文章介绍一下大模型的 sft 如何去做。相比较于上一篇文章介绍的 pretrain</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445303&amp;idx=1&amp;sn=cae55e0e581e260dfb40df6a9ae0f83f&amp;chksm=bfadfc49bd22d4097638ea12daddcda7880d49b786f941406e96a3627987ec7b6eb1e8071c53&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 09 Oct 2024 07:56:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024年诺贝尔物理奖官方解读：他们用物理解码信息]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIXM2OJMOJmibe3GicicukSzmiaNQjdv6ticGDreqlgpL7NxicukkKmwbxib5KoNCnkMliaZUA30InZGDhQYg/300?wxtype=jpeg&amp;wxfrom=0"/><p>源：中科院物理所今年的获奖者利用物理学工具构建了一些方法，为今天强大的机器学习奠定基础。约翰·霍普菲尔德（John Hopfield）创造了一种可以存储和重构信息的结构。杰弗里·辛顿（Geoffrey</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445303&amp;idx=2&amp;sn=a1d907587fd891d7032b83532e0f5374&amp;chksm=bf7339c0ec4a749942d37e564ee3341ba0faa136082789b2d5a77af49ef43af18f2de526204e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 09 Oct 2024 07:56:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[天池-蚂蚁AFAC大模型挑战赛-冠军方案分享(文末有代码)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVfsUStsEBq7vAaBVqJq8hBdQ88P3WNbrgADdOXGh5NMC34IcsDNIZEDtiaibMjiby3KC7mGzctKcJQ7Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言❝作者    彭欣怡 华东师大; 马千里 虾皮; 戎妍 港科广说在前面    在当今信息技术迅猛发展的背景下，大模型技术已经成为推动人工智能领域进步的重要力量。    前段时间备受瞩目的AFAC赛</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445303&amp;idx=3&amp;sn=58f198732ef21b44871262dc02f022af&amp;chksm=bfd3e41960a31b8e10ca949980edeb26367058dd2aaae4884c59f5aa3ac0dddfed39e6341ed6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 09 Oct 2024 07:56:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型是否具有自己风格？这个风格来自于哪里？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiawBZfF689rxSflI0IpicsL0m511RkybJWwFBAwTD6NalUoG99kog0KsqSv8CuFtVEKRVSe59Ipo9Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：bhn (已获授权)链接：https://arxiv.org/abs/2309.17415背景这篇文章研究的是大模型生成任务中，出现上下文信息，与模型本身的知识冲突时（常见于rag场景），模型的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445303&amp;idx=4&amp;sn=4e80d3ffcf5a3bdaaf15680b325da2bf&amp;chksm=bf2e99579ecb3e5c897c971a94e484659938160e823701859e24bccde109a6f2a67fe2c3f284&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 09 Oct 2024 07:56:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM开源项目】LLMs-开发框架-Langchain-Tutorials-Basics-v2.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdBYEj1f5rwrMGJp0tEItiaSqug9PWn9RRSXKjVxTVOmOwjYpvAF9w3lusIia57PWtxePkNwcab3ad1g/300?wxtype=jpeg&amp;wxfrom=0"/><p>【1】使用LCEL构建简单的LLM应用程序(Build a Simple LLM Application with LCEL)https://python.langchain.com/docs/tut</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445303&amp;idx=5&amp;sn=f623873b3cd190e84bfb078d8a58c1a7&amp;chksm=bf81fe10ce57e8a75d24f1ce9eccee784de9ce77ef18309d63f2442402f83ddd58782ec3a922&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 09 Oct 2024 07:56:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[又一本开源免费的大模型书来了，449页pdf！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLqRFgO1HNQMUngG5LfKK4eN15Rxeib8cEFnJzb40Okh6icNvR3v0o2Irr32NgWJVwGKibOic18ibly1ibg/640?wxtype=jpeg&amp;wxfrom=0"/><p>介绍《自然语言处理：大模型理论实践》（预览版）一书以自然语言处理中语言模型为主线，涵盖了从基础理论到高级应用的全方位内容，逐步引导读者从基础的自然语言处理技术走向大模型的深度学习与实际应用。自然语言处</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445276&amp;idx=1&amp;sn=c7f802b7f6758907a73c95afb518de58&amp;chksm=bf0e5321a5053ad603ce37d0ee27cc5a5e7b8ea9dac749b1acd07981023487bae5939b863eb0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 08 Oct 2024 02:09:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM高效预训练(二)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW467AukRdq9SPFe8zBtoWBI5qwLzXc0AkmRvUJQckrJ9FNS945oko2LyzVPib0HadCTZHxWhDYv47hyQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>从目前的实践结果来看，从大模型通过裁剪、蒸馏等手段获取小模型，效果是比较好的，同时成本也相比直接从零预训练要低廉得多，而且也免去了大量收集数据和清洗数据的工作。今天就集中讲一下模型裁剪的工作。裁剪 +</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445276&amp;idx=2&amp;sn=be55cd18bf4fc30bddd4f7302515818c&amp;chksm=bf4f2b2c1813ea2b84486f875625ae17069cdfaca2aaa417a6091a1391a65a4f95f884c83a80&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 08 Oct 2024 02:09:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OpenAI o1 技术初探2：使用MCTS增强推理能力（基于代码实践的解读）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkNOOc1O2OnNnXpEv2R0OHfQv4IF4YU0RbzQ7436wjX43s2uKAib2SEtMSnbHO46N5fgw3M4IlLW7uw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在o1的整体框架篇中（https://zhuanlan.zhihu.com/p/773907223），我们从现有开源的论文和代码中（https://github.com/hijkzzz/Awesome</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445276&amp;idx=3&amp;sn=fc255f07e150ca773e62dc516e5d5121&amp;chksm=bf890bf8ca84e757dd25fb773beef81cc146e5b6c9dcd369c13416befac8ada8f50ce9d04d53&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 08 Oct 2024 02:09:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型落地困境讨论与解决思路]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jT5Sp7MICPxiciaXd4CDibrv60kBrU2Y8IiatCIvsFeVh9FUic7uojDicGY5MXDMHFZunkz3269xP6VAx2icXeJrtCHug/300?wxtype=jpeg&amp;wxfrom=0"/><p>大模型出来的时间也不短了，以chatgpt发布时间为里程碑（22年11月），至今已经快过了两年时间，虽然目前的热度仍未下降，但是从我最近和几个朋友的沟通来看，大家的心态已经逐步从当初的热情变成了目前的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445276&amp;idx=4&amp;sn=99b0529aa06d04a83742f45111a4300c&amp;chksm=bf9016e6a620801056e051663725f911fae93436bc231c660e54d789a4d54ecdc7187ae24903&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 08 Oct 2024 02:09:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Neurips 2024 | 通过解耦的位置向量探索大语言模型的上下文窗口]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/G7ia3FZ0o0OqDtrZdAFnbK0LoDIlgk6MVCibM1rWlAa2wWwjQVWia9RKWH9PkL2jJ4uWo3h0TT9r6ypfuFm5QF9LA/300?wxtype=jpeg&amp;wxfrom=0"/><p>© 作者｜董梓灿‍‍‍‍‍‍‍‍机构｜中国人民大学研究方向｜大语言模型、长文本处理基于Transformer的大语言模型天然具有固定的上下文窗口。虽然已有一些方法用于拓展上下文窗口，但对于其背后的原理</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445276&amp;idx=5&amp;sn=119d6c445e7427941eae15ea34599bf8&amp;chksm=bfdcb8dca5927742a6e9b303e6201e9c94a80df3d271959221c0c570a3c68fb35485eeaa244e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 08 Oct 2024 02:09:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型最热方向：LLM-Multi Agent 来了！！！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLmC7XupDBzUH8LCPfwV9VOKaMibjhXcoJJlcoibBsticpMK6XOKlcKmAbplvEB9jqS2X6ExpH4Icseg/640?wxtype=jpeg&amp;wxfrom=0"/><p>大语言模型(LLM)2024年火出圈了。然而,单一的LLM在处理复杂任务时往往力不从心。多智能体辩论方法应运而生，它通过模拟多个智能体之间的互动，提高语言模型在事实性和推理能力方面的表现，有效缓解了单</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445261&amp;idx=1&amp;sn=01eb66f15725a462cebec66a0d40d1c3&amp;chksm=bfeebb885ab5438fc93723702f03387b012cc5f43f77c184ff44c23cec17955acd5d920a8e98&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 07 Oct 2024 02:12:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OpenAI o1 技术初探1：整体框架，利用Test-Time Scaling Law提升逻辑推理能力]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkOibl50lXj5CZaPDGGkyRVkMGRaftWsjfl9b06ZjicQ5Wyh1Yx0whWJ0Rxu5WHteSsPLCiaiaxHWmmDJA/300?wxtype=jpeg&amp;wxfrom=0"/><p>前段日子OpenAI推出的o1模型，以其提升显著的逻辑推理能力，引发了人们对它背后训练方法的热烈讨论。关于o1的介绍和输出结果demo，这里就不再赘述，大家可以去openai的官网上阅读（很短，读起来</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445261&amp;idx=2&amp;sn=a77fce570c1011ba22111625efcc3d4f&amp;chksm=bfcdb93f7193e0bbf4903b453aa0a972381fed714c86414928337639019c55ebf2bb4958d962&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 07 Oct 2024 02:12:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[还在“卷”长度？长文本模型真的基于上下文进行回复吗？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag2bO6GGCNvku2fdsq8nsPy8uMeHDr4zyjKIBUKibEHEPgdgF69EVp4CCOMa0CclNWhOUibUJJqiamcQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，随着长文本模型（Long-context Model, LCM）技术的突飞猛进，处理长上下文的能力已成为各大语言模型（Large Language Model, LLM）的核心竞争力，也是各大</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445261&amp;idx=3&amp;sn=d4ede8fee2936b1b0dd8bc1036f4b597&amp;chksm=bf7822b7c912c0ece1d68b5e7f2aa11cb74698d019c09078cadf31a6a468d9ded3221f3fedd5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 07 Oct 2024 02:12:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM模型量化】-官方教程-qwen官方教程v2.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdBNLaTxqVrRzg2mRJb209Vw8pcLKcXRCjwRXpVZOOqt3zl3BoW7JT1icsUjeoeu8eo8FQlfCI8sHicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>转载自qwen doc，: https://qwen.readthedocs.io/zh-cn/latest/quantization/awq.html https://qwen.readthedoc</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445261&amp;idx=4&amp;sn=24758ff0f49a7ed029d8cc961866b0b3&amp;chksm=bf48c4287386221cf7cb46a49d66e09a2cc2ad31e3b538c9521411a1b85a17dd018439c22d56&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 07 Oct 2024 02:12:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[通过负样本挖掘炼出更强Embedding模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/vtIvcrPJjh5LiaFLIwDO54vmUP5Jl1SLs5s9J80uLicT44xIShtxmic0pssX4cCz94gyfOKnrico0ibsfibHcgTWTyVg/300?wxtype=jpeg&amp;wxfrom=0"/><p>一句话总结：Conan-Embedding模型，旨在通过利用更多和更高质量的负样本来提升嵌入模型的能力。论文原文： https://arxiv.org/pdf/2408.15710研究方法预训练阶段:</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445261&amp;idx=5&amp;sn=3d5aa09aa3e052658427d4ab82f6ad10&amp;chksm=bfe60e649fab86a6d86ff59a2782a4706819650c3a9f836a2e178841f8052f967da44632a3a9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 07 Oct 2024 02:12:44 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
