<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    































    <item>
      <title><![CDATA[LLM真的解决表格问答了吗？全面覆盖复杂应用场景的新一代表格问答测试基准TableBench]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLibCgVI8QyTibIMo4gaboYK0cfTxrvOmniayuhvCsnj4AyKommZwcibCjRnnxkClRXHJmSckvNPkhMrg/640?wxtype=jpeg&amp;wxfrom=0"/><p>LLM真的解决表格问答了吗？该工作提出了新一代的表格问答评测基准(TableBench)。TableBench通过涵盖四大类表格问答能力（如事实核查、数值推理、数据分析和可视化），并深入到18个子领域</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444348&amp;idx=1&amp;sn=5d8f4ff455c4cd32968618750a361afc&amp;chksm=bfe35f9ea3963cbfac551e92e51d4e392ad654515250277dbf454a054f278220f566b03429c4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 23 Aug 2024 09:09:37 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[黑神话悟空的薪资与招人标准!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/icmWrEONNM8WLmAOibic98bp45OmcpSr9MuLxYRKR9O9TwNdCLEdPOVK7VnNrLP5yhWaNBVpu7LepGrx4hibZcVf5A/300?wxtype=jpeg&amp;wxfrom=0"/><p>黑神话悟空总算是熬出来了，前几天正式发布后，彻底火出圈，也轻松打破了一些记录。它的同时在线人数，突破了 241 万人，这个数字使得它成为了 Steam 历史上在线人数第二高的游戏，仅次于吃鸡游戏绝地求</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444348&amp;idx=2&amp;sn=10fee4ddc559ca379a7e26b92d0202f7&amp;chksm=bf2735f5a4776a23ffe78986627dc918dd8e07a7523be5621271dd741087b86a40e884bacd8a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 23 Aug 2024 09:09:37 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[大模型：一文滤清 BPE]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HAFUHkn3vxtUKpfgz44pxzGamkl2HpaxVC1TtRsTO4ib6kja3oqvmP0MCZqm6VjvYoTiccKiauwoz9XnqLR8ibcBtg/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言最近在整理笔记，陆续会把一些笔记整理下发布出来。分词器一直是 NLP 领域中非常重要的一项工作，而对于不同的语言，分词算法都可以采用：词，字以及字词结合来表示。经过多年的发展，现在不同语言的分词算</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444348&amp;idx=3&amp;sn=d5fb8d9d2958863eaeb0d5f128d0075c&amp;chksm=bfc6a99009740a7358f8190b96083d8ffb0c9459cb9b9e3f44b0188e9c51862d3b91ea9ba6d8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 23 Aug 2024 09:09:37 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【LLM模型微调】LLMs-PEFT[微调]-LoRA总结笔记v5.0]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdD3zFSqVDbo9rqAy521pIqprj0TIl3z8bHGuu4CLt1gjvNL2OJkYXfWEicIncicTGux5LSy7f5cYN9A/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM模型微调第五篇，分享论文LoRA：LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS的解读。主要内容有论文解读(提出背景、关键优势，实现步骤</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444348&amp;idx=4&amp;sn=c10f7e9dbe4728b888350e296c5e25e4&amp;chksm=bf16bdf9865d252fc903576722fdf9058881dc66c690b7673f9f7e545d8bb7fad5887dce3395&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 23 Aug 2024 09:09:37 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[机器学习中的样本重要性权重 (Importance Weight)]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/QLDSy3Cx3YIZUXqXHndqDsyeyQNIQOP8GX0FVYdl57NqtUjRWoMGLWb5UhFQfT9GCVichf7EBOcsXZM7oX2ibVqQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>样本重要性权重（Importance Weighting, IW）是一种在机器学习中应对「训练-测试数据分布不一致」问题的经典方法，通过对样本给予合适的权重，理论上我们可以在分布不一致的情况下，学出在</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444348&amp;idx=5&amp;sn=bfae6b1d6487707f52625d7c6e595abf&amp;chksm=bf23c01e3670a3efaa5fcc8ebfd536927c69a35cfd55127e55b648de72ac35865c98554a43ca&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 23 Aug 2024 09:09:37 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[多模态融合，顶会超神了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIqHRuDrib60qtLmiahAf5TEicnS2bZZbibw1lkGfBp3YqJfUBfv0p1rQb2jD6aUZb1z9zAkNVM8Nc0Yg/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，今天分享一个我认为未来最好发论文的方向：多模态融合。我总结了56个多模态融合的创新点，并整理了对应论文，来自ICLR2024、AAAI2024等顶会。想发论文的同学们赶快扫下方二维码下载资料合</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444268&amp;idx=1&amp;sn=92999ab31375006bb30ff20e61e1ff9b&amp;chksm=bfdb72cbbce9ebf5d29b49b4f04d13b7956683ec284bb857a51c2b2f597b0a93918d409c0202&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 22 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型是泡沫吗？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5lxJECCOzWcqM0iabdRw2HZSwRqh3XHrCQMe7YsU3tN7R7g3WwRaI0PbaCl48bPSVqT6rJE2PlSLwg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来知乎好友@ybq（欢迎来关注），一篇关于从事大模型工作的感悟文章。不谈技术，只聊聊这两年从事 llm 工作的一些感悟。知乎：https://zhuanlan.zhihu.com/p/71</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444268&amp;idx=2&amp;sn=8d1ab522b0ff135f5abd73cfee5b27f7&amp;chksm=bf54701c7bbc8924b16c35a2d8c17f87ecc446b8f2eab585ef9088364271498e7fbd230e705a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 22 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一文讲明白大模型显存占用（只考虑单卡）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJKiaEiaHF6VvMg4UVJ17JanicXOtIiap3m1FoMdCo20QUDk5uicQiaMB1kIyhIcx8jmhhrMMErzFy5seyQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：然荻链接：https://zhuanlan.zhihu.com/p/713256008整理：深度学习自然语言处理1.告诉你一个模型的参数量，你要怎么估算出训练和推理时的显存占用？2.Lora相比</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444268&amp;idx=3&amp;sn=6bab0713cf62b984a878499b0d90daa1&amp;chksm=bf0406f417812741b161de78334eb8886b1424fa1b2202ac847731792e5000af6b266f785c3d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 22 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM模型微调】LLMs-数据筛选-DEITA-231225代码解析v4.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdCVwhULkOAZvIg0Y1koKucqwC3vArnp3znY0ibY9p4e254VXgN1nYBCT4P2VGYv4hOrIpovsjlM6eQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>DEITA代码解析【1】DEITA质量评分模型-hkust-nlp/deita-quality-scorerdeita-quality-scorer是用于自动标注SFT数据中指令质量的工具。模型类型：</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444268&amp;idx=4&amp;sn=b724bf9b44b5fdcdd07aaeb35cceebe1&amp;chksm=bff64accc64fd9f7cf66bb088123065a583aa21ed5cb7ae3657e60111e963e1677334d6b43d3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 22 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[基于 Quanto 和 Diffusers 的内存高效 transformer 扩散模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2ouTCuWXvqUCnn5PxnBpBJQ4RB7IwZyoEK5iaicd22Jj4NQtUYomwt37UFXfiaHiarlicUnzAaMEGtsd2w/300?wxtype=jpeg&amp;wxfrom=0"/><p>过去的几个月，我们目睹了使用基于 transformer 模型作为扩散模型的主干网络来进行高分辨率文生图 (text-to-image，T2I) 的趋势。和一开始的许多扩散模型普遍使用 UNet 架构</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444268&amp;idx=5&amp;sn=d4092d568fada4e63fd75dcab1212b2e&amp;chksm=bf6883bcd69c4b5ef997ca836257258464a5f29d60a0855fd85439b9400cff444d0624c3c2f8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 22 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM预训练和后训练新范式]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJ0ssLyuaGlOgib5Yic5PWYjmiaEyRk73hSkv1jf1nPgG4VLZsvT5ZzJiaM8ibtXdZaXBgPk8XceYLiaSkQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文翻译自 Sebastian Raschka 的“New LLM Pre-training and Post-training Paradigms” ，他也是《Build a Large Langu</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444240&amp;idx=1&amp;sn=667767561ac463e6686598d2337bd206&amp;chksm=bfecf86f11e7fab10801581b314199bdc602229eea113b0a61ccf4d093996d3e183318274130&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 21 Aug 2024 02:58:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[李沐：创业一年，人间三年！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJ0ssLyuaGlOgib5Yic5PWYjmrH7fZibWI7ledW0WV7VHJOcXECTn1KM5qrxHib76MtcdicjavxHLm5Xxw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：李沐，CMU，BosonAI 联合创始人给小伙伴汇报一下LLM创业第一年的进展、纠结和反思在Amazon呆到第五年的时候就想着创业了，但被疫情耽搁了。到第7年半的时候，觉得太痒了，就提了离职。现</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444240&amp;idx=2&amp;sn=168fe03bed88eff045a1a8a9a864a356&amp;chksm=bf2450dc333675cd2751164f496af8884fdf504c71bb56eb49b6f5206126a381c9f47d869bd2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 21 Aug 2024 02:58:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[InternLM系列模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW467bzdpG32FGljY5vqBzVXoMj5iaIwUyaMiaNb90do4fpbQ5o4ibetF6Wg1zjnnfBH9tpLgCLfic7zR9tA/300?wxtype=jpeg&amp;wxfrom=0"/><p>InternLM系列模型的参与方有上海AI实验室、商汤、香港中文大学，以及复旦和上交。主力应该是前两个，InternLM中的Intern这个名字也是继承自它们之前的视觉模型项目的名字。最近Intern</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444240&amp;idx=3&amp;sn=aae3566301b46d42cdc4d180db182662&amp;chksm=bf263826a3bf55d7764025decb6e3d4c7ea66850379b8fe30f1925a0bb89e537ecbe2291f5d4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 21 Aug 2024 02:58:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【RAG】FastEmbed：一种轻量的快速文本嵌入工具]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGDIVr5MwATh2fQkM23gdrCSlicsAs55WBgHJH4DVAsY2UiayKCNKWic0fVmkNsVfAj8AAHicsYjUx84pA/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言在进行文本嵌入时，尤其是RAG系统，有一个快速高效的文本嵌入工具是非常有必要的。因此，FastEmbed设计目标是提升计算效率，同时保持嵌入表示的质量。此外，FastEmbed还支持一些图像嵌入模</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444240&amp;idx=4&amp;sn=a11a83b2c0fcb53b367cb64270516c69&amp;chksm=bfb7fa8c269d75f2695ea5f00c1e410aec4d3b98fc95c5fbb104c25f57da359ac8214859a698&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 21 Aug 2024 02:58:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Grok-2 &amp; Grok-1.5 介绍]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HIKk7OFDjoSffsbOvZcy2SLibITfJTlibicGEJkZDQrEJEDZUpM4aia2WIlicEsVCTPs4fGBkxoBM6f9qOico30H9A0w/300?wxtype=jpeg&amp;wxfrom=0"/><p>2024.08.13 xAI released Grok-2 Beta★Grok-2 is our frontier language model with state-of-the-art reas</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444240&amp;idx=5&amp;sn=a382193e0f2108e68344a2bb3526896d&amp;chksm=bfda732e443f0bcbac0e898c3e94680b3dca603cb26fca3f4102c29d8434ba1f4710a9440c47&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 21 Aug 2024 02:58:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[脑洞大开！扩散模型杀向NLP，本科生一作获 ACL 最佳论文]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJPQGeFlaT4XqLwEHqf6bDvGCQmhqhl8fmcGKQgoFyYSia5pPZGhmibaicltdXBk7TK5UGibH5SW2KkuQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今年 NLP 领域的顶会 ACL 于8月11日在泰国曼谷开幕，共有7篇论文荣获 ACL 2024 最佳论文奖！其中引人注目的一篇论文是用扩散模型做了一件非常有趣且有价值的事 —— 借助扩散模型破译甲骨</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444210&amp;idx=1&amp;sn=4d86a0866d4daf9daf0fd43fdb836962&amp;chksm=bfd92bcb93c70a2663debc2650ee311f9b76a98750bff53e1bbb61ecc3fc9b9270cfcbaed463&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 20 Aug 2024 02:18:33 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[三万字详解！GPT-5：你需要知道的一切]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJ0ssLyuaGlOgib5Yic5PWYjmTRcHMEQwnkWRmTq54vdeLbYtTs62tyvdLb7JVtu9hKj0c7YIzYDULg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：Alberto Romero （青稞AI整理）原文：https://www.thealgorithmicbridge.com/p/gpt-5-everything-you-need-to-kno</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444210&amp;idx=2&amp;sn=336110dd23e1b8efe94c090c8b9c9c40&amp;chksm=bf3ea78b16d503c97d3edcfe3eb833bbe2b7a7025b564523c0aafc893e004322da99d89706fa&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 20 Aug 2024 02:18:33 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[百川大模型算法实习生]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJ0ssLyuaGlOgib5Yic5PWYjmXJgXEFIRoibtFkE0dBHRBcs9IxyZLAMgvZicySFZD3SozwElqt8OTaog/300?wxtype=jpeg&amp;wxfrom=0"/><p>百川大模型算法实习生 （百川智能科技有限公司 北京）搜索增强大模型算法实习生职位描述：1. 优化搜索排序召回算法以及大模型总结能力，增强知识库产品的综合能力。2. 追踪大模型/RAG 等相关领域的前沿</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444210&amp;idx=3&amp;sn=0aa4d8960aac060b2a01f1d1aec7cefc&amp;chksm=bf6b7007cd862cec809b1336a27d339459bd87eee1762fb9e5348eab26cb26681c17c1d9a516&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 20 Aug 2024 02:18:33 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[15 种高级 RAG 技术，值得收藏！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svdiaQBwfseS8EDBoUhkm18gHVWOL1ibiam56wjsIjoy0l7lyia1beAdBy1ELhzjxtKT2o8BhwPe5DmqUt8cztFibwg/300?wxtype=jpeg&amp;wxfrom=0"/><p>一篇报告，介绍了 15 种高级 RAG（检索增强生成，Retrieval-Augmented Generation）技术，可以从预检索、检索、后检索和生成四个环节来细分。值得学习。15 种高级 RAG</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444210&amp;idx=4&amp;sn=044c039a168b6251cf71bcc26cc8b87e&amp;chksm=bfe19fcabbd39a90026d3a3fae340717cdf80612eb4b5e0658b6f803d14c9db702e953dbdb42&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 20 Aug 2024 02:18:33 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【5分钟论文速读】【微调数据过滤】LIMA: Less Is More for Alignment]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/d6902wUyyvI8BOEvEicIpu4uTIo4M82fGiaNibHhZRegf4EbIQw5yaI7sODRhU0pwYPYMI3ib8rveLAIHuSiaSU4o2g/300?wxtype=jpeg&amp;wxfrom=0"/><p>主要观点：大模型的所有知识都是通过预训练阶段获得的，只需要很少的指令微调数据就可以获得高质量的输出。凸出了预训练的重要性，并倡导在做微调阶段更加重视数据多样性，而不是简单的扩大数据规模。数据生成过程：</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444210&amp;idx=5&amp;sn=052c7fb1ea2b34c9f15bf3f97ebc5691&amp;chksm=bf95e0aaa3ac558037b1b45282ce407e586125a9269a0bbabe5f40de7d82ba39330865e6caf2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 20 Aug 2024 02:18:33 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[自愿离职！每人补偿400万！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIOhRvhQUWzA5b3hHWbCQ7Q325j3NoicKsaNibwaw4W2w9pMtbOA0h7ZmbicIZNOyjXyQdiaw4cke152Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>8月13日消息，据外媒报道，英特尔在爱尔兰裁员补偿方案出炉，该公司向当地员工提供了高达50万欧元（约合人民币392.17万元）的自愿离职补偿金！据悉，该裁员补偿方案于近期分发给员工，要求员工在8月23</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444184&amp;idx=1&amp;sn=afc2a4c64d18f8a2588fc6ba7b4bc2fd&amp;chksm=bff911c4171f557de87a5e06d29c64d28ec0e5c287075a5c19612534ddcf7b39c9d85138a977&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 18 Aug 2024 13:25:24 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[没有大模型经验，面试官给机会吗？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuxCg4e5rBNd6QQmicUMSeqpxNia3GhV5XkFzZrUGGhJVFYD278hCiaFWCRxWialJWokG7xXMSvlhBeHqw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Author: [Quokka]Link: [https://zhuanlan.zhihu.com/p/715031517]做大模型一年半，经历了无数场面试。经验我最常听到的候选人（尤其是学生）的说辞</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444184&amp;idx=2&amp;sn=8891e8e779e64682e0607f77c9535a7e&amp;chksm=bf50eb5ac97a75840958cb27955622f150ec13e623f96757e368defb0d687ed5e359a0ae0740&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 18 Aug 2024 13:25:24 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM模型微调】LLMs-数据构造-LIMA-论文总结v3.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdCT91b9RU0ibozJFEoIpaxRfMsx3JxbelRf1kYNyk7XUNAWvicrzGAYYFmziazmiaibHM0pemeZmrWusjg/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM模型微调第三篇，分享论文LIMA: Less Is More for Alignment的解读， 主要学习其中1k条微调数据的构造技巧。LIMA【1】LIMA相关论文LIMA论文</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444184&amp;idx=3&amp;sn=f8a245053ec233252a8877024177a270&amp;chksm=bf4b4367f67088dc00ce1aea3b7018e722354ee235caef720c61b72ae45e3e28ec51212ad36f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 18 Aug 2024 13:25:24 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一个模型支持智能助手系统]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW467ic7Y20wZFeDrvicGnXd5REvhG7S2Tucwy1hbrD5rzIKVoicfsZ1JCDykEnicyo8ygVbBx5KIicsIBNEg/300?wxtype=jpeg&amp;wxfrom=0"/><p>这是一篇关于三四年前的旧项目的回顾。前一阵看苹果AFM端侧模型的做法，让我想起了前几年做的项目：用一个Bert模型支持智能助手多个任务。方便起见，本文后续就把这个Bert模型叫BFM（Bert-bas</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444184&amp;idx=4&amp;sn=c30e307027c6de32a57a6236cbde9de8&amp;chksm=bf92990ff8dbf9e5d59464bfb8596229e2791bd6ed34689d4d5759c79c785c182f55d159304a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 18 Aug 2024 13:25:24 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[用AI察觉AI生成的文本（3）验证检测能力的不同场景]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/MwhqibymFECG188C6N0NVGbv8spCzQszfOabfI5eicw34cDpURFkHoiaf1jicIxLwYJh1m5oxxb4nqCcv0MGMEniczA/300?wxtype=jpeg&amp;wxfrom=0"/><p>用AI察觉AI生成的文本（3）Use AI to Detect AI-Generated Text (3)“特别鸣谢（Special thanks）：在读论文的过程中，有几小点疑惑，所以当时请教了论文</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444184&amp;idx=5&amp;sn=7b7f7727020cb01ff566ddf24a02e5e8&amp;chksm=bf6d85cb4d22a496dfd2424ebfb506540bca3d76510031610dd5ec2fdfe014dfda85867b68e0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 18 Aug 2024 13:25:24 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[谷歌前CEO怒斥员工“每周只来一天”、“卷”不过OpenAI，遭争议后火速道歉！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLdnXWNxOqAlYA16ypEUoFmBDahib67HwTEIdjmYZbzicsVgmzkSZZTOxkKgjGpxwrZbMdhAmich1TKw/640?wxtype=jpeg&amp;wxfrom=0"/><p>整理 | 郑丽媛来源 | CSDN（ID：CSDNnews）本周，斯坦福大学发布的一则视频引起许多热议：谷歌前首席执行官 Eric Schmidt 声称，谷歌之所以在 AI 方面落后于 OpenAI，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444169&amp;idx=1&amp;sn=2777be98fb3dbde46c183172c2687c98&amp;chksm=bfc5294559932efd9c5b97bd239c313f2953160a159b9c5fb57811f5f0cf451e8e6933049d9b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 17 Aug 2024 14:27:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[留言赠书 | 大神李宏毅“机器学习”课程集结成书]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLdnXWNxOqAlYA16ypEUoFmYrye5RByYzuu4K6qgkMqxd6nL2GoP9ZneDUSJ6UOWbicl7uP3d067oA/300?wxtype=jpeg&amp;wxfrom=0"/><p>文末赠书GitHub上持续火爆的《LeeDL-Tutorial》项目，一发布就迅速获得了11.4K的星星！这个项目基于李宏毅老师“机器学习”课程，课程全网超过百万播放量，如今Datawhale新书《深</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444169&amp;idx=2&amp;sn=bf8808e1a838651df1b7684645f47797&amp;chksm=bf175ceec9710c8cf65176b201c999450535038748299b28417f08bc726befab9b3bd5cfdded&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 17 Aug 2024 14:27:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型 VS 小模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5k1msNBGEHgM7s4ibSp3iaUG5lxQLTiclRjibFs3NSZTq6wicGAj8ZBfMYiaMc3IU7mBVQpYzjJLUDt2Aibg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来知乎好友@ybq一篇关于大模型和小模型讨论的文章。首先，我们思考一个问题，为什么 qwen2 基本上是当下最受欢迎的开源模型？说实话，相比于 deepseek、llama、minicpm</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444169&amp;idx=3&amp;sn=23cd68a5082e6abd3f97da1be925b44d&amp;chksm=bfd41b9f39593f23b99d7e11d45ccb4ec07129d1d7b035f84b1961e7ad61281c25d2a5d528d4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 17 Aug 2024 14:27:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多模态大模型: 盘点&amp;Highlights part1——从BLIP到LLaVA]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jT5Sp7MICPzEw3c9CSxTcUYDCYUK2N4723Ye9ovykbATaRQ1k3lVKzyOiaD0yQmK4YowdmhSJRNicquQo2NyRic5A/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言Hi大家好，我叫延捷，是一名计算机视觉算法工程师，也是叉烧的老朋友了。我们计划发布一系列关于多模态大模型的文章，帮助大家快速、精准地了解多模态大模型的前世今生，并且深入各个多模态大模型领域优秀的工</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444169&amp;idx=4&amp;sn=a42f44ec56042e95421d9d409f940182&amp;chksm=bfce63339b1b1f7ac5371c4de5013ed94f1273a04f0ff500f359c7efc87d3d464ea25a4eb83e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 17 Aug 2024 14:27:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[phi系列模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW464vO6vLrOOpzgEVDnV6JMXTm9crR7NL3ZhNnn5AWB9VYic4kSppYECq4usxBCowcRbKJQAwLyZ4LIg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近在做端侧模型和数据合成的工作，微软的phi系列是受到关注比较多的一个小规模模型，整理一下细节，看看有什么可以借鉴使用的。1.phi-1phi-1包括两个模型：350M参数的phi-1-small和</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444169&amp;idx=5&amp;sn=6838089434c53da6613b446a4a113573&amp;chksm=bfa9f71c7e6c519bce97fe013b79ba603c45b6a22f3706178a8a6efd71a047c1fd313fe0fc00&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 17 Aug 2024 14:27:15 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
