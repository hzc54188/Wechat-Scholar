<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    































    <item>
      <title><![CDATA[小红书大模型论文分享会来了，还有岗位热招]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJzMMvvp4KGxnYrcSpl2VVPKoO4nh3rk1kKI8Pe4QAe0ic6vcu3FxskDcsOgR39N5fJwvLIm4LuMicw/640?wxtype=jpeg&amp;wxfrom=0"/><p>作为 NLPer，我关注了一些大厂的官方技术团队账号，发现有几个做得很不错，REDtech 就算一个：小红书技术团队经常做一些技术分享，比如这次的主题就是LLM大模型。大模型正引领新一轮的研究热潮，业</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443157&amp;idx=1&amp;sn=1388c1ac2fec1b7d114bd09a5c31a435&amp;chksm=bfc80885be87599c8f43630992b15ca453acd3c4ac33097698e1a5f685e68e723e604289ffc2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 22 Jun 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[多模态大模型VLMs一年多的进展与思考]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJ54UCnEU6CGMBawN8QlPXCEFKYMw0b4Z441nBWvxPibCb2xvD5bWiaO7kGbsNqEq3MIkCqDmhoHt6Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：dlutxubo，电子工程师声明：本文只做分享，版权归原作者整理：青稞AI原文：https://zhuanlan.zhihu.com/p/702811733前言自从ChatGPT问世以来，人工智</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443157&amp;idx=2&amp;sn=4493fecc9fcf23a1a6f52b754f05c68d&amp;chksm=bfc082bcbc3c16834bafbdb05a297fbbf63058fc06e1cdc660c0d38597161b2c921c1c254c0e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 22 Jun 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【LLM基础知识】LLMs-Tokenizer知识总结笔记v2.0]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdAt34EIm91U1drY8ezNnJmHx21xG8VxjujAz7f7aI3Z5JpKoPkFe3icKRVj8qvu4ibcadkCw73LJzxg/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM知识点第二篇，介绍Tokenizer的三种方法，着重整理subword分词算法的BPE(BBPE)，WordPiece，ULM。同时也介绍分词工具SentencePiece。To</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443157&amp;idx=3&amp;sn=94417dda5a387368f9a7fbc983224914&amp;chksm=bf2c4f6070e5ca787db92ad6eab3b1cf6099dd3831150c0672658efdac6db7905aaef1d519bd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 22 Jun 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[openai原班人马最强模型Claude 3.5发布]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuziaBWTiaGD36E32LAepGP9CPzdQEYSDb4aUVEJfibEO99PlnCFXTkCuTpENx1Rhd2yiccWnhoUyJMPLg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天，我们推出了Claude 3.5 Sonnet——这是即将推出的Claude 3.5模型家族中的首次发布。Claude 3.5 Sonnet在智能方面提高了行业标准，在广泛的评估中超越了竞争对手模</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443157&amp;idx=4&amp;sn=24eac97effa4477ef54493100dabb9ce&amp;chksm=bf6cbf16c142e62a60f47ffb1a785297e3834ac63c26c94458a82479a525d0973c140442ed0a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 22 Jun 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Kaggle知识点：文本分类与LoRA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/uoTGEibAZUEhyMcibyMdtmq4xcdeStylUGmbfFnaFeoc1oI1TXImLPGKwyf1nHMjDofpNtCGngNLibgJGIzqRB0Uw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在这篇博客中，我们逐步进行参数高效微调（Parameter Efficient Fine Tuning，简称PEFT），使用大语言模型（LLM）的低秩适配（Low Rank Adaptation，Lo</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443157&amp;idx=5&amp;sn=f0b7e88f7a482bfe5ae4600818c6fe56&amp;chksm=bfb66d4febfb0aa9bf2ccef0c7979d011f81183c7dbce56948f643fd16b54cb1ed24af9548a9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 22 Jun 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[首届“AI高考”落幕，21款顶尖大模型及格率仅33%，“冠亚季军”都是谁？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/aH1o6ChDInWiaz2rQb5P3Bc8RwajmUuqI6Be4n3whUv2nxGserNZgibP0H0fK3lACmw7iceB4nJqaI6km5SMwKOUw/640?wxtype=jpeg&amp;wxfrom=0"/><p>首届“AI高考”落幕，21位大模型宝宝参加高考，及格率只有 33%！其中，OpenAI 的 GPT-4-Turbo、智谱AI 的 GLM-4-0520 和 GLM-4-Air 分别斩获COT 版本考试</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443144&amp;idx=1&amp;sn=aaed9c01c29c5e1b175d00d32ba1092b&amp;chksm=bfffc231e585105209e5dc93db4278a11568761803bc3eea6ca7bb0436f458f89952e5eba490&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 21 Jun 2024 11:37:35 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[张雪峰高考推荐专业​（最全总结）！！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJzMMvvp4KGxnYrcSpl2VVPVWTkoXWtr7niajPEc3xsh3LXNS3WI4PUZCZGx8xBxgnLesIW6tY81Jw/300?wxtype=jpeg&amp;wxfrom=0"/><p>高考：张雪峰推荐专业（最全总结）来源：Datawhale进技术交流群请添加AINLP小助手微信（id: ainlp2)请备注具体方向+所用到的相关技术点关于AINLPAINLP 是一个有趣有AI的自然</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443144&amp;idx=2&amp;sn=1d2c80a4efe1bfa661413608402ab25c&amp;chksm=bf89c925332df9425fc162e2ca0544a66f3ad6e43e2a23d8c131f98094955d1254fbbb0d140a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 21 Jun 2024 11:37:35 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[英伟达超大号340B大模型技术报告]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuwPic5tpIE8JF7bQolRm3CkT4LbGiaR181ib8MhGsHpKQY64IvicngrHib2E0icK8fVRkJ1QDdzNibcrbBPg/300?wxtype=jpeg&amp;wxfrom=0"/><p>迟到的技术报告，太长不看版如下：1.模型有340B的超大参数，包括基座，chat模型，reward模型，全部参数开源。2.对齐过程使用了超过了98%的合成数据。 3.rope，GQA，不要dropou</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443144&amp;idx=3&amp;sn=638a730a89f3e748ef99a85653d6af1d&amp;chksm=bf0416fab4ca7b41a8c2218e1fae5907f8c299852cd83747b518f33c048d725f37cfbe7f28e0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 21 Jun 2024 11:37:35 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM基础知识】LLMs-Transformer面知识总结笔记v1.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdBBLCIEtO9CaW8CkPfXANbDhttoib1mZlO55hINtsdjOujuvcNp2grFibHrwJhUDv6XEDLwNRKhKUXg/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM知识点第一篇，整理了10个Transformer面试相关知识！                                                          </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443144&amp;idx=4&amp;sn=9c3b1b9e8c151643121266e51a2f6a30&amp;chksm=bfd2bcc49d0c2d6d2d770379c10ae0c3a42c64400018bac4ccb13d3d58bdcb409ee751ee48aa&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 21 Jun 2024 11:37:35 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Spark向量化计算在美团生产环境的实践]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/hEx03cFgUsWDdFm152IibNPBAZ5X2BDTLd1ug9SSMY6QGr5gw2ST1PgyuD9ibUatJ5c46ibQykOYnlZZohPIlUSqA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Apache Spark是一个优秀的计算引擎，广泛应用于数据工程、机器学习等领域。向量化执行技术在不升级硬件的情况下，既可获得资源节省，又能加速作业执行。Gluten+Velox解决方案为Spark换</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443144&amp;idx=5&amp;sn=cb6e1d9bb1c6928f8a2e7d919e86f295&amp;chksm=bf50ecf7fffa111a8edf067cff7271c714871d8282a717a7f80d27f73b1301592e2b2be3b0d4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 21 Jun 2024 11:37:35 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[GPT-4o颠覆世界，700篇大模型论文首次公开！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLKeMfIzI8ARAQ9lUXlnWvQELrLyib1OtFdJFjwPIa3Zfr95yPz0B2DRGZIgaaEu0CGKWjUyZbibkYQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>5月中旬，OpenAI向世界揭开了GPT-4o的神秘面纱，这个全能的多模态巨人站在了GPT-4的肩膀上，将人工智能的边界推向了新的高度。为了让大家更好的抓紧大模型机遇，这次我整理了1-4月最新600篇</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443122&amp;idx=1&amp;sn=75a8dfc6489e13a14d75cab7516cf7d3&amp;chksm=bfc1f4f202f54915b1335239263a5e22c25398868634d31ca8849dfee3556515f2ee757b90d7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 20 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LlamaFactory 一键式LLM训练、微调工具介绍与实践]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL7f5GdKHmw4T41l0ta7ic09dob4b0Ml2BoQtiabn4XZkV22MNGrKOt4X7g966iaicu414lHAG6l3re9Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：LeonYi，四川大学 计算机技术硕士声明：本文只做分享，版权归原作者整理：青稞AI原文：https://zhuanlan.zhihu.com/p/697773502一、LlamaFactory</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443122&amp;idx=2&amp;sn=93705f3eef230ad38d5fec356d45b0bd&amp;chksm=bf0a11f21e7e1b05857f3d9a440548889f2594463f46b886f0a705141698d49534dd7f6ba2b7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 20 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[RAG框架，都在这了!]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svdiaQBwfseTwGSo2ZeRyAbJ713l9ZQQja45iaHOUFNtMnIQW89NSVAWedxQtDcDTicXGRRRKf4VuVMT07CyhCLaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>RAG 很多人都听说过，或者实践过，目前最直接的应用就是构建智能问答系统。什么是 RAG？RAG 是 Retrieval Augmented Generation 的简写，翻译过来就是检索增强生成。从</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443122&amp;idx=3&amp;sn=089da3f6a5845f9df44208e878e3df9c&amp;chksm=bfdfa7c94a3c61ca3b918783de364eb0080d9b3b0b1f12a680f44df598f19c3edea892088d5b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 20 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[长文本模型近期研究工作梳理]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/G7ia3FZ0o0OqKibjdFWXh2Dl8htHvARZCclaibbTpTrrVbdyicGKSmb9aIblPzWRlEoPKF5znSca77oO4s9NlGEH3Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>© 作者｜彭涵机构｜中国人民大学研究方向｜自然语言处理、大语言模型本文聚焦并总结了当前长文本模型的最新研究进展。文章也同步发布在 AI Box 知乎专栏（知乎搜索 AI Box 专栏），欢迎大家在知乎</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443122&amp;idx=4&amp;sn=86c213c4a4c110a368a8f0f2cad3d779&amp;chksm=bfe7815e4ac2286f8a056bb22363895987a59dff7b7ecb04a3cef43545b38b70bc6c0b196077&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 20 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ACL2024 | AI的时空穿越记：大型语言模型共时推理的奇幻之旅！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiacIDTBwibtYiby36QiaVPV5Rv2pr1ePlLUdmtgiayuY0iczGdPUh1qpQmIWAOz54AKB5RvSgm4Rsiczfzg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：苏肇辰标题：Living in the Moment: Can Large Language Models Grasp Co-Temporal Reasoning?录取：ACL2024 Main</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443122&amp;idx=5&amp;sn=03b294926d4b25251863d03cfb76afdd&amp;chksm=bfd628d022762123ae9d4e53073cbb02700ba74301dd1e67c50e590f29a8dca88cbf1a19a784&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 20 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Gemini大考终于赢了GPT-4o！Jeff Dean连续转发三次！Video-MME首个视频多模态基准来了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLKeMfIzI8ARAQ9lUXlnWvQuO09jcFT5uusor08k2fiaAk4D8Hd7kD6MkwhOMicINbdibuIKVRYT6Xnw/640?wxtype=jpeg&amp;wxfrom=0"/><p>近日，中科大、厦大、港中文等高校联合推出多模态大模型视频分析综合评估基准Video-MME，全面评估多模态大模型的综合视频理解能力，填补了这一领域的空白。Gemini 1.5 Pro在这份榜单中遥遥领</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443106&amp;idx=1&amp;sn=95768902fa4d2b71a0cbf5b701607dec&amp;chksm=bf806b9a3f82efe52a5c0512cfb1989efb4dade6f6f9f2e24e175ad7519f8a1983d47be0f370&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 19 Jun 2024 10:21:50 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[聊一聊大模型应用落地那些事]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLKeMfIzI8ARAQ9lUXlnWvQVrE3V04uMlchTKNgxPoyeDrjJPic9Yne3ZODK3OmBibR2JyUq1cS6REQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：混沌福王，专注于 web 前端技术和通用软件架构、代码整洁、研发效能、复杂性系统 。主页：http://www.imwangfu.com声明：本文只做分享，版权归原作者原文：https://zh</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443106&amp;idx=2&amp;sn=c9483e5d1085eba2bc1dbc3979e2dfb9&amp;chksm=bf9e577335849008e7982a3225a9b0c17292373e3a3a1c389e67eea56dd002d390e9314b50cd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 19 Jun 2024 10:21:50 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM的重复生成和ICL]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW464hE3O3kjib0ecqro2vKP6djQvgPrxODEEl9CeAfoOqFPlysItBzvlZuAkZE1iagWxjvMomX4kjvzicw/300?wxtype=jpeg&amp;wxfrom=0"/><p>LLM的重复生成问题，俗称复读机问题。对于这个问题的研究很多都和in-context learning相关。1.背景在目前这个时间点，其实已经很少会遇到字符级别的重复生成问题。自ChatGPT发布以来</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443106&amp;idx=3&amp;sn=c712434587e7952de7a6e044a4591b1a&amp;chksm=bfeb77ee2fb1f39992049a2227586f9557b4af2d9a32ff17f35a53fe963f3d1f9b7f0c486988&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 19 Jun 2024 10:21:50 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[将强化学习重新引入 RLHF]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2qS3reQqUpolwqaCk04rzkHCgw3RdVl09Hn0PU1WqYmCfNm7kaseJI0RZz9YA7vG06XAAa4ztYn4g/300?wxtype=jpeg&amp;wxfrom=0"/><p>我们很高兴在 TRL 中介绍 RLOO (REINFORCE Leave One-Out) 训练器。作为一种替代 PPO 的方法，RLOO 是一种新的在线 RLHF 训练算法，旨在使其更易于访问和实施</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443106&amp;idx=4&amp;sn=40dae13ec54af9e24fce455fb0d83075&amp;chksm=bfbaea40b31cc49e7eb1bfb7708c5e8dc51bb14a67b55a90d7b2fc5d3028a4fa156014bcc09e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 19 Jun 2024 10:21:50 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【京东】数据/爬虫实习生]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLKeMfIzI8ARAQ9lUXlnWvQ48Co5bDbtEPJ7PdLzw7Qia0Aj50Vh4ia6OWibCnqlfbkGoRXqTQqjvmVg/300?wxtype=jpeg&amp;wxfrom=0"/><p>【京东】数据/爬虫实习生（北京）【岗位描述】1、负责爬虫工具的设计、开发与优化2、负责爬虫策略算法的更新维护、确保高效、持续的数据爬取能力3、负责文本、视频等模态数据的预处理等工作【岗位要求】1、有爬</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443106&amp;idx=5&amp;sn=cec0b0493efe951670dbf26550fef255&amp;chksm=bf75d66bbb0d7c4f2d6443a41b29551f7afa672c4aebf4c7bfaaab561c816a7f65085c505cee&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 19 Jun 2024 10:21:50 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LSTM又火了：xLSTM追平LLM新SOTA，LSTM-transformer混合架构荣登Nature]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIPTfm5Kdc8h7ygWj0ZLNqy38EbWibgzy1c7fq5jrw74NOEAGBfFpKCiaH1KicxzsbGicTP16hu5bgPWQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今年上半年，LSTM火了！LSTM原作者分别提出xLSTM和Vision-LSTM，解决了以往的局限性。同时，LSTM+Transformer登上Nature；LSTM+CNN、LSTM+Attent</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443078&amp;idx=1&amp;sn=5e881cc7d7a10da4381e324dcc8bd7e0&amp;chksm=bf26b3ddc657ed5a8e882b8eee8238d363d6c0f95ef2eed18908b75d9cb12fcea39de30d599a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 18 Jun 2024 02:09:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[模型调优（RLHF/DPO/ORPO）终极指南]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJzORgQ0rkdiaLsSlgRWPGhRWoHy8t50gcmwW1wS9MJDzy3nzvaOWv2DIaMl4IEic0dssEIRSUuQEgA/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：FelixCoder，致力于分享我的编程经验原文：https://zhuanlan.zhihu.com/p/692594519前言虽然大规模的无监督语言模型（LMs）学习广泛的世界知识和一些推理</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443078&amp;idx=2&amp;sn=305eefdb4c20fa0b67d69be9045fb0a4&amp;chksm=bf651c5205aebc00e68242321d330cb5eecee21bdb633ff6d9f1e3d3322b9e9a9f76ece48cd7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 18 Jun 2024 02:09:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[从loss视角理解大模型涌现能力]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW464zkN6dJr2zNWDOFNrfa8CPD4OYPStVKibFJ84K3KlmkwNvDz0RAo8xP9gkANzWmfeBm0hVuzQySiaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>智谱在《Understanding Emergent Abilities of Language Models from the Loss Perspective》中提出一个观察大模型涌现能力的视角 </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443078&amp;idx=3&amp;sn=721ae6d376b556a9e31f2a4e78609841&amp;chksm=bf2ab2931bcc9118a716f5335f539f4515623ab09cce550ceff22f0c437f81eebf8ecc3722a5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 18 Jun 2024 02:09:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Text2SQL之Vanna优化]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgyhb8WbReHb5MddHjdURWXUOzGTg96HeAfAbsIbP8khHXQib3BZ0wsDBAeunAFeE0VdpD86CvfhHZw/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言前阵子写了篇Text2SQL的简单介绍，发现其也是RAG只会，写下了Text2SQL之不装了，我也是RAG最近也一直在做Text2SQL的优化，于是把自己的一些心得，总结于这篇文章。一、优化方向既</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443078&amp;idx=4&amp;sn=8a6bc2291a26573f943d245bf6553378&amp;chksm=bf7235d2ee77f92716b16ace04d79c54b7ad10aa1cc99d8dd103dc314a1098466f3b26878253&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 18 Jun 2024 02:09:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM】PISSA：一种高效的微调方法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGDyPfGLncJOtKrkjA4A2vBTCiawyicrKoRdWb5wOJaOVKZF5V62R2UicBMDDMRja294CtE9qnKqfNA9w/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言介绍PISSA前，先简单过一下LLMs微调经常采用的LoRA（Low-Rank Adaptation）微调的方法，LoRA 假设权重更新的过程中有一个较低的本征秩，对于预训练的权重参数矩阵，( 为</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443078&amp;idx=5&amp;sn=f35550d1a83eb40bd25b3438b7dd75ba&amp;chksm=bfdcea89eb66c3558399cdea10b4f1546056a588cbb2f07878b16c3f9ab7ace72bb02932c0d6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 18 Jun 2024 02:09:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[真心建议大家冲冲这个新兴领域，应届生年薪炒到65W＋]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLrGVInuf8VoGGibMVRoAZdZPPp8Fics0qib1N7WJyDUjDQngMgjRnoqmicohlwOWLnzy98PcOQj8TVIQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着ChatGPT的火热出圈，AI大模型在全球掀起一轮开发浪潮！Google、百度、腾讯，阿里等各个科技公 司，都在高薪挖掘AI大模型人才！不少企业甚至开出百万年薪挖掘大模型人才！！不夸张地说，未来A</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443059&amp;idx=1&amp;sn=a79b82d2a38627268c1668399e281699&amp;chksm=bf57e1674c8945fb7f38a3803f499ec8597ee33b58703773dbb9c67dd28e5cefd6adf2313fcb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 17 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLaMA Factory 实战——单卡 3 小时训练专属大模型 Agent]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLrGVInuf8VoGGibMVRoAZdZSiaGggobmJru7x7CO16YqJZdzGLRk8cE7fLQmtfm6leL2qZuCzg4Xpg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：hiyouga，NLPer原文：https://zhuanlan.zhihu.com/p/678989191引言Agent（智能体） 是当今 LLM（大模型）应用的热门话题[1]，通过任务分解（</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443059&amp;idx=2&amp;sn=80d2a893f03b96dd5f66e7192f5d2584&amp;chksm=bf11c144b796fe7713698ab1c76139a1b8586a185288c872a2a50c9d7dfea507ee8b36f76a22&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 17 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Index-1.9B: 小巧精炼的B站大模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVe9P3cc5EJrhDsDxdBsIHEKVkwSLYpEnGgJ017lEDxB2p8w4CnE67IfibSkOVCr092SVUdWXHmOjQQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言今天，B站大模型团队发布了Index-1.9B系列模型，是Index大语言模型系列中的19亿参数规模的模型，如下所示Index-1.9B base : 基座模型，具有 19亿 非词嵌入参数量，在2</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443059&amp;idx=3&amp;sn=49995054631e7410767bfdbd4c00b0e3&amp;chksm=bf1bcc59c8d41e8fedbd17f768271d1eb9a8a9b2b14cf5355791dd233a0df54ae2b44523b0b2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 17 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型推理加速-MEDUSA]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW464ZcXgG5rb5zXSN3WQ98H5t4EIuaC4GVCxAibZaRFQLbtLA9dW7h2kVsfrdcmzbZy5iaISibGpRrqepg/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前对speculative decoding的做法做了介绍：大模型推理加速-投机解码。本篇介绍一下另外一个热门的解码加速算法，MEDUSA。MEDUSA在不同的训练方法下能提供×2.2~×2.8的解</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443059&amp;idx=4&amp;sn=a045c2fe820e1adb828cfd6dfaca27d4&amp;chksm=bfb3bfe4e24ab90452447dfafa598496f96d4ac1a89e2b35896c94c3e134b8e427833d1ea54a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 17 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【文档智能 &amp; RAG】RAG增强之路-智能文档解析关键技术难点及PDF解析工具PDFlux]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGANq7aTicjwcbibyBibLAvY0gzictbShvYr6iaT7pnaEuoHR9M1BPrIQRAVUQhQEfxZmFyOpXLAPm6Rnrw/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言在私域知识问答和企业知识工程领域，结合Retrieval-Augmented Generation（RAG）模型和大型语言模型（LLM）已成为主流方法。然而，企业中存在着大量的PDF文件，PDF解</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443059&amp;idx=5&amp;sn=74d87faf129bbc55e9515bda1afba981&amp;chksm=bf3ecf1c3e73d80e6926694f3e48c6d0491fa6ebad04c2c6263bce28f52e69106dd66fa2dc75&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 17 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM后端推理引擎性能大比拼]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLrGVInuf8VoGGibMVRoAZdZsI0eykDTVe2jWX2dyqyO7EibrXa51jaX5QyI4WTqsk18ZzZX6pyR2lQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>原文：BentoML 工程团队翻译：OpenMMLab原文链接：https://www.bentoml.com/blog/benchmarking-llm-inference-backends选择适宜</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443040&amp;idx=1&amp;sn=5a751e7ce8c6a19e0764bba08f9b928d&amp;chksm=bf9716bce79c54f66ac14306929dfbb1eff913871fd70ac66370c07ad9eedf75cbc7f150f56a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 16 Jun 2024 03:56:06 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【文末赠书】大模型时代，如何用时间序列与机器学习解锁未来？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLrGVInuf8VoGGibMVRoAZdZEhTcSonsur30UXpH4l1picd0hhqFlacGUoH3aOZanaqWUsNJuDyicCBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>--文末赠书-在人工智能领域，大语言模型（Large Language Models，LLM）特指那些具有大量参数、需要巨大计算资源来训练和运行的深度学习模型。近年来，随着计算能力的提升和数据可获取性</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443040&amp;idx=2&amp;sn=21799e3f725075c6ef4d59eeb0d72370&amp;chksm=bffd309999943ee29b95ed40b84cd5f0c5f8d4edfcacff3534a3fb8299ab32635ff6598062d0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 16 Jun 2024 03:56:06 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Ollama 本地CPU部署开源大模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/4WgILHBwVH90R6CriaBywevOnmQQ6ibN9nWNwibzbee2syNbtR1Hx2Eq2RZS0dy8UOIt9MJ3NOPLPiaib1bOLsUwLcA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Ollama可以在本地CPU非常方便地部署许多开源的大模型。如 Facebook的llama3, 谷歌的gemma, 微软的phi3，阿里的qwen2 等模型。完整支持的模型列表可以参考：https:</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443040&amp;idx=3&amp;sn=b5baf2504c21de81d178bc8356f76bcc&amp;chksm=bf4e39dd839049004e6bdcf1ac5f1c74e40be40f414f0ac9aa0e759b27baa7bdf7d8ddbe0b6f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 16 Jun 2024 03:56:06 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[数据合成方法-让模型自己说出用了哪些指令对齐数据]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5nCvMu19JKoJtyJyApt7SKSnnZoPicb4SN4PKfjf95l4VVBC9301A2UMME2FiaialNeYgA3TBeIsSjKg/300?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面大模型时代，数据至上，如何利用大模型合成更多高质量数据也备受关注。今天给大家分享一个有意思的大模型合成数据方法-MAGPIE，在不需要种子数据和额外人工干预的情况下，挖掘出对齐过的模型自身的指</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443040&amp;idx=4&amp;sn=6b66de9d047aa418cd92c9003f755101&amp;chksm=bf6a72d8d81d5257514258474402649527da9df14e390661f9805f52b71280ad54ab5649990b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 16 Jun 2024 03:56:06 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【文档智能 &amp; RAG】RAG增强之路：增强PDF解析并结构化技术路线方案及思路]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGASKcfJtp9G00sykMjuXXExSOpjZgibV3nZA4WCaUibGI3tHUPdT9HVibyMxXCrlaPOejUcdOticjOWIQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言 现阶段，尽管大模型在生成式问答上取得了很大的成功，但由于大部分的数据都是私有数据，大模型的训练及微调成本非常高，RAG的方式逐渐成为落地应用的一种重要的选择方式。然而，如何准确的对文档进行划分c</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443040&amp;idx=5&amp;sn=8fd04b517df755f7cd7cdaca87200e7d&amp;chksm=bf912d130016a22fb696749ac94ae3586a14c9e6c89b6db4dd73ceb236fbbb26fd394177d264&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 16 Jun 2024 03:56:06 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
