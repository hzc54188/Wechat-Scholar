<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    









































    <item>
      <title><![CDATA[2024 年了，你的长文本训练数据真的够长吗？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIN3EPicAEiay4NMTKLS5LmMluhANuzdTiaia89zJqJyZwf2xUnSMrC6XQka3g4mQXibTPmdnxcx9k1uww/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文标题：Long Context is Not Long at All: A Prospector of Long-Dependency Data for Large Language Models</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443336&amp;idx=1&amp;sn=009f49aeee7e4f4cc5903bf85d2d641a&amp;chksm=bf7a38571daaeb6049c5f3ed8b26df73bbfd99269f1a5a402c61049b7b9d910907493909840d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 01 Jul 2024 14:01:28 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[月之暗面kimi底层推理系统方案揭秘]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuxe5SBIw9qaAr5TDcgtpiaFBaWrEaiczwSogfnx8akps5MN7fibOcQ3F41DuibrT6ezpvvQG9SnGLxGxw/300?wxtype=jpeg&amp;wxfrom=0"/><p>太长不看版（作者大佬自己的在知乎碎碎念）：本论文与很多 Prefill/Decoding 分离的论文不同的是，这套方案已经在大规模集群上进行几个月的验证并证明了方案的有效性。目前这套系统承载了 Kim</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443336&amp;idx=2&amp;sn=ff8a2773a5bb2bbbd2722babf6ef2bb6&amp;chksm=bfa22c96eef8708ae399c328d640ec528c54e41143980fea519e1dbad905081419813f85d588&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 01 Jul 2024 14:01:28 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Hugging Face Accelerate 两个后端的故事：FSDP 与 DeepSpeed]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2q4zkWrSBs9FJnBuEVmExTheMebSct2qta6dqg8hlaqiaIOs7nWZQ8P2F2Pc7GwHMQPfnh7FxjeEwg/300?wxtype=jpeg&amp;wxfrom=0"/><p>社区中有两个流行的零冗余优化器 (Zero Redundancy Optimizer，ZeRO)算法实现，一个来自DeepSpeed，另一个来自PyTorch。Hugging FaceAccelera</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443336&amp;idx=3&amp;sn=5972bcf2e987b2c2b4e424dc1348e7fe&amp;chksm=bf156a5fe0043ddb743f9e9b2c910a81e81d6d4ebc83c017ea8c5b707ff2359b8f0d56423478&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 01 Jul 2024 14:01:28 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Multi-task Hybrid Loss Training：因地制宜，充分利用数据信息]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKpvTic1FcPFgVHjqObjWIIrlIOibLSmPY0ibtRApXlKDjTviag7LRiamOyLF4l5ulJ4SMIsqQkkskDWn6eg/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲‍‍‍‍‍‍‍‍‍‍‍‍1 简介2 Multi-Task Hybrid Loss Training    2.1 Retrieval and Reranking Loss    2.2 STS a</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443336&amp;idx=4&amp;sn=50cc9b707353fdc001400cd192d70bc6&amp;chksm=bfe6d841966147d69de2b885bfbc190161b2f7c039db8ff8169ca3acdce25333c7dd62e6199a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 01 Jul 2024 14:01:28 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[深度文本检索模型：DPR, PolyEncoders, DCBERT, ColBERT]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BAVX0pafImm4UvL6oG2x5VZurZKMg8vptiahHX4YFCVqBFyns9n6iaXCjvAGLlfPSU7fqqoibeOjXHk9McDzVoHtQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>文本匹配与检索是NLP中的经典问题，主要研究两个文本的主义相似度，通常用在检索系统的召回阶段。传统的召回方案如tf-idf和BM25具有速度优势，但在语义匹配方面有所欠缺。随着预训练模型的发展，使用深</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443336&amp;idx=5&amp;sn=2884c1d7434f2fc3d0d493531e67f213&amp;chksm=bf8d00a4a422b72150f3f455320b381c5af97b2c77bf3cc8406ef035a9976b5179de304c29d9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 01 Jul 2024 14:01:28 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[GPT-4o炸裂登场！大模型仍是最大赢家！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIA1W521D3d1eUZQOGBDKA1TFUwJMbRVLPSZQfr3eHrHb6ESLiadNoyNOTLKCfb60WfV6y6e4eKBicQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>从一年前ChatGPT突然爆火，到不久前文生视频大模型Sora以霸屏之势吸引全球舆论，再到OpenAI发布的王炸GPT-4o，与AI大模型相关的议题越来越多地被大众所讨论，如果说2023年的大模型风暴</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443290&amp;idx=1&amp;sn=bb3c4a517629f9e59813573a88739704&amp;chksm=bf6095931c0fcd88dee71c6baa0a18f9ddc41033ac0e68de1b4538f419cffac7c7cc11094bae&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 27 Jun 2024 01:29:31 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解MoE是什么，以及大模型为什么需要？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLJafiaSCI5sfmEUB5x6SrRIeeOl3SlH6k8EmeCRL2ZocFSPic1r6UH0SeX5IKfTVrG7SG1LBge3ic1A/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：蓟梗，北京邮电大学声明：本文只做分享，版权归原作者来源：青稞AI原文：https://zhuanlan.zhihu.com/p/694826485MoE，全称 Mixture of Expert</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443290&amp;idx=2&amp;sn=a5674706a2ebcca8333b211056c0959b&amp;chksm=bfd87467e0d91df52062ecfcccba56f3ccb9dd81ad55372661ea4693b2f80f101353f8d2e463&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 27 Jun 2024 01:29:31 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[更难、更好、更快、更强：LLM Leaderboard v2 现已发布]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2oQRQku1E1icBklls2AGo56twsHe2nQCfJVZxJKIQhibRNXeD1FatcFd10bzsDfNRfUQU4zibxuKlL4g/300?wxtype=jpeg&amp;wxfrom=0"/><p>评估和比较大语言模型 (LLMs) 是一项艰巨的任务。我们 RLHF 团队在一年前就意识到了这一点，当时他们试图复现和比较多个已发布模型的结果。这几乎是不可能完成的任务：论文或营销发布中的得分缺乏可复</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443290&amp;idx=3&amp;sn=309c93fae0d036fc98b2750eed7bd734&amp;chksm=bfa5f920e199a11d2ed744c49c68aba63085035b57baeec28c6d0bfca4ded20d3e241df8765a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 27 Jun 2024 01:29:31 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【RAG论文】通过HyDE提升检索效果]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVeWCCMYFhPDicrl1ufG0TibKmBzoKdh4RdaxTc8CbYZgEsuvXqJibpgvUoibESo5H2texbkdSoNrxu4wA/300?wxtype=jpeg&amp;wxfrom=0"/><p>paper：https://arxiv.org/pdf/2212.10496code：https://github.com/texttron/hyde这篇文章主要做zero-shot场景下的稠密检索，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443290&amp;idx=4&amp;sn=80d314463d570591cca8edfab7945db8&amp;chksm=bfb3576c3d4c703b375819bcabcc2206a97610f6fa5f2c4bb8f12d9dae88e4d2977320f1a68b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 27 Jun 2024 01:29:31 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【TKGQA】关于时间知识图谱问答的一篇综述]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGDiaDkY5InpbL3LmQibUDMgbKDzjwJoVdDyOnx3elxzPQtXX99YSPXs4S5EfjR9ITD53py3htZiapjXw/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言时间知识图谱问答（TKGQA）是KBQA中一个关注时间问题的重要子任务。时间问题包含时间约束、需要时间标记的答案，反映了现实世界事件的动态和演变性质。一、TKGQA1.1 概述时间知识图谱（TKG</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443290&amp;idx=5&amp;sn=9fb8e519de23339d3886574a7ec7d15c&amp;chksm=bfe636a74e81b7ba67b0db691ad9d7299ba24995c0c45f9aa82667e0838668d8b870ae5cd187&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 27 Jun 2024 01:29:31 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[无需人类标注！在环境交互中实现LLM的自我进化]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIA1W521D3d1eUZQOGBDKA1ZZUxaEDXycgsxLY81SmvBHuugKdzIIUU3NuXvoicsiaf6sHlB5KYqtzA/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文题目：Interactive Evolution: A Neural-Symbolic Self-Training Framework For Large Language Models论文地址：</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443269&amp;idx=1&amp;sn=d0cfd9ac4bbd16e0e4ec0313cfe210de&amp;chksm=bf2db3facedfcc25b588d093ef30a98ca36786522949d67681a87f38ede24c70094b7dbfaa37&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 26 Jun 2024 13:38:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[文末赠书 | 24岁提出图灵机，38岁定义机器智能，70年后重识图灵，人工智能之父的传奇人生]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIA1W521D3d1eUZQOGBDKA1u7cuf7VibTcGsJwtboQO0EjGWHoCylcw4facUVScibGK6o9xtTBEUShg/300?wxtype=jpeg&amp;wxfrom=0"/><p>“Sometimes it is the people who no one imagines anything of who do the things that no one can imagin</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443269&amp;idx=2&amp;sn=d5260cb1f9805a527fdca8c0dba7a736&amp;chksm=bfb31bf60d5b0dac7ef89dd6cc2ed412c9a35b1b52695e0bf7b24c8c5db4073dc8ef027a109c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 26 Jun 2024 13:38:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[RoPE的远距离衰减]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW4679JTaaic8JeQ9vIJWaa0ibc1hkIP2sfZ3zDTPjC3MIvQicGJugybnGAicgOYDFR8tPiaRpUtQRaN6nohQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>有朋友问到了关于RoPE远距离衰减的问题，这里给出几个示例，提供一个直观理解的视角。之前对RoPE的梳理参考 理解LLM位置编‍码:RoPE。1.公式回顾一下RoPE的实现。RoPE通过在q和k上分别</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443269&amp;idx=3&amp;sn=cc73685229140fe3f46b016719738ec6&amp;chksm=bf280f675bcb5ba64b31e34e0ecc9ce829eb1db9c4e8f64dd750a758636004e9a7b740934e71&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 26 Jun 2024 13:38:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型面试之MoE高频问题]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/s7YKINJYHDBtI8xU7iaZibGqQEZwaQ0HZ3QIsTkfFs0rYV2nlicwnJJArvZbRrETzucS3LAicF9n6b32lkXzChZU0Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>MoE原理回顾MoE 是用稀疏 MoE 层替换前馈层。这些层包含一定数量的专家（例如 8 个），每个专家都是一个神经网络（通常是 FFN）。然后，路由器/门网络负责选择要使用的专家。MoE 的一个显著</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443269&amp;idx=4&amp;sn=2c44520e8be9e9802f4690854645dcda&amp;chksm=bf184abb03f9e6525c84cda9b744e5390bad8ab26bae9106be2ce6854252588736fe29006b12&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 26 Jun 2024 13:38:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Meta生成式推荐模型GRs关键问题探讨]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/TnZw73HawgmbOTibiaOFCHtZ51pWJd5iaWU0KqEd4BvMia4p7ibujfINRPOzqicE8ZmnHpsaLrdutzojUSr5KQUYz3lQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>此前我们解读过Meta生成式推荐新作: 行动胜过言语: Meta落地工业界首个万亿级别参数的生成式推荐系统模型，整体工作很棒，但有一些关键问题没有交代特别清楚。在和作者交流的过程中了解到不少信息，同时</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443269&amp;idx=5&amp;sn=144aaf27301fe00b5bf5ee2898896a1c&amp;chksm=bf903272ab4e999cfac48275fc656df769bbbe21adeed4b322c77a24c1955764424d26cbdb30&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 26 Jun 2024 13:38:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[开源论文复现神器：45个顶会都在用的模型涨点方法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKA4I72GEjAecfoKqNcVRhjME6qOQvDGzsIzMQicMdeGGhZjMmOCuftJXzobcvCQbNlIvfm66laxhw/640?wxtype=jpeg&amp;wxfrom=0"/><p>分享一个顶会都在用的模型涨点方法：多尺度注意力。在CVPR2024、ICLR2024、TMM2023都有多篇基于多尺度注意力的改进创新。因为它的应用面真的很广：你可以用它来提升模型的泛化性、鲁棒性和效</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443214&amp;idx=1&amp;sn=b1e3dedb65cbb055169bc40cca4b678d&amp;chksm=bfba5d8aa885bafeaeafab7e12675291c4c616836890b848ce6bec88962b9942a281c4ac6200&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 25 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[解析 RLHF 微调三阶段]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLibibayNrHGUtMw9hxgwib80poW4IBF4icTicNPaxkiaTR7WLTTibuJKCiaBIKAbmXgWoUmKZmfuZvaRPNicQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：暧暧内含光，中山大学 · 核工程与技术声明：本文只做分享，版权归原作者来源：青稞AI原文：https://zhuanlan.zhihu.com/p/646934197现在有很多效果卓越的基座语言</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443214&amp;idx=2&amp;sn=e769042a760488f93ef3717cdf77b649&amp;chksm=bf542eea8fd4e7c5d599864e7961b9c93a2083cf67f009a22627a3a71f86a12c1c73f0b8999b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 25 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[探讨 | 大模型在传统NLP任务的使用姿势]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5kcic6OOuVSoQ9UeTyibKD76MNjlKUjYaD0AdRLQ8icKI2Tc5ZN7geWIrm2T02at9wTvnibw1Ln9Q8ATQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面今天给大家带来一篇震宇兄（@知乎邱震宇）探讨大模型技术在提升传统NLP类任务效果上的应用方式的文章，主要从文本分类任务出发。知乎：https://zhuanlan.zhihu.com/p/70</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443214&amp;idx=3&amp;sn=c80c9ff624ffd1f5c420880984082d99&amp;chksm=bf4c39bfcccc8efbac5624ecc22989976bbba9b050839b1de356e84cd8b486bcb24fcaf84f7f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 25 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[梳理一下MiniCPM]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW465vmMOy49qO5fMicWz8iaXtGMB12lAHlx1bDia7Q31UYANFTK7oA3Q2IUN2GjqkF1GoSPJ7fg65BrGicQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>MiniCPM是面壁智能和清华开源的模型，MiniCPM开源系列包括非embedding参数为1.2B和2.4B两个规模的模型，以及对应的MiniCPM-DPO，MiniCPM-MoE和MiniCPM</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443214&amp;idx=4&amp;sn=f68b7098b0c500b20ecf7035fbe35475&amp;chksm=bffd5d1d3ef6c24892d6f4db122df5d8cd38c1c29dfbc6101862ab04c67a5f726736737cb895&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 25 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen2 介绍]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HIKk7OFDjoTeK2fg6Le9p4ccn1cYdojkIfVeYia4kb1FuImAhL8030vSDJIFrDuHZicrkPm1mjaPgUq8ryN30Spw/300?wxtype=jpeg&amp;wxfrom=0"/><p>2024年6月7日 阿里发布了最新的Qwen2系列模型：https://qwenlm.github.io/zh/blog/qwen2/https://github.com/QwenLM/Qwen2已在</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443214&amp;idx=5&amp;sn=b96d71051465be552a70ca69ced1fd62&amp;chksm=bf3dcd0cb27ea4706c473af9e7da7df0808969185a7c32aa0f62f67e7f5b2d2761676743dedc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 25 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
