<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    




































    <item>
      <title><![CDATA[有了大语言模型后，知识图谱该何去何从？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKU0UKq6plqwwTlhlgjK1l1SvxJRpNuPpp2D1MSNZPEymYZY2O5oWKUQHwlPvNjQX4dXddgAA7Jog/640?wxtype=jpeg&amp;wxfrom=0"/><p>进技术交流群请添加AINLP小助手微信（id: ainlp2)请备注具体方向+所用到的相关技术点关于AINLPAINLP 是一个有趣有AI的自然语言处理社区，专注于 AI、NLP、机器学习、深度学习、</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444540&amp;idx=1&amp;sn=495b30598f728b064b28ef85617b9348&amp;chksm=bf48cc129eca17fe6b4343df742c374b7ac626df3387f52a61afd67dba157b881ba6aa2eb2ec&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 06 Sep 2024 08:53:08 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[LLM是否具备天然的探索能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/d6902wUyyvJZa8Wdlr3g5ib2qhKQ5tDDic3bFIVc4EuMyJk0EWr8V2EoWfqANSRF9WZGMicE11Uqahv55TzzlNgGQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言今天分享一篇研究大模型在强化任务中的探索能力的论文《Can large language models explore in-context? 》。探索能力是强化学习中非常重要的一环，虽然在RLH</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444540&amp;idx=2&amp;sn=153100af4dee5e6c6ebe62353f2fb27d&amp;chksm=bf3da0857e63d1ebd50bb6ec36ca8b75c9765e3ecec0cf6e7111914285843b5b31dc91a273f4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 06 Sep 2024 08:53:08 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【LLM模型幻觉】LLMs-模型幻觉-腾讯LLM幻觉综述-20230924v3.0]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdD5NMibf8YiaAuBlh1xnpxgUGoaYQplhTQjic0u9PxRgxkV4XibYBkdT91X0GoVibMjlic9aYEclzpiciaMZQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM模型幻觉第三篇，分享腾讯AI Lab大模型幻觉综述：Siren's Song in the AI Ocean:A Survey on Hallucination in Large</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444540&amp;idx=3&amp;sn=74ce4294b1ac51f8a726e7538a0329e8&amp;chksm=bf18500084bbd8ed8d43397fc5971d7e91a50701128f9301711e8cdeb76fca98c0a8c8df2cf5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 06 Sep 2024 08:53:08 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[轻松构建聊天机器人、准确性新SOTA，RAG有了更强大的AI检索器]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKU0UKq6plqwwTlhlgjK1l1IO5Ltd9DO6JgZxTT4G4oXPlbkMtNUbOzwkNuahK5KbC5FR9hLARNNg/300?wxtype=jpeg&amp;wxfrom=0"/><p>黄志恒拥有爱丁堡大学博士和加州大学伯克利博士后研究经历。志恒曾在微软、百度、Facebook、腾讯和亚马逊等 IT 公司工作。志恒在亚马逊 AWS 担任首席科学家领导了 Amazon Kendra 和</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444540&amp;idx=4&amp;sn=9b1a264a1a0ddbbf950265dd176c22a7&amp;chksm=bf4821667628a885de609fa771db912c271c500fc7a7f09fd446c2dd3401df46e2f85c02015f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 06 Sep 2024 08:53:08 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[分类中的语义一致性约束：助力模型优化]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/BwrOLGIZh5XCoez6Jjr8WgySXWytwxLUdC5BpibpGnTPxicyZwLBYYaYs4vM7EW9nrlofyWD832AnWhmcOtKpkBQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言这里介绍一篇笔者在去年ACL上发表的一篇文章，使用了空间语义约束来提高多模态分类的效果，类似的思路笔者也在视频描述等方向进行了尝试，也都取得了不错的效果。这种建模时对特征进行有意义的划分和约束对模</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444540&amp;idx=5&amp;sn=b234f924e42eea8f762cdc886124aabd&amp;chksm=bfd469d600c7944666e046cd7e0589a4c815fd7661aa3ec6e4aa8f03984b0302f493cd377c03&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 06 Sep 2024 08:53:08 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[学术顶会变成了“大厂”顶会?]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJBLyicqPallBV0pRpk8sJOqmDYmrCJx9438ebhmUE9FJ78PD3kw97r39IauIH7V5eoeArjCIIz34w/640?wxtype=jpeg&amp;wxfrom=0"/><p>万物皆卷的时代，升学、就业的竞争越来越激烈，想要保研、申博、进大厂，没有高质量论文在手就相当于“裸奔”！尤其是这个人人惶恐又内卷的时代，想要抓住点什么来增强安全感。有一份拿得出手的成绩——发论文的数量</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444519&amp;idx=1&amp;sn=60ce42e7940e0105e39658cad0200f01&amp;chksm=bfe451e71d1a54c8ce40da607bd0ce4e00348241d1a90dfbbffb44f4d0a8523d79c569b66dc8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 05 Sep 2024 02:09:40 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024大模型秋招面试被锤大赏！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJ9GBPficA5Jic2DRh4YOKNThn2yZjh0c69223hGX9uakmcJJLVu26XXIgLTRQ95ibgpD1ZFzGzuFN5g/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：rtfffhttps://zhuanlan.zhihu.com/p/717917077转眼9月了，秋招不知道条有没有过半，只是大致投了几家感兴趣的。（当舔狗是没有好下场的！）。浅浅罗列了些最近秋</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444519&amp;idx=2&amp;sn=ca48f9fd64e46afd3e5de83654c22d23&amp;chksm=bf7212664a333229fd81ab974540fed9795a32a23e9ef71e4fae087627f55b2691cc9b0e97fc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 05 Sep 2024 02:09:40 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[长文详解--LLM高效预训练(一)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW467DiccdD8p6cYiciaP4suWuvWYIqH6PEyQVQHvoWJh5BjUfOseogFNfQombdERR8czXt6M4x4zY8cNLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>大模型在生产和生活中的应用越来越多，这对大模型开发者来说是利好消息。不过随着应用场景增多，对大模型的需求也多种多样。比如有些场景需要参数量为5B的模型，但是开源模型中正好没有这个规模的；也可能有些场景</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444519&amp;idx=3&amp;sn=cf025169791d423a3ced76dbbe74df31&amp;chksm=bf24665b24fe8f4e5ef79f8c6c11a3cd4692a2c485478c00630247e7d061ad64d6af359b97aa&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 05 Sep 2024 02:09:40 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[基于骨架的AI连笔书法生成的一些启发]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/BwrOLGIZh5WJAiaKicPHrebB1DG2KTJq3fjf9CCt6WicReFegsQpavkI2z5Lo8VEtwoK9B88vicBYzlCkVQxEd66eQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言：这篇文章是笔者之前AI手写连笔书法生成的一个工作，是联合中央美院几位非常知名的老师完成的。当时提出的思路相对简单，主要结构是基于对抗生成网络（GAN）。虽然方法在大模型横行今天可能已经不算太新颖</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444519&amp;idx=4&amp;sn=cf7aea2aaabcc20ed85e0dfc0b83b20a&amp;chksm=bfb41c3b3a54bf60050f6d78334f0dfc6d632acba525fe063b88636ec829b5f1dd37fbfe8a0f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 05 Sep 2024 02:09:40 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ACL2024 | LLM+RAG可能要毁了信息检索，一份深入研究]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajx2W5iciboKvJicT1rGVWkuYoYZDCcrwGR8OQTickc18vRHss6OM3d915tpI7tZ6tJ2yU9mMWPvcxciaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：[ACL2024] Spiral of Silence: How is Large Language Model Killing Information Retrieval?—A Case St</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444519&amp;idx=5&amp;sn=9e3a9cc7949b5e28106d0b9215c12820&amp;chksm=bf220891b8fa482f5a165b40c1935107329b7ea2da503d0b862522554f9aab17a45047bcccc2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 05 Sep 2024 02:09:40 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM最新黑马：Transformer时序大模型来了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJ1UV8Uv3UQgXW2OMNvMdSB8vQSAO6yvzicH3E3Kos8HaxAozGTJMcEuWv7XA1ibyn83e2xaH0SPx7Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>时序+大模型开始火了，大家最近关注了吗？在ICLR'24、WWW'24、AAAI'24、IJCAI'24等今年的顶会上，都有多篇时序+大模型的研究入选。时序+LLM的潜力非常大。首先时序的应用面就很广</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444500&amp;idx=1&amp;sn=e9197080daa6caa00d330846d40a767f&amp;chksm=bf1f47fc65c3b8dbdd474c373908d0c977b910a52c4c78dd13cf1a5f99779854ca4f13d41f02&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 04 Sep 2024 02:07:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[55个大模型比赛汇总]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuyqYdr1xCdIxOBycEubQh9TlKKahy7QicB2hQ7CXic5QXWSg18OUI1rcJWBKLF7Jz5rLiby8TIKfOGOg/300?wxtype=jpeg&amp;wxfrom=0"/><p>砍手豪(授权原创)链接:https://zhuanlan.zhihu.com/p/717365109目前的想法是收集尽可能的多收集市面上的大模型算法竞赛，后续再从这些比赛的应用范围以及获胜方案的视角，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444500&amp;idx=2&amp;sn=64d0078ca22e53ec0cc259bcf403b832&amp;chksm=bfaa3d778a8c5c6897b1cc4864267cdd442b094447578660f746bc8b68586033127e8b2d3919&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 04 Sep 2024 02:07:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[GraphRAG综述来了~]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahibmq5xXBZEg2DnZ2t6DSicXXEfxIHXKwdTMGjuUfRcg3TBGSiaOePrHPsV9VzXqGVHaWMKfkufNPAg/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：Graph Retrieval-Augmented Generation: A Survey链接：https://arxiv.org/pdf/2408.08921研究背景这篇文章要解决的问题是如</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444500&amp;idx=3&amp;sn=591d7188e010f122029b0e89d2bb25f4&amp;chksm=bfc82a875d0a60c6ec8018ed2c23b34582ae10f078face9c9956be1f78befec03d9d2ae6b3e2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 04 Sep 2024 02:07:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【RAG】WeKnow-RAG：融合Web搜索与知识图谱的自适应检索增强生成方法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGArzYQQPduicafLWcqG643oPyDHiaY7gyvj3a7EdxrKjzb4ofibsTLluIpK1ic9SO5q8WpA6vicIa93fhg/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言往期文章介绍了《【RAG】混合RAG系统，提升复杂推理任务表现》，本文再来看看KDD CUP2024的CRAG的第三名方案，该方案提出WeKnow-RAG方法，结合了知识图谱和基于Web的RAG技</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444500&amp;idx=4&amp;sn=2faadfb62f0413ccd26848dfe3af00b9&amp;chksm=bfb19b4d301f793873f6c7f47e7710f5df6260d8c7aaba42ceca51b1297644bc342b254c1a77&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 04 Sep 2024 02:07:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【保姆级教程】如何在Win11上搭建一个GPU环境]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVfQYaBj6VxwoQNDeUyenPQDxvTicIC4gMYN1PelmgJW2hYM9wticFMNtFIFe0gZjYl6BDtrQRA8lujw/300?wxtype=jpeg&amp;wxfrom=0"/><p>unsetunsetCUDA和CUDNN安装unsetunsetCUDA安装下载对应cuda环境下载链接：https://developer.nvidia.com/cuda-downloads，图片下</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444500&amp;idx=5&amp;sn=0f035a4ae03c42946675044719ecede3&amp;chksm=bf68ed2623220b29bedb206b1377b0a01aa96b1abe74a2ebc3b73f996bbdc643d0d8a35179c8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 04 Sep 2024 02:07:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型实战！从0构建一个功能完备的RAG项目]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL0QuKNxzYruAYPLOMohXq1FoK3h7nEScP2dmLnKKdzdoOkft0j9Wo1zVT0Viaa9IdsNETttmaa3gA/640?wxtype=jpeg&amp;wxfrom=0"/><p>大语言模型 (LLMs) 的应用面临的挑战有：领域知识的缺乏、信息准确性问题以及生成的虚假内容等。检索增强生成 (RAG) 技术通过引入外部知识库等额外信息源，将传统信息检索技术与大语言模型技术相结合</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444484&amp;idx=1&amp;sn=a120e85653d22c8e14c2ee885bbeab4e&amp;chksm=bf55812da848ef79bb99f650d86c67eb0be00cdb603b1c918a77c5d79a01e6b971e1eaba605b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 03 Sep 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[入坑大模型18个月的反思与贩私]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJ1UV8Uv3UQgXW2OMNvMdSBrjt7ibEQT9DiccibKx32jpou6N8Z0DHbeKia3GFB8r3Szw6LdGXWEKhHGg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：Minogamehttps://zhuanlan.zhihu.com/p/71740269前几天开完一个有高层参加的会议，会后组里的技术大佬直接就开喷“要规划没规划，整天只知道对着几个糊弄老板的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444484&amp;idx=2&amp;sn=d17243d07902a167f4164f86b977846d&amp;chksm=bf929a58da482179648d945900d2f3f176e1cdb1f4f5c00a4534138e7afdb163211171fbfef1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 03 Sep 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[IJCAI-信也科技杯全球AI大赛-华东师范大学亚军队伍分享]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVdVz9WXWwCeWTCjdLTQ1bNxkViaiakpSa4nCiciaPuSAX698oehqQgqWa6oSQKUFDiasibeSnq6soz8U2Ig/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：彭欣怡(找不到工作版) 华东师范大学; 马千里(搬砖版) 虾皮;
指导：闫怡搏(科研版) 华东师范大学 比赛链接：https://ai.ppdai.com/mirror/goToMirrorDe</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444484&amp;idx=3&amp;sn=28c44881bb604cd70e347803c04986fa&amp;chksm=bf47b40d9efcb2388a3f8dd662835357e183aaaa723ffcd993d9d90806eb22e085f99eae55b5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 03 Sep 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM系列 |  解读阿里开源语音多模态模型Qwen2-Audio]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/w3hibrVDUAib6ZOJpkvcKQibZ8oreKAJYn5ddyLm7dW0V5t1Lh651rRlPRqzumS6LOQ0VemxbzjkO74a4WgaCCJHQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言模型概述模型架构训练方法性能评估实战演示总结引言金山挂月窥禅径，沙鸟听经恋法门。今天这篇小作文主要是介绍阿里巴巴的语音多模态大模型Qwen2-Audio。近日，阿里巴巴Qwen团队发布了最新的大规</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444484&amp;idx=4&amp;sn=b2a4bc362720fd43412f5c7d70bab097&amp;chksm=bf5e71bc57575b963a3a1fb37fa3e959f34536f55f1651e6fbba6404ef9b519455c88793d5d8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 03 Sep 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM之RAG理论 |  RAG和Graph RAG对比]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/N5aX12H1SiclcTWL7ibiakNTLe7aVqDe9vhaDtmP7Dtic0DYlGI2eSD0kE9eictQnaXHI52IRWTb5dGIfibUOoBUaHsg/300?wxtype=jpeg&amp;wxfrom=0"/><p>     最近Graph RAG非常火，它来自微软的一篇论文《From Local to Global: A Graph RAG Approach to Query-Focused Summariza</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444484&amp;idx=5&amp;sn=015dff2608a9906e0afaa304d888b066&amp;chksm=bf0fe090f70d52e95e4f63a551675a6eafb43b6462dc205e4ae06ddd284c8c6187f938e617b6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 03 Sep 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[AI 之王 GPT-6 猎户座 来了！大模型杀疯了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL9USXuo7TZj4klLIpC70xibrqUjGNHGJ9xNsG15WEoRcnvOOrD4uQ3jaaEcxiaKGxqvMPkzWXeruAA/640?wxtype=jpeg&amp;wxfrom=0"/><p>OpenAI不装了,祭出大杀器！新的AI大模型 "草莓"（Strawberry）和"猎户座"（Orion）。值得一提的是，OpenAI还计划利用"草莓"生成的合成数据来开发最新的大型语言模型"猎户座"</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444462&amp;idx=1&amp;sn=be983211ea6d95d9b372ccfaf02771e2&amp;chksm=bf6077b55b9ce290c0f8352162508192aa1db49d808b7823375ab2708085826cc4f3851783ce&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 02 Sep 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[如何估算LLM推理和训练所需的GPU内存？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL0QuKNxzYruAYPLOMohXq1dMiclTYicfroTiajrV9qDYrzRLqHgk0wibCFoicaicrHFeL5bWHz9mend4Bg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：孙鹏飞，南京大学 · 计算机科学与技术原文：https://zhuanlan.zhihu.com/p/716317173在实际工作中，经常有人问，7B、14B或70B的模型需要多大的显存才能推理</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444462&amp;idx=2&amp;sn=5967d81909a8066a01c5fe3b04cbf545&amp;chksm=bf68ad35b401f2de4ab301189734a7c418969cbcdd11dc76735ebb750f39af34300585012c92&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 02 Sep 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【超级对齐】CriticGPT: LLM Critics Help Catch LLM Bugs]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/d6902wUyyvJ6XPVaDJWZibt0y2cje3a4icicQjd17LdDoZFJlse28gAWU538gh35uAzR3KSfZkP0oHvoJNXbib27GQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>超级对齐类似ChatGPT这类大模型在构建过程中，在对齐阶段仍然需要大量的人工标注数据的参与，而最终模型的性能与标注数据的质量极其相关。当前gpt4在个别任务里面已经超越人类，大多数任务中的表现也很难</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444462&amp;idx=3&amp;sn=ce609a2bc9812784243c48612753ac41&amp;chksm=bf7a6e4a6646a0631d833a64e5bb3d5080106dc2bf4b4a1c98e4111004459cfbe7e4f451eed4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 02 Sep 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[KDD 2024 工业界搜广推工作整理]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/TnZw73HawgkBgfCQbvrVZ8dKgNic34PYAzqib458icuzWknmzR9g69LPsuuatZKLVysGoAeB8LU4ickJeMNyOBhhyw/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，KDD 2024论文新鲜出炉，整理下工业界搜广推方面的工作。文末还整理了大模型相关的搜广推工作。排名不分先后，由于工作较多，存在遗漏的可能。AlibabaAlibaba工作涵盖面广泛：推荐上，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444462&amp;idx=4&amp;sn=ca976242655a5190ab34a5deaa8135de&amp;chksm=bfee96671b12338226f5c06ca66fd34277b186e6b6f9fdab07cca21d23a502c51edb4f05c1be&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 02 Sep 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen2-VL：Qwen系列已在开源的路上一骑绝尘]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5mISTgTBRotAFockGXIkpnyIJib3vPczAVQmVE6yBHYCzDJOvnCe9gJWfQVzwZ0XBcRAib8gVejKpEw/300?wxtype=jpeg&amp;wxfrom=0"/><p>良心Qwen，开源了Qwen2-VL的2B和7B，72B需要API调用暂未开源。该说不说Qwen系列模型真的是在开源路上一骑绝尘，全全全！vl、audio、text连续更新，kpi直接拉满！HF: h</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444462&amp;idx=5&amp;sn=e057c8abea98f13af2cb2326d1254cd8&amp;chksm=bf498fb6bcbcf4699948895adba007a9e595855b1567ec0cad300f672009b5f36fbbb71a5571&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 02 Sep 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[如何解读 Yann LeCun推文建议学生不要在大模型方向工作？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKX3fLUSrGjMUgIT8L8ZeWSrBhcHAPbWh2J0SPmJ7jiaEjYluK1wkFrlAhRAia4vEic6e82MNqQq4VCg/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：摘星狐狸链接：https://www.zhihu.com/question/656903686/answer/3527956804Yann LeCun的建议说得很直白，LLM已经在大厂手里了，作</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444448&amp;idx=1&amp;sn=0b86be0b36082e11ce5dad936aaded18&amp;chksm=bfaf6f51c3457e3186db84fe79fbfcd92c156356493fbb1ddad84600a56aadefafa0fc11e3b9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 01 Sep 2024 14:16:09 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【赠书】AI for Science：人工智能如何重塑科学研究]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKX3fLUSrGjMUgIT8L8ZeWSECZzLwcmfr08kdhPH74pEwic026ztTIqNgUF6u1HAB3rREuWrRhaTqw/300?wxtype=jpeg&amp;wxfrom=0"/><p>--文末赠书--在古希腊神话中，工匠之神赫菲斯托斯曾打造出拥有人类意识与智能的黄金机器人，这可以被视为人工智能（AI）最早的思想起源之一。此后，人工智能的影子便无数次出现在人们对未来的幻想之中，但也仅</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444448&amp;idx=2&amp;sn=cfe7f2132c8a587ff34cad17fafdb94b&amp;chksm=bf9e24495e47fa5cf28a6c7fb86865ff7634b720631f812eacb9650a16057e0756ee6d71ce90&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 01 Sep 2024 14:16:09 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM模型微调】LLMs-微调经验-LLaMA微调指南v7.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdDO4yUOGegp19peWnYgbVibF6LPfaibM4icSia1fOpM2KQ2MQiao92z2sRsHj6nYTITJfjrGCBNWh7pAlQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM模型微调第七篇，分享Meta于20240807的开源三篇文章：Methods for adapting large language models，To fine-tune or</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444448&amp;idx=3&amp;sn=25e2b7456d733a2243df30fe5a40a22d&amp;chksm=bf2584472ea8653b3f0a5bfd3a97d96171b5f1b7af5172708c0c2f3585b622709532dba24f45&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 01 Sep 2024 14:16:09 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多模态大模型: 盘点&amp;Highlights part1.5——从LLaVA-NeXT到LLaVA-OneVision]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jT5Sp7MICPygPdaZeYpHjmrxT0eFO8NA7ibcuP6ehGBKptWAXVto2GzciaHDQShJkcAvqmzsj2dTic4I8mJvtykww/300?wxtype=jpeg&amp;wxfrom=0"/><p>Hi大家好，我叫延捷，是一名计算机视觉算法工程师，也是叉烧的老朋友了。我们计划发布一系列关于多模态大模型的文章，帮助大家快速、精准地了解多模态大模型的前世今生，并且深入各个多模态大模型领域优秀的工作，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444448&amp;idx=4&amp;sn=e94ddd090f058c74b66ccd0958ac444a&amp;chksm=bfa4b3a40b217aa9e19ff398c56cbf23b8b706237fef313d6b7d0aaaa7e684d57769947fbd5a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 01 Sep 2024 14:16:09 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[样本权重对深度学习可能没那么有用？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/QLDSy3Cx3YIfxXUuLHTibgcBCMTibfW2OaYk9reicHMhy5jmxlEABjZ6HkZTqgoPPsopTgqLicg0xOpAgrRWkK5nHA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在上一篇文章中：机器学习中的样本重要性权重 (Importance Weight)我们通过简单理论分析似乎说明，使用目标分布的先验构造的样本权重，可以使得学习出来的模型更加贴合目标分布。在“回归问题中</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444448&amp;idx=5&amp;sn=9eaf6e33aa50abd19abb0c0cce6eb0bd&amp;chksm=bf7c8e627cb9da613e34273e5c46f16213aaad48762167419fe609d442c33a37de6678b6353d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 01 Sep 2024 14:16:09 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型微调终极指南]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSI3KiaZyOrB7CBgPJOfvicKO3rVkyYLss0X8f82uiaxs4hmQXiaa5FKlHceqR839IBhFWKOR1EzSKnvMw/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来一篇大模型微调相关的最新综述，主要大模型微调归纳为7个阶段分别为数据准备、模型初始化、训练环境配置、模型微调、模型评估与验证、模型部署以及模型监控与维护。Paper: https://a</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444428&amp;idx=1&amp;sn=c063aeb1c800622c85bf69a759633bbe&amp;chksm=bfcd8fa9f8b98c8f3fce64b111473add241a94bd8bfd73f4a0d47bc3350fd78854c24010d3c6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 31 Aug 2024 14:45:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[校招生做大模型，选预训练还是SFT？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIURkEnvhgvAZACdIicTK4TtdhVoxV0eNwFxodzKOiblVsHzxibx5mvibfEH3ht3cMFJl0d7XOk7yoqiaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：ybq链接：https://www.zhihu.com/question/635761315/answer/3608088928我推荐选 pretrain，理由如下：pretrain 提高工程能</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444428&amp;idx=2&amp;sn=4ff95d3b5f12e40b66489dc2a8631c98&amp;chksm=bf1814efe9072eb6d6e5bc25edfd11e04da052ca55b9c3e90ce4be5834a562220599db229793&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 31 Aug 2024 14:45:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM模型幻觉】LLMs-模型幻觉-大模型幻觉缓解技术综述-v2.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdCw4YiaggpSvfJiaYksAg6eE1jgTE2V4GyH5UjnXPIg8pj1xBV2tk2gIkB0XG8D2TfIBOmcF6NTfo8w/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM模型幻觉第二篇，分享大模型幻觉缓解技术论文综述：A Comprehensive Survey of Hallucination Mitigation Techniques in </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444428&amp;idx=3&amp;sn=aa9d7a9948363df436baec7c5d341259&amp;chksm=bf57fd1cbf0dcb760ed52547d8a90f0e90cfdc6c83cea6e8fda31d224bc38e9cff9acfa66349&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 31 Aug 2024 14:45:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[prompt综述的解释和个人思考]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jT5Sp7MICPwicoQDRqib3uEVs3f20oIQJia8uQTRbfs168aKszsyKAT5ibg8AIfOauqEMRGgPvdJXeZUwbIiaPtYCWA/300?wxtype=jpeg&amp;wxfrom=0"/><p>上周手上不太方便，即使后续好了也没有搞定（不过说实话，这篇文章的量似乎没读完也不好搞定）。最近是有3篇prompt的综述非常出名：The Prompt Report: A Systematic Sur</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444428&amp;idx=4&amp;sn=d2241a200e180232bfbbf30f00a07826&amp;chksm=bfb6ccdc6644f30ed081866ac14d93a79454d1405b44e836aaaccda3a6fc54977bf2ea58d17b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 31 Aug 2024 14:45:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一次失败的实验 - 无限注意力，我们为什么坚持实验]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2rJLNiaUdNmEc0xuDqUIVHcY4fM8usrrw4KJRIl9xYrg2txZjObNQ56y2UtIibHt9BmrpibRuxWYJJuQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>总结: 随着我们增加内存压缩次数的次数，Infini-attention 的性能会变得越来越差。据我们所知，ring attention、YaRN和rope scaling这三种方法仍是将预训练模型拓</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444428&amp;idx=5&amp;sn=821202221df2322d0649f9917035ae98&amp;chksm=bff2c02089793f1ecb9712c51ae269d5007868f2f6e1136fd1b98aa34a1b712a89bff8612a40&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 31 Aug 2024 14:45:20 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
