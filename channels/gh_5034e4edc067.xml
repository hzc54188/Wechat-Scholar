<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    































    <item>
      <title><![CDATA[大模型的基本功]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIURkEnvhgvAZACdIicTK4TtOUC093l7xjQrpru5GeT0uQ9298wUghH1jmZtPBgXCs5ffl4lyO0DoA/640?wxtype=jpeg&amp;wxfrom=0"/><p>Author: [ybq]Link: [https://zhuanlan.zhihu.com/p/716344766]这篇文章给大家推荐几个大模型的练手程序，也就是所谓的“基本功”。先问个问题，除了 </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444410&amp;idx=1&amp;sn=e805ae79fbbba4daf2d5fd066fa921f3&amp;chksm=bfee2ffff1a99fb6b774d7befbd6eee80f78dd5cb0ddb44abd2928a8bc872df3c7d375529a6a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 29 Aug 2024 15:17:11 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[449页pdf！深入探讨大语言模型的世界：赵宇教授新书《自然语言处理：大模型理论与实践》]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIURkEnvhgvAZACdIicTK4TtKNticcLMn7SGPcBFl6fc6pPUHfBe0TANSOeewiaOQkjTCnFFCjmX0Jhg/300?wxtype=jpeg&amp;wxfrom=0"/><p>教材官网：https://nlp-book.swufenlp.group/PDF预览版下载链接:https://nlp-book.swufenlp.group/%e3%80%8a%e8%87%aa%e</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444410&amp;idx=2&amp;sn=285fd97ecd92170f6f7300718441963a&amp;chksm=bf9bc053f1bb630f8f1aa8fc0fc97caef37853e863eda09ae86f597e56d48c4a7eb506868f44&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 29 Aug 2024 15:17:11 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【LLM模型微调】LLMs-PEFT[微调]-QLoRA总结笔记v6.0]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdAGjG6CTCktBa8hUfec1MISxXE7Yvktanp4iaCxgnnEBA0OBfxjop6WPvprmxm29mDJy9nbNAAbxzg/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM模型微调第六篇，分享论文QLoRA: Efficient Finetuning of Quantized LLMs的解读。主要内容有论文解读(提出背景、技术原理，细节补充...)</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444410&amp;idx=3&amp;sn=e35eaf27b0c684ade62a8db04bf5c270&amp;chksm=bf2ae3c8ffa953e805d02fbfc4963824345cb341fd487a7ad4538b36419d38b9af3d44120342&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 29 Aug 2024 15:17:11 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Monte Carlo Tree Search介绍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/d6902wUyyvLjYIwlnRicx0bEVVOnPZ7YGtNv5uwCSDKMibaFfOm0j7vSZUWicwYicvp2Qr5z4MY7Nibuics6rbouibc1w/300?wxtype=jpeg&amp;wxfrom=0"/><p>背景最近Andrej Karpathy在网上对RLHF的吐槽引起了很多人的精神共鸣，总结下来核心就是RLHF中很难定义清晰的奖励函数。RLHF训练的目标是构建一个有用的LLM助理，意味着要处理各种通用</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444410&amp;idx=4&amp;sn=c13e630930d94ced5a1be5a8877c7626&amp;chksm=bf1926c8d4cbcb800bb1125c4813083eeae56da44b963a2352dff6139c59e33a49cc3eaa0d4f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 29 Aug 2024 15:17:11 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[使用重排序（Re-Ranking）来改善LLM RAG检索]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/xicQMWhcBia0I8lib9Qicic5FuYTe9b5UicgtcTgyqPHnILn6eQdPYJ4Oaibm3aC1omXmcL3cF7NofG02QiavmYG5sqicNA/300?wxtype=jpeg&amp;wxfrom=0"/><p>基于大型语言模型（LLM）的聊天机器人可以通过检索增强生成（RAG）技术来获取外部知识来增强大语言模型的能力。这些外部知识可以减少错误答案（幻觉）并且还可以让模型获取到训练数据中没有包含的信息。在RA</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444410&amp;idx=5&amp;sn=150fd9e638808a158bd6c0750b8c59eb&amp;chksm=bf9d0aa6e2c74a799bac44ce0b1ab6b2406936394859105ccab44203f391cd29460ae9b1aa23&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 29 Aug 2024 15:17:11 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[LSTM+Transformer王炸创新，荣登Nature]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIjsADKYbj6sxmhrwk8CcR1WepTGV9ajCQV2Ppc11UwZtq44HaW7TVLegJgJMSUuhYUNsmricWTZMA/640?wxtype=jpeg&amp;wxfrom=0"/><p>今年LSTM火了！LSTM原作者分别提出xLSTM和Vision-LSTM，解决了以往的局限性。同时，LSTM+Transformer登上Nature；LSTM+CNN、LSTM+Attention等</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444387&amp;idx=1&amp;sn=e97c0e309bcd9e3ba37c92af968d69e7&amp;chksm=bf9e521b1ea1def5f31588abf4350331e1e50c21cc7db3fde6499ec826419bbf255b4ee41969&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 27 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[这段时间搞大模型的血和泪]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5m7xaFAUayiclBI8EoHkTF0qotaA06wic167BrLHtuYG63cFgYefd4qu9czkq1Ric56LwtRUQDKZKS8g/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家分享一篇好友知乎@赵俊博 Jake在这段时间搞大模型的心路历程。作者：@赵俊博 Jake知乎：https://zhuanlan.zhihu.com/p/716420396李沐大神最近分享了很</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444387&amp;idx=2&amp;sn=eef3dc84d54b4e9452e7e38f25e06f3b&amp;chksm=bfbe19ec8b95b8a41e7c45410bf703c9172cd9edd6a06a89c1d5579ac50d1c5f5c06849ffd2d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 27 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型知识蒸馏的两种方式]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/vImdeGStOOeLic4Xg0fgSyjt4lgyymYHWD2RKMBKuOJxoVPucFTGsKJh2VKITMcSBmiby8rHJWtxAh9gGibo57XQA/300?wxtype=jpeg&amp;wxfrom=0"/><p>      上个月llama3.1的405B已经发布，除了感叹开源模型效果的厉害之外，另一个普遍的感受就是，跑不动，根本跑不动，没资源，就算能训练，也部署不起。所以很多人就自然而然关注到了知识蒸馏，通</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444387&amp;idx=3&amp;sn=6181d42138f21d4f6920edda1393655a&amp;chksm=bf615aa5ad6380d4e8dc61757dd5e2b7d4b8b00456606f260ccb191f09cb23b4941b12b7ead7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 27 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ggml 简介]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2ouTCuWXvqUCnn5PxnBpBJQ4JN2AouvrhDlkg2bHYic5unPZ3ea1cTWCZTicGIOfOOj4yIpz5mfN9Fw/300?wxtype=jpeg&amp;wxfrom=0"/><p>ggml是一个用 C 和 C++ 编写、专注于 Transformer 架构模型推理的机器学习库。该项目完全开源，处于活跃的开发阶段，开发社区也在不断壮大。ggml 和 PyTorch、TensorF</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444387&amp;idx=4&amp;sn=6471e0cf2a63ca8b352413fbeba5c099&amp;chksm=bf6cb4e8753de60eccf51dfe8852ed27d494c0f94cfec3fbb748622719b3c8850dae3cd169d6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 27 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【微调数据过滤】One-Shot Learning as Instruction Data Prospector]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/d6902wUyyvI8BOEvEicIpu4uTIo4M82fG20U2ucZbdmMkic2PwOkVhwAq47UhFxyTGtk0UnBrKhQibMWO2dXg8xQg/300?wxtype=jpeg&amp;wxfrom=0"/><p>这篇论文介绍了一个挑选数据的trick，这么说好像论文很简单，但确实非常简单。虽然论文里还用公式阐述了提出算法的实施流程，但我感觉完全是形式大于内容。既然是trick，那我们就尽量用简单的语言描述清楚</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444387&amp;idx=5&amp;sn=af4efa5e332a3a87db0ffd600bed1f55&amp;chksm=bf4c685111284b2a8020655ad1c40082dafbafa1ab66f049f5b1522e344cf9ee6bdb3cb77b0c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 27 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[奇书：《一书解决几乎所有机器学习问题》.PDF下载]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKpiaZvAC2DexvQpTSw6A7eDVL6TFibYAusB6gIIzEYDrYnjP5L7lDxLlYwBLOfFdJ7micePzQ61le5g/640?wxtype=jpeg&amp;wxfrom=0"/><p>介绍本次分享1本「机器学习」和「深度学习」好书。专治ML和DL炼丹过程中遇到的挑战，而非单纯地算法理论，适合想应用机器学习的读者。作者作者是 Abhishek Thakur，AI公司的Chief Da</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444369&amp;idx=1&amp;sn=6e429e3a539ef64be7dacd42710b9b3f&amp;chksm=bf506dfb671079787bec1b4b62b537f68ea63c7a4d392806e5375f79f4fb8f9c82418c860165&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 26 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[突发！IBM中国研发岗访问权限一夜关闭，千人或被裁]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIjsADKYbj6sxmhrwk8CcR1vovod1IicKqAtOyfaFmCUhxeMdxA3vuIbxC48hXic2hibYKOlfdfJYzVQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 编辑：桃子 乔杨 (新智元报道）【导读】一个时代即将结束？「蓝色巨人」IBM中国区一夜关闭了研发测试岗员工的内部权限，波及1000多名员工。有消息称，这是IBM中国区大裁员的前兆。IBM中国区，要有</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444369&amp;idx=2&amp;sn=ccd8cde6346c39a696a8685f4b53b40b&amp;chksm=bf874032f63264650435eb7ddfbb7f0339a786d0a614819190fcda6e34d8385d792ed17390bf&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 26 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[关于post-training和一些思考]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuzDV6E5glFv6xor20yqrRPz6tBm4QCibIvND09OrKL7gTCkxvoXnRgiaW8AKL5G2EukVOOguAqiapDtw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Author: [yanwushen]Link: [https://zhuanlan.zhihu.com/p/710936230]最近有趋势是要扩大post-training规模，本文讨论的就是Lla</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444369&amp;idx=3&amp;sn=cba84567bfb558136c800e63c194ae0d&amp;chksm=bfb33a5b6b6f703c396acf8dee591bca04127ae5acdf3496f75fc2b298264799116fa697db25&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 26 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[腾讯版GPT-4o开源平替方案：VITA]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/w3hibrVDUAib6In88kx5YuAkeBic3Mnx8wduUvRBT3XzVcd9iaYiaQ8nPjjqztvs03ghUEqGtN9mY64XxmicnjYYtuHg/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言小伙伴们好，今天这篇小作文主要介绍腾讯开源(截至2024年8月25日尚未真正开源，只是在github创建了Repository)的GPT-4o平替方案：VITA。简介VITA是腾讯优图实验室在交互</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444369&amp;idx=4&amp;sn=283a9f763d3e931706a7813d1d7ecff5&amp;chksm=bf54a344235168c6d997bc90c6a695576ca3a67f8b3c2c73747aeea4d12f3a19b95e7a5e019f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 26 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[RecLLM-Gen:将LLM应用于推荐系统]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hg6UPGp0Hib5uQBLE6luJ77Rp0pJGsENx7zggVoj2qMKNJcD8Je3eHFiaSgiaXywjM3LY7VPbSUstLT2jKQAyhIdQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文标题: Aligning Large Language Models for Controllable Recommendations链接: http://arxiv.org/pdf/2403.0</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444369&amp;idx=5&amp;sn=45cb53694d4e738234e57fd050de99df&amp;chksm=bf3b7b7ad103e87ca07d3ed427c40f7e12f820367e517626d342a337489a3b792a882a6a1a01&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 26 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM真的解决表格问答了吗？全面覆盖复杂应用场景的新一代表格问答测试基准TableBench]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLibCgVI8QyTibIMo4gaboYK0cfTxrvOmniayuhvCsnj4AyKommZwcibCjRnnxkClRXHJmSckvNPkhMrg/640?wxtype=jpeg&amp;wxfrom=0"/><p>LLM真的解决表格问答了吗？该工作提出了新一代的表格问答评测基准(TableBench)。TableBench通过涵盖四大类表格问答能力（如事实核查、数值推理、数据分析和可视化），并深入到18个子领域</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444348&amp;idx=1&amp;sn=5d8f4ff455c4cd32968618750a361afc&amp;chksm=bfe35f9ea3963cbfac551e92e51d4e392ad654515250277dbf454a054f278220f566b03429c4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 23 Aug 2024 09:09:37 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[黑神话悟空的薪资与招人标准!]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/icmWrEONNM8WLmAOibic98bp45OmcpSr9MuLxYRKR9O9TwNdCLEdPOVK7VnNrLP5yhWaNBVpu7LepGrx4hibZcVf5A/300?wxtype=jpeg&amp;wxfrom=0"/><p>黑神话悟空总算是熬出来了，前几天正式发布后，彻底火出圈，也轻松打破了一些记录。它的同时在线人数，突破了 241 万人，这个数字使得它成为了 Steam 历史上在线人数第二高的游戏，仅次于吃鸡游戏绝地求</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444348&amp;idx=2&amp;sn=10fee4ddc559ca379a7e26b92d0202f7&amp;chksm=bf2735f5a4776a23ffe78986627dc918dd8e07a7523be5621271dd741087b86a40e884bacd8a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 23 Aug 2024 09:09:37 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型：一文滤清 BPE]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HAFUHkn3vxtUKpfgz44pxzGamkl2HpaxVC1TtRsTO4ib6kja3oqvmP0MCZqm6VjvYoTiccKiauwoz9XnqLR8ibcBtg/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言最近在整理笔记，陆续会把一些笔记整理下发布出来。分词器一直是 NLP 领域中非常重要的一项工作，而对于不同的语言，分词算法都可以采用：词，字以及字词结合来表示。经过多年的发展，现在不同语言的分词算</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444348&amp;idx=3&amp;sn=d5fb8d9d2958863eaeb0d5f128d0075c&amp;chksm=bfc6a99009740a7358f8190b96083d8ffb0c9459cb9b9e3f44b0188e9c51862d3b91ea9ba6d8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 23 Aug 2024 09:09:37 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM模型微调】LLMs-PEFT[微调]-LoRA总结笔记v5.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdD3zFSqVDbo9rqAy521pIqprj0TIl3z8bHGuu4CLt1gjvNL2OJkYXfWEicIncicTGux5LSy7f5cYN9A/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM模型微调第五篇，分享论文LoRA：LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS的解读。主要内容有论文解读(提出背景、关键优势，实现步骤</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444348&amp;idx=4&amp;sn=c10f7e9dbe4728b888350e296c5e25e4&amp;chksm=bf16bdf9865d252fc903576722fdf9058881dc66c690b7673f9f7e545d8bb7fad5887dce3395&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 23 Aug 2024 09:09:37 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[机器学习中的样本重要性权重 (Importance Weight)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/QLDSy3Cx3YIZUXqXHndqDsyeyQNIQOP8GX0FVYdl57NqtUjRWoMGLWb5UhFQfT9GCVichf7EBOcsXZM7oX2ibVqQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>样本重要性权重（Importance Weighting, IW）是一种在机器学习中应对「训练-测试数据分布不一致」问题的经典方法，通过对样本给予合适的权重，理论上我们可以在分布不一致的情况下，学出在</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444348&amp;idx=5&amp;sn=bfae6b1d6487707f52625d7c6e595abf&amp;chksm=bf23c01e3670a3efaa5fcc8ebfd536927c69a35cfd55127e55b648de72ac35865c98554a43ca&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 23 Aug 2024 09:09:37 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
