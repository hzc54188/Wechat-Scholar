<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5034e4edc067.jpg</url>
      

      <title>gh_5034e4edc067</title>
      

    </image>
    



























    <item>
      <title><![CDATA[EMNLP顶会最佳论文解读！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJvwxS6MT3ic26SA7vcz0fGkFc2Yia0SPC8Kib5Qy1C6oUPCPSskKaDVV5AswAA5VxqZ87mCtL6bxsxw/640?wxtype=jpeg&amp;wxfrom=0"/><p>EMNLP会议在自然语言处理领域拥有不可替代的地位。作为计算语言学领域的顶级会议，汇集了世界领先的研究人员、学者和从业者，分享这些领域的最新研究和进步技术。上月中旬 EMNLP 2024最佳论文奖新鲜</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446553&amp;idx=1&amp;sn=96b0074ae1b6cbadc661d15dce74837f&amp;chksm=bf48c844f4e6e3336a00830657099a21c059b519d15c2263b38c7a1f642a1ff023fae970afb9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 23 Dec 2024 02:07:37 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[LLM训练全细节 | 如何从零到一进行 pretrain 工作]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSK2y5DziavvVj7obPrPwSiaLQhut1aOouU4Xkrcf8OmxGQZyCFFu75Jw9r42a9N8wxBLoiad2GOPftWA/300?wxtype=jpeg&amp;wxfrom=0"/><p>整理：NLP工作站知乎：https://zhuanlan.zhihu.com/p/718354385这篇文章介绍下如何从零到一进行 pretrain 工作。类似的文章应该有很多，不同的地方可能在于，我</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446553&amp;idx=2&amp;sn=1d9cde149df7d62b2410e6e4578aa1e2&amp;chksm=bf25ef2890fadd3b7b15dd224cb2e3666d69cdf3d3807fb546aa67345f72fe2697e49c211b01&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 23 Dec 2024 02:07:37 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[RevThink: “逆向思维”助力每一个LLM梦想]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKpuV3Nhze3fSVlP4YPibCOrxFu3o6Y3OYdfFz9iaUibtsnoOecr3oic9kXlfGekrTtiazaTeLcZ22yLQsxg/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲1 简介2 问题背景3 RevThink    3.1 数据增强    3.2 联合学习4 实验5 讨论参考文献1 简介    逆向思维在人类大脑中占据了重要地位，我们不仅可以从问题推导到答案，也</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446553&amp;idx=3&amp;sn=297af29761877911bf7bff1ad11a5538&amp;chksm=bfd97c4685f8a205f35097adfa3647fca0f6dbce4e0aa18c12f4b37108047c98ebb2a71e2232&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 23 Dec 2024 02:07:37 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[一局定乾坤！主流O1模型，究竟谁才是地表最强王者？实测对比揭开三足鼎立局面！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/w3hibrVDUAib4HicVib0Do1M1sPdB8gXbL1f0IAS6My9wwDSXhuwt9ibibvoGqqNTzXoXs9ekkJCJjHxQkvfAOpJpmkg/300?wxtype=jpeg&amp;wxfrom=0"/><p>近期，国内多家大厂与创业公司陆续发布了类 O1 推理模型，主打逻辑推理能力。其中，不少模型更是声称在性能上已大幅超越 OpenAI 的 O1-preview 等竞品。那么，这些 O1 模型的实际表现究</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446553&amp;idx=4&amp;sn=490959098c5c51f6439f07f5ddb521b1&amp;chksm=bf67e108789b11a67484b5a75a4d3358f97eb78af57ddbb10e33a6d5a116397adac2352e9870&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 23 Dec 2024 02:07:37 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[从近100场大模型比赛看大模型关注热点]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuwe2rvshJ33UZIovSKagiaXObw4ibBwRNicMcuckzEkGTibO3r5hR3kQGxWf4TleiaDvUnkpDM4KDzqnQg/300?wxtype=jpeg&amp;wxfrom=0"/><p> 作者：砍手豪（授权原创） 链接：https://zhuanlan.zhihu.com/p/720381778在之前的文章55个大模型比赛汇总里可以看到,从去年十月 Kaggle 第一个大模型比赛ht</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446553&amp;idx=5&amp;sn=215f9d5cc6e4836b9a3ec9dd1586c88a&amp;chksm=bf309299ff9cd346a5c9c3e2effddb05d4494ecd312f0f5b1e6f248ee108e116fad8783b579f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 23 Dec 2024 02:07:37 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[Qwen2.5技术报告解读]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJvwxS6MT3ic26SA7vcz0fGkbjKz6AFRvHca6UUH7TBWtlhIJqkjQI2sdK18VzcOez0IbWajXOVnkQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>来源：包包算法笔记这两天Qwen团队发布"Qwen2.5 Technical Report" 的技术报告，下面对该报告做了简单的概括，希望让大家有个快速了解。链接：https://arxiv.org/</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446547&amp;idx=1&amp;sn=b005dc62fbab891b71300d41be28a938&amp;chksm=bf8b014d1b1b6bbcca6c37eed38737278552fdc70099348ea385166f4593bef644eb877a26c7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 22 Dec 2024 07:10:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[对OpenAI o3模型的看法、思考与反思]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJvwxS6MT3ic26SA7vcz0fGkUibdxIeic0Pd9IYSWuicl3Qx6O9gBh9IJnfqwv2NMf7bwicrRdhYakjq3w/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：https://www.zhihu.com/question/7416922570/answer/60763494897o1 刚出来的时候，很多人还质疑这还达不到 AGI（通用人工智能）。o3 </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446547&amp;idx=2&amp;sn=d66decf5b3c47382f1c5b1763a640460&amp;chksm=bff48b609e8f67c194e9b5ea3844fa9bce575e7497d6e668fa7ab0247a5825c269929ff99c23&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 22 Dec 2024 07:10:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen 2.5 技术报告发布！其中有什么秘密？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVfVicUEiagTZov6FPIwI4NSkNYMZ5GicM35KLZf0h10wOJEWtibYGcNbtdbHRYKs91icXpxLiaIKA7c7Fyg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Qwen2.5 如何成为最佳开源 LLM？Qwen2.5代表了大型语言模型 (LLM) 开发的重大飞跃。最新版本在前几版的基础上全面改进了预训练和后训练方法。通过利用 18 万亿个 token 的庞大</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446547&amp;idx=3&amp;sn=56459147391365787260c7315318eeb7&amp;chksm=bf075850e0491584121604bc11013913e676d0ad5ecc5888dcee153010d7d7d1c91751956070&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 22 Dec 2024 07:10:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[我国退步最快的985大学？曾位列全国前十，如今排名连年下降...]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJtpW8Eha7IODSyRqGY9PKwj1pPDpvIuDFqQl7h5gkibVtxx6VwlcaiabFCcuRoCcwc5rUSjxp6rlMg/640?wxtype=jpeg&amp;wxfrom=0"/><p>来源：网络从19世纪末至今，我国高等教育发展已拥有100多年历史，也形成了基本稳定的格局，目前，全国已拥有3000多所高校，可分为两大类：本科大学与专科大学。本科大学又能分为公办本科与民办本科大学，公</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446527&amp;idx=1&amp;sn=7b07bbcdf7b5f87bc79f4ad4b82daf88&amp;chksm=bf34b1eede0f66815ba6a84b603d09d17585140c8bbfc2e97adcd02db4d28f5e52fa12e4e258&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 20 Dec 2024 10:59:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[像教女朋友一样教你用 Cuda 实现 PyTorch 算子]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJtpW8Eha7IODSyRqGY9PKwCm24ImjxVZ0gNRWfyNJSibH8zp4dusJiapWHict29QqyEiciaeqiacmYOB9Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言 CUDA（Compute Unified Device Architecture）是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。开发人员可以使用C语言来为CU</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446527&amp;idx=2&amp;sn=024615f5bca182ff9c463e4275102157&amp;chksm=bffd965b9d0090032d746cebc472715f56f5be5ed23bac7099b6a9560c9506b925491c948698&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 20 Dec 2024 10:59:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[通义实验室招聘大模型算法专家]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKzPhuVnIGXEon53TWIzS1uB5WXQRgvxYLcoj5fq3SVd04LLuPqyt5BGPc4CjnG56vYhM38cGfoHA/300?wxtype=jpeg&amp;wxfrom=0"/><p>通义实验室-大模型算法专家团队介绍阿里巴巴通义实验室-对话智能团队 以大模型对话技术为核心，研究及应用方向包括智能客服、个性化对话、角色扮演、分身复刻、社交智能、数字人等，主要业务场景包括（1）通义晓</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446527&amp;idx=3&amp;sn=595e7a5b21770ed71bea37e87406fd1f&amp;chksm=bfa90834f3c6b725183a8d72237bd6281d010d4a653b3bd3b1d2cea578e7853a57fab0d3fcf0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 20 Dec 2024 10:59:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[现代LLM基本技术整理]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKzPhuVnIGXEon53TWIzS1uzxVQRd0aAEPaqKCs4MjO6KoDtRyubkaLiaQN85drBibfa3KQ2pDBErFw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：hadiii，北京大学 电子信息硕士在读原文：https://zhuanlan.zhihu.com/p/713794852编辑：青稞AI0 开始之前本文从Llama 3报告出发，基本整理一些现代</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446527&amp;idx=4&amp;sn=cfdda652f7276604ce4d29b927bc23dd&amp;chksm=bff32bd87f632f3af65f6781e8666df6ccf94657e8ee0efd99cd4d7fb76221d85c8abe537426&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 20 Dec 2024 10:59:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM训练系列01】Qlora如何加载、训练、合并大模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVcdaxn4qxxSwok1Zic5A5DjrTY5rYtXuEvqNcjQS1BA8wFcaNhJlOFURicvzhibCGvRIYKHm4FBYol5g/300?wxtype=jpeg&amp;wxfrom=0"/><p>示例1：Qlora训练Qwen2.5参考脚本：https://github.com/QwenLM/Qwen/blob/main/recipes/finetune/deepspeed/finetune_</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446527&amp;idx=5&amp;sn=9de2d0c87921f0619cff03f255129e76&amp;chksm=bf66a8222316907aff8e4c7c527120efd72462064541c486c0da7123ed9358b804aca1a36612&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 20 Dec 2024 10:59:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[知乎大佬解析Ilya最新言论：pre-train丸啦，搞agentic和reasoning吧]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJtpW8Eha7IODSyRqGY9PKw8D3fAiciaZs7VEAzq3Ifib9iarkQLxergLiagbtziapVZCA6uPhDnAoREgGg/640?wxtype=jpeg&amp;wxfrom=0"/><p>Author: 曹宇Link: https://zhuanlan.zhihu.com/p/12588939986Ilya 在 NeurIPS 2024 上演了一个名场面：在回望了自己十年前的工作的时候</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446520&amp;idx=1&amp;sn=a818ffaa84f20f785b5342fb52d64dfc&amp;chksm=bfaf9defef91d3dc2792864a75448482bf4951a5674c9f0e20c765d59498cbd554b284b9be37&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 19 Dec 2024 11:19:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型Infra王朝2024]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJtpW8Eha7IODSyRqGY9PKwEVdEbUxPAoLib5Uk4uIJ45Udauib5RKoCyia6ZZ8RibMOEDYoJ0VFKIZDg/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：手抓饼熊（已授权）链接：https://zhuanlan.zhihu.com/p/12663989502记录一下2024做大模型Infra的一些破防瞬间。大厂All in大模型的历史背景不上称四</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446520&amp;idx=2&amp;sn=81c378eb18df01e48160de54815f8518&amp;chksm=bf56193c2c5e451eb9cd20227a480c11fe898ff5866091e33e898f229763cddc8cc0529e9e9f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 19 Dec 2024 11:19:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NAACL2025研讨会征稿 | 主题：自然语言处理中的跨文化研究]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKsbExfKbIEV4GF2vavXOEtVLoSIjXeebEib4enKgEK9kppibwUBZqg9QLbgRPn9F3IrgFnCmtYXxPw/300?wxtype=jpeg&amp;wxfrom=0"/><p>研讨会信息第三届Cross-Cultural Considerations in NLP (C3NLP)研讨会，将于2025年5月3日在阿尔伯克基，新墨西哥州（美国）召开，研讨会同NAACL 2025</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446520&amp;idx=3&amp;sn=0e8a14b77f2f8a4355a70a70b212ef5b&amp;chksm=bf1c5a5e2712d8cfec10ef347654647322caf8da9d2cac770f90da3997b32f382f2cd58ed52a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 19 Dec 2024 11:19:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[机器推理的突破？田渊栋团队的关于增强大模型推理能力的热门论文]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/9MSPBmHaWGyoxVURS6Bmic7ergROXLsLmKiabAMn19brNuKGKnIuunjGIkrCjDk7flLgvrmA8IYtAOeXYfb6gLmg/300?wxtype=jpeg&amp;wxfrom=0"/><p>      由于本人这几天一直在整理有关增强大模型推理能力的论文，突然发现一篇新闻，就是田渊栋团队最近发表了一篇关于增强大模型推理能力的论文《Training Large Language Model</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446520&amp;idx=4&amp;sn=3566be449e35a44c79d11f05667445e3&amp;chksm=bf257307e29024f6eef049adfc6490301126c9f888c379759e5877a1ca188c8df6de0c72fe1b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 19 Dec 2024 11:19:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[模拟世界！OpenAI 王炸来袭！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJGao4HsKSkwlDibVn6HR3XiaU5frSWtpw297Dr28A0HiaEGaMJ8oRv3JF1hiaZFQfoTUnHz9fcBRoGsg/640?wxtype=jpeg&amp;wxfrom=0"/><p>开服就被挤爆服务器！OpenAI的Sora正式开放，带着革命性的AI视频生成技术，突破性地从文本生成高质量视频。新Sora功能突破不仅代表了视频生成技术的进步，也表明OpenAI在多模态生成能力上的技</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446478&amp;idx=1&amp;sn=2ef8388983b883338dd731ce3313f6db&amp;chksm=bf37beae3bc5e64a4260728f10c35dc546e2981a7b091888670506ce1e9c985dd645e299f013&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Dec 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[The Bitter Lesson（苦涩的教训）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJGao4HsKSkwlDibVn6HR3XiaodHAxZPAmlDdOariafzjLj6fR4ibk0s7UFI3NmJuEplSgKib9apf5GpibA/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言Ilya Sutskever（前 OpenAI 联合创始人兼首席科学家）在前几天召开的 NeurIPS 会议上表示，大模型的预训练已经走到了尽头。而  Noam Brown（OpenAI 研究员，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446478&amp;idx=2&amp;sn=02a3d7849cf2cb4d138f662878de3200&amp;chksm=bf23516e3ffa3a7854f79452e95d219bc26a693aa059c7939f5948b76a1e1c1a11725684e17a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Dec 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【从零训练Steel-LLM】模型设计]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/ic2h7M1BWibNnUXGOMWBIo461uwl9pgFGsshAFu5EhibChic0TgQ4IricgKEfH6aJZ82NeGWibpREmYmugVR7icwV99icA/300?wxtype=jpeg&amp;wxfrom=0"/><p>这是从零训练Steel-LLM的第三篇文章，于24年7月9日首发于我的zhi hu帐号：“战士金”，略有修改。目前正在进行模型微调和评估的相关工作，近期已经将训练过程中的多个checkpoint上传到</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446478&amp;idx=3&amp;sn=5fae012891bb01abe01d76c2acb4b472&amp;chksm=bf3955f67b100b317886742eb9a44e9fa3e69af1609dfe558e5b723a2fb7ab1e3b05abb89bf3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Dec 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[千问LLM：LLM的解码都有哪些方式?]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iabUOs2OBUhTJchV1800lWEhIq8F6xhCBBmI7mrYULAlSl0oCbTL3shIUt5ic9JRFtYZSMek7jTNicib53iakDz9dSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>千问LLM之三十一：LLM的解码都有哪些方式?“人生也有多个解法，轻松是一个活法，累死也是一个活法，不求人人都是一样的人生，但人人都做最有意义的事情。”上次博文介绍了 千问LLM之三十：什么是Post</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446478&amp;idx=4&amp;sn=9bd885df3f4ba45ce0274c6796e784df&amp;chksm=bfcfd7e518bbd42541b7ca9e2108f4adca7a73ca709cc41611d9dd032090e72cb08827a13b11&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Dec 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NeurIPS2024，LLM-Multi Agent 依旧火爆！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLxmB9ibsQMosXCkvicKeNsicCMuXQibpBPIJvG6GiaicJHEiaGyEae3yDfCpHQHtx5q75B9vt1DDwqPCJLg/640?wxtype=jpeg&amp;wxfrom=0"/><p>顶会NeurIPS‘24录取的4037篇论文中，LLM-Multi agent依旧火热，热度不断攀升。而ACL’24也是如此，LLM-Multi agent无疑是今年的热点词。国内外多个权威研究团队都</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446463&amp;idx=1&amp;sn=2c95bd8d098286a1de7f99400020984c&amp;chksm=bf8928d70404ab260cff37b6efa42a4dccefc97f881355e74f6188d6f6730868187cd9698ae3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 17 Dec 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[工业界主流大语言模型后训练(Post-Training)技术总结]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLxmB9ibsQMosXCkvicKeNsicCXxvIP79EGqW8Jicr7lfKzib8oIDTibOIIEFNYxvEnKoHnnBmJtsbsDGRw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者丨唯亚@知乎来源丨https://zhuanlan.zhihu.com/p/987052830编辑丨极市平台导读 本文整理工业界主流开源LLM的后训练方案，着重介绍训练算法和数据处理部分 前言今年</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446463&amp;idx=2&amp;sn=3e2061a18d7509cc605b36fb4197a7d7&amp;chksm=bfebed82b15f4534a49f027232fb02b4d9fe390f7bf685d09a3290867ce1385b9830b7465a2d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 17 Dec 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解OpenRLHF中基于Ray的分布式训练流程]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkNm8wIw4A1k1R4xmpIBGt8odIEZiafnOxHXedNnWcv0aleCNL8aSzx1dAGGfbmIIrD1CSyiaqbqiantQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文着重分析OpenRLHF中的PPO-Ray训练架构设计，没有使用过Ray的朋友也可以通过本文快速上手，本文共分成四块：1. 为什么用Ray2. 使用图例抽象出整体训练流程3. Ray核心知识速过4</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446463&amp;idx=3&amp;sn=a3cc0bd44fbd5d4828b7325b7368eb6d&amp;chksm=bf2525c59ec9efd0c397165bbc2b0e1a2b92df545c72b7e54cd7c66f8c0fa0928c04f82d3c63&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 17 Dec 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[模仿、探索与自我提升：类 o1 慢思考推理系统的复现之路]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLxmB9ibsQMosXCkvicKeNsicC2bqRhBdbU9ru9MqGtc7IClvRcBud7iarZhGdAmVdicjvp8sRh5LMt2HQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>© 作者｜蒋锦昊，陈志朋，闵映乾‍‍机构｜中国人民大学研究方向｜大语言模型与推荐系统近年来，类似于 OpenAI 的 o1 等慢思考（slow-thinking）推理系统在解决复杂推理任务方面展现了卓</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446446&amp;idx=1&amp;sn=a6a27ee83cef0cd1f4f5b71c4a94a6fb&amp;chksm=bf53acf91ae589dd8e84023e2c67d2fc627610c9f369f9de463542b58d613af560485631f058&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 16 Dec 2024 10:29:24 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM模型微调】LLMs-微调经验-SFT总结v9.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdCP0XlmKKJdiaZk7gUGAufmoW0zkwjP6dlCMM87CLic0Gib9iauZ7xX0l5oWo3Ic3XWicg9BP1kVNa1ibCA/300?wxtype=jpeg&amp;wxfrom=0"/><p>【1】大模型微调到底有没有技术含量，或者说技术含量到底有多大？老生常谈的一句话吧：有没有技术含量取决于这个工作你怎么做，尤其是 llm方向，上手门槛相比传统 NLP变得更低了。我举一些例子吧，针对大模</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446446&amp;idx=2&amp;sn=034b485a5dd13e5617be6d933a83b5e2&amp;chksm=bf19c0b7df5b39b2ed8345fefe807bef047570115670c1ba2910b0cf003ffe679528e4add704&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 16 Dec 2024 10:29:24 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[聊聊对强化微调（RFT）的理解及看法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5nxYicQntALI7B9EibEjqOVGA8x15FwqM8CqvyspyLClPhJqehRzJiaHSO4zvIicoibx9qMarEZzogsO1g/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来一篇好友 知乎@ybq的文章，聊聊对RFT的理解及看法。作者：ybq 知乎：https://zhuanlan.zhihu.com/p/12328929529在看了 OpenAI 的直播，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446446&amp;idx=3&amp;sn=d0d0cf2ef705391f993c18635f230899&amp;chksm=bf9a2b9b8a50e59845ce276fb4f4841970232eec454653d9c2713b9852a3afed0f9396a3406e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 16 Dec 2024 10:29:24 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
