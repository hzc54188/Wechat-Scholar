<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5034e4edc067.jpg</url>
      

      <title>gh_5034e4edc067</title>
      

    </image>
    































    <item>
      <title><![CDATA[大模型中上分技巧大总结！！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLHYFxh9h81c9I2fPxHjfia0kCibwVqTfXJicytW0lQBFFfXYocM8aj5lRcUSZib1h67vHGCEJQ3BRtlw/640?wxtype=jpeg&amp;wxfrom=0"/><p>这个文章与其说是上分技巧，不如说是刷分技巧~~~很多论文你看了看发现变动不大，但是就是效果变好了，可以对应着看看这个文章。我估计，都在下面的总结了。文章内容仁者见仁~~作者:  黄哲威 hzwer链接</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446018&amp;idx=1&amp;sn=e85f97dddb74dde6322aa0cf282454d1&amp;chksm=bfcc419547f737ae947003a64ba4a1ac2515ffe84bf372487072522387d25aab145c984ef23d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 18 Nov 2024 07:06:30 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[最值得参加的LLM盛会！多模态/Agent/具身智能/安全/评估等15个论坛！早鸟注册最后一天]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLHYFxh9h81c9I2fPxHjfia0DwKBdjkwictic6BV140TYYtghpRyO7Mdzeesw9CkVpZ3VI76Hn4TMicSw/300?wxtype=jpeg&amp;wxfrom=0"/><p>会议简介中国中文信息学会（CIPS）是中国中文信息处理及其相关领域的学术团体，大模型与生成专业委员会（LMG）是中国中文信息学会旗下的专业委员会，全国大模型智能生成大会（LMG）是该专委会的旗舰学术会</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446018&amp;idx=2&amp;sn=63df715c8aee0f0e7aec57948b85a0c3&amp;chksm=bf2c2ed5a6d4bef6f3919313d53f8a891529db828c36a6205cb7d7c5ec6962deb7bdceae0b88&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 18 Nov 2024 07:06:30 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[2万字洞察Scaling Law的"终结"or"新起点"?——开源实践者的深度思考]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/yToxjhYT5ibb9Hy6qdvR9gcibt8ZeysozQw7iab7rJbPc9kicLGfdEAxSU5BVmW8nh37dRbm3FvTv0w1iafDIOVgycw/300?wxtype=jpeg&amp;wxfrom=0"/><p>| 作者：宋大宝，与大宝同学因那篇《回顾·总结·展望「融合RL与LLM思想，探寻世界模型以迈向AGI」》结识于今年春天，虽我们当时某些思想观念有些出入，也碰撞出了很多火花与共鸣，并持续地相互启发的走到</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446018&amp;idx=3&amp;sn=dfb727dd93399f4c8be1551b6af6a6e3&amp;chksm=bf4ae67bd5384706f7362c63af2d4097c6659de44b0ac6cdb828bc0b188d920aacd1476eff41&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 18 Nov 2024 07:06:30 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[训练数据合成(二)]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW465zM1pOYlC9Gt4FCttlhz2ib1h6mraibl4s4fecscDavk1Vw97H2SfvibGLk6EUOBc9ysOicGBRjmATow/300?wxtype=jpeg&amp;wxfrom=0"/><p>书接上回，训练数据合成(一)，继续看一些重要的数据合成工作。1.self-instructself-instruct算是大模型数据合成的经典工作了，它的目的主要是为了低成本获得大量用于大模型微调的指令</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446018&amp;idx=4&amp;sn=afd4768ee01f5180b044b5dacef05ff4&amp;chksm=bf0eb610c92a9211775529c9484955772614b89bceaf527c2cb0e593a53b89455f59fbffed28&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 18 Nov 2024 07:06:30 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[突破长度偏差:Meta AI的LIFT方法让大语言模型更懂分寸]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hq9ANWCLRic1IWYzkjQ4jYkYaMK6XP8IUzbribMPphMV0HITZfOu7lDE5CN53d4FQ8ME8Yf7yhsy5VePZQYX0gag/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言在人工智能快速发展的今天,大型语言模型(LLM)的指令跟随能力已成为衡量其性能的重要指标。然而,一个长期困扰研究人员的问题是:这些模型似乎有一种偏好,倾向于生成冗长的回答。这种"长度偏差"不仅影响</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446018&amp;idx=5&amp;sn=1e27b6e3559231c84a9d46f815019573&amp;chksm=bf8bbf9f43d4cb7fd85d54d4901bee1747d749ad39773a1672d48e463c1d6288be408219acbc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 18 Nov 2024 07:06:30 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[校长书记双院士！教育部副部长，任C9党委书记！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLXBLtNe9OP5LQ69DJUkgV7Pvcicy0VtoDNZMibhND5ia5ujC2NextmLEic5DczC2fslwHmT0VYx7qz9Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>日前，中央批准：陈杰同志任哈尔滨工业大学党委书记。11月13日，哈尔滨工业大学召开教师干部会议。中央组织部副部长张光军同志到会宣布中央决定并讲话，工业和信息化部副部长、党组成员张云明同志，黑龙江省委常</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445994&amp;idx=1&amp;sn=ec7a85ecf4289d287e1440e9d21c5fe2&amp;chksm=bfb91da1db24b6579397c021d3d7b8e1559a912adcfc747458f2356b0603e43a45d0e666fc41&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 17 Nov 2024 12:42:25 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【文末赠书】专补大模型短板的RAG入门与实战书来了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLXBLtNe9OP5LQ69DJUkgV7QJC3MyYyNodArhJBzmoXGxGXkhV58nfW3K86U59QwsAOoLuYKoFLxA/300?wxtype=jpeg&amp;wxfrom=0"/><p>文末赠书RAG自2020年由Facebook AI Research推出后，一下子就窜红了。毕竟，它是真的帮了大忙，在解决大语言模型的“幻觉”问题上起到了关键作用。如今，Google、AWS、IBM、</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445994&amp;idx=2&amp;sn=a70950fb59839c173634ee604d699ea7&amp;chksm=bf4d3fd02f6163083e7b63ceb92d7a008c8f9139b085769661021270f838b8e11dec21664410&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 17 Nov 2024 12:42:25 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[人人都能看懂的RL-PPO理论知识]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkMyjq7MvIma1htP55lDYuSo2Z61FZWE0KJTnub7ev5jBJxibibnX7NhEqsVVdIY5HLic0Ldrc5QWqqCg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在去年的这个时候，我以deepspeed-chat的代码为例，解读了rlhf运作的流程。当时写这篇文章的目的，主要是想让读者在没有强化学习知识的情况下，能从直觉上快速理解这份代码，以便上手训练和修改。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445994&amp;idx=3&amp;sn=debe81f782e23315b6307de960e24a30&amp;chksm=bfef2cb400cc748d7f57093d2d62e90b47b55f0fa877d0e937a8e8d6c1d626823ae70b907543&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 17 Nov 2024 12:42:25 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[语言模型之text embedding（实战篇）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKpsxU3lqwnFAOjEHVCVRgJSfswPgElzVzFmuCiblpRiciaiaj8uhLtzAAwK8xSQTrYChzfD6ic8q8yictyuQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲1 简介2 背景‍‍3 基底模型选择4 使用方式5 训练方式‍6 讨论‍‍1 简介‍‍‍‍‍‍    在前面2年时间里介绍过数十种text embedding模型，虽然不同模型在MTEB这类ben</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445994&amp;idx=4&amp;sn=14b57f977649ab6271ce870533762cb9&amp;chksm=bf0271a820c763fc38ce1250804b868fc8ec4a9d219237053e6432df6462c5b7a797da3902e0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 17 Nov 2024 12:42:25 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024时序预测都有哪些经典工作——总结篇]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/dcUv9UF2OUWjxVWRjq6pChCocendQeDVAS9B679pPliayjTxgjoOtpXGtHqC3ibjDLoNRlEG0J4ySfNr4mSxmRGQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在这个系列里，圆圆会带大家梳理2024年时间序列预测领域的经典工作，涉及多个优化方向。在这一节里，会为大家整体介绍2024年的时间序列一些具有突破性进展的领域。后续章节将持续在知识星球中更新，深入解读</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445994&amp;idx=5&amp;sn=9d1c8bb5f0d1cfaa7af2538a5737e24b&amp;chksm=bfee7acf703fe830ac2e643cebe51be8b2522d692f8113ace5592f6233e4eda0d5717fc8429e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 17 Nov 2024 12:42:25 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[个人从零预训练1B LLM心路历程]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/ic2h7M1BWibNm1GLIVa8o7x1Got9gefxQicEvNfKB8yyfeZoHZsgaicpz8icRURFneIPibiaZViaGjcyGWggpYSpPDTsibg/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言项目开始于2024年3月初，当时朋友搞到了一台不知道能用多久的A100。这么棒的机器放着也是浪费，就琢磨着尝试从零训练一个小型号的LLM。其实在当时就有不少些这种“从零预训练LLM”的开源项目了，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445971&amp;idx=1&amp;sn=e1b0aa686abc0ac821296c76c707304a&amp;chksm=bf317ee4ab11181586a1bb9aecc1ffb22397d37c58287a944fd5fac93073038a11fb0cc2f805&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 15 Nov 2024 02:17:10 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[开放注册｜中国中文信息学会2024学术年会暨第三届全国大模型智能生成大会（CIPS-LMG2024）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKia6icUNbQXlUH60jufVANqibyAqKRUtySC2VljdGUnJHqjYuyQD0XL5z0RYEwe1b1bwicvCEaeT6Fcw/300?wxtype=jpeg&amp;wxfrom=0"/><p>会议简介中国中文信息学会（CIPS）是中国中文信息处理及其相关领域的学术团体，大模型与生成专业委员会（LMG）是中国中文信息学会旗下的专业委员会，全国大模型智能生成大会（LMG）是该专委会的旗舰学术会</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445971&amp;idx=2&amp;sn=c6517f3938ce4bbc91bcd5182b4ae383&amp;chksm=bf4e60acd742d762d88fbf91b4ab4b23081cd8f6c2156c6b4d4bdae57c2799840ff4b64409c4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 15 Nov 2024 02:17:10 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【字节跳动生活服务算法实习生】]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKia6icUNbQXlUH60jufVANqiblCJ8LaMiaxqws3hBFl4TANO8VR2BZKGWQ3Smb6juDgwySEDY9BdpaSA/300?wxtype=jpeg&amp;wxfrom=0"/><p>【字节跳动生活服务算法实习生】【岗位职责】1. 开发及优化算法，与产品和业务团队紧密合作，调研并实现前沿技术并应用于落地场景，包括但不限于激励、理解、增长营销等场景；2. 对现有算法、数据进行分析和评</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445971&amp;idx=3&amp;sn=4d98b3fd64a4fa221ccb68935efc6a18&amp;chksm=bfc750d3a6e46da92e7e55c47580c24c16196b0cb8ab9512a9db566a31c33c4dc3ab3f8ed048&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 15 Nov 2024 02:17:10 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[「深度」学习计算广告，我为什么从推荐系统转向计算广告？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/7YJVBU9FXkXTRiaM3cq7SczaK8RUmYaaiaFKdWq1N5RMNjLjW67IPGemxeicsuakOj2JRJJu92HxBNW8K4oPl16pw/300?wxtype=jpeg&amp;wxfrom=0"/><p>「深度」学习计算广告，我为什么从推荐系统转向计算广告？你好，我是王喆，这里是「深度学习计算广告」的第一篇文章。熟悉我的朋友们可能知道，从2018年底开始，我更新了一系列推荐系统相关的文章，主要集中在推</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445971&amp;idx=4&amp;sn=93b412093c953d05729be2d6bddd13be&amp;chksm=bfb341597929add737bbb40444eb867250501a52b5d579d9f060d396434ced09e43b7918a720&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 15 Nov 2024 02:17:10 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[北航&amp;清华提出LBPE切词优化LLM]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/UkaMPMaoibmiaD5o9bzq3p6n5CLzbcZuaDJaITrB23ibvTgib9PA4mRemcQlgjOG2rZF4vO71PnCb6ZIuwQiaShP9dQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在大型语言模型（LLMs）中，BPE避免了OOV的问题。但对于长词元，富含语义信息，与短词元相比，在标记数据集中的出现次数较少，这可能导致不同词元之间的不平衡学习问题。针对这个问题，北航&amp;清华提出LB</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445971&amp;idx=5&amp;sn=8c0fdc26f967498d7bec77eb4cd96728&amp;chksm=bf0666b5d6e22131a6765c263c5dd357e134d1c92424b0b837a5c56f5e9fc4d70edaad728442&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 15 Nov 2024 02:17:10 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[今年顶会这情况。。。大家提前做准备吧！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKbTg2qwIlrzLUZibxAibJgZuVhsRnicAcTNaQcYibFFnt6brtmyaqVAIibl9UuSubw8A2tLrOjKQjyLww/640?wxtype=jpeg&amp;wxfrom=0"/><p>写论文之初最难的是找到一个不错的idea，这是非常重要的。一篇论文从课题的确立到文章最终被接收大概会经历以下几个过程：确定课题—调研—阅读文献—idea和实验—撰写初稿和润色—投稿—rebuttal或</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445953&amp;idx=1&amp;sn=f94881c7d4bf1af3b0b2f6c22fcc452b&amp;chksm=bf9d865038d0355b301c7d5341a74fdb0df2495429e361e82dd11d7f81960f73d026303804b9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 14 Nov 2024 02:09:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[SFT洗数据，有多少细节？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKf8hgPn3bsKZWXicnUJ6AtQianmzpKOhT7hia1oj7BiagGngic7HMxH5sIMEwtlh8aHk1o1biameQOtKTA/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：ybq链接：https://zhuanlan.zhihu.com/p/6497090767最近在清洗 sft 的数据，不得不说这工作是真磨人啊，细节多到让人抓狂。可能，这就是为什么从业者们都懂得</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445953&amp;idx=2&amp;sn=654b2e19c7b1d2f4f16b6a3c71012bea&amp;chksm=bf3c1b136e0aa0e66398bc4a2fcfd39a45d42648b5cd25ce96d2353d7feb27c3a7b1b260ed16&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 14 Nov 2024 02:09:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[对于Ilya当下Scaling law瓶颈观的思考]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/yToxjhYT5ibalDDMIucd5DgCExSdV8DibCUiaZacJOFyiaIYlJZXEibXpno6v1aamvOC9sZoCiblCiaZcBhGrpqRfENPQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>继The Information周日文章说Pre-Train模型的预训练“撞墙”了，近日Ilya Sutskever与SSI(Safe Superintelligence)接受路透采访，亦提出了类似观</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445953&amp;idx=3&amp;sn=584d542bf758986fea888d80a3cd2a56&amp;chksm=bfadee5501dcd54304c14dc45243f825986e4332c4b3237fbd434c38eb41b82d8ff0d7c00f10&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 14 Nov 2024 02:09:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[苹果发布Ferret-UI 2: 跨平台UI理解多模态大模型(精炼版)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/w3hibrVDUAib7YlVqod6Xkoicwic36VEJI8HYMjcOBiaek2neog0PcibzvFF47TD4RjhSOlgXAEJgfVb5RHs85k2XxYQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言简介方法实验结果总结实战0. 引言在数字设备日益普及的今天，用户界面(UI)已经成为人机交互的核心桥梁。近期，苹果公司发布的Ferret-UI 2 凭借其多平台兼容性和自适应编码等创新特性，在通用</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445953&amp;idx=4&amp;sn=a38643597418f788e26ab791f6814a3a&amp;chksm=bf2d2599e89cdbacdb347d0a9a436b6e8367d223167baf37c32a59c8132327f2498a899e3b46&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 14 Nov 2024 02:09:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[模型解释新方向！浙大揭秘LLM隐层之间的知识流动！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagPzaaVicAu3rUaOic95GhbNnFCPIhum64iaW2oBEjjWAlpAKPULicS2Y12wfu0Ghj4sibibkrLicWThptEA/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：bhn论文：https://arxiv.org/pdf/2405.17969 - NIPS2024代码：https://github.com/zjunlp/KnowledgeCircuits本文</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445953&amp;idx=5&amp;sn=05fad59d5400c4263375460b0b78d6cc&amp;chksm=bf2636af2d261ddcb5e8d7aafada66be77ce6bddfbb11baa2bed0011aa89535bdb3e375946e1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 14 Nov 2024 02:09:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LSTM再升级！xLSTM杀入大模型，连超Transformer和Mamba]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJhANLL2tAvHHWZMrG0icas96G1ibQAVRttUnYdeulgoKm1esEVBYM0D5xoA9iccMxJrhmic0Cib7ONWicg/640?wxtype=jpeg&amp;wxfrom=0"/><p>时隔27年，原作者携xLSTM回归，通过引入指数门控和修改记忆结构来增强传统LSTM的能力，不仅打破了LSTM在处理长序列和复杂依赖关系方面的局限性，并在广泛的任务和基准测试中表现出了显著的性能。为了</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445936&amp;idx=1&amp;sn=a97944f10d899eb526494c6c5496e13d&amp;chksm=bfc31c641c92aa329df26e703b8218132d5529479bb3cdae388331738c805143af27ea486737&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 13 Nov 2024 02:08:47 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLaMA系列一直在假装开源...]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJhANLL2tAvHHWZMrG0icas9zh4rzwzFrRB5vialyQk2WWDzY4C8j7R2GKibYIKyhUqVPtalrBcQNoBw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：chenyi源：深度学习自然语言处理伙伴们，很奇怪~ 关于LLM的开源与闭源模型的竞争又开始愈发激烈。众所周知，开源模型以其开放性和社区驱动的特点受到一部分用户的青睐，而闭源模型则因其专业性和性</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445936&amp;idx=2&amp;sn=3ea5f1d127af2ed2ab79b721da4aa297&amp;chksm=bfbf40fede70cf1bdadbb86c64a873f6a54d8a8b4fb217e86a879886839cf8b4f3a01ad38a16&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 13 Nov 2024 02:08:47 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[代码大模型(二)--OpenCoder]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW467gHs3ulgIHQ7ttdIuxMn0eicKnJhCRSDl3FqwwkiaMbIoyIJodibDkXPtj6KcT2HxKVVn33mXYxz65w/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近由M-A-P、无限光年、墨尔本大学、复旦大学等机构共同开发的OpenCoder开源了模型和部分数据，并且后续还会有更多资料放出。先来学习下技术报告的内容。目前各个规模和阶段的模型在 https:/</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445936&amp;idx=3&amp;sn=2de5ca87565b0f197970ecb5594efc20&amp;chksm=bff86ccfd60e97b60386fbd214daa8ae1f5fe130cd742a638b7ee4406eb6bd6b415ae4ecf58d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 13 Nov 2024 02:08:47 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[AI回答，不止于文字！阿里OmniSearch与传统的一场检索较量]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagPzaaVicAu3rUaOic95GhbNnjNRV6RiaHaCmhhg3vqCzgCcxUEa5LlicU8AOYfpmRTBtzdt4jWJe8I9A/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家分享一篇阿里的文章，目前还在ICLR2025投稿中，真的很不错！这篇论文提出了一种新的自适应规划代理OmniSearch，用于多模态检索增强生成（mRAG），并通过构建Dyn-VQA数据集展</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445936&amp;idx=4&amp;sn=910b5c903b6681827970cfc2e6522dd5&amp;chksm=bf35bb0153f6ac4a45b69e0895ba94e451461f08649ff537724188186075a2e29fe323e8192b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 13 Nov 2024 02:08:47 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【RAG】浅看引入智能信息助理提升大模型处理复杂推理任务的潜力-AssisTRAG]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGDwAI50wAX8Gz0nJFy83cTXJy2DZkhgTNvmbGbMrQC95cCxqzKnNxUapMsia38jtHcvfjQENhnx12Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>AssisTRAG通过集成一个智能信息助手来提升LLMs处理复杂推理任务的能力。该框架由两个主要组件构成：一个冻结的主语言模型和一个可训练的助手语言模型。AssisTRAG与之前的RAG对比1. 组件</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445936&amp;idx=5&amp;sn=c61cad09ad9a1b21ddc4b0ed84d8f1fb&amp;chksm=bff8c164a3b0e5498cf04feb10f83c73b16b7f5e4a88f8764cb07fccf3f77e41b0414cc6a528&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 13 Nov 2024 02:08:47 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
