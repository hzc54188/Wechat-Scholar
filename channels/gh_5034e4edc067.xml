<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    


























    <item>
      <title><![CDATA[大模型，再一次爆发！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJxicS1PnCwTxtEibn7coAIgogNbIvLOwuibwYTfSLalSLe6nN9DPdR5nWEuKHflVnO1ARKksX5Q5M5g/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着GPT大热“AI大模型”无疑是最火爆的话题！Google、百度、腾讯等巨头互联网公司，无不在布局人工智能技术和市场，为挖掘会用AI的后端相关人才甚至开出60k*16薪的高薪抢人作为普通程序员，如何</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443942&amp;idx=1&amp;sn=02f941c7acf24f4fea07bc7812a0bf0b&amp;chksm=bfe1af6c39078502234b67e9f5494dccabeca022bd3909934792ee5f5907f182eef1ac4052a9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 03 Aug 2024 03:30:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[2024 互联网公司工作时长排行榜出炉！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJDeOmO9jdR7tUNibWiaMpMuQTAgBWRBldHk845S4FIxD7YkI00BgexLEMhRGlsGw06icJ2vGQxoV3WA/300?wxtype=jpeg&amp;wxfrom=0"/><p>转自：菜鸟教程周末轻松一下，转篇文章仅供参考~不吹牛，月薪多少你能接受 996？现在大部分人选择在互联网公司工作的时候，除了会关注总包收入以外，还会考虑加班时长是否合理。摸鱼式 996，薪资到位倒是也</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443942&amp;idx=2&amp;sn=67dcfd14dd7d5d5e19576a9750b9abff&amp;chksm=bf8c12998703114566be7aca97f2feca8e5e04345a16dc0d50d726bde8f73231695603a45e65&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 03 Aug 2024 03:30:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[万字长文详解InfiniBand]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/J0mLianhFicBEOBzicVbQR7bLK9icEk41iclQJ2dW5olsR3clRZlmib6w7qIjM1sIHVdfzibH6dGvk1SF9Wyrqwkkm07w/300?wxtype=jpeg&amp;wxfrom=0"/><p>GPU在高性能计算和深度学习加速中扮演着非常重要的角色， GPU的强大的并行计算能力，大大提升了运算性能。随着运算数据量的不断攀升，GPU间需要大量的交换数据，因此，GPU通信性能成为了非常重要的指标</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443942&amp;idx=3&amp;sn=1412cd8bb9c48e25b572b862ca64daab&amp;chksm=bf34af209c512a1851c8f79213d622ba80fcb4212288347214d998bfa1bf2de137e558fe82c6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 03 Aug 2024 03:30:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[苹果智能系统模型--AFM]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW464bUxTuYPp1pXJu3cm5RUu7jdN8APaOeqnSKYviaOrqqITEoBlvUIgwLCfTaXz1pdskKc6Kx3yyticA/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前苹果在WWDC24发布了包含多个强大模型的Apple Intelligence系统，苹果刚刚最新发出来的技术报告《Apple Intelligence Foundation Language Mo</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443942&amp;idx=4&amp;sn=fe75cfc0fccd1b1c77dc9663c43e8477&amp;chksm=bf78064ad5269621b39ee7471926472c868e6979b9aa2bfb5d5c5e6397b009c052058e7d2a17&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 03 Aug 2024 03:30:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[SmolLM: 一个超快速、超高性能的小模型集合]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2ptlGvxOrxz1HajicEFWZY75rq88W1YQNEsJn3viaV5vSZxkwxiaIf0Rlm2hhvPfkTW3Ht6kpMJibvg5Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>简介本文将介绍SmolLM。它集合了一系列最尖端的 135M、360M、1.7B 参数量的小模型，这些模型均在一个全新的高质量数据集上训练。本文将介绍数据整理、模型评测、使用方法等相关过程。SmolL</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443942&amp;idx=5&amp;sn=19fba235d61a2b00fa516053725ce0e6&amp;chksm=bffe36e63a0552248b2bd76f27c2901f9ed9fcca87d0b24386ca78695c9fdf0c224d2ae3ddb4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 03 Aug 2024 03:30:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[探索混合专家（MoE）模型预训练：开源项目实操]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLy45lQiafOjJhNXiaBdyn6vu6ibl5gF1ibdYlEu9SzdibicIHhrghnMHDBYlA8FASI8icBFN8UbkQX457tg/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：Mantaverse，算法、产品、AGI，拥抱新时代声明：本文只做分享，版权归原作者，青稞AI整理原文：https://zhuanlan.zhihu.com/p/708804769MOE模型是什</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443908&amp;idx=1&amp;sn=bb12249cf0d284469760c451218f5e07&amp;chksm=bf6b9cc90fdabec5e773c2da4624b5e406aa7f47778d0351ae837d06510b83b83d7282f2d10f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 01 Aug 2024 14:09:30 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM开源模型】LLMs-Qwen2-通关攻略笔记v2.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdAXjIXxza8x2XFbqyaqIncia9oMfbsug8uKBE73uFibXmjm1PvhRh8c1TRqryaH7fQicNxHxrKX8aaag/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM开源模型解析第二篇，介绍Qwen2系列的开源报告QWEN2 TECHNICAL REPORT，其中会涉及Qwen2核心总结，模型架构(Dense,MoE)，模型预训练(基本预训练</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443908&amp;idx=2&amp;sn=288e787bdb3c6bb0136dfa7b6d491adc&amp;chksm=bfc0a248f1df88b56a34023b07fca1bc29e078e415056b2f303d9eec40ee581da282f5410c00&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 01 Aug 2024 14:09:30 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一文详解模型权重存储新格式 Safetensors]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/J0mLianhFicBHgGYjELapDzUdsMKMa9tj9MzM9E8oDG3sB04WKYg8Wiaq04bfBuWOSUrVNMiboIvzPQl6OmX4wdAGQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在日常AI模型训练过程中，需要好的模型权重通常需要以一种格式存储在磁盘中。比如：目前最流行的AI框架 PyTorch 使用 pickle 格式存储模型权重文件。但 PyTorch 文档中有一段话说明如</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443908&amp;idx=3&amp;sn=40dfed24e1d92e3ac384dffdfc7425a0&amp;chksm=bf69bcceeca4c1edea725969df458236570f889d33267e1ff6227d349de8d638d72a8cc8c9d6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 01 Aug 2024 14:09:30 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[模型平均 -- model soup]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW466M8Y3U3QB91CqLRAlGaSWiaKRAQa7p0bSYEbAQuLNlvpRkLzHcE7zzG3sZr5w4XnvpgJTEqG6u3CA/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近苹果的DCLM和Llama-3.1技术报告都提到了model soup：《Model soups: averaging weights of multiple fine-tuned models </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443908&amp;idx=4&amp;sn=8e2715aabbd33e1c7301e0fa403a65a1&amp;chksm=bfa020199772c4811e0504612a9e3d1d180e2ac3fbcdda9de7360eb7727feba259cbc2e60148&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 01 Aug 2024 14:09:30 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Language Modeling 中的negative diversity ignorance问题]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/QLDSy3Cx3YJdJDpxic9ZaJz8DRGxxas0VkAibvG8kka3akOWv5VR1feRT4Oju8q4Clm5nFMnk4evIbAV4lPXnngA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Language Modeling 中的negative diversity ignorance问题Auto-regressive language modeling 使用 cross-entropy</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443908&amp;idx=5&amp;sn=d5031cf6c424a886e8c4182b2e5c6970&amp;chksm=bfa8e4e4be1c3f1d989324d05c6770f43db8a114e77ff1b0fb6630a5a89db83b41a5327c23dd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 01 Aug 2024 14:09:30 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[“我，在腾讯月薪6万，离职后突然惊醒：人越努力，只会越平庸”]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL5XkL946ZRAn14LSUn6KtxOqLYtEU1RIz2YiasfArW7SqtZg4DGLFGjDM51kY3TuXYsjIwOD7w4lQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>“人要努力，要有上进心，才能成功。”这句话我听了无数遍，所以我一直在努力。小时候努力考100分，长大后努力工作，努力买房买车。可我努力了快半辈子，但感觉成功还是离我好远，好像看得见，但总是摸不着。而且</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443895&amp;idx=1&amp;sn=94c88baeda0c4d02f9807058a1ff7d10&amp;chksm=bf4207343846a0f242d829a7b72fcecfca97bcbcaf58cfb37fb7b6e316e6e8e48004184a7e5e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 30 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解Attention优化: 从Online-Softmax到FlashAttention V1/V2/V3]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLG41KibtRk3XGfoRibZP2iaU3Gcc8eicqTOoTSXicJz11EZyWmhkJvribRbxed4rIicGibDsJclnpqxiaaqHg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：DefTruth，AI Infra，暨南大学(JNU)主页：github.com/DefTruth声明：本文只做分享，版权归原作者，青稞AI整理原文：https://zhuanlan.zhihu</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443895&amp;idx=2&amp;sn=869eb05182628907d0f21c7d820b4799&amp;chksm=bf48dcf4bdb3682c20766d39752e1b608c3ab8484a0acd1ab1ac072fa11ad83cc9a1455e5379&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 30 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM开源模型】LLMs-Llama3.1-240723通关攻略笔记v1.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdAXjIXxza8x2XFbqyaqIncia9oMfbsug8uKBE73uFibXmjm1PvhRh8c1TRqryaH7fQicNxHxrKX8aaag/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM开源模型解析第一篇，介绍Llama3.1系列的报告The Llama 3 Herd of Models，其中会涉及LLama3.1核心总结，模型架构，模型预训练(预训练数据，模型</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443895&amp;idx=3&amp;sn=7cdd80c9cb922f189f9d063ce1d46255&amp;chksm=bf3b826f4adfe4008fb5c0fdd5096d85430693feb09d10d0d21e165482954dfe27d7f7fecb92&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 30 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[基于LLM的搜索排序]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BAVX0pafImnIo1TQpcomicOE9ibS6OIufooCE2r3xBgVoXVs6vYRzXm4EV7Db4G9QJfneZzGlWtAZmle5QV2KulQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>大语言模型在各种与语言相关的任务中表现出了显著的零样本泛化能力，包括搜索引擎。然而，现有的工作主要利用LLM的生成能力进行信息检索，而不是直接进行段落排序。这篇EMNLP2023的论文(Outstan</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443895&amp;idx=4&amp;sn=0c3b540744d161093b16a57749f1c39a&amp;chksm=bf8d8ad5410cc0e12c15c734c236ac3220cd49839ad34da5ced9f80b3255954292124fe6af9e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 30 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Nvidia提出ChatQA 2，提升LLM的Long Context和RAG能力]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/s7YKINJYHDDlVFYzMaJU5uPu0Gf4Jt5Z0ywsKHUquJNUfsOmqEZKYpEUS9Ck1f3sPvILBdzbRTyZOW23NkoZ7g/300?wxtype=jpeg&amp;wxfrom=0"/><p>近日，英伟达发布了ChatQA 2模型，其想法是弥合开源模型和领先模型如GPT-4-Turbo之间的差距。文中提出了一种训练方法，以有效地扩展 Llama3-70B 的上下文窗口 (8K->128K)</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443895&amp;idx=5&amp;sn=5093a0f95c6d46476a8e06eec6b8578e&amp;chksm=bf2f99cf633ea2c26026d1e428d1d2b06a0d58d9a38a02eb8a1b01a795cf6a627e3e0b4d7149&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 30 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Llama 405B背后的训练、对齐技术演变路径]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJNm9ibRjg92hvspnjfnnUJxRDzu5IQtX0Q0L9mVKiaWibJeWQd7AYbsxj27X6NlDJYzqH6aGOOmwVjw/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着大模型的飞速发展，在短短一年半间就有了大幅度的技术迭代更新，LoRA，QLoRA，AdaLoRa，ZeroQuant，Flash Attention，DPO等技术效果已经在工业界逐渐得到验证。过去</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443872&amp;idx=1&amp;sn=d1e12680276f9237dabe7ba80ebfa466&amp;chksm=bf252fa7a7a786644522d7fa8d68b1f1a5e153a83e5132a9a33d316b8bc01cfcc5de59d1350f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 29 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[为什么说大模型训练很难？聊聊预训练的一些经验]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL5XkL946ZRAn14LSUn6Ktxv57nAWWy5rPhzuZn6mfEEzbgLLLoOyeMbeFFBTfWOLibKQGN0unX6hg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：罗小黑，主要做NLP声明：本文只做分享，版权归原作者，青稞AI整理原文：https://www.zhihu.com/question/498271491自从Bert网络模型产数量超过3亿规模，当</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443872&amp;idx=2&amp;sn=3df3010223b426ce74c8edca121bfd54&amp;chksm=bf2a2aaa5037c579c45620a6b5fb6ddf1923e2b5d34009bb9f25dd67e02bf8f282f224484557&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 29 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Llama3.1--post-training要点一览]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW464iactcJwYsUrZcBMI7BgI5ZMbgUd9kClmXjZ5icto96sODFT3SY3u6kvBQRiak1gfl5DCjHQ5F4tSGA/300?wxtype=jpeg&amp;wxfrom=0"/><p>书接上回：Llama3.1--预训练要点一览，继续整理一下Llama-3.1中post-training的内容。在Llama-3的报告中，任何在pre-training之后发生的训练都属于post-t</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443872&amp;idx=3&amp;sn=05f2ce4a16c8228801c02e9f41d00fab&amp;chksm=bf36231f619f25b0a2e815a81b55a613f7b0ec640fdb9a21f22b9694d7b0d1c8ab147783cff8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 29 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM基础知识】LLMs-Norm&amp;激活&amp;FNN层知识总结笔记v5.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdBbOW12YJpSibiaSgCWJB70SsNl1lwC3L5zBZpy5zkib8Ba5qpjr1Osw5MbCmJ354aicMibhQLGD6Pia8Ww/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM知识点第五篇，介绍LLM中采用的Norm方法，重点介绍LLM常用的LayerNorm，RMSNorm，DeepNorm。接着介绍ReLU，GeLU，Swish激活函数和GLU及其</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443872&amp;idx=4&amp;sn=af329c7b93a7e864bc18cc8b6b9cdd3f&amp;chksm=bfb8d5e126a88ad082efa3a86551ffe80b68742914362a23c1a0929a32df80026f36ac48d057&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 29 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[语言模型之text embedding（Decoder_only篇）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKpsGBXO4eSaJl81GYQgRZ3NyQKicfZq3vTctrGmuBGKXJKOvl22D2Lp7zXaPMicGcfRbjoF3E7P8ib5dg/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲1 简介2 任务介绍3 decoder-only    3.1 模型基底优化    3.2 注意力机制优化    3.3 Pooling方式调整    3.4 训练数据优化    3.5 训练方式</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443872&amp;idx=5&amp;sn=80d40eca682034aa6dd59a963612ae67&amp;chksm=bf78acde071fcfdcd373a1108dfee76e5802d20c914729a20bebc86610a8060d04d2883cd5ee&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 29 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[腾讯宣布全员调薪了...]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJNm9ibRjg92hvspnjfnnUJx4R42s2NzFricyXQoGqIUGDAAPpLnkJErBNSreicXhicWbCdh0zpHGtTyw/640?wxtype=jpeg&amp;wxfrom=0"/><p>7月10日，从腾讯内部人士处获悉，腾讯发布全员邮件，称将调整内部薪酬福利政策。主要内容如下：1. 校招生的房补从每月4000元调整为按15个月发放，并将其纳入月薪基数中。调整后，员工每月基本工资增加3</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443846&amp;idx=1&amp;sn=6d8272b34fe553d453cb4df0027256a7&amp;chksm=bf6791f66a2655c88a7bdc4fa5254e66b372ce89519dbba51f0cac55fbff521f5a315493d758&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 28 Jul 2024 11:25:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[赠书：《快速部署大模型，LLM 策略与实践》]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJNm9ibRjg92hvspnjfnnUJxrdzWibgBsKMHoeFib9GWaWN01qJKPjqqWEgsiaPaS9hS2gICicTrL5S7tg/300?wxtype=jpeg&amp;wxfrom=0"/><p>❝本文“如何写好提示词”节选自《快速部署大模型，LLM 策略与实践》一书提示链提示链涉及使用一个LLM的输出作为另一个LLM的输入,以完成更复杂或多步骤的任务。这是一种利用多个LLM的能力,并实现单个</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443846&amp;idx=2&amp;sn=04ccaf98ff4c97564aebb4a6f8b45320&amp;chksm=bf8b261fc726c4696bf4620ec3b7c03fc9af16174c63dd89047537b38d9af5975457f3f3ab8a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 28 Jul 2024 11:25:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[如何从Meta窃取价值百万的Scaling Law数据]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/d6902wUyyvLfeJib8wQKFH6zcM9Rial544FClvia23rLqem3jVkQoYs5cT2mBlaQV0C1cTSVme7VXKpy3s3Dcwp3Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>Surprise surprise 恭喜你被骗了，这里的一切内容都是合法且符合中国特色社会主义价值观的。背景开源皇帝meta最近推出新的开源模型llama 3.1，其中最大的模型尺寸来到了巨大的405</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443846&amp;idx=3&amp;sn=68380eeb803ce0a9a4319456a654f320&amp;chksm=bf982d028d3ba82edfa4872d27364460f83f11591199fae9a36801c46109118bb2b6c1499ea7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 28 Jul 2024 11:25:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一大堆Llama3.1-Chinese正在袭来]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5kuOUbz3AyNbp5qse4qsk9dFcK5tXRLkfWkRY8WjxSQiadlDzf5yfTxBiauzF6EiaXsDklvAItibicKFJw/300?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面Llama3.1模型已经开源，在这短短几天之内，也是出现了一些Llama3.1汉化的repo，开源社区也是相当的卷。主要是Llama3.1没有关注中文，虽然是多语言，但主要针对英语、法语、德语</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443846&amp;idx=4&amp;sn=c566979ad666e3a1f77bac9429faa205&amp;chksm=bf85f894796094c6247456e29f209c1c03e7737698529133f0f16ace864ff3dbbe7c5061af20&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 28 Jul 2024 11:25:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【推理加速】vLLM加速部署LLM重要参数]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGDTOu5v1pvJZ5c9MiaEdgSRDmib6LX2ibTdIWb2MI8Pwv4icibQLtNlqQclWPX0mHnuJXm9jkvjT3MthKA/300?wxtype=jpeg&amp;wxfrom=0"/><p>部署简单示例from vllm import LLM, SamplingParamsprompts = [    "Hello, my name is",    "The president of t</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443846&amp;idx=5&amp;sn=7c2a1989009b90e172bb8200ac64235b&amp;chksm=bfe1a6f8a76b7a206aff597db74b67a5919546925859f7ccc99fa3d396dbca9221050fd0f7a0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 28 Jul 2024 11:25:39 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
