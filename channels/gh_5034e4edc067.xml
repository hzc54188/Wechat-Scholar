<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    









































    <item>
      <title><![CDATA[GPT-4o炸裂登场！大模型仍是最大赢家！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIvgYwzYO97qmBRfkkPv1wz9br4RPQw75FR6Pn6j9SgkMIcJaccr5q3kVBVLNnH9RGkSxCUARWE7w/640?wxtype=jpeg&amp;wxfrom=0"/><p>从一年前ChatGPT突然爆火，到不久前文生视频大模型Sora以霸屏之势吸引全球舆论，再到OpenAI发布的王炸GPT-4o，与AI大模型相关的议题越来越多地被大众所讨论，如果说2023年的大模型风暴</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443749&amp;idx=1&amp;sn=42f6ee45b028da74a7f6c0d94224dc15&amp;chksm=bf0592850fe51ba8faa1e067df36fd29b2702d21feb03da712215e44c0738fbee307bae19d6e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 23 Jul 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[2024年大模型LLM还有哪些可研究细分领域？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/s7YKINJYHDDbRBlyS0HB5ib1wvuEj19dd4Og24zsWBlC94Vvf73iam0w8hibKTBAAqgj5sEbC5tzZdXW8kuCeYVdA/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：swtheking来源：知乎Pretraining部分Data Collection整个pretrain阶段最重要的部分就是数据收集，尽管OpenAI已经给我们了一套标准化的数据收集流程并也有很</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443749&amp;idx=2&amp;sn=43d05bbf11ec3d43f83fdd704baeb34b&amp;chksm=bff423f01a86941b9bf29864645e752397a6c69da4e8469ee864708840f057290f0a9dc74e6a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 23 Jul 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[从dense到MoE -- sparse upcycling]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW464KJqafZSxMgcFxyCd4r3vs1gmEdfVEr2WZu1OIeYYSeIJgDATYXUDicwjOib61m98Mnme0OvVfGChQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>目前已经有很多优秀的dense大模型，那么要通过MoE获得更强的模型，用已有的dense模型进行初始化是一个自然的想法。Google的sparse upcycling对此做了一些实验，由于实验是在20</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443749&amp;idx=3&amp;sn=c3fb9129c8d56fad741b209b21078e01&amp;chksm=bfabc9dfae3d89e4e5e40a2435a88476b69ea31aab0c39bb482e9e80853e5da82384a7cb4ed2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 23 Jul 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【LLM基础知识】LLMs-Attention知识总结笔记v4.0]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdBbOW12YJpSibiaSgCWJB70SsNl1lwC3L5zBZpy5zkib8Ba5qpjr1Osw5MbCmJ354aicMibhQLGD6Pia8Ww/300?wxtype=jpeg&amp;wxfrom=0"/><p>‍【导读】：本文是LLM知识点第四篇，介绍LLM中的最重要的Attention机制，具体有Attention机制，Self-Attention，Multi-head Attention的原理和实现细节</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443749&amp;idx=4&amp;sn=fc3695180d8a3ff584cd7180d430851a&amp;chksm=bfd514001223d3fb68b7def815549f77a790544d1e787b38e651ad95de7241d100a40282f49e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 23 Jul 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[ACL 2024 | 关于多语言上下文学习中示例影响的多维分析]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ibj1ATvtMalpSwjy3eOS2RDA2CIm0B42MeA6KPIPzPrNx3tUB2DYDjmQHp3Zd00RxZk9jOb4tAS1DaiaNL68CjNw/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文分享萨尔大学和慕尼黑大学团队合作的一篇ACL 2024 Findings 长文: The Impact of Demonstrations on Multilingual In-Context L</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443749&amp;idx=5&amp;sn=95cbc4557ceb1e831a39a3d146ef42cd&amp;chksm=bf77c04f25555605de05e3eef6985bdf67ee2c509ae61dc9fe3c24d0750f4997cfa8030cd362&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 23 Jul 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[刚刚，中国IMO奥数憾失第一，五连冠统治被美国队终结]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL12cxZFvsFfTxbxRLDXwM5BoMq1GIZO2KfibKca3ZBJ2ZR5HRa8Aj3LU7OxB9Dz4wQLHibIVSWDzsg/640?wxtype=jpeg&amp;wxfrom=0"/><p>来源 | 量子位意外！全球奥数终极对决，第65届IMO，中国队以2分之差，憾失团体第一……卫冕失败，“五连冠”被终结。此次中国6位选手共摘得5金1银，总分190分，团体排名第二，位列美国队之后。中国队</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443733&amp;idx=1&amp;sn=836f8700b5449a73c20e2d3741725cbb&amp;chksm=bf135c320039611881c158b4588c364951af8cee82b58e577e3ef3196b9892daffe4fe472812&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 21 Jul 2024 09:30:05 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【文末赠书】清华汪玉教授团队：首部高效模型压缩与设计专著重磅上市]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL12cxZFvsFfTxbxRLDXwM5Ol8K0KrEI8P9HwUibOPvlG1nKKYaE4iaicvhOdM0G1ibtQbRpNM7bBnjPA/300?wxtype=jpeg&amp;wxfrom=0"/><p>汪玉 宁雪妃 著电子工业出版社-博文视点 2024-07-019787121480591 定价: 119.00 元新书推荐🌟今日福利｜关于本书｜本书系统地介绍了高效模型压缩和模型设计的方法，在编写上兼</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443733&amp;idx=2&amp;sn=ce42184634f20e600ff53eff81a79f7c&amp;chksm=bf8f7a94354b89c784a4e8f8887a4c25f5f2de0d8629159a9ae86089d77ef50d5f587f1dabda&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 21 Jul 2024 09:30:05 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[对话AI科学家何晓冬老师：大模型时代的业务探索和个人发展]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/BwrOLGIZh5WZiavuf6aAsYBcibhER7PdKnWRc6q7ic7GSAoiaGUzGzv7c5BSgvv1Gc8OcuxoiaENhgJAl3ZbfBkadxA/300?wxtype=jpeg&amp;wxfrom=0"/><p>特邀嘉宾 | He Xiaodong访谈编辑 | Yuan Shaozu【导读】非常荣幸能与何晓冬老师进行一个小时的深入交流，这次对话让我学到很多。何老师主要分享了大模型带来的机遇、业务探索的过程，以</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443733&amp;idx=3&amp;sn=fddd1944c345250332114348c3a89355&amp;chksm=bfc845510576ad81822c574fe7288e81b5213b6c13e7d8ff627b5ef3dd8f84e4888db380dc52&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 21 Jul 2024 09:30:05 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解大模型计算加速系列：分离式推理架构2，模糊分离与合并边界的chunked-prefills]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkP0NCwHmDcdRAso0pHZib3DRvsLroqjxugylE4AiaI4wJBnAaBqeF9MfJ80qXZtJDaj1bibJxuU6A7Zw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在分离式推理架构1中，我们以DistServe为例，解释了“为何要使用分离式推理架构”：分离式推理架构可以解耦prefill（compute-bound）和decode（memory-bound）过程</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443733&amp;idx=4&amp;sn=79e9d3258e3971ea6cb627b8910a85b6&amp;chksm=bf85f8b53992bda7d6d08ccfd23265189c476a29d66fb81e90c2374d08680b39ce80d9094124&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 21 Jul 2024 09:30:05 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Google最新开源大语言模型：Gemma 2介绍及其微调(上篇)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/w3hibrVDUAib4icLAibNLvZrOVxK4RXXjBSJXHhJ5JTpwGXjJm1F11ogE0JAy35aZUjM46DTCh3Utnnib5AptFLaAPg/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言简介Gemma 2模型介绍架构设计训练方法后训练优化关键发现:知识蒸馏的影响性能评估使用体验：Hugging Chat如何提示 Gemma 2基于Hugging Face Transformers</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443733&amp;idx=5&amp;sn=cee404b5aa92c1c8dea1654e61a5254c&amp;chksm=bf2da97dd3cef381d53727aa4b4a7d30088d18a0257048433953657be6ee050c248ab93f8531&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 21 Jul 2024 09:30:05 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[用最酷的LR，训最猛的模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIGNAd6DMJrmXXkrrzAGibbkMtibRZjze4nrrVKXTI9szRy9wLoZWFjFia9vHunkVIOHAiapQjY2dOibqg/640?wxtype=jpeg&amp;wxfrom=0"/><p>来源：李rumor预训练中，除了模型尺寸、数据、计算量之外，比较重要的就是batch size和learning rate这两个超参数了。从DeepSeek的scaling law工作[1]中可以看到</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443695&amp;idx=1&amp;sn=657606cbbd17a24cb424fc871f5ef578&amp;chksm=bfed5d097720acc0abe58a1e9a17351f0ef2b06eba3357f1181c0c60d727e10497d6aefea960&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 20 Jul 2024 13:55:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型精细化对齐之step-dpo]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIGNAd6DMJrmXXkrrzAGibbkUU0F73P0qeEktI3gqNFiafic2QVAkEPdjZbocIicia5WkjIHt3C1ibhDrYQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>来源：算法让生活更美好前言相信大家对dpo都比较熟悉了，今天给大家介绍一篇dpo的变种step-dpo。数学任务相比于其他任务有着明显的不同，其每一步step的推理都必须准确无误，不然一步错步步错，传</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443695&amp;idx=2&amp;sn=0c562644485edbbec2383132ef8d9ed4&amp;chksm=bf1c20e86ef4a1bc5e3f4ad5c6213e30f4a34dfea2a721e9bfaa5e8b5f363e918131eddb94d8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 20 Jul 2024 13:55:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Neural Networks（CCF-B）特刊征稿：大语言模型时代的模型压缩]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIGNAd6DMJrmXXkrrzAGibbkJsuoVnTUv7q9GncOx3wDCzBlKjych1Rch8H2X1utSP0mjdWGMvZVAg/300?wxtype=jpeg&amp;wxfrom=0"/><p>大语言模型（LLMs）作为基于神经网络的大规模预训练统计语言模型系列，在自然语言处理、多智能体系统和多模态AI等多个领域取得了显著成功。由于应用场景广泛，LLMs 面临显著的效率挑战。直接在个人电脑和</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443695&amp;idx=3&amp;sn=25a39fa4025348ce3c2f762f3ea362fa&amp;chksm=bf1fa45831634ac57de1126408c4a4e01a71279c3546650ae2ae3fb264a12a37ca84154ce927&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 20 Jul 2024 13:55:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[领域大模型修炼手册—从训练、评测到应用搭建]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/BwrOLGIZh5WBicpclFjUmWsKEiacUoLWJGmmHDdbVIYibibh2k7NuDgVibHQk8ajRKpRb4D3drwtyTryZ8xp2DvHdicQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者| Zhenyu Zhang, Shen Lei, Yuming Zhao, Shaozu Yuan, Meng Chen    编辑| Shaozu Yuan, Yuquan Le一、整体介绍及</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443695&amp;idx=4&amp;sn=5c4298f3235d46437f568cc6fab95828&amp;chksm=bf19105910d8cf16a0ab466d1c20bcde1727632536724aed9e80589a6e04e52250355fbe0a46&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 20 Jul 2024 13:55:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[vllm代码更新太频繁，我该怎么办？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkNODJJ7uxbMLJevFmrdYlZLiaXqdu7GMB3GwibIk897DsIaAvWZlZCvUcluoV0P3sQFlOiccodaRnVNw/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，大家在读vllm源码解读系列时，肯定会有以下疑惑：“vllm仓库当前主分支的代码，好像和当前文章中展示的代码，存在许多不同之处，这是为什么呢？”这是因为vllm的开源社区非常活跃，代码一直在持</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443695&amp;idx=5&amp;sn=ab9da6544aeb23d4d411707d262270f5&amp;chksm=bff0fe6b83555a2c8b28f1fa4c46d2ea0767b5be4ab6f700134a9e2e54f27e6a558b8d941b46&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 20 Jul 2024 13:55:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[MMEVALPRO: 更加可靠、高效的多模态大模型评测基准]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLtBshx1pv6Jxdn7szZVia935qjF1db4o6WXIbMSBxXDNYs40YicPWtACFMaVxrD9uO6RnuOm9tZeNg/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：MMEvalPro 团队 单位：北京大学，中国医学科学院，香港中文大学，阿里巴巴摘要:  近期，多模态大模型如GPT-4o、Gemini-pro和QwenVL-Max在各类评估中崭露头角，频频登</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443675&amp;idx=1&amp;sn=11a546e0232a9c33aceb56630cad8d2b&amp;chksm=bfa03e5d446b31ad4c877bb55fa4108fe02280f96fb2e78bf90685eee17f99529b9f157a065f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 19 Jul 2024 13:19:17 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[我为什么不看好LLM——记过去一年实习经历有感]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BIxKnWsJfBaqwjLTFVeoibMz4HJruvGG9vNQ44ksjzAGLohx0BsICe6yguITTrmrtKsiakDP4lCn6SXxAzWnWqJg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天分享一位好朋友过去一年在各个大厂和初创大模型公司实习的经历，现在大模型是风口，他的眼光和思考都值得我们认真体会和学习~笔者为了寻求科研界的不同体验，试图在工业界寻求一些经验，在大三一整年做过差不多</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443675&amp;idx=2&amp;sn=00c27d479e19b7cddb6f0ef5070af46d&amp;chksm=bf0307e9912820c85d7d45f34b248a012884c695576c9a10fa24ba7226a7338591ee51e94189&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 19 Jul 2024 13:19:17 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[壹点灵招聘AI Agent工程师/架构师]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLtBshx1pv6Jxdn7szZVia93aSRl7EHbcHy6tqmfBibND5QhoCQIe26gV3bLXibicKmu8M62icMpvINDgA/300?wxtype=jpeg&amp;wxfrom=0"/><p>AI Agent工程师/架构师  工作地点： 上海/ 杭州 简历投递：liuf@yidianling.com岗位职责：1. 负责AI Agent的核心逻辑实现，算法及模型的设计、实验、调优等研发工作；</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443675&amp;idx=3&amp;sn=8fa2215d638aaeb3e28b2fa4ecef9b59&amp;chksm=bfccff952b0f5bdf9da901039dfc597c8c5d53aba71994ce29c1d5b40526a8aa654475cbb1c6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 19 Jul 2024 13:19:17 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM基础知识】LLMs-位置编码知识总结笔记v3.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdAD1Oo35L747k4MCxcHVYYP7QAVMC3crJVO6lnnGicXOXouIPicTGocMMzhzGmqQ58KZ8zaTd2Yvp0w/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM知识点第三篇，介绍LLM位置编码的三种方法，主要介绍绝对位置编码sinusoidal位置编码，旋转位置编码RoPE，相对位置编码ALiBi位置编码。#接下来会更新围绕RoPE的改</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443675&amp;idx=4&amp;sn=a0d20d53c2525835ab10534619a0a827&amp;chksm=bf7e251ec22629f6885a0847d2bc7eb5a55e35a002f0cf972d6c474fc08387fba832d6f6e917&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 19 Jul 2024 13:19:17 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型算法题(8)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW467K6QOibf2swlTicAicrYHw6mianJMoqMTmXOcTibKK35dcsc67IXsjOaG3ueTlcy8BXgch7ibe2GuzyCPw/300?wxtype=jpeg&amp;wxfrom=0"/><p>本系列将持续整理一些LLM中关键的、细节的、值得关注的内容，持续更新~如有错漏，欢迎指正~1.激活函数GeLU是怎么设计的，有什么优点？GeLU函数在2016年在论文《Gaussian Error L</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443675&amp;idx=5&amp;sn=a32cdd57b8bc0a365d789c4c2d3047d5&amp;chksm=bf4888e6f91d524801d941de98bcb3f3746e2f9759680da3994b4286a22cb3b83e84f2cf11f8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 19 Jul 2024 13:19:17 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[薪资真猛！小红书「REDstar顶尖人才计划」全球启动，大模型、算法、开发全都有！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLjjIjsuXOFg7G22yZoTDkHSpNFohmLBTHWZgrHoB1y8deCeVL7z9iaNAjpAPhAOSLiafsRhwW2oRUw/640?wxtype=jpeg&amp;wxfrom=0"/><p>📢 小红书「REDstar顶尖人才计划」启动！大模型、算法、开发岗全都有建议今年校招的同学都去冲一冲毕竟小红书这几年发展特别特别快给顶尖人才的待遇属于Top1梯队 大家现在冲一波趁着校招提前批把小红书</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443648&amp;idx=1&amp;sn=ee06af34d3a49ac7990f591b3b58ecba&amp;chksm=bfed279516ba61405027cd768503587fb72be610f4fbe21f2dec1ab11b480de6bf0eb4173845&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 18 Jul 2024 12:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[首个WebAgent在线评测框架和流程数据管理平台来了，GPT-4、Qwen登顶闭源和开源榜首！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJBmOWaUib0Yq1t4m2RhFChv645UWGnPS9YMb1QEYJuIJxJ2ZUlGGKo77D9UBA3FBPDPDWUdZk1kRw/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文标题：WebCanvas: Benchmarking Web Agents in Online EnvironmentsArxiv论文链接：https://arxiv.org/pdf/2406.1</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443648&amp;idx=2&amp;sn=dfa7391a5f0babbdabf17d2634d00391&amp;chksm=bf1760340ddb3d5b79dae8f2f9ff6a7f3fbb93edd2cb58c88d638d4c18a7e9fff322eceab5bf&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 18 Jul 2024 12:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen2技术报告]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW465Z198r2JSfhntlPNWtV9icJy1icM8Cb0G8pMB8Afib6kxe7CTrUlr1AhWngFTUtPS4N6iaWstoia1ETQQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>不久前Qwen2发布了4个dense模型和1个MoE模型，模型规模从0.5B到57B，实用效果都还不错。现在技术报告终于来了，来看下技术报告里披露了那些有用的信息。1.模型Qwen2的5个模型结构和训</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443648&amp;idx=3&amp;sn=824a060865fa36f9cb540fb0efd8956d&amp;chksm=bf9584c8cf08bc74d5ef2fdcc9a4b82498c3aa9e323b816005f777592fb611659857a9ff34b2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 18 Jul 2024 12:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型数学能力增强方法总结]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/s7YKINJYHDDaPlxPvo65sjR5bYFAaiabBaJU0xezVEDlPXcwQ7WJF4AcxAbWxjCVJjxR3gjqYZE1aNficxVgXiaoA/300?wxtype=jpeg&amp;wxfrom=0"/><p>WizardMath (2023-08) WizardMath模型的设计理念和训练方法体现了深度学习领域中对于特定领域知识处理的最新进展。下面简要概述一下WizardMath模型的训练流程：监督式微调</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443648&amp;idx=4&amp;sn=c3badc841ace914e0e6b4279e629c88b&amp;chksm=bff047ed1b53a5bf730ffaf3f32c37085cf4fc841f26969409335707693a6bacce0a89a09396&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 18 Jul 2024 12:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[微调 Florence-2 - 微软的尖端视觉语言模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2qJicbLk0lNibZMmJicddzyvITrWdibVKUibibtMakmcPoNpHre8T7FIqA6DojNOX0SZudcAS3N8quI9YfA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Florence-2 是微软于 2024 年 6 月发布的一个基础视觉语言模型。该模型极具吸引力，因为它尺寸很小 (0.2B 及 0.7B) 且在各种计算机视觉和视觉语言任务上表现出色。Florenc</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443648&amp;idx=5&amp;sn=a6741ca595c1fdc34961fab8f2fc4545&amp;chksm=bf41f0487dbda9bdc64451ef89fbcd7acfee0a93a6ab463a4091697318a3cc4c1f7e3cb6755e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 18 Jul 2024 12:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM新机遇：多模态大模型SOTA来了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSINDeXxekXCmTAZ1b8TdgnCzd8JuyHwISZZVdyCDLKiaWDLbBAPcM09vg8I0wcp0VX9Tv3xeic0FFew/640?wxtype=jpeg&amp;wxfrom=0"/><p>GPT-4o在人工智能领域掀起一股多模态热潮，多模态技术也正处于大爆发早期。今天的多模态AI在科研领域几乎与2017年的NLP科研路线一样，所有需要研究的上下游任务与所有可能的技术路线之间，正在上演各</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443613&amp;idx=1&amp;sn=d6b8ca5c11c1afdcdb6d9a95c2200e58&amp;chksm=bf925eaceb09106202142d99a4677b28d225f8a9dd522b5916aefad07eaa5dcdfb365881af85&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 17 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型Infra这些年，从黑铁时代到黄金时代再到白银时代]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJBmOWaUib0Yq1t4m2RhFChvBuZfWVloibDFu9JvpscPP0DTh2g1bibc47JBWAfWcibWuPuG1u0FBQDWQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：方佳瑞，清华大学 计算机科学技术博士；腾讯 · 专家工程师。声明：本文来源青稞AI，已经授权，版权归原作者！原文：https://zhuanlan.zhihu.com/p/708594043越来</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443613&amp;idx=2&amp;sn=fad70357f9a0ae0fbf7c5c278f6bb3ec&amp;chksm=bffb332cafa91c43172b0091def0b5a66ecc5b8e05a6f3be29c494e9b6bc703d4b921b052f0a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 17 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大语言模型高效推理知多少？三万字长文带你揭开神秘面纱（数据级、模型级和系统级）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icojeaw0hI4pYfd9YGsUzibiaeXk12tIVfiblCFTEIciagEfLb8C4t9uFaGoZxHzicGe4KibsNfSJrh3w2oIg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：Zixuan Zhou等解读：AI生成未来      论文链接：https://arxiv.org/pdf/2404.14294.pdf大语言模型（LLMs）因其在各种任务中表现出色而受到广泛关</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443613&amp;idx=3&amp;sn=de6aef5b8ccafc35d53a081981828b9f&amp;chksm=bf2c7b9d8819e0ec121a24c2533303e9ee7183f22d6ea3b6351810086a6a057e2a168e7bc2a4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 17 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[对MoE模型的一些观察]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW465JrAA3I2jCvGvQBvqU3licQlvNPm1dYwZI2V1CRD2YIZBuAib4JFCeMKOwF9LeLX0ibuokhlP3etscw/300?wxtype=jpeg&amp;wxfrom=0"/><p>包括清华和港科大的五所高校对几个MoE模型进行一些研究，并给出一些相应的模型设计建议。1.MoE当前主流的Sparse Mixture-of-Experts模型在N个专家中激活k个，k < N，具体建</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443613&amp;idx=4&amp;sn=dc5abe660357efb712474422977ec68c&amp;chksm=bf40dc916306fa5a47602f6a8b670b64f18860c8439021362463ea9d54a192c709f8e7b07da6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 17 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Cosmopedia: 如何为预训练构建大规模合成数据集]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2rYictgPCf8GWGydcas3SuwTOVF1LEGwkWREYmYCukdtTeGJ5Q2bbn16eVBEFwfGbReNibiakMwzDqZw/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文概述了我们在生成含数十亿词元的合成数据集以复现Phi-1.5过程中所遇到的挑战及其解决方案，由此最终创建了Cosmopedia合成数据集。合成数据已成为机器学习社区的 C 位话题，其题中之义是用人</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443613&amp;idx=5&amp;sn=673db84624d3f0ebeba79b94f2091a1b&amp;chksm=bf5c443bd687910bb60dc2846ad26e75d71a1096233f3554cb030806dacc458ad66dafeee461&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 17 Jul 2024 02:10:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
