<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    































    <item>
      <title><![CDATA[速领！2024龙年新春红包封面来啦]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKjTKZhAIwZwZWibDricdbEfoFKfiagee5F21zWqsDbWPvkGOY0L4RRYumKMRIFgK2NVc6SzVoyjs9xA/640?wxtype=jpeg&amp;wxfrom=0"/><p></p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440875&amp;idx=1&amp;sn=37686aafa1d4593e7b00d91d22079583&amp;chksm=bf0d4ad22ea458be78ee2873b470620ff2b1e3ad41b127be533dd6f2fbeb1df92619622f41e6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 08 Feb 2024 10:40:11 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[详解各种LLM系列｜LLaMA 1 模型架构、预训练、部署优化特点总结]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/DHibuUfpZvQcss8pHBLzYLxNSPZeB3yWJuyNT7cJQI0XqlQ5yLRN8y4OpJLGxU3z1iaoZ8oqqEhZZrFNl7vRNpXg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者 | Sunnyyyyy https://zhuanlan.zhihu.com/p/668698204LLaMA 是Meta在2023年2月发布的一系列从 7B到 65B 参数的基础语言模型。LL</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440875&amp;idx=2&amp;sn=17d34c0e95c4fd5c969777d41cf5acd5&amp;chksm=bf61681ae40881b2fac4d9321dcca1bd7104ecf1356f8219a363eb5173c7d2358b782752005a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 08 Feb 2024 10:40:11 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[全世界 LoRA 训练脚本，联合起来!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2oTm4VSzmicmftwmV7x6qmnQiaoCmDySTPHOVIUjgtzzsbEYgHK5nNfMbCxCSyHKiaMP2PMfoLGN7ACQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>太长不看版我们把 Replicate 在 SDXL Cog 训练器中使用的枢轴微调 (Pivotal Tuning) 技术与 Kohya 训练器中使用的 Prodigy 优化器相结合，再加上一堆其他优</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440875&amp;idx=3&amp;sn=7122a66f53255e3abf9b0604bcc14ef2&amp;chksm=bf6fca277fa640861a241c404f5e0b8e551e7534a0259d7b51215ca5481e579dc53505e1ee65&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 08 Feb 2024 10:40:11 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[LLM之RAG实战 | 使用Mistral-7B和Langchain搭建基于PDF文件的聊天机器人]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/N5aX12H1Sickjjl7zah14T3S3nhLxEUGvKWBhe7IpSI1I5FHTFCwsGj7gIVhG6PULCiaAb1CKWLSISriaja8DH0Sg/300?wxtype=jpeg&amp;wxfrom=0"/><p>        在本文中，使用LangChain、HuggingFaceEmbeddings和HuggingFace的Mistral-7B LLM创建一个简单的Python程序，可以从任何pdf文件中</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440875&amp;idx=4&amp;sn=998b5d055579d2f98cb7e22ae9cf1666&amp;chksm=bf1aa0cc0418cee09a1137ae8a557bcc94136a54d680755a37e822c3d5b6131270bcaae7ed30&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 08 Feb 2024 10:40:11 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Smaug-72B 大模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/uibOQg13Dptzw14wczn20pHlkiayVico9LY4eWpb754yCJBwcAYgMVBT3Rw7OBZ1UVpu9x1Q1XlWEOM0s09UVia5YA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Smaug-72B是由Abacus AI推出的一款开源语言模型，目前在Hugging Face的LLM排行榜上名列榜首，成为第一个平均得分达到80分的模型。该模型采用了多种源自Qwen-72B的微调技</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440875&amp;idx=5&amp;sn=6f5463c3397636e5171d50f6b46d562f&amp;chksm=bf3415434f0951b63a8f885c6c77e4966872c451cc33664f836e2c661f5adf3219ff24c4c3a9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 08 Feb 2024 10:40:11 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[抽奖了！给你一点程序员新年的震撼]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSI2xKDk7cJX4EbHNjz1JRicaibGaTrLLcn5bm1vvdLKHpJQzMgjClJYx2AYVs9SbkIFQ2ZWdoJghXvA/640?wxtype=jpeg&amp;wxfrom=0"/><p>在这个数字化时代，技术日新月异，稍不留神，可能就会被“弯道超车”。春节的钟声即将敲响，这是一个团圆、温馨的时刻，对于那些热爱技术追求创新的开发者们，春节也是“充电”的好时机。文心大模型携手飞桨，以“龙</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440858&amp;idx=1&amp;sn=0ab0c522a25429bcd840a505d9c0599a&amp;chksm=bfdc61ac04d2571e0aa40bfa7bd615f020b6e26622cff2e734b1bcb4800d7d790405b2263f8a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 07 Feb 2024 04:08:08 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解大模型训练系列之：DeepSpeed-Megatron MoE并行训练（源码解读篇）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkON9dQfUsworsThbX65FDBn3vTPO5gCgT5Vj8wuib5Fc3crFDeKJM7GGibKs2Hib3f8wwqcYiaKA3kpXg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在这篇文章中，我们会先介绍deepspeed moe并行训练实现，然后引入Megatron moe并行训练做对比，涉及到的git仓库有：Megatron-DeepSpeed: https://gith</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440858&amp;idx=2&amp;sn=b5250b99b75f1f222bdfc8bfd03f8e30&amp;chksm=bf73bc9841001fdc7c3980dfdecc0e534a85856c403ba525ad8783079454e0d5662f8901d8c2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 07 Feb 2024 04:08:08 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Megatron-LM学习：流水线并行的设计与实现]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/d6902wUyyvIvJ5jWHqlqqvguGqjkFgl1MBjBwT6JqX30bVuCm7JQHdlWMH6Gd2bgueaOCC1lpjBfQOOR6YILTQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Megatron中包含了大多数目前大模型预训练中所需要的并行技术，并且相较于Deepspeed在硬件层面可以得到更多的优化支持。Megatron的优势体现在其先进的并行化设计上面，而其中流水线并行是非</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440858&amp;idx=3&amp;sn=7337bb3af1419d7104ee393715046b27&amp;chksm=bf83502b801d36c34952c1673babd8a2149ae7281ab0aa781e2630de7f0dd4923a6b1572c12d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 07 Feb 2024 04:08:08 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[随机 Transformer]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2oqDe4zJ7fzxPfy52HbEKicDehfURia8SapfHhFeNWxOweE5u3LXiaHh0hNdia3GNhtfHlD0sJ40EKoZw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在这篇博客中，我们将通过一个端到端的示例来讲解 Transformer 模型中的数学原理。我们的目标是对模型的工作原理有一个良好的理解。为了使内容易于理解，我们会进行大量简化。我们将减少模型的维度，以</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440858&amp;idx=4&amp;sn=d17a6e701cc1e246400548a7cf765bd6&amp;chksm=bf9ccbc056e7778a89492e7cfa88b8a0917bb7db3cb883ff967fdbdfbc24d1dbd68eca7c7cec&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 07 Feb 2024 04:08:08 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[微软Phi系列——教科书级合成数据的力量]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/s7YKINJYHDBGCfsuaMLoFOoNDJjJSdc8uoO4eR3eAicVpj0iavCyM8KsVGtwicK4ze2obcJ0f1iawk7ibtn1WotOjow/300?wxtype=jpeg&amp;wxfrom=0"/><p>背景分享三篇微软推出的「合成数据」研究的系列文章——Phi系列。整个系列的宗旨是研究在「模型尺寸小」，「数据规模小」，「数据质量高」的综合配置下，小模型（SLM）能达到怎样的效果，研究的核心是「数据质</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440858&amp;idx=5&amp;sn=8a289b282118ecca0c4c173a95eda45f&amp;chksm=bf9186601688cb92ac2cf113be5b804024ef530d4ec192cb2f64087bec8d9d6d58cbbf4eb5d9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 07 Feb 2024 04:08:08 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[YYDS!  大模型LLM从理论到实战]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLhb7ZiaHx1ZnyFwI5c8kbHKcDEZksRGMZ3rny5X92sTsiasDIEAscd273iaZ77qUicn2DqBX1akY5iaSA/640?wxtype=jpeg&amp;wxfrom=0"/><p>2023年大西洋彼岸的OpenAi公司，首次向世界吹响「大模型主导未来世界变革」的号角。AI大模型，正在构建的颠覆力，为了更好的入局AI大模型，这次我特意复盘和整理大模型学习脉络，开了30节大模型的课</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440845&amp;idx=1&amp;sn=24dad0fe28222a3f881aa8aac4ff75d8&amp;chksm=bfdf165eb05e91d0d35c1f046fd0bdc5d95f7cd5c4f0701aed0cb78621d44b587b68b101eff8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 06 Feb 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[复刻ChatGPT语言模型系列-（三）指令学习微调]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hq9ANWCLRic06XsITuUpaMrqVQTXnWOtWr67UjLib1xo5bvZQKFg6EnC4Mslf7vSPGWOjWibPBHlQgksYnUhFoGaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言今天开始我将会推出一系列关于复刻ChatGPT语言模型的博文。本系列将包括以下内容：复刻ChatGPT语言模型系列-（一）基座模型选取复刻ChatGPT语言模型系列-（二）参数高效微调复刻Chat</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440845&amp;idx=2&amp;sn=41b4827aae7b136d53ba8d39950708a1&amp;chksm=bf1feeaa3c88c1ac9cea975dc2c4fde42117e8a68cd632f161b05dea02031c68ee86ad210066&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 06 Feb 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM &amp; KBQA】FlexKBQA：一种结合LLM的KBQA框架]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGBmkdJKCkicgFU1WhzfsmiakquDyltIbjQLnMq5kEEDISRFwt9RRpiaV8OBCPgH80ibdNpEN9nHGBqo3Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言 大语言模型（LLMs）在知识库问答（KBQA）领域的应用主要集中在包括但不限于以下几个方面：直接生成答案：一些方法直接利用LLMs生成答案，而不是生成中间的程序（如SPARQL查询）。这种方法通</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440845&amp;idx=3&amp;sn=4ff0a937bc43b70cba3d73de58df3007&amp;chksm=bf9712c9f942cdfb6b1555a612349b416c144e5a9abbd46b5c9b7146eaad45fe45b5908a103f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 06 Feb 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM之RAG实战 | 如何构建一个RAG支持的聊天机器人，包括聊天、嵌入和重排序]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/N5aX12H1Sickjjl7zah14T3S3nhLxEUGvoHBv45bPojsstCfiaxYU1nZDr6pukfXwewyHIea0jHL8CtYI2vFqSDw/300?wxtype=jpeg&amp;wxfrom=0"/><p>      在人工智能和机器学习不断发展的环境中，聊天机器人变得越来越复杂，从简单的基于规则的回复转变为基于上下文的对话。在这篇博客文章中，我们将深入研究创建一个RAG支持的聊天机器人，该聊天机器人利</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440845&amp;idx=4&amp;sn=6184042081f13191f8a11dcb81f81c33&amp;chksm=bff54cc829aedc41969200e389b32230ce1cb616c508a3b41beafc43ffe76ed15129122ba999&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 06 Feb 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[GLM4 介绍]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HIKk7OFDjoTv6mQl5EUOKicPicncVEQdJFaCOjmjItKpv9fMCERmQz5gbLygF3fAXHxXibeeWO8nOuBzHCHCMCeiaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>GLM-42024年1月16日，智谱AI正式推出GLM-4新一代基座大模型，整体性能相比ChatGLM3全面提升60%，根据实际测试，GLM-4在以中文为主的应用场景中实际性能逼近GPT-4的95%，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440845&amp;idx=5&amp;sn=335738b04123fb8506c132ebf53d512b&amp;chksm=bff007dd0fdd39c44ea9a8c12b83a7896371787247211e550763fb6b16c7951398457ecff1f9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 06 Feb 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[在华为，请假一天的代价是3700…]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/6fuT3emWI5Kw8tPicUuoMKvt6zZkkrMtFlaia9eGNPfdjiaVNias3Od5FSiaMxwPqQM0yUSls0qDEv6KiaDbZHmQuBMg/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近，一篇「在华为，请假一天的代价是3700」的帖子引发网友热议原来，在华为请假会影响每个月的奖金和年终，所以很多人都会选择拿周末的加班来调。在华为周末加班是双倍工资，请假一天相当于扣除双倍的日工资，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440830&amp;idx=1&amp;sn=826708be8664e602be502818de8ebdd3&amp;chksm=bf9ead1622f548eb7931c01907258dfc34bca45611ad7e06f25689b127056d353a9259bd37d8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 04 Feb 2024 10:38:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[复刻ChatGPT语言模型系列-（二）参数高效微调]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hq9ANWCLRic0KXWTjSbKPblT2EDkES9lLtVfOk4h1kMLQSwpsTgNVd1hGBh8nAtlXTqzYjwLuWxMSfdYXicKDuYw/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言今天开始我将会推出一系列关于复刻ChatGPT语言模型的博文。本系列将包括以下内容：复刻ChatGPT语言模型系列-（一）基座模型选取复刻ChatGPT语言模型系列-（二）参数高效微调复刻Chat</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440830&amp;idx=2&amp;sn=03266e804eb9b72131a1a187f1b1b6eb&amp;chksm=bf400c5346cc8b4417cb680e6c5741085d297b9c87e9c30755a306c640427fc460dfa1d3a0ea&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 04 Feb 2024 10:38:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[BGE M3-Embedding：智源最新发布的text embedding模型，多语言检索效果超过微软跟openai]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKptTaLq0mFs3ypIxIkXJERY1vlGBl0ic3QvbfE02M3Pow0ZnK9FhPaesFNibM8stMXiaLF8AN2KDiatu2g/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲‍‍‍‍‍‍1 简介 2 BGE M3-Embedding    2.1 训练数据构建    2.2 混合检索    2.3 训练方式3 实验4 讨论参考文献1 简介    24年的第一个月，智源</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440830&amp;idx=3&amp;sn=0e37d46c60db7472945c5ae27b17449b&amp;chksm=bf9f1fa4181c10aea13733c2f0a526e843b51301917f2a70a6921f6fb72e9c0a5e37278f68a4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 04 Feb 2024 10:38:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM之RAG实战  | 高级RAG 03：多文档RAG体系结构]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/N5aX12H1Sickjjl7zah14T3S3nhLxEUGvLuwDsM6kQ5KaZg0HzYvm6VkSk28WQPhhic5JqyHLY6ib2gibo8MqU5Cuw/300?wxtype=jpeg&amp;wxfrom=0"/><p>       在RAG（检索和生成）这样的框架内管理和处理多个文档有很大的挑战。关键不仅在于提取相关内容，还在于选择包含用户查询所寻求的信息的适当文档。基于用户查询对齐的多粒度特性，需要动态选择文档，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440830&amp;idx=4&amp;sn=8b2278ebacaf7bf8adea49fc18ff9982&amp;chksm=bf2030b381dc8e98c4f60108691722438c0e1f5a090992ad8a723183b22e77c71c41071355e0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 04 Feb 2024 10:38:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[vllm的SamplingParams参数]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_png/1FD1x61uYVcRrJHP52OV89EaAkIk3BJ7O3WWAaKNAGSu9iariaafobkgKnWkkVW2TQQeLkqViaTDhvibgn8knmK6Wg/300?wxtype=png&amp;wxfrom=0"/><p>vllm部署示例from vllm import LLM, SamplingParams# Sample prompts.prompts = [    "Hello, my name is",    </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440830&amp;idx=5&amp;sn=2c7b80072c084dccb9d147a70a66fe34&amp;chksm=bfbb4fcb5caaf076240467350499b2e0c7c3a64b25858ac8135097e096050aa42c5c9a0eefe3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 04 Feb 2024 10:38:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[HiFT全参数微调新范式---逐层微调]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKxsUzia3vHMcwJQNbWe8eOLsF9e4q4IibhTcby3GmxIa4YwMMfSTUXAK1JGWj9pwTyYUs3WkL2ibsGA/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：刘永康单位：东北大学、慕尼黑大学论文链接: https://arxiv.org/abs/2401.15207HiFT 是一个端到端的层级优化策略。目前论文的结果是原始混合精度的结果，目前最新进展</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440818&amp;idx=1&amp;sn=eca12dd3efd45d92f17bdc98d36ed99c&amp;chksm=bfdfa6e2381035c24e6820105831a7fc7df400a499cbc1b2fdf495c17b7c46c7daf8ea82bbf6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 02 Feb 2024 13:28:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解大模型训练系列之：DeepSpeed-Megatron MoE并行训练（原理篇）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkPcHSDaCg1w25tL8ScnHd1ljib4lE3I1X8icQakbqcRET7ibnJcT9oUQINP1KHMlzyrNtBmwfDFyMDPg/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，时隔不知多少月，LLM并行训练系列终于又有更新了（抱头防打），这一章我们来讲MoE并行，同样分为原理篇和源码篇做讲解（本来想合在一起的，但是MoE的细节太多实在写不完，所以还是分成两篇）。关于</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440818&amp;idx=2&amp;sn=0e0bb7931c2b55dc19814ccb37180ff6&amp;chksm=bf7fc512fe79291cc0b5704e06c8f7c7d181ab814d661a80400843512a0f72eca4e2e0c7de87&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 02 Feb 2024 13:28:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[京东零售搜索算法团队招聘实习生]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJ3HGy24dbxwWCWEoAD0vRB2BSZOBCJiagylojllZJql85dUBiba750ap1x7A7KOaic9bqS9V9zCmNjA/300?wxtype=jpeg&amp;wxfrom=0"/><p>团队介绍：我们是京东零售负责京东app搜索算法的团队，承担京东全站自然搜索流量的分发。团队氛围十分NICE，团队成员主要来自清华北大中科院等高校的硕博，团队成员曾在多个顶会上发表论文，包括不限于ICM</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440818&amp;idx=3&amp;sn=b854e1bf7ea17fc59909aacad1092d00&amp;chksm=bf11631dc4c80419bb0ee4123ae27fdd888f2482306f93f20c344d8a5142f9abe84c7480a99c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 02 Feb 2024 13:28:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[AAAI 2024 |大模型时代，什么是比代码更好的数值推理中间表示？——方程]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/58FUuNaBUjqCByXGW7gKibOQPlnYFxXHbeGmIEs8yVeG85PEhzKDE7aFvibopy6Dhic9eD4e3bu7QfuW88PfNIlGA/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：探索方程作为一种更好的数值推理中间表示作者：王丁子睿、窦隆绪、张文斌、曾俊瑀、车万翔链接：https://arxiv.org/abs/2308.10585项目链接：https://github.</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440818&amp;idx=4&amp;sn=572534deb46cab949073b459bbc0e918&amp;chksm=bf25bcc7c7b2000233bf653f2b8ab87489448e945a4159642808247df826ed505f796a9a7bf4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 02 Feb 2024 13:28:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ICLR 2024：无需标签即可评估模型性能？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/DHibuUfpZvQc14a8W9lvErDGJ3FuYHlHbB0EAomDJ8S2qVbmfIgKOdvTLMd2wYxz4icHJlGicWMMGsC14H15T87iaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者 | 彭儒@浙江大学 https://arxiv.org/abs/2401.12689今天分享来自浙江大学ICLR 2024的关于自动模型评估AutoEval的最新工作：MDE。概要机器学习模型的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440818&amp;idx=5&amp;sn=da1b3ca4362d1ada9a0a9ab5eb1f32f2&amp;chksm=bf4195520faa6871e90b29cd79505ad3cd33f165036cdd6ec39f831f6b4ec91d4ae9a2a44c40&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 02 Feb 2024 13:28:03 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
