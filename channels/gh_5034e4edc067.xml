<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    


























    <item>
      <title><![CDATA[还是决定去小红书实习了!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKXCWuFzcB7IcMniceF5dCdicibIy3WO3ic6ttfiaibTd0jCG3BHuNowiaBHzrBnCAibND9PAxuibeIgU7RAKw/640?wxtype=jpeg&amp;wxfrom=0"/><p>📢 小红书25届实习生招募火热进行中NLP/大模型/算法/前端/后端/客户端等超多技术方向岗位等你来!AINLP要来了专属内推码拿内推码可以优先筛选哦60B2Y2QM88D8也可以直接通过内推链接投递</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441591&amp;idx=1&amp;sn=4c66ad3a368a75b30866f50cc6d55ea9&amp;chksm=bfdfae0aa78c545f450004eb859ef22b674f505a2492f3e16673a205a368dd92655070a44d3e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 29 Mar 2024 04:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Qwen1.5-MoE模型：2.7B的激活参数量达到7B模型的性能]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5mjS1tvianwIk1Rcuic9sGH22UWLW1IGIPvlZnMa8iaNELLPkDxpAKibxibDVzPafCEMQWdOs6ReVrr45Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>Qwen1.5-MoE模型：2.7B的激活参数量达到7B模型的性能写在前面今天阿里放了MOE的模型，总参数量14.3B，具有64个专家，每次激活8个，在仅激活2.7B参数情况下，效果可以与Qwen1.</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441591&amp;idx=2&amp;sn=9cef61077e1751756fa3959bd72df9f3&amp;chksm=bf1f025f0e5a0d5adea27517ec53992280fab72b886c6e3717f30fba1186cfcc87f90f97862e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 29 Mar 2024 04:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[LoRA原理解析]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgz65reXkaewsAWUHiadHBiaZIrfa8p8lTWYjN3GoWPbkuHibppFnWXxLIrwBbYibbZpQkNXvUkwnoicRSQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言随着模型规模的不断扩大，微调模型的所有参数（所谓full fine-tuning）的可行性变得越来越低。以GPT-3的175B参数为例，每增加一个新领域就需要完整微调一个新模型，代价和成本非常高！</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441591&amp;idx=3&amp;sn=6905865a4474ef3a6422121bad9842fb&amp;chksm=bf7cdd090b33ac26ff89c8dc054a2693fd78dbaaa1c3e9714e8d4d509d38222d290a7f04f022&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 29 Mar 2024 04:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[EMNLP 2024 征稿通知]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/EsDKszDSKDGShwibZciaDL2bxeooGiaD7ReHyhvLjibVf60cmPyibo1gbI4duhFgSlNagXVUn4Gq0B13XKuHkEWhicLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>计算语言学与自然语言处理顶级国际会议EMNLP 2024将于2024年11月12日至16日在美国佛罗里达州迈阿密召开。EMNLP 2024只接受ACL Rolling Review（ARR）投稿通道，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441591&amp;idx=4&amp;sn=e5be647d6105610f20211bcfb82adda5&amp;chksm=bfd3dbc273ddcd449b5961614133f156e1543ace7806e9d5c648e98b7a7bd20b1ee7f049762d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 29 Mar 2024 04:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[大模型数据之代码语料The Stack v2]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/s7YKINJYHDC9CFAicTSRD5jY2CduuMXTgd1Qup9ck8g7gxa3JgXXgHQrhR5kyBRxiaNpewTOdq0ArfbdFYOvoF3g/300?wxtype=jpeg&amp;wxfrom=0"/><p>与 The Stack v1 相比，The Stack v2 拥有更大的数据规模，采用了更先进的语言和许可证检测流程以及更优的过滤机制。The Stack v2有900B+不同的tokens, 是Th</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441591&amp;idx=5&amp;sn=8730d29e9002bde168603359d88c43f5&amp;chksm=bf111f1cc6ebde8e9c8f8bc32dda8f6d52ac38fa6c0a30555a5a4edac8cdb37edf715c2c805f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 29 Mar 2024 04:00:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[50W奖金，校招绿色通道，确实可以封神了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKVy22NDn5JSJNWXsZKggQFJB5dLPjnSNreSuXnhsuJPy8MjnybBAQhZeldQFBYug0OgAHCNcibsMw/640?wxtype=jpeg&amp;wxfrom=0"/><p>新赛制，新玩法飞桨黑客马拉松第六期全新挑战，重磅回归！开源贡献个人挑战赛、飞桨护航计划集训营、Fundable Projects、优秀稿件征集与传播四大赛道，邀你挑战！多难度梯度开源任务、导师1V1指</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441534&amp;idx=1&amp;sn=a1ad868512de6ae3c76647f88de9a0a9&amp;chksm=bf7488c5e23aff0bfd53e5b034d61694fa8c0c4646369b9cea2751630cf7ee3d0a27d9cb7e0e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 27 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[使用自己的领域数据扩充baichuan模型词表（其他模型也一样）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgwggq0p7QF461l6swuOYzjpPpNtkicc2YM6YsecM4VJTqwICubtXa8fjVIg8SuTs2EMgvhibkP95gGg/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言总的来说，扩充词表可以加快解码速度，对于对中文支持不太友好的模型（如llama），扩充词表还能提升模型在中文的表现。环境jsonlines==3.1.0sentencepiece==0.1.99t</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441534&amp;idx=2&amp;sn=1edf0ce111749a9624ee6b25086a0729&amp;chksm=bf6fdc9cea0fb41cae3f407e05e1498f3bd116bb895c389d38133f1016a005d5d7f6a20a2422&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 27 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【社招】小红书增长技术多个岗位热招中！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKqDYic1fUolyca4lJx4DnuZlveQ2uM9iaJyZqgKxQYibOpupYleO999opKmZn79KgibkeBGdX2DhL87g/300?wxtype=jpeg&amp;wxfrom=0"/><p>工作地点：北京/上海收件箱：houmengchao@xiaohongshu.com算法工程师-画像方向工作职责1、负责优化小红书社区上亿用户的用户画像；2、应用数据挖掘方法和Multitask Lea</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441534&amp;idx=3&amp;sn=31e92e0403fe8e396a48bef3080e4300&amp;chksm=bfb711a01311dfebf870a534ba08884def56a013af2a53349775405bed448de918d33f197d18&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 27 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[生成模型大道至简｜Rectified Flow基础概念｜代码]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/vtIvcrPJjh7sn8o32iciaaBkpSCU6Fx8QzJOQVX904plwCewZv6x4UAFwVkucWWx3NFmAl5mjyImFv2picO0Wy5Mw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近看了下SD3的论文，里面用到了Rectified Flow，之前没有接触过，了解了下是项有意思的技术。值得推荐，这里记录下Rectified Flow的基础概念和代码实现。详细的原理和深入理解建议</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441534&amp;idx=4&amp;sn=408e997771da40a527cfb6160a8d6ecc&amp;chksm=bf1ec3caa72314d315c8dcebb6b37d0c376e64f7e8911c5a4b405362901ceae88b61c2c68872&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 27 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[为什么语言模型的本质是压缩器？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BAVX0pafImn4deViaa4kKDibasaupfNtw2tgsryYPkSZbUFIZFQ3RMZlFlDrOYM7txdqcW9mLfffBicBDrNlQwaWQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>最早听说语言模型的本质是压缩器的想法是在黄仁勋和Ilya的围炉对谈，当时只是直觉上觉得这个说法很有意思，但却没想明白原理是什么。2023年9月，DeepMind写论文进一步论证了语言建模与压缩的等价性</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441534&amp;idx=5&amp;sn=a3f6c2f17d7b6e3e433563bda6f5207e&amp;chksm=bfe0cbd1feefc3a7f9b0779f0976d3641d74823de07a8fca5de8fa78bce1be4c5c78fd897938&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 27 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[整理了2024年最新顶会论文【附PDF】]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLryynjoWcgOVLUtHe6TPhIPL6BFYib4micZaCNr8yySg84cM7qHCQzibk5Vz02s2yW8z7UGkRpFAV6g/640?wxtype=jpeg&amp;wxfrom=0"/><p>ICLR 作为机器学习领域的顶级国际会议，每年都吸引了全球众多顶尖学者和研究者的目光， AAAI 人工智能会议在AI领域极具声望， CVPR 是计算机视觉方向的“顶级流量”。现在会议论文审稿结果也已经</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441503&amp;idx=1&amp;sn=a6fffc4c0e753904b433b97908a04ad6&amp;chksm=bf10daaecce4bc4872efcfa45ad5a3c6e167da149fe4a0aeff2890431345a06814c2f3fbdfb0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 26 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[RAG与Long-Context之争—没必要争]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5lbP3QtkAdeYzoxVajibBtXQEowGWbjwdb57Q9BApHTiaI9sgHZVrg6odiaBcncRCIOeG0liceCY7WOPQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面随着大模型可以支持的上下文(Context)长度越来越长，网上（好几个群里都在聊这个话题，也来聊几句）竟然出现了RAG与Long-Context之争，是真没必要。。。主要是两者不冲突，并不是非</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441503&amp;idx=2&amp;sn=557bdf8f2ced3315a4332db28b759c4c&amp;chksm=bf0637a5bb044720ac5444eeb4f155be674bf01d6dd3488c040af3fd0380aa6828797f395c42&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 26 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[transformer中normalization的二三事]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW464icRJNKxxaiaQYn9XW6nth9Ez9IFYbBody7tGoxb02qib0KgiaMe5EjJm5Qiafu5niaDzOFthyE4AFY1icA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Normalization在模型中，相对于attention这种经常被魔改的结构，受到的关注度似乎没那么高，但它对模型能否顺利训练，却有很关键的作用。在此简单梳理下normalization相关的背景</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441503&amp;idx=3&amp;sn=7e9dfc241ca6e2525e542a40d8ceb93d&amp;chksm=bf691d08588ca3b3d16a3f400efc3c9dcdc94bf14fc49f9da6e019ad49fa877da97dc93f3fd3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 26 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[百川Dynamic NTK-ALiBi的代码实现：无需微调即可推理更长文本]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgy2fJK3Eu7hcY8AoHcHW3Ep8BJMiba2ibU36Rbhxryxy9DlG7M6pFJShneynTrMIhNgzf0a9eGgTWzw/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言NTK-ALiBi原理：NTK-ALiBi：通过插值实现大模型ALiBi位置编码的长文本外推[1]代码实现打开百川模型文件夹中的modeling_baichuan.py1、增加build_dyna</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441503&amp;idx=4&amp;sn=a57364cfb4cb78b83e5339c68b3e37f4&amp;chksm=bff5f35da586b60bfd5cc784a9685b28836cc9453ffb0c955254b131e4587ba65133ef7bec22&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 26 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Echo embedding: 把文本重复两次，自回归模型就能生成更高质量的embedding]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKpuIRbwVtvfco2cdwibbGF5bwcQYPLjbBS8dRxD2Ras0tCVqVDpmlotVvyb7ib9J1c2MrKsBSUNzaEHQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲1 简介‍2 背景‍‍3 Echo embedding4 实验‍‍‍‍5 讨论参考文献1 简介    针对目前在生成文本表征时自回归模型架构的局限，卡内基梅隆大学的研究人员提出了“echo emb</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441503&amp;idx=5&amp;sn=910344262c0b7a2b7f3e128ff12c5757&amp;chksm=bfdee31920aea32e00432049b03c83ec6a4baafae506d2b5f25aff4496c73157cba012bc9788&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 26 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[研发大模型的血液--万字长文详谈数据工程]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLryynjoWcgOVLUtHe6TPhIDhXqJcDIGLaRln0cW7g1T5yEpOdqgPGkTowjqQ7zVY6MpicJHDSYkFg/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：西红柿牛腩原文：https://zhuanlan.zhihu.com/p/685077556整理：吃果冻不吐果冻皮最近1年研究大模型，有个很不好的现象，大家都认为做大模型，认为只要喂数据就行，甭</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441493&amp;idx=1&amp;sn=9f64ea38c75ad5d2db379e3f7f947ae9&amp;chksm=bf426d3179c33dc90428f67ac363bd8df6af6aa7e16576b839c55f18c08771ae485d298f169d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 25 Mar 2024 12:38:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[虾皮(Shopee)招聘资深算法工程师 - 智能客服/对话机器人方向]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLryynjoWcgOVLUtHe6TPhI6q2gmTXl3J4JsfM9mV0icMXdsmic3tovZkJLkib4EyTwKWagU5Nf4Igsg/300?wxtype=jpeg&amp;wxfrom=0"/><p>[电商业务] 资深算法工程师 - 智能客服/对话机器人 Marketplace Intelligence and Data部门介绍：Marketplace Intelligence and Data </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441493&amp;idx=2&amp;sn=1412c41ee9886089d3015c5dd76f38fd&amp;chksm=bfc170308d9dd1127b07efbb141658679df8f95b7c8d7f3cf224cba5d95e205de2ed121d10f0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 25 Mar 2024 12:38:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一篇新鲜出炉的RAG综述]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKptW5MX5pIe79PgWH74GxP0IqTianFO8HnaHAG3aTFZlCV2mCB4S8QUEDrL4MbEBrdCFcic2mYtxrSDA/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲1 简介2 RAG分类3 RAG增强4 讨论参考文献1 简介    尽管目前大模型取得非常不错的效果，但是依旧面临不少挑战，包括如何获取实时跟长尾知识，如何规避数据泄露的风险，以及高昂的训练跟推理</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441493&amp;idx=3&amp;sn=7d0d1c2fb5bc84595b3cddd0ee8a33f5&amp;chksm=bf235a5d4f9656270605576f8a35a0bdadced7aa79495fe6e6a5cdcd1f282b404e82301f3bdc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 25 Mar 2024 12:38:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[SentenceTransformer使用多GPU加速向量化]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgz9wicRes81YFsbvhuoiauS1I5NaaGFboSFmxVfuTPen85uoHS5zTAIukKDFIw5NzqcuT9wgemhNH4g/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言当我们需要对大规模的数据向量化以存到向量数据库中时，且服务器上有多个GPU可以支配，我们希望同时利用所有的GPU来并行这一过程，加速向量化。代码就几行代码，不废话了from sentence_tr</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441493&amp;idx=4&amp;sn=0d841cdcb016a62d834ea5d39b5d9ff5&amp;chksm=bf481cf820c6c4053d12915cefd89637a9d2293418ac10c00cf6ab6497ce462363816ed6f1d5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 25 Mar 2024 12:38:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[EMNLP 2023｜利用LLM合成数据训练模型有哪些坑？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gTSf9kr5zrMVV78xnqk4ZxY6wEVLUEouv4djTDrKPHRQLspc84zpGNV9GGXesicUypkz3QXQfbexmiaWVCE0G1CA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天我们将介绍EMNLP2023的一篇大模型（LLMs）生成文本分类任务合成数据的文章，标题是《Synthetic Data Generation with Large Language Models</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441493&amp;idx=5&amp;sn=5fd67806bbe2fb52e1871c2b1bef0b87&amp;chksm=bfd205215d639ef0c736c2486deeab5b2dc91a9aea022e763c2e1b1ec55eef2538a3aa59f667&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 25 Mar 2024 12:38:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CCL2024-Eval | 第二届汉语框架语义解析评测正式开启，诚邀各界专家学者参与]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJXh19q8OiaAhadayBQS8rGyN0T8d4pOLTT1OflfkNh6vJ1ZNKTUb3agrVibPh2YcZlwLeEN8Uiaibrxg/640?wxtype=jpeg&amp;wxfrom=0"/><p>     简介框架语义解析（Frame Semantic Parsing，FSP）是基于框架语义学进行语义分析的任务，其目标是从句中提取框架语义结构，实现对句子中事件或情境的深层理解。框架语义解析对阅</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441468&amp;idx=1&amp;sn=81a72c318be39a0ee289a0a29291dccc&amp;chksm=bf4f36d815f6ef8fe9c376ac28aff288b38b71c1103e7afeaf3568c30b7dc90c63c9c382c6fc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 23 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[RAG 2.0来了，它能成为生产落地的福音吗？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/aaN2xdFqa4EAdfMqoGtcaicCECNS8PyRF5DMZukvGZqSXabmicSD6l9O1G6CUkJc2Piceo28yV5CF1SUNHTyhfHhw/300?wxtype=jpeg&amp;wxfrom=0"/><p>RAG作为当前最流行、相对成熟的的LLM应用架构，受到了开发者的广泛关注，相关围绕RAG优化的技术层出不穷，但依旧难逃达不到生产应用要求的尴尬。在典型的RAG系统中，通常会采用现成的通用嵌入模型来实现</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441468&amp;idx=2&amp;sn=3b35053a91f847bca41d8ab244d5055b&amp;chksm=bfc9f1676489f6a23f662aa2c8c5ed8095027a3517e19ce21b9ec841b4acbacc5827cf72e2f5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 23 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型的 Context Window越来越大了？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/fI41EfAgQvvVic8Bsm0WiaVtKNMfjF6Hq12oQeecibDWsSciaqKf7mRicaoEfZRne93Nc2RKYDxRIBbltN1burRcM2A/300?wxtype=jpeg&amp;wxfrom=0"/><p>刚在知乎上看到通义千问升级了，给用户带来了处理 1000 万字文档的能力，一举成为“全球文档处理容量第一的AI应用”😂。全球文档处理容量第一的AI应用感觉国内的风气都被 kimi 往长文本上带了，当然</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441468&amp;idx=3&amp;sn=62d3827b83529314fef1ef7004462775&amp;chksm=bfa60aa6b02e4a1c6e7ee4721dc9cac9cb472ca564f130b72796db534aaa12e10edcc0c4ad54&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 23 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大众点评内容搜索算法优化的探索与实践]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/hEx03cFgUsVNhP8iaHXy9gN7VTTJLKiaRay4rDGrK3lYAiaItNcU5sUrK1nyjWobbdWexj6DicB55iay90ocItdTiaJQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文整理自美团技术沙龙第80期《美团内容智能分发的算法实践》，分享内容主要包括三部分。第一部分介绍了大众点评内容搜索的场景特点以及面临的挑战；第二部分介绍了为应对这些困难和挑战，技术团队在链路各环节上</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441468&amp;idx=4&amp;sn=7f773855b87f9b4896f16f408b122482&amp;chksm=bf93c3f68f5b4bbb2f67cffc726d8ece13a3de4429b5053ac765a268c52dbee82fb0f8962e9d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 23 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[通用人工智能的本质：一场进行中的辩论]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/37kWYypzzEcciaZMSoRMSZlRyibjUE06iclfgN8llKC9x5kMjgWicrCjXos4kKdOZcQzHqlsS7kwxAv1r2Etv0ncSA/300?wxtype=jpeg&amp;wxfrom=0"/><p>大模型的飞速发展让通用人工智能（AGI）的概念再次成为了近两年来最热门的话题之一。在讨论 AGI 是否以及何时会到来之前，人们关于 AGI 的含义和本质尚未达成共识。为了防止其最终沦为一场概念的炒作，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441468&amp;idx=5&amp;sn=b4d7a772fd29e0ded307f801014890d4&amp;chksm=bf92d7d263d709042c3e9ec818d4db8717568847d857a73a6053434b94670c7f9e95debab0cc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 23 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[原来阿里P8的工资这么低啊。。。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/icmWrEONNM8WEZGWlghyyR5gg9dY8agJ5kc1ibVdsZWFzj5608EUC0g2u9fpWCasFtxUG6JuiaXarKvDVVEz5ksXw/640?wxtype=jpeg&amp;wxfrom=0"/><p>原来阿里P8的工资这么低呀。。。曾经的国内互联网公司，无论大小，职级上或多或少，都有点对标阿里的意味，毕竟阿里就是之前十年的Top1，辉煌过，加上创始人自身性格也很高调，使得其影响了很多企业。P8在阿</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441454&amp;idx=1&amp;sn=a34e45b9d57a2b6bc491ac88935a7e13&amp;chksm=bf451f376dd84a934cc3641475d112fd18993ad8f81d91e84be6b74ed414b3c2511b969e5b84&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 22 Mar 2024 10:44:35 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[从任务结构到世界模型：LLM 知道什么？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/37kWYypzzEfXicYH5IHM6xcJZWFa0cLQuKPudeLDSCU9zLDTzk8uibDFnkiaDeJeQV3EUEpRf2iaOHJXOovOGtPv6g/300?wxtype=jpeg&amp;wxfrom=0"/><p>近日，来自 MIT 的两位学者证明大语言模型（LLMs）能够理解世界，他们不仅可以习得表面的统计特征，还可以学会时间和空间等维度的结构化知识（该文章在本周的研究速递中获得了推送），表明 LLM 本质上</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441454&amp;idx=2&amp;sn=07742d5c142c9900f83f16137f873fea&amp;chksm=bf9f3903b2fbfc9cb74c19043ae40147ab8ba4e064838ec7cc3a39ec0fd4e8b23650456e3166&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 22 Mar 2024 10:44:35 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[百度文心一言招聘大模型算法实习生]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJXh19q8OiaAhadayBQS8rGyJGBIhK7yhkiaTAEvPXDbwnbhepZt8dQQyYkJqzy3teib5atic9xicYNUnw/300?wxtype=jpeg&amp;wxfrom=0"/><p>百度文心一言招聘大模型算法实习生百度文心（ERNIE）团队致力于预训练大模型基础技术的研究和应用，在预训练大模型领域具备深厚的技术积累。文心 ERNIE 自 2019 年诞生至今，在文本、代码、多模态</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441454&amp;idx=3&amp;sn=ae33011c89d798e95817162bd7edcfe2&amp;chksm=bf8eb6726588b0d145ee027d1528609f53b9acd74cb3aaf433701423796909ca82d738b5484e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 22 Mar 2024 10:44:35 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[使用opencompass验证模型效果]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgw4KQuYUIQckJMAco6AibX7rrAly6mYGBbHYY2icpa5bAeZVOg6FVVuWm9zibcGic3pNbs5RCKn9tJIog/300?wxtype=jpeg&amp;wxfrom=0"/><p>准备环境使用fastchat部署的openai api server模型官方仓库：https://github.com/open-compass/opencompass1、git clone http</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441454&amp;idx=4&amp;sn=f1311458faaa0c4542226ab8b409799f&amp;chksm=bfe2a42c24f4d08cd1e97300a0baa7a53c1490b634bb29d6856ed05785649d1b0dc1b5d85bb3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 22 Mar 2024 10:44:35 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM之RAG实战  |  利用LongContextRetriver克服RAG中的中间丢失现象]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/N5aX12H1SicnEpfXACBAIY398EiaP6B3ib5yoIUH14LRiaRtK7p0GicQvqds7JowdSHzQTLqWExQEJ0x2sp43YhiaHWA/300?wxtype=jpeg&amp;wxfrom=0"/><p>       人类和大型语言模型（LLM）都有一个共同的行为模式：他们往往擅长处理位于给定内容开头或结尾的信息，而中间的信息往往会被忽视。       来自斯坦福大学、加州大学伯克利分校和Samaya</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441454&amp;idx=5&amp;sn=64d2cc80c298a017a70c80237c43082c&amp;chksm=bfd3fd30704fd96117a4e1eb4484a80478650ff01f17c356d036ceba30fe8c92e96ced53bd7a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 22 Mar 2024 10:44:35 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
