<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    































    <item>
      <title><![CDATA[YYDS!  大模型LLM从理论到实战]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLhb7ZiaHx1ZnyFwI5c8kbHKcDEZksRGMZ3rny5X92sTsiasDIEAscd273iaZ77qUicn2DqBX1akY5iaSA/640?wxtype=jpeg&amp;wxfrom=0"/><p>2023年大西洋彼岸的OpenAi公司，首次向世界吹响「大模型主导未来世界变革」的号角。AI大模型，正在构建的颠覆力，为了更好的入局AI大模型，这次我特意复盘和整理大模型学习脉络，开了30节大模型的课</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440845&amp;idx=1&amp;sn=24dad0fe28222a3f881aa8aac4ff75d8&amp;chksm=bfdf165eb05e91d0d35c1f046fd0bdc5d95f7cd5c4f0701aed0cb78621d44b587b68b101eff8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 06 Feb 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[复刻ChatGPT语言模型系列-（三）指令学习微调]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hq9ANWCLRic06XsITuUpaMrqVQTXnWOtWr67UjLib1xo5bvZQKFg6EnC4Mslf7vSPGWOjWibPBHlQgksYnUhFoGaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言今天开始我将会推出一系列关于复刻ChatGPT语言模型的博文。本系列将包括以下内容：复刻ChatGPT语言模型系列-（一）基座模型选取复刻ChatGPT语言模型系列-（二）参数高效微调复刻Chat</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440845&amp;idx=2&amp;sn=41b4827aae7b136d53ba8d39950708a1&amp;chksm=bf1feeaa3c88c1ac9cea975dc2c4fde42117e8a68cd632f161b05dea02031c68ee86ad210066&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 06 Feb 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【LLM &amp; KBQA】FlexKBQA：一种结合LLM的KBQA框架]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGBmkdJKCkicgFU1WhzfsmiakquDyltIbjQLnMq5kEEDISRFwt9RRpiaV8OBCPgH80ibdNpEN9nHGBqo3Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言 大语言模型（LLMs）在知识库问答（KBQA）领域的应用主要集中在包括但不限于以下几个方面：直接生成答案：一些方法直接利用LLMs生成答案，而不是生成中间的程序（如SPARQL查询）。这种方法通</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440845&amp;idx=3&amp;sn=4ff0a937bc43b70cba3d73de58df3007&amp;chksm=bf9712c9f942cdfb6b1555a612349b416c144e5a9abbd46b5c9b7146eaad45fe45b5908a103f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 06 Feb 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[LLM之RAG实战 | 如何构建一个RAG支持的聊天机器人，包括聊天、嵌入和重排序]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/N5aX12H1Sickjjl7zah14T3S3nhLxEUGvoHBv45bPojsstCfiaxYU1nZDr6pukfXwewyHIea0jHL8CtYI2vFqSDw/300?wxtype=jpeg&amp;wxfrom=0"/><p>      在人工智能和机器学习不断发展的环境中，聊天机器人变得越来越复杂，从简单的基于规则的回复转变为基于上下文的对话。在这篇博客文章中，我们将深入研究创建一个RAG支持的聊天机器人，该聊天机器人利</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440845&amp;idx=4&amp;sn=6184042081f13191f8a11dcb81f81c33&amp;chksm=bff54cc829aedc41969200e389b32230ce1cb616c508a3b41beafc43ffe76ed15129122ba999&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 06 Feb 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[GLM4 介绍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HIKk7OFDjoTv6mQl5EUOKicPicncVEQdJFaCOjmjItKpv9fMCERmQz5gbLygF3fAXHxXibeeWO8nOuBzHCHCMCeiaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>GLM-42024年1月16日，智谱AI正式推出GLM-4新一代基座大模型，整体性能相比ChatGLM3全面提升60%，根据实际测试，GLM-4在以中文为主的应用场景中实际性能逼近GPT-4的95%，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440845&amp;idx=5&amp;sn=335738b04123fb8506c132ebf53d512b&amp;chksm=bff007dd0fdd39c44ea9a8c12b83a7896371787247211e550763fb6b16c7951398457ecff1f9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 06 Feb 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[在华为，请假一天的代价是3700…]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/6fuT3emWI5Kw8tPicUuoMKvt6zZkkrMtFlaia9eGNPfdjiaVNias3Od5FSiaMxwPqQM0yUSls0qDEv6KiaDbZHmQuBMg/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近，一篇「在华为，请假一天的代价是3700」的帖子引发网友热议原来，在华为请假会影响每个月的奖金和年终，所以很多人都会选择拿周末的加班来调。在华为周末加班是双倍工资，请假一天相当于扣除双倍的日工资，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440830&amp;idx=1&amp;sn=826708be8664e602be502818de8ebdd3&amp;chksm=bf9ead1622f548eb7931c01907258dfc34bca45611ad7e06f25689b127056d353a9259bd37d8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 04 Feb 2024 10:38:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[复刻ChatGPT语言模型系列-（二）参数高效微调]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hq9ANWCLRic0KXWTjSbKPblT2EDkES9lLtVfOk4h1kMLQSwpsTgNVd1hGBh8nAtlXTqzYjwLuWxMSfdYXicKDuYw/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言今天开始我将会推出一系列关于复刻ChatGPT语言模型的博文。本系列将包括以下内容：复刻ChatGPT语言模型系列-（一）基座模型选取复刻ChatGPT语言模型系列-（二）参数高效微调复刻Chat</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440830&amp;idx=2&amp;sn=03266e804eb9b72131a1a187f1b1b6eb&amp;chksm=bf400c5346cc8b4417cb680e6c5741085d297b9c87e9c30755a306c640427fc460dfa1d3a0ea&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 04 Feb 2024 10:38:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[BGE M3-Embedding：智源最新发布的text embedding模型，多语言检索效果超过微软跟openai]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKptTaLq0mFs3ypIxIkXJERY1vlGBl0ic3QvbfE02M3Pow0ZnK9FhPaesFNibM8stMXiaLF8AN2KDiatu2g/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲‍‍‍‍‍‍1 简介 2 BGE M3-Embedding    2.1 训练数据构建    2.2 混合检索    2.3 训练方式3 实验4 讨论参考文献1 简介    24年的第一个月，智源</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440830&amp;idx=3&amp;sn=0e37d46c60db7472945c5ae27b17449b&amp;chksm=bf9f1fa4181c10aea13733c2f0a526e843b51301917f2a70a6921f6fb72e9c0a5e37278f68a4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 04 Feb 2024 10:38:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM之RAG实战  | 高级RAG 03：多文档RAG体系结构]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/N5aX12H1Sickjjl7zah14T3S3nhLxEUGvLuwDsM6kQ5KaZg0HzYvm6VkSk28WQPhhic5JqyHLY6ib2gibo8MqU5Cuw/300?wxtype=jpeg&amp;wxfrom=0"/><p>       在RAG（检索和生成）这样的框架内管理和处理多个文档有很大的挑战。关键不仅在于提取相关内容，还在于选择包含用户查询所寻求的信息的适当文档。基于用户查询对齐的多粒度特性，需要动态选择文档，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440830&amp;idx=4&amp;sn=8b2278ebacaf7bf8adea49fc18ff9982&amp;chksm=bf2030b381dc8e98c4f60108691722438c0e1f5a090992ad8a723183b22e77c71c41071355e0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 04 Feb 2024 10:38:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[vllm的SamplingParams参数]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_png/1FD1x61uYVcRrJHP52OV89EaAkIk3BJ7O3WWAaKNAGSu9iariaafobkgKnWkkVW2TQQeLkqViaTDhvibgn8knmK6Wg/300?wxtype=png&amp;wxfrom=0"/><p>vllm部署示例from vllm import LLM, SamplingParams# Sample prompts.prompts = [    "Hello, my name is",    </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440830&amp;idx=5&amp;sn=2c7b80072c084dccb9d147a70a66fe34&amp;chksm=bfbb4fcb5caaf076240467350499b2e0c7c3a64b25858ac8135097e096050aa42c5c9a0eefe3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 04 Feb 2024 10:38:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[HiFT全参数微调新范式---逐层微调]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKxsUzia3vHMcwJQNbWe8eOLsF9e4q4IibhTcby3GmxIa4YwMMfSTUXAK1JGWj9pwTyYUs3WkL2ibsGA/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：刘永康单位：东北大学、慕尼黑大学论文链接: https://arxiv.org/abs/2401.15207HiFT 是一个端到端的层级优化策略。目前论文的结果是原始混合精度的结果，目前最新进展</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440818&amp;idx=1&amp;sn=eca12dd3efd45d92f17bdc98d36ed99c&amp;chksm=bfdfa6e2381035c24e6820105831a7fc7df400a499cbc1b2fdf495c17b7c46c7daf8ea82bbf6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 02 Feb 2024 13:28:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解大模型训练系列之：DeepSpeed-Megatron MoE并行训练（原理篇）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkPcHSDaCg1w25tL8ScnHd1ljib4lE3I1X8icQakbqcRET7ibnJcT9oUQINP1KHMlzyrNtBmwfDFyMDPg/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，时隔不知多少月，LLM并行训练系列终于又有更新了（抱头防打），这一章我们来讲MoE并行，同样分为原理篇和源码篇做讲解（本来想合在一起的，但是MoE的细节太多实在写不完，所以还是分成两篇）。关于</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440818&amp;idx=2&amp;sn=0e0bb7931c2b55dc19814ccb37180ff6&amp;chksm=bf7fc512fe79291cc0b5704e06c8f7c7d181ab814d661a80400843512a0f72eca4e2e0c7de87&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 02 Feb 2024 13:28:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[京东零售搜索算法团队招聘实习生]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJ3HGy24dbxwWCWEoAD0vRB2BSZOBCJiagylojllZJql85dUBiba750ap1x7A7KOaic9bqS9V9zCmNjA/300?wxtype=jpeg&amp;wxfrom=0"/><p>团队介绍：我们是京东零售负责京东app搜索算法的团队，承担京东全站自然搜索流量的分发。团队氛围十分NICE，团队成员主要来自清华北大中科院等高校的硕博，团队成员曾在多个顶会上发表论文，包括不限于ICM</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440818&amp;idx=3&amp;sn=b854e1bf7ea17fc59909aacad1092d00&amp;chksm=bf11631dc4c80419bb0ee4123ae27fdd888f2482306f93f20c344d8a5142f9abe84c7480a99c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 02 Feb 2024 13:28:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[AAAI 2024 |大模型时代，什么是比代码更好的数值推理中间表示？——方程]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/58FUuNaBUjqCByXGW7gKibOQPlnYFxXHbeGmIEs8yVeG85PEhzKDE7aFvibopy6Dhic9eD4e3bu7QfuW88PfNIlGA/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：探索方程作为一种更好的数值推理中间表示作者：王丁子睿、窦隆绪、张文斌、曾俊瑀、车万翔链接：https://arxiv.org/abs/2308.10585项目链接：https://github.</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440818&amp;idx=4&amp;sn=572534deb46cab949073b459bbc0e918&amp;chksm=bf25bcc7c7b2000233bf653f2b8ab87489448e945a4159642808247df826ed505f796a9a7bf4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 02 Feb 2024 13:28:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ICLR 2024：无需标签即可评估模型性能？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/DHibuUfpZvQc14a8W9lvErDGJ3FuYHlHbB0EAomDJ8S2qVbmfIgKOdvTLMd2wYxz4icHJlGicWMMGsC14H15T87iaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者 | 彭儒@浙江大学 https://arxiv.org/abs/2401.12689今天分享来自浙江大学ICLR 2024的关于自动模型评估AutoEval的最新工作：MDE。概要机器学习模型的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440818&amp;idx=5&amp;sn=da1b3ca4362d1ada9a0a9ab5eb1f32f2&amp;chksm=bf4195520faa6871e90b29cd79505ad3cd33f165036cdd6ec39f831f6b4ec91d4ae9a2a44c40&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 02 Feb 2024 13:28:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[解决幻觉、跨语言两大难题！多模态大模型新SOTA来了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GdTaGsj8bY1X1T2RiaWhDfLs8vzs7oTAPjH6wLeBs7wibejfXasFO2EpYwlNHIyBbRrTKDlwcm3MbGDxW6Z5OXpQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>多模态大语言模型（MLLM）是近年来兴起的一个新的研究热点，它利用强大的大语言模型作为大脑来执行多模态任务。MLLM令人惊讶的新兴能力，如基于图像写故事和无OCR的数学推理，在传统方法中是罕见的，这表</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440798&amp;idx=1&amp;sn=dd98cb5d9685e57cdbdde8450dce0db6&amp;chksm=bf1ecb4bc74206111d7f444370d25376e5349526678c28640c52c317f78989bda1a1f0de9dcf&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 01 Feb 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[上下文扩展探索：FOT与MT的外部存储策略]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hq9ANWCLRic29g80WSG1u70T2a0080CX3RKbrezWGxiaey0OfMWJArF5M0sSH0Y613CnZ1JBm1bRibicrDzqtwTgug/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言Transformer已经成为一种非常流行的架构，在大语言模型上得到了广泛的应用。然而，扩展Transformer上下文长度仍然是一个具有挑战性的问题，值得我们深入研究。在本文中，我们将重点介绍M</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440798&amp;idx=2&amp;sn=a5f688119eed974b1afd0b5af6a4dc0a&amp;chksm=bf05e833275325a6596ddd09dd99f9b03202d5a24ef9c88eb05b74bfcad3ce3d55b47f8489a5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 01 Feb 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM之RAG理论 |  高级RAG技术全面汇总]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/N5aX12H1Sicm8EmszAuic6HlIR9lbLt0jQFp7aUm6bz71fFzjq5A2HgQ5KxwKYlaicoHwYwJCeeQcaU6jBQAX2AmQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>       检索增强生成（Retrieval-Augmented Generation，又称RAG）通过检索LLMs之外的数据源来支持其生成答案。RAG=搜索+LLM提示，根据用户的查询要求，LLM</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440798&amp;idx=3&amp;sn=223b734fe7091d6d74299f59cfbbb14e&amp;chksm=bfee6053f0bdaff801796699aa174c0ac1cd9635dd3d3ae2f3d305b9b4e9cf89e1c294a6ec61&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 01 Feb 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[值得一看的大模型RAG问答总括性梳理：模块化(Modular)RAG范式的定义、构成及机遇]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/fUBU1yiaEmJhNRuORpASlDKrUXybg42cWziaaQFIQ4yHlhVuDrLMKRwS7PckpoooX69MBqa0LIjujicudFibnticRJg/300?wxtype=jpeg&amp;wxfrom=0"/><p>关于RAG的综述文章《Retrieval-Augmented Generation for Large Language Models: A Survey》(https://arxiv.org/abs</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440798&amp;idx=4&amp;sn=fe962ba3b0bfaeb28377d15774200f8d&amp;chksm=bf4cdae24218736ceeae3579305a32ef0b8e3086e80dfa0ee4bbd136cdcf9d5a0c9ede702385&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 01 Feb 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[EMNLP'23：大模型时代的数据标注—FreeAL]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/DHibuUfpZvQc14a8W9lvErDGJ3FuYHlHb3geQeGYEtvnDaK17bYuBaaKjC2ET3BPyqqAhicaic4uQ0JxWoiaqmI2dQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者 | 皓波@浙江大学 https://zhuanlan.zhihu.com/p/672287298本文跟大家介绍我们和网易伏羲合作发表在EMNLP'23主会的工作FreeAL: Towards H</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440798&amp;idx=5&amp;sn=ff638a86ab429ca4e76b66a9dacb498b&amp;chksm=bf24a353eddfbcf65440474b8ac98da2541248d29da354ec0c19c722173825a84a2050086516&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 01 Feb 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[万字长文聊聊LLM Agents的现状，问题与未来]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/DHibuUfpZvQfl8v1YuNw43bE2ibmHHcDDm7mWnSFeEVhS9cpBKOgibwa4fnIBiaJ4ibHibnrjuiaypZUaz2D4JtkiaXqZQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：hadiii@知乎链接：https://zhuanlan.zhihu.com/p/679177488跨年之前，想总结一下去年上半年以来关于LLM Agents的学习经历，同时记录一下我在其中过程</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440788&amp;idx=1&amp;sn=2ea1a2fb6c8bd1ee2633ad51fa1442b2&amp;chksm=bfd16c769cf68458372a85f5d156552184fe32774a220cf1a7d45eafb41ff76e9d4675239087&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 31 Jan 2024 12:05:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ALiBi位置编码深度解析：代码实现、长度外推]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hq9ANWCLRic29g80WSG1u70T2a0080CX3wBYGVM5rvaSuBnreqiaicyd1rXicwRShPLbNqoqcLhXaka3ggbupfevcA/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言在前面的文章中，我们深入探讨了RoPE（旋转位置编码）的理论推导过程、ChatGLM/LLAMA的RoPE代码实现以及如何针对RoPE编码进行长度外推。此次，我们将聚焦于另一种编码方式——ALiB</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440788&amp;idx=2&amp;sn=a9fce51c0160ac4eb42d030283749fb2&amp;chksm=bf5a3d14b1062ba4402662a4fd35e39bd0ffa3a50d1d7176d5a78de1a4f20df611ab9544618e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 31 Jan 2024 12:05:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【字节跳动日常算法实习生】]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJPrFJVicZa4bHnthYnz9zzf1fVtqJbj4YznxcrtOmhmld24HAnuiaNqBxcPcWWYDIm6WFfvWicicPMCA/300?wxtype=jpeg&amp;wxfrom=0"/><p>【字节跳动日常算法实习生】【岗位职责】1. 开发及优化算法，与产品和业务团队紧密合作，调研并实现前沿技术并应用于落地场景，包括但不限于激励、理解、增长营销等场景；2. 对现有算法、数据进行分析和评估，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440788&amp;idx=3&amp;sn=8c32ea490783996970a5fcada0ebb7c5&amp;chksm=bf5eff38793d8bfc156c2686fe9f87488720c9a33563f8e333a10db5d5f741002c2f6f7278b7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 31 Jan 2024 12:05:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[使用KTO进行更好、更便宜、更快速的LLM对齐]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVdAdWGq0ckiay6nrs3mW5R6QPVzMNVzo87lqibjJYJqDs364WUUu8GvH2J6utxh9a17ePkuSWqjpY9w/300?wxtype=jpeg&amp;wxfrom=0"/><p>KTO全称为Kahneman-Tversky Optimisation，这种对齐方法使在我们的数据上对大型语言模型（LLM）进行对齐变得前所未有地容易和便宜，而且不会损害性能。大型语言模型的成功在很大</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440788&amp;idx=4&amp;sn=87ad47c8bc05729eb8c8a77a97b08b06&amp;chksm=bf3050ddddc3364c57b584f78a92da77ab6658b6e3a7e641673cf866950959f8c523f5b19cfe&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 31 Jan 2024 12:05:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[“激活信标”，一招解决LLMs中“上下文过长”难题！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/sevcrQuQ41GYvpfgu1BVHlGthMLRE7yxJNvKVicF1r9B9iah1ltwzqeboxDalLEmApibeNWksx1eyUULDpfibWtj8g/300?wxtype=jpeg&amp;wxfrom=0"/><p>大语言模型面临巨大挑战？？上下文太长了怎么办？？虽然精调可以拓展上下文窗口，但成本太高了！并且可能会影响LLM的原始能力！！！因此，该研究提出“激活信标”！！！01导读激活信标将LLM的原始激活（即键</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650440788&amp;idx=5&amp;sn=d8b0a4ed1bf95ded591e7bac9a4b99a2&amp;chksm=bfd7573c73deb2f90b2c66da9bdacaf4a078559b13f815f284a39cd78f9217c6f3609c509b85&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 31 Jan 2024 12:05:39 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
