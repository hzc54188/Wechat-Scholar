<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    




































    <item>
      <title><![CDATA[ACL等顶会论文合集、80个代码即插即用模块]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKbDajVZZSJfAVhMSCicGThe45P3QpNsbPiapWjwzqPRoBiatxG9OEsUhicn10NMMogDyyhaiah8s60B7Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天向所有在2024以及未来几年内发论文的同学分享一些资料：23年各大顶会论文合集、80个代码中的即插即用模块、论文写作方法论、以及完成初稿后的论文润色。发论文，首先大家需要解决idea的问题。最有效</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441671&amp;idx=1&amp;sn=f5f6a69e673841d30c93002d55eb13f1&amp;chksm=bf3ba4786dd456c31d8824680a5010fca53986686404c9b9fb72140a30e82395a79d11e55467&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 02 Apr 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[ChatGPT 终于不用登录了：Start using ChatGPT instantly]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIOgYBHiaIexlr6TK1NyQX5PphkX7rDupBtB6QicicKcVND89FicW5paSU1KWDIDIpnf1tdPKHAsYSiaoQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自于 OpenAI官方的信息，发表于当地时间4.1号，不确定算不算是愚人节玩笑，不过玩笑应该不会开得这么大，目前我这边还没有测试出来，但是官方信息说是逐步开放：https://openai.com/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441671&amp;idx=2&amp;sn=ec9344303e8e5532385a31beb4f0c66e&amp;chksm=bfab8d4ea67034685bab52b64d9cf3e2fdbdb74747d23a9e555e06bd013a61c9f4ecc3ca920a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 02 Apr 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[InternLM2技术报告]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5m3cxwGiaJdk0roAJiag1Vc5zc7rPkKpTBXZKm0z2ehPNqDzELmezgb3ZYefpRgHwDWkl4FkxwCqSYQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前分享过Llama2、Baichuan2、Qwen、Yi的技术报告，今天给大家带来InternLM2的技术报告的细节分享。Paper: https://arxiv.org/abs/2403.1729</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441671&amp;idx=3&amp;sn=f5b1db0117309d6e7db08960ea0135ad&amp;chksm=bf7e900d8c7494f6758078f665f8097323cab0c1c316bbb5ead466c673548ee2ce55069338ef&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 02 Apr 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[利用 🤗 Optimum Intel 和 fastRAG 在 CPU 上优化文本嵌入]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2pELOzGDyVictx6uQ11eiaqwW5OcCeRvMHfBXljpCqaoazPdfIlmFFBC6oF0rdupj6DkaQMLPj56byQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>嵌入模型在很多场合都有广泛应用，如检索、重排、聚类以及分类。近年来，研究界在嵌入模型领域取得了很大的进展，这些进展大大提高了基于语义的应用的竞争力。BGE、GTE以及E5等模型在MTEB基准上长期霸榜</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441671&amp;idx=4&amp;sn=07c10995587a2477c175551f701fde79&amp;chksm=bf93b413d9556569971f88998500d758973459394b404fe918019ca6cc440ac38ea08c2684e3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 02 Apr 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[也看跨模态大模型遇见文档理解：mPLUG-DocOwl1.5及TextMonkey方案中的数据工程]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/fUBU1yiaEmJhtUPpser4dv6BCKMmzyvps74VagR94uJsfQlyV3edQhqpibWiaoWlibldbeM5OjUHIpPKMPfTebejKA/300?wxtype=jpeg&amp;wxfrom=0"/><p>我们具体来看看关于文档理解大模型的相关方案，其中最重要的数据工程上的一些事儿。一个是mPLUG-DocOwl 1.5，这是阿里达摩院的工作，其对数据的构造上很有趣，我们重点来看看。另一个是TextMo</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441671&amp;idx=5&amp;sn=6762969861cdb884fc5d8f1fa48e19fe&amp;chksm=bfa9819b3902b1c9f11ca835461c7c0702951bfbe049f471ae6a60d420e6c1c655325810b530&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 02 Apr 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[再次封神！AI 大模型渗透太快了。。。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJrca4fGxRz42rBibraX6Qj9aJH0AG7xhkBYaev1D0snXIRPodmDnxONh3q7tO98ibKDASyQ7LjAKgw/640?wxtype=jpeg&amp;wxfrom=0"/><p>国内AI赛道又爆了！继科大讯飞、阿里、华为等巨头公司发布AI产品后，很多中小企业也陆续进场！人才市场上AI大模型工程师“一将难求”！甚至开出超高年薪，挖掘AI大模型人才！如今大厂老板们，也更倾向于会A</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441640&amp;idx=1&amp;sn=00937e0d65c9678a0937f619af77ecd0&amp;chksm=bf4f858102f4505a987ee31b389596f374e13ba4e4debcad05122bab093d87d7647ee948661e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型对齐阶段的Scaling Laws]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/AzuXfeINxjU0pj5htS9JujjoH7bJs3Ugw2vC1icxzba6MRyUMnLWsz2ds6kFG82V2dicBaNHPgJyXeiaQQ4PTdoTA/300?wxtype=jpeg&amp;wxfrom=0"/><p>随着过去一年大模型技术的发展，数据、模型尺寸scale up后的能力已经不容置疑，scaling law也被越来越多研究者重视起来。在预训练资源消耗如此大的情况下，掌握scaling law有众多优点</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441640&amp;idx=2&amp;sn=033e816a5b6cd4d4200304c74dc004e8&amp;chksm=bf935eeafcfe409f3671acc4291bf51f23524faed51b7f2ef47b65f75607a1873bb6d7658d51&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[基于prefix tuning + Bert的标题党分类器]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgwhmCZRaXOO3SBlDgGpsep3lJgaayYH8c4QvveZUKCJ4NvAtoibDias7w6BIoIJlic2tuwOCWhhicUGSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>背景近期, CSDN博客推荐流的标题党博客又多了起来, 先前的基于TextCNN版本的分类模型在语义理解上能力有限, 于是, 便使用的更大的模型来优化, 最终准确率达到了93.7%, 还不错吧.一、P</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441640&amp;idx=3&amp;sn=0883259cd53eac179a146d0adbc34909&amp;chksm=bf1c8dac8c4e5e19619ea4a99a541f252989f7824118bbc79afb528bea789159b901d4d84090&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM之RAG理论 |  使用知识图谱增强RAG]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/N5aX12H1SiclxFbO9XvwxDzjpsg2jo3Tnvvg6f7jZSVCHiaPvHYJYM2pQGEwYDtvu5ChhjsH1ibxyCJ5qQ3E5G7aA/300?wxtype=jpeg&amp;wxfrom=0"/><p>       知识图谱（KG）或任何图都包括节点和边，其中每个节点表示一个概念，每个边表示一对概念之间的关系。本文介绍一种将任何文本语料库转换为知识图谱的技术，本文演示的知识图谱可以替换其他专业知识图</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441640&amp;idx=4&amp;sn=0d17d778e3528e31c2189873a63d029c&amp;chksm=bf0a1a9b77ab1537ed44539e36bd36da525998aa111775bdc40218a740c661c89d78f6bef8cd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[检索感知微调（RAFT），提升领域RAG效果的新方法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/aaN2xdFqa4EAib77bKHKUPey5o9I6IDBKic9BQTJDanwIe5sNZsxhq00FTTm9rBKH0s6glbayDePnk52NmI9QJWA/300?wxtype=jpeg&amp;wxfrom=0"/><p>一般来讲，让大模型应用到具体的行业领域，那就必须让大模型懂得行业里的知识。这种知识的导入一般有三种方法，一种是在预训练阶段喂给模型一些领域的文档和知识，扩充一些领域词表的方式解决。而更为常用的是另外两</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441640&amp;idx=5&amp;sn=f194b6124afc4d3dacdbb79bbd66702c&amp;chksm=bf5442ed82753711794ac51788c5cd95d01ea617716b39219596d1644a511871a042c1aa5bfa&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[某公司新招了个牛逼的架构师后.....]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL8T5cYQl9iaFneW3JuUQTqPOAot7xDtJYVctp5GqQW4bYeJ4rkf6XDWd9Af4ReKofkXm05wUicVgvw/640?wxtype=jpeg&amp;wxfrom=0"/><p>网友评论：@口袋FPV：架构师一个响指之后。第二天，老板不见了@妹_妹_奶_白_又_大001：走走停停 回头已是数月@NereusP：是我的故事没错了，本来我们组有10个人，我把代码重构之后，只要半个</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441630&amp;idx=1&amp;sn=4ac1322b6863b613c3317ea69b3b9b8c&amp;chksm=bf3edae8ac4fa0a70c5861c9eb485f019e457049f9a2eda3c203fe719d6338b06488f6133e34&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 31 Mar 2024 12:55:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【文末赠书】大语言模型训练优化秘籍]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL8T5cYQl9iaFneW3JuUQTqPBkwQpK1rBXMlYgZXE60x0VsEicSt25RnYnicKPvlEkiavFGFQStPpGPbQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>--文末赠书--在了解大语言模型训练优化秘籍之前，我们先来了解一下大语言模型训练面临的挑战，以此进行针对性的训练优化。大语言模型训练面临的挑战随着模型参数量规模的增大，资源和效率逐渐成为制约模型训练的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441630&amp;idx=2&amp;sn=9b9687a0f0e377e1e1cf63abae3b4357&amp;chksm=bfa6155614369d0c48bb359bdc5556243eac775668e7a700450e4935c820194984d661643d21&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 31 Mar 2024 12:55:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[行动胜过言语: Meta落地工业界首个万亿级别参数的生成式推荐系统模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/TnZw73HawgnLpmXAjE2D989H5iaF24ebU900KTG4JKFmMiaOU7hcVu0p1xibf39iakICxpG4clM0oYyibpraKdjibAXw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天分享一篇Meta最新的工作：借鉴LLMs思路重塑推荐系统范式，实现推荐系统的scaling。该工作第一次在核心产品线替换掉了近十年工业界长期使用的基于海量异构特征的深度推荐模型， 在模型规模、业务</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441630&amp;idx=3&amp;sn=b9c302423a7b8903b40f7ded2c83b9aa&amp;chksm=bf11ba1141b52f49ce51b16909934e33597632cec3c64cfaaec6f6d83fc07454199feb91ddbc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 31 Mar 2024 12:55:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[平安科技语音算法团队诚招NLP实习生]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL8T5cYQl9iaFneW3JuUQTqP3gZw4kkm1SQGHc5tKcZ0K1tWGyS8fjKqxSFocibeo40TcJ1gaBmpxvQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>平安科技语音算法系列 - Jianzong Wang团队诚招NLP实习生! 🌟📍 工作地点：深圳🔍 我们在寻找有才华、有经验的NLP实习生加入我们团队！团队亮点：✨ 已发表百篇顶级学术论文，覆盖NIP</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441630&amp;idx=4&amp;sn=3ab58365d767f8180e0fbd28da8fbb7e&amp;chksm=bfbfa3d5b82f152a4d0da508d0fff3a337c0f1e2c0248e88f8617e78a357f47c2b2f4c5d1be9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 31 Mar 2024 12:55:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[AICL: 一种可以主动选择demonstartion数量的ICL方案]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKpsvauRIcxtW0Fib9BLVj4AgEaaB0G6oK5Yw4gL3XGUFAKpxHb269xJCe2cm0oJqrc5lM9baJYTbsnA/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲1 简介2 Motivation3 AICL4 实验5 讨论参考文献1 简介    目前In-context learning会在大模型prompt输入中加入固定数量的跟当前问题相关的demons</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441630&amp;idx=5&amp;sn=44f6e3f0e83968d266593f5929d2dd6d&amp;chksm=bfc19e97d2fb343842beba0fbc8ec701baf71652651bedff5a8230d2b95fe026522ecf7c690d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 31 Mar 2024 12:55:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解大模型计算加速系列之：vLLM核心技术PagedAttention原理]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkOt2TOia57jHta5zCugcYw9mNg6T0ZC2Mx48zrQpgqlgDDq0W2SqzMgqYhdtk4BP3eLRmgKjaydlfg/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，今天想来介绍下当红推理框架vLLM的核心技术PagedAttention。PagedAttention的设计灵感来自操作系统的虚拟内存分页管理技术。vLLM的论文是在假设读者对这项分页管理技术</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441609&amp;idx=1&amp;sn=6a2fe681495539c7dec14fcbdeacedbb&amp;chksm=bfe7c834bb531beb5501ff350d8cceda21ef3ff4ebd6868772c793274535d7124f008e979f43&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 30 Mar 2024 10:59:27 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DBRX：重新定义开放语言模型的新里程碑]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/fI41EfAgQvsYFHGP7wyamxDMQdy6PndlTppyQVINJZ5zHrdeHHnTcrm679SFZ8tWaCbYZc17PBLSCAG4BLk2yQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>摘自Cameron R. Wolfe, Ph.D.的twitter🧱DBRX🧱是如此出色，以至于在过去的两天里，有3-4家公司被迫发布了“竞争”的LLM（我们几乎没有听说过它们）。以下是我对此的一些想</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441609&amp;idx=2&amp;sn=e5b58c260de63a9ffcfe66476747ff13&amp;chksm=bfde368ef4ed082e0f1700ec9f5734e08f3058aebf3789b024f5e4ed1bdd80c5dcb4d3ea30d6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 30 Mar 2024 10:59:27 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[融合RL与LLM思想，探寻世界模型以迈向AGI「中·下篇」]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/yToxjhYT5iba6cnqp9ShyFHpfAyISsBHjRibg9QCpiaSIXfUIGGibCWD3ibl8pq02JOQm5PicHTSfuUCXg8bllu6siajQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>本篇文章与2023年底尝试挖掘并探寻以chatGPT为代表的LLM和以AlphaGO/AlphaZero及当下AlphaDev为代表的RL思想的背后底层理论及形式上的统一，同时与最近OpenAI暴露出</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441609&amp;idx=3&amp;sn=af36b4550f795f8eb40dafa2bf2ecb44&amp;chksm=bf94460dc4e4d2ea4e20e6506fb86a4122bff78a30ce70281ceb37da7ed89ee2016ec0e6e9c6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 30 Mar 2024 10:59:27 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[复旦MOSS团队：数据配比的scalinglaw]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuw6Coc4OutPkaXT63GWVVuHm2yDk5iaYtI6jZs1zfLkzP6olxgn0lMPFVOKezCzIFxXaPryslab3XQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在前文我们提到过，大模型训练中数据的多样性和质量是最重要的两个维度，并且在结尾挖了一个大坑，希望有大佬愿意研究多样性的scaling laws。原文链接：大模型的微调数据选择技巧（三）大模型的微调数据</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441609&amp;idx=4&amp;sn=50daec080a80004aca22840d1e324094&amp;chksm=bf89c8b2947e1b5eb72b59043e822de71d7b278b9c3b8d1130313b608f08e57bd6a292464e7b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 30 Mar 2024 10:59:27 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Yi技术报告-划重点看细节]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW464a21JEWec9C3ttVRqNFLBia8MusJVHzRP5fyfaH7vHck1FhJTuKBiaMDlsiaW83MBYP7nY0SP0mKzbA/300?wxtype=jpeg&amp;wxfrom=0"/><p>01.AI（零一万物），是李开复带队孵化的AI公司。2023年11月初，01.AI发布并开源了Yi-6B、Yi-34B base模型，同一周内，又开源了Yi-6B-200K和Yi-34B-200K b</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441609&amp;idx=5&amp;sn=c2fcfc798976a724ba6a489af8aeb205&amp;chksm=bf497cb7c4ff9bf497f6d5a106fa16e10d6a50a1a3dd267f75f0a85c5be94eec0b2781c247e7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 30 Mar 2024 10:59:27 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[还是决定去小红书实习了!]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKXCWuFzcB7IcMniceF5dCdicibIy3WO3ic6ttfiaibTd0jCG3BHuNowiaBHzrBnCAibND9PAxuibeIgU7RAKw/640?wxtype=jpeg&amp;wxfrom=0"/><p>📢 小红书25届实习生招募火热进行中NLP/大模型/算法/前端/后端/客户端等超多技术方向岗位等你来!AINLP要来了专属内推码拿内推码可以优先筛选哦60B2Y2QM88D8也可以直接通过内推链接投递</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441591&amp;idx=1&amp;sn=4c66ad3a368a75b30866f50cc6d55ea9&amp;chksm=bfdfae0aa78c545f450004eb859ef22b674f505a2492f3e16673a205a368dd92655070a44d3e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Mar 2024 04:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen1.5-MoE模型：2.7B的激活参数量达到7B模型的性能]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5mjS1tvianwIk1Rcuic9sGH22UWLW1IGIPvlZnMa8iaNELLPkDxpAKibxibDVzPafCEMQWdOs6ReVrr45Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>Qwen1.5-MoE模型：2.7B的激活参数量达到7B模型的性能写在前面今天阿里放了MOE的模型，总参数量14.3B，具有64个专家，每次激活8个，在仅激活2.7B参数情况下，效果可以与Qwen1.</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441591&amp;idx=2&amp;sn=9cef61077e1751756fa3959bd72df9f3&amp;chksm=bf1f025f0e5a0d5adea27517ec53992280fab72b886c6e3717f30fba1186cfcc87f90f97862e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Mar 2024 04:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LoRA原理解析]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgz65reXkaewsAWUHiadHBiaZIrfa8p8lTWYjN3GoWPbkuHibppFnWXxLIrwBbYibbZpQkNXvUkwnoicRSQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言随着模型规模的不断扩大，微调模型的所有参数（所谓full fine-tuning）的可行性变得越来越低。以GPT-3的175B参数为例，每增加一个新领域就需要完整微调一个新模型，代价和成本非常高！</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441591&amp;idx=3&amp;sn=6905865a4474ef3a6422121bad9842fb&amp;chksm=bf7cdd090b33ac26ff89c8dc054a2693fd78dbaaa1c3e9714e8d4d509d38222d290a7f04f022&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Mar 2024 04:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[EMNLP 2024 征稿通知]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/EsDKszDSKDGShwibZciaDL2bxeooGiaD7ReHyhvLjibVf60cmPyibo1gbI4duhFgSlNagXVUn4Gq0B13XKuHkEWhicLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>计算语言学与自然语言处理顶级国际会议EMNLP 2024将于2024年11月12日至16日在美国佛罗里达州迈阿密召开。EMNLP 2024只接受ACL Rolling Review（ARR）投稿通道，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441591&amp;idx=4&amp;sn=e5be647d6105610f20211bcfb82adda5&amp;chksm=bfd3dbc273ddcd449b5961614133f156e1543ace7806e9d5c648e98b7a7bd20b1ee7f049762d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Mar 2024 04:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型数据之代码语料The Stack v2]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/s7YKINJYHDC9CFAicTSRD5jY2CduuMXTgd1Qup9ck8g7gxa3JgXXgHQrhR5kyBRxiaNpewTOdq0ArfbdFYOvoF3g/300?wxtype=jpeg&amp;wxfrom=0"/><p>与 The Stack v1 相比，The Stack v2 拥有更大的数据规模，采用了更先进的语言和许可证检测流程以及更优的过滤机制。The Stack v2有900B+不同的tokens, 是Th</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441591&amp;idx=5&amp;sn=8730d29e9002bde168603359d88c43f5&amp;chksm=bf111f1cc6ebde8e9c8f8bc32dda8f6d52ac38fa6c0a30555a5a4edac8cdb37edf715c2c805f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Mar 2024 04:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[50W奖金，校招绿色通道，确实可以封神了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKVy22NDn5JSJNWXsZKggQFJB5dLPjnSNreSuXnhsuJPy8MjnybBAQhZeldQFBYug0OgAHCNcibsMw/640?wxtype=jpeg&amp;wxfrom=0"/><p>新赛制，新玩法飞桨黑客马拉松第六期全新挑战，重磅回归！开源贡献个人挑战赛、飞桨护航计划集训营、Fundable Projects、优秀稿件征集与传播四大赛道，邀你挑战！多难度梯度开源任务、导师1V1指</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441534&amp;idx=1&amp;sn=a1ad868512de6ae3c76647f88de9a0a9&amp;chksm=bf7488c5e23aff0bfd53e5b034d61694fa8c0c4646369b9cea2751630cf7ee3d0a27d9cb7e0e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 27 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[使用自己的领域数据扩充baichuan模型词表（其他模型也一样）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgwggq0p7QF461l6swuOYzjpPpNtkicc2YM6YsecM4VJTqwICubtXa8fjVIg8SuTs2EMgvhibkP95gGg/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言总的来说，扩充词表可以加快解码速度，对于对中文支持不太友好的模型（如llama），扩充词表还能提升模型在中文的表现。环境jsonlines==3.1.0sentencepiece==0.1.99t</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441534&amp;idx=2&amp;sn=1edf0ce111749a9624ee6b25086a0729&amp;chksm=bf6fdc9cea0fb41cae3f407e05e1498f3bd116bb895c389d38133f1016a005d5d7f6a20a2422&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 27 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【社招】小红书增长技术多个岗位热招中！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKqDYic1fUolyca4lJx4DnuZlveQ2uM9iaJyZqgKxQYibOpupYleO999opKmZn79KgibkeBGdX2DhL87g/300?wxtype=jpeg&amp;wxfrom=0"/><p>工作地点：北京/上海收件箱：houmengchao@xiaohongshu.com算法工程师-画像方向工作职责1、负责优化小红书社区上亿用户的用户画像；2、应用数据挖掘方法和Multitask Lea</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441534&amp;idx=3&amp;sn=31e92e0403fe8e396a48bef3080e4300&amp;chksm=bfb711a01311dfebf870a534ba08884def56a013af2a53349775405bed448de918d33f197d18&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 27 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[生成模型大道至简｜Rectified Flow基础概念｜代码]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/vtIvcrPJjh7sn8o32iciaaBkpSCU6Fx8QzJOQVX904plwCewZv6x4UAFwVkucWWx3NFmAl5mjyImFv2picO0Wy5Mw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近看了下SD3的论文，里面用到了Rectified Flow，之前没有接触过，了解了下是项有意思的技术。值得推荐，这里记录下Rectified Flow的基础概念和代码实现。详细的原理和深入理解建议</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441534&amp;idx=4&amp;sn=408e997771da40a527cfb6160a8d6ecc&amp;chksm=bf1ec3caa72314d315c8dcebb6b37d0c376e64f7e8911c5a4b405362901ceae88b61c2c68872&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 27 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[为什么语言模型的本质是压缩器？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BAVX0pafImn4deViaa4kKDibasaupfNtw2tgsryYPkSZbUFIZFQ3RMZlFlDrOYM7txdqcW9mLfffBicBDrNlQwaWQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>最早听说语言模型的本质是压缩器的想法是在黄仁勋和Ilya的围炉对谈，当时只是直觉上觉得这个说法很有意思，但却没想明白原理是什么。2023年9月，DeepMind写论文进一步论证了语言建模与压缩的等价性</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441534&amp;idx=5&amp;sn=a3f6c2f17d7b6e3e433563bda6f5207e&amp;chksm=bfe0cbd1feefc3a7f9b0779f0976d3641d74823de07a8fca5de8fa78bce1be4c5c78fd897938&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 27 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
