<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    





























    <item>
      <title><![CDATA[LLM预训练与SFT数据配比调研]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJsJnOHTWe75WsIgwo2tv4VZYj6VfnWGwbR0ciamfgEEIjcGeAibfcccKIicwyk1d1Efo9Yia37FX2SlQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：天晴链接：https://zhuanlan.zhihu.com/p/703825827背景与目标最终目标是在 LLAMA3 模型的基础上进行继续训练与 SFT，但 LLAMA3 的数据与配比方案</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445341&amp;idx=1&amp;sn=280ea21b46e88585cb203f7be73bd6bd&amp;chksm=bf2e6bfc4f1bd081907e5a73591a950b1c4404845e5022a73d880164139c877f4270dc8ff75a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 12 Oct 2024 09:58:34 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[OpenAI o1技术初探3：如何让模型拥有自我纠错的能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkOpqVjLraGbzg9n0LCX1PlGhB4mNkjqHLC9mpEgW9PSh5PRWTGerVXAkHO4ibE51v6c9yvGpHlrJCA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在这个系列之前的文章中：我们探索了o1（可能基于test-time scaling law）做的基本框架。以及框架中的一块积木（靠纯inference优化来增强逻辑推理能力，我们分别列举了“PRM+s</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445341&amp;idx=2&amp;sn=052314b8bc533b3cc7195837c407453c&amp;chksm=bff4591bf9fbdb6b29a7bff28685da4aa721596384325a293e93abd26462537b3f323d4fab4e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 12 Oct 2024 09:58:34 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[COLING 2025 Call for Papers: 多模态生成评估研讨会]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJsJnOHTWe75WsIgwo2tv4V1BH0Up6UpogBPhxVb8uYdr1zRlIvPKaicaAwxU1nWFTKgXY9R2Dkiafg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Call for Papers: 多模态生成评估研讨会 The First Workshop of Evaluation of Multi-Modal Generation @ COLING 2025</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445341&amp;idx=3&amp;sn=7a2641a1956981bc39e1e8cbc52fa554&amp;chksm=bf6808095642a0c8aac0502961f8abebe1ea4b9e8ee2ed9d737aa2ad42bee236b54b810bb807&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 12 Oct 2024 09:58:34 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[CodePMP：提升LLM推理能力的可扩展偏好模型预训练]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5nbQgT8S1l4BLjrkFXxvP4ia1QDwiaa5yJdhphnkRLTF0JPOwicfGiaAZblynlrhX564ibDsTnpYU1GK0g/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：鱼汇沐  机构：中国科学院信息工程研究所 paper: https://arxiv.org/abs/2410.02229在LLM（大语言模型）的对齐训练中，尽管RLHF（基于人类反馈的强化学习）</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445341&amp;idx=4&amp;sn=faaffe2962949b2a34844610544dc06b&amp;chksm=bf06f271e05111f880f0afbe313229f36c297f9739f5bef70defb501ae99dc6697688c1261ce&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 12 Oct 2024 09:58:34 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【LLM开源项目】LLMs-开发框架-Langchain-Tutorials-external knowledge-v3.0]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdBYEj1f5rwrMGJp0tEItiaSqug9PWn9RRSXKjVxTVOmOwjYpvAF9w3lusIia57PWtxePkNwcab3ad1g/300?wxtype=jpeg&amp;wxfrom=0"/><p>【1】构建检索增强生成（RAG）应用程序Build a Retrieval Augmented Generation (RAG) Applicationhttps://python.langchain</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445341&amp;idx=5&amp;sn=04219ba504100b20e3faeea94a57c24c&amp;chksm=bf58d0a6c00fd4d853c33211496815cc45b1256b25d6c113437d6d450114117213285e9ac80e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 12 Oct 2024 09:58:34 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[一份MoE 可视化指南]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahHRkRw7bHSfaGqosebVZjBMpLRAgPjSou2QqLWlDJ5A2OGFv0KryGicGqic40THnJhzq9r7LAd9PKw/640?wxtype=jpeg&amp;wxfrom=0"/><p>编辑：AI椰青整理：https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mixture-of-experts在查看最新发布的L</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445323&amp;idx=1&amp;sn=c77482d38bda5c267f7212a1f0afa0db&amp;chksm=bf0f421cd1f67b10b94fcc8d997fdf1dc81d420fdfefe70946f429f2de62e4592d7a9530c276&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 10 Oct 2024 11:46:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[RoPE背后的数学想象力]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKGvADdGyKWmHJXZI8OlCHsgB9B4dw6YtO2ywog9rcrN8kVBOGP3ENFo6HRIZPEFIXia81zgHOyRlA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Polya said it well: “When you have satisfied yourself that the theorem is true, you start proving it</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445323&amp;idx=2&amp;sn=7a9458b86c5940430c834ed28252dc65&amp;chksm=bf47842271e626e0245b659c80ba4ac8b2e39c308e929764affcc51959a2211a6daa6f54915d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 10 Oct 2024 11:46:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[[社招/研究型实习生]通义实验室-角色扮演/分身复刻算法方向招聘]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKGvADdGyKWmHJXZI8OlCHstLTKWQBh8IUVvU0unyiaLW7NzpibpIQKmoIibhrrrK4GrVicISLZdhoLuQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>[社招/研究型实习生]通义实验室-角色扮演/分身复刻算法方向招聘[团队介绍]阿里巴巴通义实验室，主要负责通义系列大模型的研发和应用落地。其中对话智能团队以大模型对话技术为核心，研究及应用方向包括角色扮</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445323&amp;idx=3&amp;sn=0872378e95e42bab7239219f8af09a0e&amp;chksm=bff610f83f3c4cb1c21078e260c1d122b70d72d348d088b3369c83ed142974d7577adc0136c4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 10 Oct 2024 11:46:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024年诺贝尔化学奖官方解读：他们通过计算和AI揭示“蛋白质奥秘”]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKGvADdGyKWmHJXZI8OlCHszqN6u61oqrnLczMW6tz1Ao5vFNBQcKo47ye4R4LbFiaLWNNIQr0ibyibg/300?wxtype=jpeg&amp;wxfrom=0"/><p>长期以来，化学家们一直梦想着全面了解和掌握生命的化学工具--蛋白质。现在，这个梦想已经触手可及。Demis Hassabis 和 John M. Jumper 成功地利用人工智能预测了几乎所有已知蛋白</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445323&amp;idx=4&amp;sn=e188b0984a295cb64fef0e50e0deee22&amp;chksm=bf1dff4cd83d7009c06e635abad0091da39004d941618f30e119cc493ad16b36ee3bd1461971&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 10 Oct 2024 11:46:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多模态入门--CLIP]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW465ZwfEVEGyUkIibc0vicYcV0aTjXLptibp5kam0S5wLtl7uNxBrGlQSy9dBsvXm6celrqxYUc3THzw7g/300?wxtype=jpeg&amp;wxfrom=0"/><p>放假了，小小水一篇多模态的经典之作，CLIP。论文：《Learning Transferable Visual Models From Natural Language Supervision》时间：</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445323&amp;idx=5&amp;sn=752509cc7386fc2175424858c6c891cd&amp;chksm=bfe692ee1fe7d8d2aaa52c492abb935dc85fa73f24bc52686246bd5114f289c6ffd422a5e750&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 10 Oct 2024 11:46:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[全是细节｜大模型SFT的100个关键点]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIXM2OJMOJmibe3GicicukSzmial8iaRAtoN081OET6Nmoib8ic9C7qElia4rULgibwicMvt7DECW6MK7M4y64A/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：ybq链接：https://zhuanlan.zhihu.com/p/809229182点击底部访问原文直达这篇文章介绍一下大模型的 sft 如何去做。相比较于上一篇文章介绍的 pretrain</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445303&amp;idx=1&amp;sn=cae55e0e581e260dfb40df6a9ae0f83f&amp;chksm=bfadfc49bd22d4097638ea12daddcda7880d49b786f941406e96a3627987ec7b6eb1e8071c53&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 09 Oct 2024 07:56:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024年诺贝尔物理奖官方解读：他们用物理解码信息]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIXM2OJMOJmibe3GicicukSzmiaNQjdv6ticGDreqlgpL7NxicukkKmwbxib5KoNCnkMliaZUA30InZGDhQYg/300?wxtype=jpeg&amp;wxfrom=0"/><p>源：中科院物理所今年的获奖者利用物理学工具构建了一些方法，为今天强大的机器学习奠定基础。约翰·霍普菲尔德（John Hopfield）创造了一种可以存储和重构信息的结构。杰弗里·辛顿（Geoffrey</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445303&amp;idx=2&amp;sn=a1d907587fd891d7032b83532e0f5374&amp;chksm=bf7339c0ec4a749942d37e564ee3341ba0faa136082789b2d5a77af49ef43af18f2de526204e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 09 Oct 2024 07:56:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[天池-蚂蚁AFAC大模型挑战赛-冠军方案分享(文末有代码)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVfsUStsEBq7vAaBVqJq8hBdQ88P3WNbrgADdOXGh5NMC34IcsDNIZEDtiaibMjiby3KC7mGzctKcJQ7Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言❝作者    彭欣怡 华东师大; 马千里 虾皮; 戎妍 港科广说在前面    在当今信息技术迅猛发展的背景下，大模型技术已经成为推动人工智能领域进步的重要力量。    前段时间备受瞩目的AFAC赛</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445303&amp;idx=3&amp;sn=58f198732ef21b44871262dc02f022af&amp;chksm=bfd3e41960a31b8e10ca949980edeb26367058dd2aaae4884c59f5aa3ac0dddfed39e6341ed6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 09 Oct 2024 07:56:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型是否具有自己风格？这个风格来自于哪里？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiawBZfF689rxSflI0IpicsL0m511RkybJWwFBAwTD6NalUoG99kog0KsqSv8CuFtVEKRVSe59Ipo9Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：bhn (已获授权)链接：https://arxiv.org/abs/2309.17415背景这篇文章研究的是大模型生成任务中，出现上下文信息，与模型本身的知识冲突时（常见于rag场景），模型的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445303&amp;idx=4&amp;sn=4e80d3ffcf5a3bdaaf15680b325da2bf&amp;chksm=bf2e99579ecb3e5c897c971a94e484659938160e823701859e24bccde109a6f2a67fe2c3f284&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 09 Oct 2024 07:56:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM开源项目】LLMs-开发框架-Langchain-Tutorials-Basics-v2.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdBYEj1f5rwrMGJp0tEItiaSqug9PWn9RRSXKjVxTVOmOwjYpvAF9w3lusIia57PWtxePkNwcab3ad1g/300?wxtype=jpeg&amp;wxfrom=0"/><p>【1】使用LCEL构建简单的LLM应用程序(Build a Simple LLM Application with LCEL)https://python.langchain.com/docs/tut</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445303&amp;idx=5&amp;sn=f623873b3cd190e84bfb078d8a58c1a7&amp;chksm=bf81fe10ce57e8a75d24f1ce9eccee784de9ce77ef18309d63f2442402f83ddd58782ec3a922&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 09 Oct 2024 07:56:58 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[又一本开源免费的大模型书来了，449页pdf！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLqRFgO1HNQMUngG5LfKK4eN15Rxeib8cEFnJzb40Okh6icNvR3v0o2Irr32NgWJVwGKibOic18ibly1ibg/640?wxtype=jpeg&amp;wxfrom=0"/><p>介绍《自然语言处理：大模型理论实践》（预览版）一书以自然语言处理中语言模型为主线，涵盖了从基础理论到高级应用的全方位内容，逐步引导读者从基础的自然语言处理技术走向大模型的深度学习与实际应用。自然语言处</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445276&amp;idx=1&amp;sn=c7f802b7f6758907a73c95afb518de58&amp;chksm=bf0e5321a5053ad603ce37d0ee27cc5a5e7b8ea9dac749b1acd07981023487bae5939b863eb0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 08 Oct 2024 02:09:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM高效预训练(二)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW467AukRdq9SPFe8zBtoWBI5qwLzXc0AkmRvUJQckrJ9FNS945oko2LyzVPib0HadCTZHxWhDYv47hyQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>从目前的实践结果来看，从大模型通过裁剪、蒸馏等手段获取小模型，效果是比较好的，同时成本也相比直接从零预训练要低廉得多，而且也免去了大量收集数据和清洗数据的工作。今天就集中讲一下模型裁剪的工作。裁剪 +</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445276&amp;idx=2&amp;sn=be55cd18bf4fc30bddd4f7302515818c&amp;chksm=bf4f2b2c1813ea2b84486f875625ae17069cdfaca2aaa417a6091a1391a65a4f95f884c83a80&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 08 Oct 2024 02:09:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OpenAI o1 技术初探2：使用MCTS增强推理能力（基于代码实践的解读）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkNOOc1O2OnNnXpEv2R0OHfQv4IF4YU0RbzQ7436wjX43s2uKAib2SEtMSnbHO46N5fgw3M4IlLW7uw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在o1的整体框架篇中（https://zhuanlan.zhihu.com/p/773907223），我们从现有开源的论文和代码中（https://github.com/hijkzzz/Awesome</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445276&amp;idx=3&amp;sn=fc255f07e150ca773e62dc516e5d5121&amp;chksm=bf890bf8ca84e757dd25fb773beef81cc146e5b6c9dcd369c13416befac8ada8f50ce9d04d53&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 08 Oct 2024 02:09:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型落地困境讨论与解决思路]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jT5Sp7MICPxiciaXd4CDibrv60kBrU2Y8IiatCIvsFeVh9FUic7uojDicGY5MXDMHFZunkz3269xP6VAx2icXeJrtCHug/300?wxtype=jpeg&amp;wxfrom=0"/><p>大模型出来的时间也不短了，以chatgpt发布时间为里程碑（22年11月），至今已经快过了两年时间，虽然目前的热度仍未下降，但是从我最近和几个朋友的沟通来看，大家的心态已经逐步从当初的热情变成了目前的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445276&amp;idx=4&amp;sn=99b0529aa06d04a83742f45111a4300c&amp;chksm=bf9016e6a620801056e051663725f911fae93436bc231c660e54d789a4d54ecdc7187ae24903&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 08 Oct 2024 02:09:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Neurips 2024 | 通过解耦的位置向量探索大语言模型的上下文窗口]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/G7ia3FZ0o0OqDtrZdAFnbK0LoDIlgk6MVCibM1rWlAa2wWwjQVWia9RKWH9PkL2jJ4uWo3h0TT9r6ypfuFm5QF9LA/300?wxtype=jpeg&amp;wxfrom=0"/><p>© 作者｜董梓灿‍‍‍‍‍‍‍‍机构｜中国人民大学研究方向｜大语言模型、长文本处理基于Transformer的大语言模型天然具有固定的上下文窗口。虽然已有一些方法用于拓展上下文窗口，但对于其背后的原理</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445276&amp;idx=5&amp;sn=119d6c445e7427941eae15ea34599bf8&amp;chksm=bfdcb8dca5927742a6e9b303e6201e9c94a80df3d271959221c0c570a3c68fb35485eeaa244e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 08 Oct 2024 02:09:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型最热方向：LLM-Multi Agent 来了！！！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLmC7XupDBzUH8LCPfwV9VOKaMibjhXcoJJlcoibBsticpMK6XOKlcKmAbplvEB9jqS2X6ExpH4Icseg/640?wxtype=jpeg&amp;wxfrom=0"/><p>大语言模型(LLM)2024年火出圈了。然而,单一的LLM在处理复杂任务时往往力不从心。多智能体辩论方法应运而生，它通过模拟多个智能体之间的互动，提高语言模型在事实性和推理能力方面的表现，有效缓解了单</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445261&amp;idx=1&amp;sn=01eb66f15725a462cebec66a0d40d1c3&amp;chksm=bfeebb885ab5438fc93723702f03387b012cc5f43f77c184ff44c23cec17955acd5d920a8e98&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 07 Oct 2024 02:12:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OpenAI o1 技术初探1：整体框架，利用Test-Time Scaling Law提升逻辑推理能力]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkOibl50lXj5CZaPDGGkyRVkMGRaftWsjfl9b06ZjicQ5Wyh1Yx0whWJ0Rxu5WHteSsPLCiaiaxHWmmDJA/300?wxtype=jpeg&amp;wxfrom=0"/><p>前段日子OpenAI推出的o1模型，以其提升显著的逻辑推理能力，引发了人们对它背后训练方法的热烈讨论。关于o1的介绍和输出结果demo，这里就不再赘述，大家可以去openai的官网上阅读（很短，读起来</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445261&amp;idx=2&amp;sn=a77fce570c1011ba22111625efcc3d4f&amp;chksm=bfcdb93f7193e0bbf4903b453aa0a972381fed714c86414928337639019c55ebf2bb4958d962&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 07 Oct 2024 02:12:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[还在“卷”长度？长文本模型真的基于上下文进行回复吗？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag2bO6GGCNvku2fdsq8nsPy8uMeHDr4zyjKIBUKibEHEPgdgF69EVp4CCOMa0CclNWhOUibUJJqiamcQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，随着长文本模型（Long-context Model, LCM）技术的突飞猛进，处理长上下文的能力已成为各大语言模型（Large Language Model, LLM）的核心竞争力，也是各大</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445261&amp;idx=3&amp;sn=d4ede8fee2936b1b0dd8bc1036f4b597&amp;chksm=bf7822b7c912c0ece1d68b5e7f2aa11cb74698d019c09078cadf31a6a468d9ded3221f3fedd5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 07 Oct 2024 02:12:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM模型量化】-官方教程-qwen官方教程v2.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdBNLaTxqVrRzg2mRJb209Vw8pcLKcXRCjwRXpVZOOqt3zl3BoW7JT1icsUjeoeu8eo8FQlfCI8sHicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>转载自qwen doc，: https://qwen.readthedocs.io/zh-cn/latest/quantization/awq.html https://qwen.readthedoc</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445261&amp;idx=4&amp;sn=24758ff0f49a7ed029d8cc961866b0b3&amp;chksm=bf48c4287386221cf7cb46a49d66e09a2cc2ad31e3b538c9521411a1b85a17dd018439c22d56&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 07 Oct 2024 02:12:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[通过负样本挖掘炼出更强Embedding模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/vtIvcrPJjh5LiaFLIwDO54vmUP5Jl1SLs5s9J80uLicT44xIShtxmic0pssX4cCz94gyfOKnrico0ibsfibHcgTWTyVg/300?wxtype=jpeg&amp;wxfrom=0"/><p>一句话总结：Conan-Embedding模型，旨在通过利用更多和更高质量的负样本来提升嵌入模型的能力。论文原文： https://arxiv.org/pdf/2408.15710研究方法预训练阶段:</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445261&amp;idx=5&amp;sn=3d5aa09aa3e052658427d4ab82f6ad10&amp;chksm=bfe60e649fab86a6d86ff59a2782a4706819650c3a9f836a2e178841f8052f967da44632a3a9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 07 Oct 2024 02:12:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[36岁当上985高校院长！女教授称“最强大的背景”是。。。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLmC7XupDBzUH8LCPfwV9VOkmrIdpPPaS6y46DIom0UAnwGvfGa8CSpdNGElb0NGzupQPRyEU02Zg/640?wxtype=jpeg&amp;wxfrom=0"/><p>转载自：募格学术 ｜ 整理自中国青年报、天津大学等一袭白色连衣裙，讲话坚定而有力。9月12日，天津大学2024年新生开学典礼举行，药学院院长刘秀云教授作为师友导师代表发言。图源：天津大学新闻网这位年轻</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445246&amp;idx=1&amp;sn=5a8f5b37607ba3b4807d222b56dbb229&amp;chksm=bf0570be6002d0213333561b73ffb6523b1f0e50a1537f327f0b33246c2061977fbc7542ebd0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 06 Oct 2024 06:45:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【文末赠书】内容透彻接地气的多模态大模型通识读本！国家队大模型紫东太初负责人王金桥力作]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLmC7XupDBzUH8LCPfwV9VOkTZ68QrOyHlcOF5gd2yAKgbObKcPU4DOsceK2kibJMo1TC00iaOBy74Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>--文末赠书--不得不说，如今的大模型应用只有具备多模态能力才更可能在这条赛道上脱颖而出，被更多人所使用！在人工智能的浪潮中，多模态学习作为一颗冉冉升起的新星，正引领着技术的未来。从ChatGPT的火</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445246&amp;idx=2&amp;sn=c32dfb91076d5850d1294eaa46a4aee3&amp;chksm=bf85b0c8ccd0ddda16ee2fc5bb25522d7ce7e7347070510cd5cd4436640fb682243003d2d211&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 06 Oct 2024 06:45:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多模态大模型: 盘点&amp;Highlights part3——Gemini系列]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jT5Sp7MICPyhqhSGTqefbv3CtwPZCGJRlt35WYuzPmicHeytQ9qeYWe01wPavHcwU6DYgxABX4jkZ3AoZIjosCw/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言Hi大家好，我叫延捷，是一名计算机视觉算法工程师，也是叉烧的老朋友了。我们计划发布一系列关于多模态大模型的文章，帮助大家快速、精准地了解多模态大模型的前世今生，并且深入各个多模态大模型领域优秀的工</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445246&amp;idx=3&amp;sn=6bcc26cdefcd923ed3c245fe40e373ed&amp;chksm=bfac0979634c8d4697b6497048b0941f4ce49ee7f8b397dc1b29e34a85b74aa6d7ee9f44be5f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 06 Oct 2024 06:45:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM模型量化】-官方教程-hf-Transformers官方教程v1.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdBNLaTxqVrRzg2mRJb209Vw8pcLKcXRCjwRXpVZOOqt3zl3BoW7JT1icsUjeoeu8eo8FQlfCI8sHicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>转载自：https://huggingface.co/docs/transformers/main/zh/main_classes/quantization量化 🤗 Transformers 模型-A</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445246&amp;idx=4&amp;sn=6600ff888bb5ed5fb42c29889aea0ace&amp;chksm=bf5c6dfea8d55f290004e923ca6f51cab3da0c303c26aab8be8584016705e566ee09d062b335&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 06 Oct 2024 06:45:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[KDD Cup 2024 Meta LLMs RAG挑战赛冠军方案开源]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/UkaMPMaoibmia9olzZnRkTqRbCl1QqBrwF3rGeAueJhs3BS742rjrU9KazYlbu1ibNn7XJmKnnKic2KvibCZcFpcZfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>先介绍下赛题：赛题背景研究表明，GPT4对快速变化事实的准确性通常低于35%。LLM（大型语言模型）基于AI代理可能出现幻觉性回应的频率取决于多种因素，包括训练数据中的偏见、缺乏上下文理解以及知识表示</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445246&amp;idx=5&amp;sn=8c3c96f34c54a1e49eab18bf6c7a6500&amp;chksm=bf41319a721a1fbf381a23ba1ac817551fd3fd68575e490802a680db397e73b840c26ca8369c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 06 Oct 2024 06:45:34 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
