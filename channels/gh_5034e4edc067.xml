<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    


























    <item>
      <title><![CDATA[Llama 3.1 震撼开源，大模型微调我已经上手了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSI8J4fXb0ka0WNEafzVDApBMVH9QSBNG5XLCBLj9s7HDABEgCVKzPAlYMwls592TPl169JBmbhyzQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>上月，Meta宣布推出迄今为止最强大的开源模型——Llama 3.1 405B，同时发布了全新升级的Llama 3.1 70B和8B模型。最近出现了一系列令人激动的开源大语言模型，伴随大模型一起爆火的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444095&amp;idx=1&amp;sn=5dbc263e3c8ed9765a0e857021dfedc4&amp;chksm=bf40fc2362551d4296144305a4e9f55584177a7bc0166b421504c996e943918d41a7ca6186fd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 12 Aug 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[算法工作5年经验分享：形成通式和突破定式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jT5Sp7MICPxJKLvoiapuBw3AK4WorFqNzMuOqvpZEPicNkwFXrpFLCvDXXA4fxwHa0ELZoLURzXGDxCGLMWib8hUQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>这个系列好像还挺受大家的欢迎，大家想看我的成长思考，而我自己也挺喜欢定时地回头看自己的成长情况，审视自己目前的短板和问题。先说说我这整年的情况技术进步大模型技术设计能力工程开发能力小结形成通式和突破定</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444095&amp;idx=2&amp;sn=a3a4cbda8d84cd833af7bdcddb5cedd2&amp;chksm=bfe58686419cd6aa37fddbc8fb212c877e667104a7083020f3aa8e5fd73f388ba3798387a570&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 12 Aug 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[LLM之Agent落地篇]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgwE1Ww48ORSXbXB5CBFSPeickM3LCg7a3aiaMo13f0Oy4kSyfqe3YmPYQlX9HtXYf5qNeH5k1nrjFicQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言继之前的两篇文章：LLM之Agent初探[2] LLM之Agent再探[3]前面两篇文章主要是介绍了如何用LLM做个Agent的Demo，离实际的落地，还差了一大截，这篇文章就来讲讲Agent该如</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444095&amp;idx=3&amp;sn=89ad64ea8d9f072244642e6dabf99900&amp;chksm=bf412c8766e3d862cb3eac7d13c5ab6569db51ca944ebefd2a520aa95242d5edbe10af617d51&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 12 Aug 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[ACL2024 |解释引导的大语言模型主动蒸馏：一种优化知识转移的创新框架 "ELAD"]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gTSf9kr5zrOotkXrSlBPefolBRpQzofMVZGibd6FWMicypicVeD8wGabibx61ghVPEm4V4xAtHMoXtpticy3OxhmiaYw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天分享一篇ACL2024关于LLM蒸馏的文章，来自Emory University，题为“Explanation-Guided Large Language Models Active Distil</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444095&amp;idx=4&amp;sn=b2d3552024ae94795dcc153fec1a9bb3&amp;chksm=bfa08ff6890cc278075c842d70e74bf150a30add99dc64e81b04a7c30ea90ba0ce9f27f0763c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 12 Aug 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[用AI察觉AI生成的文本（2）验证检测能力的不同场景]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/MwhqibymFECG188C6N0NVGbv8spCzQszfOabfI5eicw34cDpURFkHoiaf1jicIxLwYJh1m5oxxb4nqCcv0MGMEniczA/300?wxtype=jpeg&amp;wxfrom=0"/><p>用AI察觉AI生成的文本（2）Use AI to Detect AI-Generated Text (2)“特别鸣谢（Special thanks）：在读论文的过程中，有几小点疑惑，所以当时请教了论文</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444095&amp;idx=5&amp;sn=3d64c7b7286491729a54a192d78ce6c2&amp;chksm=bf459e95a7d1179811e9155117884734726a90379b549a35e741c2fa20d280687de9b76ca96b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 12 Aug 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[菜鸟补发全员年终奖。。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/icmWrEONNM8XXuAfGhZgP9qtv3L3ib4fbSdBYW3HbeD0jA3YzCL5C41ptt2Pgw26MbcsO5CZhK2MsJrloT63AMQA/640?wxtype=jpeg&amp;wxfrom=0"/><p>阿里旗下的菜鸟集团，发布全员信说，宣布给所有的员工多发一次年终奖，注意关键词，所有员工。这是对菜鸟冲击IPO失败的一种实质性的补偿。IPO可以说是很多打工人辛勤工作的原动力。作为阿里旗下的子集团，里面</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444072&amp;idx=1&amp;sn=5ae691689e709f01ae652caf6d94dce2&amp;chksm=bffbcc1d09a9e2fb951d4c0dfab3e56748d80c8dac73b9eb214cef8fa8694731a0dcbf816805&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 10 Aug 2024 15:18:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【文末赠书】AIGC时代程序员的跃迁——编程高手的密码武器]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSI5NOw3QY7TpU0Rp07qTcbLj3QhbcG4Y25g9e7mg2MDHOq7sMBy4UFQdhbULQNMSE98pAxyIfiancA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在这个迅速变化的时代，AI技术已经渗透到我们生活的方方面面，尤其是在软件开发领域。我们作为《AIGC辅助软件开发：ChatGPT 10倍效率编程实战》一书的团队，也是在实践AIGC中积累了大量的经验，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444072&amp;idx=2&amp;sn=1b591d6647f00b7508c93e0ba705ecaa&amp;chksm=bf64df61120311573fdb7ba5f9f37ffc0e3cd9602b34275756b53aae7b68ced86d7e482c6565&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 10 Aug 2024 15:18:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LEARN：百川大模型在快手推荐中的应用]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/DHibuUfpZvQetI0JKGK39O7wTNrKAv2PueBnnQEhvKvPqOpr5MNne0loHN9GfLx3YoCcfOYUctP08QHVDXvMPTg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者 | 冯卡门迪 整理 | NewBeeNLPhttps://zhuanlan.zhihu.com/p/705497209这一两年推荐的论文工作离不开冷启和长尾问题，就像过去几年离不开序列和多目标一</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444072&amp;idx=3&amp;sn=ef2a4d2c25a32d07bd10e270c70ae2ab&amp;chksm=bf89461e2a53a47d9bd0e951bf0536c9eeadb4367e98d5aac3bb90d6a6388db89c928f4d00ea&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 10 Aug 2024 15:18:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NuminaMath 是如何荣膺首届 AIMO 进步奖的？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2qNF5MCTaWiajlM0WSPFvcPicOoaEw8GYA6l9riaXtxE0JkKmzFzbwTy5ibziccYjcEtgLw4v0IejqYu8g/300?wxtype=jpeg&amp;wxfrom=0"/><p>今年，Numina和 Hugging Face 合作角逐AI 数学奥林匹克 (AI Math Olympiad，AIMO)的首届进步奖。此次比赛旨在对开放 LLM 进行微调，以使其能解决高中难度的国际</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444072&amp;idx=4&amp;sn=b93a12c4db10922a813724d2dd5f6762&amp;chksm=bfdb85abf64d10c4eb3bc7e1e79ac4ebd7dd460ba154cf4a08822a29331c42a61bb10ef7d5e3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 10 Aug 2024 15:18:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[没有等来Qwen2.5，但等来了Qwen2-Math]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5nUZP2Z6sNhMm0353ajsgQOrPdfT1Z3iaeicEdiccTSexwJqOjxsmvP8vQZcmrLiaGudE2zOVaJ39oxOA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Qwen2又出新作Math大模型，你值得拥有。我没有等来Qwen2.5，但等来了Qwen2-Math，在数学推理能力上大幅度提高，先来一张图阵阵场子，72B模型超过GPT4-o、Claude-3.5-</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444072&amp;idx=5&amp;sn=340392a3e3d97530a44fd567ae64a799&amp;chksm=bf5cbfaf929b069e2744755d058d872f0f5b63e76814f119071e92bfa9c051e0a4e6bb1b050d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 10 Aug 2024 15:18:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[独立中顶会，从读博就业无门到一举成名!]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJ06zOTMewNveRMXJjyoAMJhNaPcEOhyqTgasib4SIoLGYKCF4ibogiar9wQ5SOPQ5JSSh5VXqpUYN8Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家是不是都感觉写学术论文真是无从下手啊！写文章之初最难的是找到一个不错的idea，这是非常重要的。这个比写作难的不止一点，如果你有idea的话写起来其实挺快的。主要是多看领域内顶刊文章，模仿别人文献</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444034&amp;idx=1&amp;sn=95070b56b8e2e2193f7dd5bf70e5130d&amp;chksm=bf2cbd5c8fe6c5480430c6b2874953aa5afbe3f825a1ee5a8c56f7c9ba02734840f40a3819d3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 09 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen2-Math开源，包含1.5B/7B/72B三种参数规模的数学模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/JrHT8u594NG3WIafcOXx2F9xFbdZM6MicuPhtxcKjrgCUic27ORvHa5p53bCRtdvMBL2070ibBWALeyATXfk8N4HQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>01简介🎉好消息，继今年6月份Qwen2系列模型开源后，Qwen团队秉持着优良的开源传统，在8月8日深夜再次开源了Qwen2-Math系列模型。这是一个专注于数学推理能力的模型，该系列模型包括1.5B</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444034&amp;idx=2&amp;sn=a191f7d22de2c0862d4995343dbe77a2&amp;chksm=bf94575f240e4c58ba4b1fca8c399957cbb8c6ef89b0af7ce41308a9276a26eb1447468a2cca&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 09 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[联想子公司联想诺谛招聘大模型实习生]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKlBJvibibFiaN0S35iaWMNrVBQQxYrEs0MCbFcAJ6ePqHia8wnN40AtR62dJSlRbtVHG0ncLTYiaHlaciaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>联想子公司-大模型实习生 于 联想诺谛 in 北京团队背景：联想子公司，团队来自于联想研究院。负责支持公司内LLM相关业务需求，主要研究LLM在RAG、TOD、KBQA、Search以及Agent场景</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444034&amp;idx=3&amp;sn=4c74b2347f8fed1f7237a35fe186a92a&amp;chksm=bfc51d4f7953979e4800b8200263b938ae6de615c45180f553e543263cbba10053131c59f6a5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 09 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM数据工程】LLMs-开源数据-微调数据集总结v2.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdDx7ZfWcq5DowcYgLzMeHyxtEpYDEMFOYYIFwjvKU1WuLngNVllOhtnEOgs1P6d41nYCQibKKTGopA/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM数据工程第二篇，介绍共40个开源的通用微调数据集，医疗领域微调数据集。【@】微调数据集目录中文微调数据【001】BelleGroup/train_3.5M_CN【002】fnlp</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444034&amp;idx=4&amp;sn=3e29ab08a99e5fea2a6f4139f3210288&amp;chksm=bfedf0f92de35c424bc8bc7a271bae42eac86bd663d1cff1345271e964f0a19c9c163efbe289&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 09 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM &amp; RAG &amp; text2sql】大模型在知识图谱问答上的核心算法详细思路及实践]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGDfXX3zXexdufdE4RQDAwicBkiahxQ9vJSCMDiaCe3ChUialCmyEPpLs7YJEakibmgawqZHBsFzJXSmgxA/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言本文介绍了一个融合RAG（Retrieval-Augmented Generation）思路的KBQA（Knowledge-Based Question Answering）系统的核心算法及实现步</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444034&amp;idx=5&amp;sn=02d06854f3c21c2e714d7e203418fb0c&amp;chksm=bf5d71c31981968ac58ed593d8be73efe6dd9e7b53593e587c5638e5996cb2c302b611020624&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 09 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型落地实战指南！！！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLm4fQROpCe4NcOessS3leM209AiaThAYlve2CRnRtTLNmB81rlBymFBwTHwX9eFpHth9W6k1LgHTA/640?wxtype=jpeg&amp;wxfrom=0"/><p>根据《2024 年全球人工智能行业报告》最新的数据显示，全球 AI 市场预计将以每年超过 40% 的速度增长，到 2030 年市值将达到数万亿美元，这也是预示着在接下来的十年到十五年里，人工智能将获得</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444018&amp;idx=1&amp;sn=32c4c3353db84865cfac4a12f89428de&amp;chksm=bfd4eb259c33e372f98dfab9985e21e16f42f54dea4241ee0370ca3d8569b761ab089c54c1b9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 08 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型微调到底有没有技术含量？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5mfAIrW8ue81Nswicmj2An0IlFbtbLWvaQQ12Q1ic5iboQUIQyIxcZW6ib2WFiczAZDichjhFY7ic1qkeM0g/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来知乎好友@ybq的一篇回答-大模型微调到底有没有技术含量，或者说技术含量到底有多大？知乎：https://www.zhihu.com/question/599396505/answer/</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444018&amp;idx=2&amp;sn=fc9efc533ed84b7e825c3892f857fb2d&amp;chksm=bf46c019b701ca930b7b9808ec059f261e7fcd9d9a5b635171879570b7871fa24bd24505db2b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 08 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型Agent的核心还是prompt？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/goiboxqfW2fbY4iaA65HsCZFQP1jgDWzME1NP9icPR1SFjF0zzB3TPhm1HJSf25PHJfLSeTm9suIN7YtXnuv5iaaicw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：摘星狐狸链接：https://www.zhihu.com/question/628670548/answer/3563803799来源：知乎先说结论，大模型Agent的核心不仅仅是prompt，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444018&amp;idx=3&amp;sn=2a5e7e8a074582ef0893bf25fb7776a5&amp;chksm=bf02d4f63e67d3770a052941777fc791a57e74b9f9592280581e685e19e2463951e046dac4f6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 08 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[TransferTOD：利用LLM解决TOD系统在域外场景槽位难以泛化的问题]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Y5AJB71iahGZNlS98YlyUiaAdUWfOyL2icbNH9qt8XeO5erzFvmODHYGSG8KfJX5JASH0zo1aNN5dFbpUV6vGmPZg/300?wxtype=jpeg&amp;wxfrom=0"/><p>任务型对话系统旨在高效处理任务导向的对话，如何利用任务型对话系统准确、高效、合理地完成信息采集的工作一直是一项关键且具有挑战性的任务。目前的槽位填充数据集大多服务于用户主导型系统，往往会局限于预设好的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444018&amp;idx=4&amp;sn=682e05f7ec109e49efd493df955dee14&amp;chksm=bf24f874a152fd49a951ca6fe17936369fc07fbeada15dd8faac5cfd9205237d83bc0c793c69&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 08 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[用AI察觉AI生成的文本（1）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/MwhqibymFECG188C6N0NVGbv8spCzQszfOabfI5eicw34cDpURFkHoiaf1jicIxLwYJh1m5oxxb4nqCcv0MGMEniczA/300?wxtype=jpeg&amp;wxfrom=0"/><p>用AI察觉AI生成的文本（1）Use AI to Detect AI-Generated Text (1)“如果需要这一系列或者其他文章的PPT可编辑源文件（免费），私信发送“获取”即可。To req</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444018&amp;idx=5&amp;sn=01e09a7d335ba1c5ed413317f032505f&amp;chksm=bf2c95cd48fd6f2e28947b0201f9823d8999d6f930d08a81a76420f7669ace3765e9f9aeac07&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 08 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[不再大海捞针！Loong：贴合真实场景的长文本评测基准]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLm4fQROpCe4NcOessS3leMNWI9icKAcmCPObmfMvibTtGdWW9hpvwJbEQhkDLibx6d0BxPvhjDBMuRw/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文标题：Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA论文链接：https:/</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444007&amp;idx=1&amp;sn=168629b2788b20889b40a8dc9c4d9cec&amp;chksm=bf7ac2b818a8db79cd5096a6f7f969d676b13221ee3b8d6573bfd6d6571702dd7cc72acfd171&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 07 Aug 2024 13:39:53 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM数据工程】LLMs-开源数据-预训练数据集总结v1.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdDx7ZfWcq5DowcYgLzMeHyxtEpYDEMFOYYIFwjvKU1WuLngNVllOhtnEOgs1P6d41nYCQibKKTGopA/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM数据工程第一篇，介绍37个开源的预训练数据集。【@】预训练数据集目录【001】Skywork/SkyPile-150B【002】togethercomputer/RedPajam</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444007&amp;idx=2&amp;sn=f390a62d6b841e9862cf1f8b07b51f9f&amp;chksm=bf7d7ebc4dda11320bde8a22890497f9c3c7ad8e553c579f56dcdb14b23cb98eb9fe7d5b9652&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 07 Aug 2024 13:39:53 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[浅谈-领域模型训练]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5mfAIrW8ue81Nswicmj2An0IlFbtbLWvaQQ12Q1ic5iboQUIQyIxcZW6ib2WFiczAZDichjhFY7ic1qkeM0g/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来知乎好友@ybq一篇关于如何进行领域模型训练的文章，主要内容是对 post-pretrain 阶段进行分析，后续的 Alignment 阶段就先不提了，注意好老生常谈的“数据质量”和“数</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444007&amp;idx=3&amp;sn=7e0b8d7dd5319a3fd8b3df9add586a9c&amp;chksm=bf7367523e1647fbeb0769171fcd89e89ab50321bb7bbd5ba0abc4020ca2cd7bfe90155f7d8d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 07 Aug 2024 13:39:53 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM &amp; RAG】英伟达“ChatQA 2”训练策略概述]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGDm5RfxnTBlNxwulW9T8cpdKauTShR9RLANjbga2WBrhBnwslr7FBBOOuLyibP1nbGicKKcic3W8nibqQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>训练ChatQA 2模型的策略为了构建能够处理长上下文并具备RAG能力的模型，训练过程设计为三个阶段：1.1 扩展上下文窗口至128K初始步骤是将基础模型Llama3-70B的上下文窗口从8K扩展至1</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444007&amp;idx=4&amp;sn=eee3957eb376915abdddba12d01b388a&amp;chksm=bf6d648cd9276b44be1c70caa9d25522ecf8cef94e585c0b3a8a7697cf41096ed0e93f718dcd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 07 Aug 2024 13:39:53 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型算法题(9)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW465xsk5KW4DWoKFWlmVumN0edcpuquPMsVWJRbHL9P42UCZabKmTaxtwYxqQDHhW8q5SXibeoLOO0lg/300?wxtype=jpeg&amp;wxfrom=0"/><p>本系列将持续整理一些LLM中关键的、细节的、值得关注的内容，持续更新~如有错漏，欢迎指正~1.大模型训练过程中有什么可以缓解显存不足的办法？（1）模型结构：使用LoRA、adaptor等训练（2）注意</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444007&amp;idx=5&amp;sn=d499c07054d6c77226b17de95fbb6ee1&amp;chksm=bfcaafd3929f0e6a65e30dc467bf3f7cc073b60bc506821c38b91849b3140d60cf559612b9a4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 07 Aug 2024 13:39:53 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
