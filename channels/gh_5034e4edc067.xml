<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    



















    <item>
      <title><![CDATA[大模型最热方向：LLM-Multi Agent 来了！！！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLmC7XupDBzUH8LCPfwV9VOKaMibjhXcoJJlcoibBsticpMK6XOKlcKmAbplvEB9jqS2X6ExpH4Icseg/640?wxtype=jpeg&amp;wxfrom=0"/><p>大语言模型(LLM)2024年火出圈了。然而,单一的LLM在处理复杂任务时往往力不从心。多智能体辩论方法应运而生，它通过模拟多个智能体之间的互动，提高语言模型在事实性和推理能力方面的表现，有效缓解了单</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445261&amp;idx=1&amp;sn=01eb66f15725a462cebec66a0d40d1c3&amp;chksm=bfeebb885ab5438fc93723702f03387b012cc5f43f77c184ff44c23cec17955acd5d920a8e98&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 07 Oct 2024 02:12:44 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[OpenAI o1 技术初探1：整体框架，利用Test-Time Scaling Law提升逻辑推理能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkOibl50lXj5CZaPDGGkyRVkMGRaftWsjfl9b06ZjicQ5Wyh1Yx0whWJ0Rxu5WHteSsPLCiaiaxHWmmDJA/300?wxtype=jpeg&amp;wxfrom=0"/><p>前段日子OpenAI推出的o1模型，以其提升显著的逻辑推理能力，引发了人们对它背后训练方法的热烈讨论。关于o1的介绍和输出结果demo，这里就不再赘述，大家可以去openai的官网上阅读（很短，读起来</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445261&amp;idx=2&amp;sn=a77fce570c1011ba22111625efcc3d4f&amp;chksm=bfcdb93f7193e0bbf4903b453aa0a972381fed714c86414928337639019c55ebf2bb4958d962&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 07 Oct 2024 02:12:44 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[还在“卷”长度？长文本模型真的基于上下文进行回复吗？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag2bO6GGCNvku2fdsq8nsPy8uMeHDr4zyjKIBUKibEHEPgdgF69EVp4CCOMa0CclNWhOUibUJJqiamcQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，随着长文本模型（Long-context Model, LCM）技术的突飞猛进，处理长上下文的能力已成为各大语言模型（Large Language Model, LLM）的核心竞争力，也是各大</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445261&amp;idx=3&amp;sn=d4ede8fee2936b1b0dd8bc1036f4b597&amp;chksm=bf7822b7c912c0ece1d68b5e7f2aa11cb74698d019c09078cadf31a6a468d9ded3221f3fedd5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 07 Oct 2024 02:12:44 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【LLM模型量化】-官方教程-qwen官方教程v2.0]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdBNLaTxqVrRzg2mRJb209Vw8pcLKcXRCjwRXpVZOOqt3zl3BoW7JT1icsUjeoeu8eo8FQlfCI8sHicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>转载自qwen doc，: https://qwen.readthedocs.io/zh-cn/latest/quantization/awq.html https://qwen.readthedoc</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445261&amp;idx=4&amp;sn=24758ff0f49a7ed029d8cc961866b0b3&amp;chksm=bf48c4287386221cf7cb46a49d66e09a2cc2ad31e3b538c9521411a1b85a17dd018439c22d56&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 07 Oct 2024 02:12:44 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[通过负样本挖掘炼出更强Embedding模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/vtIvcrPJjh5LiaFLIwDO54vmUP5Jl1SLs5s9J80uLicT44xIShtxmic0pssX4cCz94gyfOKnrico0ibsfibHcgTWTyVg/300?wxtype=jpeg&amp;wxfrom=0"/><p>一句话总结：Conan-Embedding模型，旨在通过利用更多和更高质量的负样本来提升嵌入模型的能力。论文原文： https://arxiv.org/pdf/2408.15710研究方法预训练阶段:</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445261&amp;idx=5&amp;sn=3d5aa09aa3e052658427d4ab82f6ad10&amp;chksm=bfe60e649fab86a6d86ff59a2782a4706819650c3a9f836a2e178841f8052f967da44632a3a9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 07 Oct 2024 02:12:44 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[36岁当上985高校院长！女教授称“最强大的背景”是。。。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLmC7XupDBzUH8LCPfwV9VOkmrIdpPPaS6y46DIom0UAnwGvfGa8CSpdNGElb0NGzupQPRyEU02Zg/640?wxtype=jpeg&amp;wxfrom=0"/><p>转载自：募格学术 ｜ 整理自中国青年报、天津大学等一袭白色连衣裙，讲话坚定而有力。9月12日，天津大学2024年新生开学典礼举行，药学院院长刘秀云教授作为师友导师代表发言。图源：天津大学新闻网这位年轻</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445246&amp;idx=1&amp;sn=5a8f5b37607ba3b4807d222b56dbb229&amp;chksm=bf0570be6002d0213333561b73ffb6523b1f0e50a1537f327f0b33246c2061977fbc7542ebd0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 06 Oct 2024 06:45:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【文末赠书】内容透彻接地气的多模态大模型通识读本！国家队大模型紫东太初负责人王金桥力作]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLmC7XupDBzUH8LCPfwV9VOkTZ68QrOyHlcOF5gd2yAKgbObKcPU4DOsceK2kibJMo1TC00iaOBy74Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>--文末赠书--不得不说，如今的大模型应用只有具备多模态能力才更可能在这条赛道上脱颖而出，被更多人所使用！在人工智能的浪潮中，多模态学习作为一颗冉冉升起的新星，正引领着技术的未来。从ChatGPT的火</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445246&amp;idx=2&amp;sn=c32dfb91076d5850d1294eaa46a4aee3&amp;chksm=bf85b0c8ccd0ddda16ee2fc5bb25522d7ce7e7347070510cd5cd4436640fb682243003d2d211&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 06 Oct 2024 06:45:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多模态大模型: 盘点&amp;Highlights part3——Gemini系列]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jT5Sp7MICPyhqhSGTqefbv3CtwPZCGJRlt35WYuzPmicHeytQ9qeYWe01wPavHcwU6DYgxABX4jkZ3AoZIjosCw/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言Hi大家好，我叫延捷，是一名计算机视觉算法工程师，也是叉烧的老朋友了。我们计划发布一系列关于多模态大模型的文章，帮助大家快速、精准地了解多模态大模型的前世今生，并且深入各个多模态大模型领域优秀的工</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445246&amp;idx=3&amp;sn=6bcc26cdefcd923ed3c245fe40e373ed&amp;chksm=bfac0979634c8d4697b6497048b0941f4ce49ee7f8b397dc1b29e34a85b74aa6d7ee9f44be5f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 06 Oct 2024 06:45:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM模型量化】-官方教程-hf-Transformers官方教程v1.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdBNLaTxqVrRzg2mRJb209Vw8pcLKcXRCjwRXpVZOOqt3zl3BoW7JT1icsUjeoeu8eo8FQlfCI8sHicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>转载自：https://huggingface.co/docs/transformers/main/zh/main_classes/quantization量化 🤗 Transformers 模型-A</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445246&amp;idx=4&amp;sn=6600ff888bb5ed5fb42c29889aea0ace&amp;chksm=bf5c6dfea8d55f290004e923ca6f51cab3da0c303c26aab8be8584016705e566ee09d062b335&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 06 Oct 2024 06:45:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[KDD Cup 2024 Meta LLMs RAG挑战赛冠军方案开源]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/UkaMPMaoibmia9olzZnRkTqRbCl1QqBrwF3rGeAueJhs3BS742rjrU9KazYlbu1ibNn7XJmKnnKic2KvibCZcFpcZfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>先介绍下赛题：赛题背景研究表明，GPT4对快速变化事实的准确性通常低于35%。LLM（大型语言模型）基于AI代理可能出现幻觉性回应的频率取决于多种因素，包括训练数据中的偏见、缺乏上下文理解以及知识表示</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445246&amp;idx=5&amp;sn=8c3c96f34c54a1e49eab18bf6c7a6500&amp;chksm=bf41319a721a1fbf381a23ba1ac817551fd3fd68575e490802a680db397e73b840c26ca8369c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 06 Oct 2024 06:45:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[知识链=知识图谱+大模型+推理-幻觉]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIFN058Yaa2kstdtAsDY4ueHoMibYs4V5WHcK1ic9gRHka4WFtWIhNlgCXNchgGDLNnO96CEf47j9OA/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近由华东师大和香港大学联合提出了一种面向大语言模型推理的幻觉缓解方法Chain-of-Knowledge被ACL2024接收为长文主会。PDF: https://arxiv.org/pdf/2306</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445225&amp;idx=1&amp;sn=9efb520e27d39e0934331e64ee54cde5&amp;chksm=bfc799b2c52069038eefcce5dc4dae8c9532502f8d9a89fcfff99ffb72eb99635511204f1404&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 04 Oct 2024 12:06:10 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[什么！SFT完全没用！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiawBZfF689rxSflI0IpicsL07icfq5k0VeN6veIhkicI4vGTgtkU1BT4XMK8oHlAe1ENjrp9vKKX4DyA/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：莫笑傅里叶链接：https://zhuanlan.zhihu.com/p/744847498Google Deepmind: Training Language Models to Self-C</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445225&amp;idx=2&amp;sn=39274f196dc8b67bfc91b467cae48f07&amp;chksm=bfac856dbd547c6a4d9ea4320659b9b49a78560f5deba818a951071195fd7e4d0d3a5995251c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 04 Oct 2024 12:06:10 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen招聘：让我们一起点燃这支大火箭！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/JrHT8u594NG5pmullG4zBQdvHxKINP4RldgMtYd1WHC9SzvwvUvQzSWDrqLZfN6GbBVGGl4Gp7MIibOL02WV3Vw/300?wxtype=jpeg&amp;wxfrom=0"/><p>这是一条关于Qwen整个大团队的招聘帖，下面将拆分为多个部分来介绍我们在做的事情以及希望和什么样的同学合作。01Qwen开源现状伴随着Qwen2.5的开源和发布，Qwen系列模型在全球的影响力进一步扩</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445225&amp;idx=3&amp;sn=09ebbb51a5da51f29d30e3c74b51ff04&amp;chksm=bf42f6c1805f34939f5dce77f094d46770048519f2b70a3648646116104eaece2c344a92b9d4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 04 Oct 2024 12:06:10 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
