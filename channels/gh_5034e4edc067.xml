<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    


























    <item>
      <title><![CDATA[自愿离职！每人补偿400万！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIOhRvhQUWzA5b3hHWbCQ7Q325j3NoicKsaNibwaw4W2w9pMtbOA0h7ZmbicIZNOyjXyQdiaw4cke152Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>8月13日消息，据外媒报道，英特尔在爱尔兰裁员补偿方案出炉，该公司向当地员工提供了高达50万欧元（约合人民币392.17万元）的自愿离职补偿金！据悉，该裁员补偿方案于近期分发给员工，要求员工在8月23</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444184&amp;idx=1&amp;sn=afc2a4c64d18f8a2588fc6ba7b4bc2fd&amp;chksm=bff911c4171f557de87a5e06d29c64d28ec0e5c287075a5c19612534ddcf7b39c9d85138a977&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 18 Aug 2024 13:25:24 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[没有大模型经验，面试官给机会吗？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuxCg4e5rBNd6QQmicUMSeqpxNia3GhV5XkFzZrUGGhJVFYD278hCiaFWCRxWialJWokG7xXMSvlhBeHqw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Author: [Quokka]Link: [https://zhuanlan.zhihu.com/p/715031517]做大模型一年半，经历了无数场面试。经验我最常听到的候选人（尤其是学生）的说辞</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444184&amp;idx=2&amp;sn=8891e8e779e64682e0607f77c9535a7e&amp;chksm=bf50eb5ac97a75840958cb27955622f150ec13e623f96757e368defb0d687ed5e359a0ae0740&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 18 Aug 2024 13:25:24 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【LLM模型微调】LLMs-数据构造-LIMA-论文总结v3.0]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdCT91b9RU0ibozJFEoIpaxRfMsx3JxbelRf1kYNyk7XUNAWvicrzGAYYFmziazmiaibHM0pemeZmrWusjg/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM模型微调第三篇，分享论文LIMA: Less Is More for Alignment的解读， 主要学习其中1k条微调数据的构造技巧。LIMA【1】LIMA相关论文LIMA论文</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444184&amp;idx=3&amp;sn=f8a245053ec233252a8877024177a270&amp;chksm=bf4b4367f67088dc00ce1aea3b7018e722354ee235caef720c61b72ae45e3e28ec51212ad36f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 18 Aug 2024 13:25:24 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[一个模型支持智能助手系统]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW467ic7Y20wZFeDrvicGnXd5REvhG7S2Tucwy1hbrD5rzIKVoicfsZ1JCDykEnicyo8ygVbBx5KIicsIBNEg/300?wxtype=jpeg&amp;wxfrom=0"/><p>这是一篇关于三四年前的旧项目的回顾。前一阵看苹果AFM端侧模型的做法，让我想起了前几年做的项目：用一个Bert模型支持智能助手多个任务。方便起见，本文后续就把这个Bert模型叫BFM（Bert-bas</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444184&amp;idx=4&amp;sn=c30e307027c6de32a57a6236cbde9de8&amp;chksm=bf92990ff8dbf9e5d59464bfb8596229e2791bd6ed34689d4d5759c79c785c182f55d159304a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 18 Aug 2024 13:25:24 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[用AI察觉AI生成的文本（3）验证检测能力的不同场景]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/MwhqibymFECG188C6N0NVGbv8spCzQszfOabfI5eicw34cDpURFkHoiaf1jicIxLwYJh1m5oxxb4nqCcv0MGMEniczA/300?wxtype=jpeg&amp;wxfrom=0"/><p>用AI察觉AI生成的文本（3）Use AI to Detect AI-Generated Text (3)“特别鸣谢（Special thanks）：在读论文的过程中，有几小点疑惑，所以当时请教了论文</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444184&amp;idx=5&amp;sn=7b7f7727020cb01ff566ddf24a02e5e8&amp;chksm=bf6d85cb4d22a496dfd2424ebfb506540bca3d76510031610dd5ec2fdfe014dfda85867b68e0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 18 Aug 2024 13:25:24 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[谷歌前CEO怒斥员工“每周只来一天”、“卷”不过OpenAI，遭争议后火速道歉！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLdnXWNxOqAlYA16ypEUoFmBDahib67HwTEIdjmYZbzicsVgmzkSZZTOxkKgjGpxwrZbMdhAmich1TKw/640?wxtype=jpeg&amp;wxfrom=0"/><p>整理 | 郑丽媛来源 | CSDN（ID：CSDNnews）本周，斯坦福大学发布的一则视频引起许多热议：谷歌前首席执行官 Eric Schmidt 声称，谷歌之所以在 AI 方面落后于 OpenAI，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444169&amp;idx=1&amp;sn=2777be98fb3dbde46c183172c2687c98&amp;chksm=bfc5294559932efd9c5b97bd239c313f2953160a159b9c5fb57811f5f0cf451e8e6933049d9b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 17 Aug 2024 14:27:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[留言赠书 | 大神李宏毅“机器学习”课程集结成书]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLdnXWNxOqAlYA16ypEUoFmYrye5RByYzuu4K6qgkMqxd6nL2GoP9ZneDUSJ6UOWbicl7uP3d067oA/300?wxtype=jpeg&amp;wxfrom=0"/><p>文末赠书GitHub上持续火爆的《LeeDL-Tutorial》项目，一发布就迅速获得了11.4K的星星！这个项目基于李宏毅老师“机器学习”课程，课程全网超过百万播放量，如今Datawhale新书《深</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444169&amp;idx=2&amp;sn=bf8808e1a838651df1b7684645f47797&amp;chksm=bf175ceec9710c8cf65176b201c999450535038748299b28417f08bc726befab9b3bd5cfdded&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 17 Aug 2024 14:27:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型 VS 小模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5k1msNBGEHgM7s4ibSp3iaUG5lxQLTiclRjibFs3NSZTq6wicGAj8ZBfMYiaMc3IU7mBVQpYzjJLUDt2Aibg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来知乎好友@ybq一篇关于大模型和小模型讨论的文章。首先，我们思考一个问题，为什么 qwen2 基本上是当下最受欢迎的开源模型？说实话，相比于 deepseek、llama、minicpm</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444169&amp;idx=3&amp;sn=23cd68a5082e6abd3f97da1be925b44d&amp;chksm=bfd41b9f39593f23b99d7e11d45ccb4ec07129d1d7b035f84b1961e7ad61281c25d2a5d528d4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 17 Aug 2024 14:27:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多模态大模型: 盘点&amp;Highlights part1——从BLIP到LLaVA]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jT5Sp7MICPzEw3c9CSxTcUYDCYUK2N4723Ye9ovykbATaRQ1k3lVKzyOiaD0yQmK4YowdmhSJRNicquQo2NyRic5A/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言Hi大家好，我叫延捷，是一名计算机视觉算法工程师，也是叉烧的老朋友了。我们计划发布一系列关于多模态大模型的文章，帮助大家快速、精准地了解多模态大模型的前世今生，并且深入各个多模态大模型领域优秀的工</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444169&amp;idx=4&amp;sn=a42f44ec56042e95421d9d409f940182&amp;chksm=bfce63339b1b1f7ac5371c4de5013ed94f1273a04f0ff500f359c7efc87d3d464ea25a4eb83e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 17 Aug 2024 14:27:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[phi系列模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW464vO6vLrOOpzgEVDnV6JMXTm9crR7NL3ZhNnn5AWB9VYic4kSppYECq4usxBCowcRbKJQAwLyZ4LIg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近在做端侧模型和数据合成的工作，微软的phi系列是受到关注比较多的一个小规模模型，整理一下细节，看看有什么可以借鉴使用的。1.phi-1phi-1包括两个模型：350M参数的phi-1-small和</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444169&amp;idx=5&amp;sn=6838089434c53da6613b446a4a113573&amp;chksm=bfa9f71c7e6c519bce97fe013b79ba603c45b6a22f3706178a8a6efd71a047c1fd313fe0fc00&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 17 Aug 2024 14:27:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[更高效的RAG文本检索和排序: 多语言GTE系列模型开源]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJD5g2Zyzt6Iian2Ugd7znLfjLkbZ0CKvtWx6zw3Fqg8mJMiavKjztGjib6FB0UafnXVgRn1iaNnVpyUQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：zyznull本文为投稿，原文链接：https://zhuanlan.zhihu.com/p/714602435背景检索增强生成（Retrieval-Augmented Generation, </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444147&amp;idx=1&amp;sn=4161fb8abbcc5283a4c33d26a7edc287&amp;chksm=bf66aa798522cf34dd940fa2281cfdbda28ac48c77f1d5645201ae8ae20ea7861a4de88c68f6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 15 Aug 2024 14:09:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM模型微调】LLMs-垂域微调-微调经验总结v2.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdARBPqic4HRewicFC1ke1QF24h1dlOzamcy7whMHR97fvrMD1sEJgWPrM2hvgU2xXsmB9t6FgpyFrAA/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM模型微调第二篇，继续分享一些 关于垂域模型微调经验的优质文章，供大家做微调任务时借鉴参考。【致谢】在此感谢作者的分享，如果有用的话，欢迎移步原文链接 点赞+收藏。【#】大模型微调</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444147&amp;idx=2&amp;sn=3d860e7177a70c20143834f5bbaddca7&amp;chksm=bf63a761fd0fed5ec34e62c4f7e5407211f5fcafe4cb8ccffbe0efbf85c4d6a33edbb4caf8f6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 15 Aug 2024 14:09:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Alignment下一站：合成数据]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/AzuXfeINxjVjauzc58GXbY1EtZ4YKVyYGJe5ZWkcKiarxDJpe4icQeCdSKWDBuMWNq9ZDOAzh9f90qyiapcWBAOLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>大模型训练中，数据质量已经是所有人的共识了。在23年开始接触Alignment之后，我一直是人工标注流派，深信InstructGPT[1]中所描述的，先train好标注员，再train好模型。那时候各</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444147&amp;idx=3&amp;sn=e79752948e0f489636705a3498631308&amp;chksm=bf9118e51f6fd1ff931eb9a9e977c522d3011ff05e714be4bd38f4f20c6a3d127ed1cb8425b7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 15 Aug 2024 14:09:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Sakana AI ｜AI Scientist爆火背后的技术详解以及优缺点分析]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gTSf9kr5zrMJZX8Dy7U5b4GmKg18v6WyuBia0iardHufVs8ltl2bB913VXEUuG7XpEEB497z5M7ZHktKNDQZZicGw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天分享一篇最近比较热门的日本创业公司Sakana AI的一篇文章，标题为《The AI Scientist: Towards Fully Automated Open-Ended Scientifi</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444147&amp;idx=4&amp;sn=b5bcf30ea6d3cfefa4fab6d923d4b82c&amp;chksm=bf4a48184cbfa61b68cd6b58d27557d62fd5482565820a3f75bf846940338c9eaf911fe9a404&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 15 Aug 2024 14:09:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[使用先验分布来改进语言模型的交叉熵损失]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/QLDSy3Cx3YJWDWJMqV2CI03Jb4xz6asEZ7vA0hn6ia9SI2UxlGGGItfSneppFlu7tfLZuyoAEFkYsz26JxxvfmA/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言前文（Language Modeling 中的negative diversity ignorance问题）中谈到使用交叉熵损失函数（CE Loss）来进行自回归语言模型的训练时，会出现所谓的 n</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444147&amp;idx=5&amp;sn=47c156b2e16f76f7db6dd0f36b88ce34&amp;chksm=bf72cbc7deb29c40f18244e85ba3c016dc2fa3a7cc900383c464211746a2edadc77497cda5d2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 15 Aug 2024 14:09:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型训推一体、多硬件适配，LLM时代的飞桨3.0新特性全面剖析]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLaUzdrS3micOd9OuEIC66RTyhhJsWF4Y0bGE3txELvFGEt78ibLKiaOfGiaibhTUAqx4KapcT15C2V2bQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习框架作为基础软件，不仅促进了深度学习技术的飞速进步，更为人工智能技术的广泛应用铺设了坚实的基础。深度学习框架为开发者提供了便捷易用的开发接口，这些接口对数据和操作进行了高度抽象，使得开发者能够</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444120&amp;idx=1&amp;sn=3e3594c2f64c98cabe8b751277faf11d&amp;chksm=bfd020aa111f00ae6d69839f5167cb943ea24cfe383db45a8bfb71f6277b6ca870363af9b28a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 14 Aug 2024 10:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[互联网大厂月薪分布。。。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLaUzdrS3micOd9OuEIC66RTAb2J2icIdI7Qap4R95eExwbLHDg7jaBCBZOictcOST4Vkf4lv4icYUPxg/300?wxtype=jpeg&amp;wxfrom=0"/><p>转自：菜鸟教程下面表格列出了国内互联网大厂月薪分布，包括字节、知乎、携程、小米、小红书、网易、腾讯、拼多多、陌陌、美团、快手、京东、华为、国美、滴滴、贝壳、阿里、B站、58同城和360。共有 8 个月</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444120&amp;idx=2&amp;sn=ad8046933f407f7e78614cfcdde5070b&amp;chksm=bfe97cfbdc2d38ec66852f007ee88e77f0fd86e5eb656b7dc79c1b306f20089b8b787bc085aa&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 14 Aug 2024 10:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型来自面试的体会和分享 2024版]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuzpyrVJ98spIZIqvCicxN4NGhdju7RFeAsrzOJnW5LzGqqfngQnic4url3L1kMdztQLACQYwbJHOp9Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>去年大概这个时候写了文章大模型来自面试的一些体会和分享，当时正值大模型的热情巅峰，市场上处于严重的供小于求的状态，一年过去了，情况有所变化，觉得这是一个合适的节点给大家汇报一下。大模型的赛道逐渐清晰，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444120&amp;idx=3&amp;sn=72f4fae61b56598f36824fef0ef5a0f4&amp;chksm=bf6a5fb5fb80d02814705c1321f0ae30cc42dc8b5581ee4b89329fc6e5991ffda60f99740086&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 14 Aug 2024 10:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM数据工程】LLMs-数据构造-Self-Instruct总结v3.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdAEcyKPjNQ1Zu2Z88KpmnZ5xbTTKqbFmDP2zjJ94jOH0IfCCEBJkqeMia6eWcTwFkeHrKlF4KWPjYQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM数据工程第三篇，介绍微调数据构造框架Self-Instruct的工作原理和具体实现。同时，介绍Alpaca，具体有Alpaca的训练流程、微调数据生成以及微调数据生成的代码解析。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444120&amp;idx=4&amp;sn=853755b5506fa60fe878f8a53d3c9d17&amp;chksm=bf0677dbaa8a103578a1c44db1323f15133734308cf55c45f4c0095171747f01b930cc58f163&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 14 Aug 2024 10:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【RAG】混合RAG系统，提升复杂推理任务表现]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGDdQL9CFBXmgnIIqVSibnQhEN4qvjYakauKkrP8PDgkxicThKamSodJ6ibibke7o1krtXqJb4ewMpkwNg/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言检索增强生成（RAG）系统在处理复杂推理任务方面展现出显著的潜力。然而，现有的RAG系统在面对需要复杂推理、多领域知识集成及数值计算的任务时，仍存在性能瓶颈。为了进一步提升系统的表现，本文提出了一</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444120&amp;idx=5&amp;sn=bd5c43989d5df2cbc17284937be0dec1&amp;chksm=bf6b084a3580c5f8c601c663de2c23066bc42cf5b2018c4380ed51bc6b121e7871153cbb6230&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 14 Aug 2024 10:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Llama 3.1 震撼开源，大模型微调我已经上手了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSI8J4fXb0ka0WNEafzVDApBMVH9QSBNG5XLCBLj9s7HDABEgCVKzPAlYMwls592TPl169JBmbhyzQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>上月，Meta宣布推出迄今为止最强大的开源模型——Llama 3.1 405B，同时发布了全新升级的Llama 3.1 70B和8B模型。最近出现了一系列令人激动的开源大语言模型，伴随大模型一起爆火的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444095&amp;idx=1&amp;sn=5dbc263e3c8ed9765a0e857021dfedc4&amp;chksm=bf40fc2362551d4296144305a4e9f55584177a7bc0166b421504c996e943918d41a7ca6186fd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 12 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[算法工作5年经验分享：形成通式和突破定式]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jT5Sp7MICPxJKLvoiapuBw3AK4WorFqNzMuOqvpZEPicNkwFXrpFLCvDXXA4fxwHa0ELZoLURzXGDxCGLMWib8hUQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>这个系列好像还挺受大家的欢迎，大家想看我的成长思考，而我自己也挺喜欢定时地回头看自己的成长情况，审视自己目前的短板和问题。先说说我这整年的情况技术进步大模型技术设计能力工程开发能力小结形成通式和突破定</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444095&amp;idx=2&amp;sn=a3a4cbda8d84cd833af7bdcddb5cedd2&amp;chksm=bfe58686419cd6aa37fddbc8fb212c877e667104a7083020f3aa8e5fd73f388ba3798387a570&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 12 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM之Agent落地篇]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgwE1Ww48ORSXbXB5CBFSPeickM3LCg7a3aiaMo13f0Oy4kSyfqe3YmPYQlX9HtXYf5qNeH5k1nrjFicQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言继之前的两篇文章：LLM之Agent初探[2] LLM之Agent再探[3]前面两篇文章主要是介绍了如何用LLM做个Agent的Demo，离实际的落地，还差了一大截，这篇文章就来讲讲Agent该如</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444095&amp;idx=3&amp;sn=89ad64ea8d9f072244642e6dabf99900&amp;chksm=bf412c8766e3d862cb3eac7d13c5ab6569db51ca944ebefd2a520aa95242d5edbe10af617d51&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 12 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ACL2024 |解释引导的大语言模型主动蒸馏：一种优化知识转移的创新框架 "ELAD"]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gTSf9kr5zrOotkXrSlBPefolBRpQzofMVZGibd6FWMicypicVeD8wGabibx61ghVPEm4V4xAtHMoXtpticy3OxhmiaYw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天分享一篇ACL2024关于LLM蒸馏的文章，来自Emory University，题为“Explanation-Guided Large Language Models Active Distil</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444095&amp;idx=4&amp;sn=b2d3552024ae94795dcc153fec1a9bb3&amp;chksm=bfa08ff6890cc278075c842d70e74bf150a30add99dc64e81b04a7c30ea90ba0ce9f27f0763c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 12 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[用AI察觉AI生成的文本（2）验证检测能力的不同场景]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/MwhqibymFECG188C6N0NVGbv8spCzQszfOabfI5eicw34cDpURFkHoiaf1jicIxLwYJh1m5oxxb4nqCcv0MGMEniczA/300?wxtype=jpeg&amp;wxfrom=0"/><p>用AI察觉AI生成的文本（2）Use AI to Detect AI-Generated Text (2)“特别鸣谢（Special thanks）：在读论文的过程中，有几小点疑惑，所以当时请教了论文</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444095&amp;idx=5&amp;sn=3d64c7b7286491729a54a192d78ce6c2&amp;chksm=bf459e95a7d1179811e9155117884734726a90379b549a35e741c2fa20d280687de9b76ca96b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 12 Aug 2024 02:10:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
