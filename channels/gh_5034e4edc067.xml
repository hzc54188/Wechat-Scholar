<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5034e4edc067.jpg</url>
      

      <title>gh_5034e4edc067</title>
      

    </image>
    























    <item>
      <title><![CDATA[特朗普上台，第一刀再次扎在了留学生身上。。。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJS7qhNsT6qCjBDA3SLCPvov1d2nQGiaBrDkxYrbSJp3NibD1StCg2HGKNWKNw8bicewQyz3xlaEVWVw/640?wxtype=jpeg&amp;wxfrom=0"/><p>还没正式上任，经验丰富的特朗普已经开始布局了。业内人士分析：结合大选后的一系列动作，“准总统”特朗普的系列动作可能已经箭在弦上。关于“大幅调整美国移民政策”的前路，也已经基本清晰，大概率要有大改革。美</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446077&amp;idx=1&amp;sn=d50b13aa52ebef2ee01f8741161ee603&amp;chksm=bf652920e726d60cf4be7ec27673df1eae2e6984982ae44037777833a609e2f53b1d3a3178b6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 23 Nov 2024 13:40:54 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[探索 OpenAI O1 模型复现：从 Kimi K0-Math 到 DeepSeek R1 Lite]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagYMeVbsIFQQ9miatD9Gic6xTm9QhyGESWYBJemg1F8kiaEqPP8oul8sJjicxMuD5BZBc6PCZuic607wpA/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：初七123334（已授权）地址：https://zhuanlan.zhihu.com/p/8102196012最近，随着Kimi K0-Math和DeepSeek R1 Lite模型的发布，Op</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446077&amp;idx=2&amp;sn=d0832754ad2f5c6fb01617f19a6f1657&amp;chksm=bf74e77e39f9c5ef21b0e3c0da2692916bd297a9e46af352abbb0b3cfcdf592d0b13492ddca2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 23 Nov 2024 13:40:54 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[阿里云大语言模型算法研究实习生(base杭州，可直通秋招转正)]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJS7qhNsT6qCjBDA3SLCPvoRE9icK7SGIegtGkc5sILMkwwhwkRY590j3PbvfdzvHUrCveMic2iaKaWw/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里云大语言模型算法研究实习生(base杭州，可直通秋招转正)我们是阿里云人工智能平台（PAI）深度学习团队，专注于人工智能算法及框架开发，我们团队在深度学习各大方向都有很多的研究和算法创新工作，在顶</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446077&amp;idx=3&amp;sn=1089a3cd2f14f4eff9e8988fc28b0190&amp;chksm=bfb7c735b58685a7289d23b3dc874bc55e54a99798b3b1eeed34872ffb79e00f4b933a23210b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 23 Nov 2024 13:40:54 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[LLM实践系列-详聊OpenRLHF中的各种Loss]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5mZ5ljdNGNXWYMRuYDvGFibggAmG8libojRt9O4FSVdknRAqhuA4uiaiauKvUCFlDFAtpZcyvtclzibMrw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家来带好友知乎@ybq关于OpenRLHF的学习笔记，主要介绍其中的各种loss内容。作者：ybq 知乎：https://zhuanlan.zhihu.com/p/6290579087从这篇文</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446077&amp;idx=4&amp;sn=2329567c9fbb4ae055b2a4e6358dd2b9&amp;chksm=bfc792d2efbeaeeca0706db90f410aeb88a9d9dc689bbabb6a1656affb34c64447da0b75b59a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 23 Nov 2024 13:40:54 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[ICLR 2025 多语言大模型相关论文速览]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/G7ia3FZ0o0OoHeZC4KTMkZrxzd9xYA6ibQfdqhL8CEYYlOBuFpKIuMcdPPLI4eW1rxWfXs67phKaApQ1bDExbXLQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>© 作者｜罗文扬机构｜中国人民大学研究方向｜大语言模型Dataset and benchmarkMMTEB: Massive Multilingual Text Embedding Benchmark</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446077&amp;idx=5&amp;sn=73ce5b06de4eb267a67322b53db798ff&amp;chksm=bf7d49c0366468451b0b51335914f28e9318a70f8cb9fc24f47ae16ec57b5430ba449cb853f7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 23 Nov 2024 13:40:54 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[深挖：埃隆·马斯克与OpenAI 分手内幕]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJgOicGfbopwGWdkGSwib5K8Lv4iaVdPw8Zzs9W7w9MEia0QdE2XFYwSG7PkhVYZBLoaN4tZtXw4EWwIw/640?wxtype=jpeg&amp;wxfrom=0"/><p>上午在微博上看到阑夕大佬的这篇解读，很有意思，推荐一下，感兴趣的朋友也可以直接看The Verge的英文原文：Inside Elon Musk’s messy breakup with OpenAIh</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446056&amp;idx=1&amp;sn=efc6f5ba84a48d3e025fc52bb49a41ba&amp;chksm=bfd99ad71200ca647ce30aa0c022857cd10d4f42f350a76d40f2d53fc6c44b4c951b3cd10c0b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 21 Nov 2024 14:57:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[王者归来！白皮书《从头训练大模型最佳实践》开源了。。。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLicqqqr1gllU6vbdichMgZyoia42QoMmWbldIU2pH06v2TvgZ6fuEMC5mumNfdHTOgOsaOqcIeTc9jQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>介绍《Current Best Practices for Training LLMs from Scratch》是由Weights &amp; Biases（W&amp;B）提供的一份关于从头开始训练大型语言模型（</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446044&amp;idx=1&amp;sn=502b991734e03e9b6708c9945dad5777&amp;chksm=bf3bbe608cc5fbe0a370d6a357ac10eec20402f49c5f427b7b2c0c7ab98398574a771e1609cb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 20 Nov 2024 02:03:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[FlashAttention 系列技术详解：加速大模型训练的利器]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/G7ia3FZ0o0Or0PE0VQ6SgHe8HKGOvUiaVmMCBuFSOV4uPRez7iaSSSmyRobvQiaOeEPMCcNOeEYspGgMBIM1THoG2Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>© 作者｜陈杰机构｜中国人民大学研究方向｜自然语言处理、大语言模型本文将深入介绍 FlashAttention 系列技术的核心原理、算法优化及其在大模型训练中的实际应用。通过减少内存开销和优化 GPU</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446044&amp;idx=2&amp;sn=15e295dc6389cc9cd2ca3c22623ed868&amp;chksm=bfa3e7ed08448c9fc3971203bd1e4a78b3fc89602c72572d94eb9f500dfb75be7da949e92628&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 20 Nov 2024 02:03:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[深度求索DeepSeek 系统方向核心研发岗位招募]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSInibbGYAXASFBGttPRAPUEvt2Diawypicwk8PYvubiaJmdSrla4e8KzcqAE7W1IBzBtChcwHkE7gxqIA/300?wxtype=jpeg&amp;wxfrom=0"/><p>工作描述：1. LLM 的成功是 AI 基础设施的成功，这是一个相当复杂的系统工程。每个成功的大模型背后，都有无数个从硬件到软件，从存储调度到算子编译器的极致优化故事，最终将这个模型的训练效率推动到了</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446044&amp;idx=3&amp;sn=61288acc441f99f314d8e7053f47271e&amp;chksm=bfc990648f2372f9f3731c7c261446dd77de91f1e2b51b7603f927ecfc60ca4cf7d436f839f0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 20 Nov 2024 02:03:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[对话语音合成大模型GPT-Talker: Generative Expressive CSS]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/C0j7wmyZGH6RmDIQmInVNDGSlv8LgooTRicW4ficMsG9N0LGnbaqxHWFhnSpsCqiarCicicKsOQoRTYXXfM7ic2FxYdQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>本次分享由内蒙古大学刘瑞研究员与字节跳动青年科学家任意、香港中文大学(深圳)李海洲教授合作发表于ACMMM2024的对话语音合成大模型工作GPT-Talker《Generative Expressiv</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446044&amp;idx=4&amp;sn=b98f7e24e67e3246e5f1178fac6f16d5&amp;chksm=bf4744bdbb57db89bf453c11dcd6c5fdde64c2a9f762e4478601d98644c282b519f497fc5a1d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 20 Nov 2024 02:03:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型也有侧脑？揭秘WISE如何带来终生学习新突破]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaHO0PdInkbhA7ppFsq7vqPkBazibwibnD5UCXNXiaicwk50icUTEKJOjhcqBx02icPRib3vaZ4HSaY97XQw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者: bhn论文：https://arxiv.org/abs/2405.14768代码：https://github.com/zjunlp/EasyEdit人类的学习能力是独特而强大的。我们不仅能够</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446044&amp;idx=5&amp;sn=b6fa4428f5b03c627f1f3f353e4e8564&amp;chksm=bf04bec4b19d7d00a989e1f1572c2f465a3d79233d36d595acc10184c32cdb0333b02f2e3cae&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 20 Nov 2024 02:03:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[打破多模态检索的瓶颈，OmniSearch实现智能动态规划！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLicqqqr1gllU6vbdichMgZyoWkcGodA6oTL2XLCxZxVBpYkHZFB7ywOs9DfibNSgW3Udv9n6ma1OCIw/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着多模态大语言模型（MLLM）的广泛应用，模型在理解复杂问题时经常会出现“幻觉”现象，即模型生成的内容与事实不符。多模态检索增强生成（mRAG）技术旨在通过外部知识库的检索来解决这一问题，但现有的m</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446032&amp;idx=1&amp;sn=aa5a26c598c9dffa9d80ce7e791ba09f&amp;chksm=bfe08ac77e81ac0847e76a573bb4bd6b3f1873b5403c966c3108a2c4c930deb733004c6b29c5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 19 Nov 2024 15:07:27 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型中上分技巧大总结！！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLHYFxh9h81c9I2fPxHjfia0kCibwVqTfXJicytW0lQBFFfXYocM8aj5lRcUSZib1h67vHGCEJQ3BRtlw/640?wxtype=jpeg&amp;wxfrom=0"/><p>这个文章与其说是上分技巧，不如说是刷分技巧~~~很多论文你看了看发现变动不大，但是就是效果变好了，可以对应着看看这个文章。我估计，都在下面的总结了。文章内容仁者见仁~~作者:  黄哲威 hzwer链接</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446018&amp;idx=1&amp;sn=e85f97dddb74dde6322aa0cf282454d1&amp;chksm=bfcc419547f737ae947003a64ba4a1ac2515ffe84bf372487072522387d25aab145c984ef23d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 18 Nov 2024 07:06:30 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[最值得参加的LLM盛会！多模态/Agent/具身智能/安全/评估等15个论坛！早鸟注册最后一天]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLHYFxh9h81c9I2fPxHjfia0DwKBdjkwictic6BV140TYYtghpRyO7Mdzeesw9CkVpZ3VI76Hn4TMicSw/300?wxtype=jpeg&amp;wxfrom=0"/><p>会议简介中国中文信息学会（CIPS）是中国中文信息处理及其相关领域的学术团体，大模型与生成专业委员会（LMG）是中国中文信息学会旗下的专业委员会，全国大模型智能生成大会（LMG）是该专委会的旗舰学术会</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446018&amp;idx=2&amp;sn=63df715c8aee0f0e7aec57948b85a0c3&amp;chksm=bf2c2ed5a6d4bef6f3919313d53f8a891529db828c36a6205cb7d7c5ec6962deb7bdceae0b88&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 18 Nov 2024 07:06:30 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2万字洞察Scaling Law的"终结"or"新起点"?——开源实践者的深度思考]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/yToxjhYT5ibb9Hy6qdvR9gcibt8ZeysozQw7iab7rJbPc9kicLGfdEAxSU5BVmW8nh37dRbm3FvTv0w1iafDIOVgycw/300?wxtype=jpeg&amp;wxfrom=0"/><p>| 作者：宋大宝，与大宝同学因那篇《回顾·总结·展望「融合RL与LLM思想，探寻世界模型以迈向AGI」》结识于今年春天，虽我们当时某些思想观念有些出入，也碰撞出了很多火花与共鸣，并持续地相互启发的走到</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446018&amp;idx=3&amp;sn=dfb727dd93399f4c8be1551b6af6a6e3&amp;chksm=bf4ae67bd5384706f7362c63af2d4097c6659de44b0ac6cdb828bc0b188d920aacd1476eff41&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 18 Nov 2024 07:06:30 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[训练数据合成(二)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW465zM1pOYlC9Gt4FCttlhz2ib1h6mraibl4s4fecscDavk1Vw97H2SfvibGLk6EUOBc9ysOicGBRjmATow/300?wxtype=jpeg&amp;wxfrom=0"/><p>书接上回，训练数据合成(一)，继续看一些重要的数据合成工作。1.self-instructself-instruct算是大模型数据合成的经典工作了，它的目的主要是为了低成本获得大量用于大模型微调的指令</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446018&amp;idx=4&amp;sn=afd4768ee01f5180b044b5dacef05ff4&amp;chksm=bf0eb610c92a9211775529c9484955772614b89bceaf527c2cb0e593a53b89455f59fbffed28&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 18 Nov 2024 07:06:30 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[突破长度偏差:Meta AI的LIFT方法让大语言模型更懂分寸]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hq9ANWCLRic1IWYzkjQ4jYkYaMK6XP8IUzbribMPphMV0HITZfOu7lDE5CN53d4FQ8ME8Yf7yhsy5VePZQYX0gag/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言在人工智能快速发展的今天,大型语言模型(LLM)的指令跟随能力已成为衡量其性能的重要指标。然而,一个长期困扰研究人员的问题是:这些模型似乎有一种偏好,倾向于生成冗长的回答。这种"长度偏差"不仅影响</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446018&amp;idx=5&amp;sn=1e27b6e3559231c84a9d46f815019573&amp;chksm=bf8bbf9f43d4cb7fd85d54d4901bee1747d749ad39773a1672d48e463c1d6288be408219acbc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 18 Nov 2024 07:06:30 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[校长书记双院士！教育部副部长，任C9党委书记！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLXBLtNe9OP5LQ69DJUkgV7Pvcicy0VtoDNZMibhND5ia5ujC2NextmLEic5DczC2fslwHmT0VYx7qz9Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>日前，中央批准：陈杰同志任哈尔滨工业大学党委书记。11月13日，哈尔滨工业大学召开教师干部会议。中央组织部副部长张光军同志到会宣布中央决定并讲话，工业和信息化部副部长、党组成员张云明同志，黑龙江省委常</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445994&amp;idx=1&amp;sn=ec7a85ecf4289d287e1440e9d21c5fe2&amp;chksm=bfb91da1db24b6579397c021d3d7b8e1559a912adcfc747458f2356b0603e43a45d0e666fc41&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 17 Nov 2024 12:42:25 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【文末赠书】专补大模型短板的RAG入门与实战书来了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLXBLtNe9OP5LQ69DJUkgV7QJC3MyYyNodArhJBzmoXGxGXkhV58nfW3K86U59QwsAOoLuYKoFLxA/300?wxtype=jpeg&amp;wxfrom=0"/><p>文末赠书RAG自2020年由Facebook AI Research推出后，一下子就窜红了。毕竟，它是真的帮了大忙，在解决大语言模型的“幻觉”问题上起到了关键作用。如今，Google、AWS、IBM、</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445994&amp;idx=2&amp;sn=a70950fb59839c173634ee604d699ea7&amp;chksm=bf4d3fd02f6163083e7b63ceb92d7a008c8f9139b085769661021270f838b8e11dec21664410&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 17 Nov 2024 12:42:25 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[人人都能看懂的RL-PPO理论知识]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkMyjq7MvIma1htP55lDYuSo2Z61FZWE0KJTnub7ev5jBJxibibnX7NhEqsVVdIY5HLic0Ldrc5QWqqCg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在去年的这个时候，我以deepspeed-chat的代码为例，解读了rlhf运作的流程。当时写这篇文章的目的，主要是想让读者在没有强化学习知识的情况下，能从直觉上快速理解这份代码，以便上手训练和修改。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445994&amp;idx=3&amp;sn=debe81f782e23315b6307de960e24a30&amp;chksm=bfef2cb400cc748d7f57093d2d62e90b47b55f0fa877d0e937a8e8d6c1d626823ae70b907543&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 17 Nov 2024 12:42:25 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[语言模型之text embedding（实战篇）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKpsxU3lqwnFAOjEHVCVRgJSfswPgElzVzFmuCiblpRiciaiaj8uhLtzAAwK8xSQTrYChzfD6ic8q8yictyuQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲1 简介2 背景‍‍3 基底模型选择4 使用方式5 训练方式‍6 讨论‍‍1 简介‍‍‍‍‍‍    在前面2年时间里介绍过数十种text embedding模型，虽然不同模型在MTEB这类ben</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445994&amp;idx=4&amp;sn=14b57f977649ab6271ce870533762cb9&amp;chksm=bf0271a820c763fc38ce1250804b868fc8ec4a9d219237053e6432df6462c5b7a797da3902e0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 17 Nov 2024 12:42:25 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024时序预测都有哪些经典工作——总结篇]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/dcUv9UF2OUWjxVWRjq6pChCocendQeDVAS9B679pPliayjTxgjoOtpXGtHqC3ibjDLoNRlEG0J4ySfNr4mSxmRGQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在这个系列里，圆圆会带大家梳理2024年时间序列预测领域的经典工作，涉及多个优化方向。在这一节里，会为大家整体介绍2024年的时间序列一些具有突破性进展的领域。后续章节将持续在知识星球中更新，深入解读</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445994&amp;idx=5&amp;sn=9d1c8bb5f0d1cfaa7af2538a5737e24b&amp;chksm=bfee7acf703fe830ac2e643cebe51be8b2522d692f8113ace5592f6233e4eda0d5717fc8429e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 17 Nov 2024 12:42:25 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
