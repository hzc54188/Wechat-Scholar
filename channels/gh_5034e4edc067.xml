<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    


























    <item>
      <title><![CDATA[某公司新招了个牛逼的架构师后.....]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL8T5cYQl9iaFneW3JuUQTqPOAot7xDtJYVctp5GqQW4bYeJ4rkf6XDWd9Af4ReKofkXm05wUicVgvw/640?wxtype=jpeg&amp;wxfrom=0"/><p>网友评论：@口袋FPV：架构师一个响指之后。第二天，老板不见了@妹_妹_奶_白_又_大001：走走停停 回头已是数月@NereusP：是我的故事没错了，本来我们组有10个人，我把代码重构之后，只要半个</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441630&amp;idx=1&amp;sn=4ac1322b6863b613c3317ea69b3b9b8c&amp;chksm=bf3edae8ac4fa0a70c5861c9eb485f019e457049f9a2eda3c203fe719d6338b06488f6133e34&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 31 Mar 2024 12:55:18 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【文末赠书】大语言模型训练优化秘籍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL8T5cYQl9iaFneW3JuUQTqPBkwQpK1rBXMlYgZXE60x0VsEicSt25RnYnicKPvlEkiavFGFQStPpGPbQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>--文末赠书--在了解大语言模型训练优化秘籍之前，我们先来了解一下大语言模型训练面临的挑战，以此进行针对性的训练优化。大语言模型训练面临的挑战随着模型参数量规模的增大，资源和效率逐渐成为制约模型训练的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441630&amp;idx=2&amp;sn=9b9687a0f0e377e1e1cf63abae3b4357&amp;chksm=bfa6155614369d0c48bb359bdc5556243eac775668e7a700450e4935c820194984d661643d21&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 31 Mar 2024 12:55:18 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[行动胜过言语: Meta落地工业界首个万亿级别参数的生成式推荐系统模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/TnZw73HawgnLpmXAjE2D989H5iaF24ebU900KTG4JKFmMiaOU7hcVu0p1xibf39iakICxpG4clM0oYyibpraKdjibAXw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天分享一篇Meta最新的工作：借鉴LLMs思路重塑推荐系统范式，实现推荐系统的scaling。该工作第一次在核心产品线替换掉了近十年工业界长期使用的基于海量异构特征的深度推荐模型， 在模型规模、业务</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441630&amp;idx=3&amp;sn=b9c302423a7b8903b40f7ded2c83b9aa&amp;chksm=bf11ba1141b52f49ce51b16909934e33597632cec3c64cfaaec6f6d83fc07454199feb91ddbc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 31 Mar 2024 12:55:18 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[平安科技语音算法团队诚招NLP实习生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL8T5cYQl9iaFneW3JuUQTqP3gZw4kkm1SQGHc5tKcZ0K1tWGyS8fjKqxSFocibeo40TcJ1gaBmpxvQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>平安科技语音算法系列 - Jianzong Wang团队诚招NLP实习生! 🌟📍 工作地点：深圳🔍 我们在寻找有才华、有经验的NLP实习生加入我们团队！团队亮点：✨ 已发表百篇顶级学术论文，覆盖NIP</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441630&amp;idx=4&amp;sn=3ab58365d767f8180e0fbd28da8fbb7e&amp;chksm=bfbfa3d5b82f152a4d0da508d0fff3a337c0f1e2c0248e88f8617e78a357f47c2b2f4c5d1be9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 31 Mar 2024 12:55:18 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[AICL: 一种可以主动选择demonstartion数量的ICL方案]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKpsvauRIcxtW0Fib9BLVj4AgEaaB0G6oK5Yw4gL3XGUFAKpxHb269xJCe2cm0oJqrc5lM9baJYTbsnA/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲1 简介2 Motivation3 AICL4 实验5 讨论参考文献1 简介    目前In-context learning会在大模型prompt输入中加入固定数量的跟当前问题相关的demons</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441630&amp;idx=5&amp;sn=44f6e3f0e83968d266593f5929d2dd6d&amp;chksm=bfc19e97d2fb343842beba0fbc8ec701baf71652651bedff5a8230d2b95fe026522ecf7c690d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 31 Mar 2024 12:55:18 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[图解大模型计算加速系列之：vLLM核心技术PagedAttention原理]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkOt2TOia57jHta5zCugcYw9mNg6T0ZC2Mx48zrQpgqlgDDq0W2SqzMgqYhdtk4BP3eLRmgKjaydlfg/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，今天想来介绍下当红推理框架vLLM的核心技术PagedAttention。PagedAttention的设计灵感来自操作系统的虚拟内存分页管理技术。vLLM的论文是在假设读者对这项分页管理技术</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441609&amp;idx=1&amp;sn=6a2fe681495539c7dec14fcbdeacedbb&amp;chksm=bfe7c834bb531beb5501ff350d8cceda21ef3ff4ebd6868772c793274535d7124f008e979f43&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 30 Mar 2024 10:59:27 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DBRX：重新定义开放语言模型的新里程碑]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/fI41EfAgQvsYFHGP7wyamxDMQdy6PndlTppyQVINJZ5zHrdeHHnTcrm679SFZ8tWaCbYZc17PBLSCAG4BLk2yQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>摘自Cameron R. Wolfe, Ph.D.的twitter🧱DBRX🧱是如此出色，以至于在过去的两天里，有3-4家公司被迫发布了“竞争”的LLM（我们几乎没有听说过它们）。以下是我对此的一些想</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441609&amp;idx=2&amp;sn=e5b58c260de63a9ffcfe66476747ff13&amp;chksm=bfde368ef4ed082e0f1700ec9f5734e08f3058aebf3789b024f5e4ed1bdd80c5dcb4d3ea30d6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 30 Mar 2024 10:59:27 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[融合RL与LLM思想，探寻世界模型以迈向AGI「中·下篇」]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/yToxjhYT5iba6cnqp9ShyFHpfAyISsBHjRibg9QCpiaSIXfUIGGibCWD3ibl8pq02JOQm5PicHTSfuUCXg8bllu6siajQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>本篇文章与2023年底尝试挖掘并探寻以chatGPT为代表的LLM和以AlphaGO/AlphaZero及当下AlphaDev为代表的RL思想的背后底层理论及形式上的统一，同时与最近OpenAI暴露出</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441609&amp;idx=3&amp;sn=af36b4550f795f8eb40dafa2bf2ecb44&amp;chksm=bf94460dc4e4d2ea4e20e6506fb86a4122bff78a30ce70281ceb37da7ed89ee2016ec0e6e9c6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 30 Mar 2024 10:59:27 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[复旦MOSS团队：数据配比的scalinglaw]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuw6Coc4OutPkaXT63GWVVuHm2yDk5iaYtI6jZs1zfLkzP6olxgn0lMPFVOKezCzIFxXaPryslab3XQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在前文我们提到过，大模型训练中数据的多样性和质量是最重要的两个维度，并且在结尾挖了一个大坑，希望有大佬愿意研究多样性的scaling laws。原文链接：大模型的微调数据选择技巧（三）大模型的微调数据</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441609&amp;idx=4&amp;sn=50daec080a80004aca22840d1e324094&amp;chksm=bf89c8b2947e1b5eb72b59043e822de71d7b278b9c3b8d1130313b608f08e57bd6a292464e7b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 30 Mar 2024 10:59:27 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Yi技术报告-划重点看细节]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW464a21JEWec9C3ttVRqNFLBia8MusJVHzRP5fyfaH7vHck1FhJTuKBiaMDlsiaW83MBYP7nY0SP0mKzbA/300?wxtype=jpeg&amp;wxfrom=0"/><p>01.AI（零一万物），是李开复带队孵化的AI公司。2023年11月初，01.AI发布并开源了Yi-6B、Yi-34B base模型，同一周内，又开源了Yi-6B-200K和Yi-34B-200K b</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441609&amp;idx=5&amp;sn=c2fcfc798976a724ba6a489af8aeb205&amp;chksm=bf497cb7c4ff9bf497f6d5a106fa16e10d6a50a1a3dd267f75f0a85c5be94eec0b2781c247e7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 30 Mar 2024 10:59:27 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[还是决定去小红书实习了!]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKXCWuFzcB7IcMniceF5dCdicibIy3WO3ic6ttfiaibTd0jCG3BHuNowiaBHzrBnCAibND9PAxuibeIgU7RAKw/640?wxtype=jpeg&amp;wxfrom=0"/><p>📢 小红书25届实习生招募火热进行中NLP/大模型/算法/前端/后端/客户端等超多技术方向岗位等你来!AINLP要来了专属内推码拿内推码可以优先筛选哦60B2Y2QM88D8也可以直接通过内推链接投递</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441591&amp;idx=1&amp;sn=4c66ad3a368a75b30866f50cc6d55ea9&amp;chksm=bfdfae0aa78c545f450004eb859ef22b674f505a2492f3e16673a205a368dd92655070a44d3e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Mar 2024 04:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen1.5-MoE模型：2.7B的激活参数量达到7B模型的性能]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5mjS1tvianwIk1Rcuic9sGH22UWLW1IGIPvlZnMa8iaNELLPkDxpAKibxibDVzPafCEMQWdOs6ReVrr45Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>Qwen1.5-MoE模型：2.7B的激活参数量达到7B模型的性能写在前面今天阿里放了MOE的模型，总参数量14.3B，具有64个专家，每次激活8个，在仅激活2.7B参数情况下，效果可以与Qwen1.</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441591&amp;idx=2&amp;sn=9cef61077e1751756fa3959bd72df9f3&amp;chksm=bf1f025f0e5a0d5adea27517ec53992280fab72b886c6e3717f30fba1186cfcc87f90f97862e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Mar 2024 04:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LoRA原理解析]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgz65reXkaewsAWUHiadHBiaZIrfa8p8lTWYjN3GoWPbkuHibppFnWXxLIrwBbYibbZpQkNXvUkwnoicRSQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言随着模型规模的不断扩大，微调模型的所有参数（所谓full fine-tuning）的可行性变得越来越低。以GPT-3的175B参数为例，每增加一个新领域就需要完整微调一个新模型，代价和成本非常高！</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441591&amp;idx=3&amp;sn=6905865a4474ef3a6422121bad9842fb&amp;chksm=bf7cdd090b33ac26ff89c8dc054a2693fd78dbaaa1c3e9714e8d4d509d38222d290a7f04f022&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Mar 2024 04:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[EMNLP 2024 征稿通知]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/EsDKszDSKDGShwibZciaDL2bxeooGiaD7ReHyhvLjibVf60cmPyibo1gbI4duhFgSlNagXVUn4Gq0B13XKuHkEWhicLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>计算语言学与自然语言处理顶级国际会议EMNLP 2024将于2024年11月12日至16日在美国佛罗里达州迈阿密召开。EMNLP 2024只接受ACL Rolling Review（ARR）投稿通道，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441591&amp;idx=4&amp;sn=e5be647d6105610f20211bcfb82adda5&amp;chksm=bfd3dbc273ddcd449b5961614133f156e1543ace7806e9d5c648e98b7a7bd20b1ee7f049762d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Mar 2024 04:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型数据之代码语料The Stack v2]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/s7YKINJYHDC9CFAicTSRD5jY2CduuMXTgd1Qup9ck8g7gxa3JgXXgHQrhR5kyBRxiaNpewTOdq0ArfbdFYOvoF3g/300?wxtype=jpeg&amp;wxfrom=0"/><p>与 The Stack v1 相比，The Stack v2 拥有更大的数据规模，采用了更先进的语言和许可证检测流程以及更优的过滤机制。The Stack v2有900B+不同的tokens, 是Th</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441591&amp;idx=5&amp;sn=8730d29e9002bde168603359d88c43f5&amp;chksm=bf111f1cc6ebde8e9c8f8bc32dda8f6d52ac38fa6c0a30555a5a4edac8cdb37edf715c2c805f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Mar 2024 04:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[50W奖金，校招绿色通道，确实可以封神了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKVy22NDn5JSJNWXsZKggQFJB5dLPjnSNreSuXnhsuJPy8MjnybBAQhZeldQFBYug0OgAHCNcibsMw/640?wxtype=jpeg&amp;wxfrom=0"/><p>新赛制，新玩法飞桨黑客马拉松第六期全新挑战，重磅回归！开源贡献个人挑战赛、飞桨护航计划集训营、Fundable Projects、优秀稿件征集与传播四大赛道，邀你挑战！多难度梯度开源任务、导师1V1指</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441534&amp;idx=1&amp;sn=a1ad868512de6ae3c76647f88de9a0a9&amp;chksm=bf7488c5e23aff0bfd53e5b034d61694fa8c0c4646369b9cea2751630cf7ee3d0a27d9cb7e0e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 27 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[使用自己的领域数据扩充baichuan模型词表（其他模型也一样）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgwggq0p7QF461l6swuOYzjpPpNtkicc2YM6YsecM4VJTqwICubtXa8fjVIg8SuTs2EMgvhibkP95gGg/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言总的来说，扩充词表可以加快解码速度，对于对中文支持不太友好的模型（如llama），扩充词表还能提升模型在中文的表现。环境jsonlines==3.1.0sentencepiece==0.1.99t</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441534&amp;idx=2&amp;sn=1edf0ce111749a9624ee6b25086a0729&amp;chksm=bf6fdc9cea0fb41cae3f407e05e1498f3bd116bb895c389d38133f1016a005d5d7f6a20a2422&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 27 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【社招】小红书增长技术多个岗位热招中！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKqDYic1fUolyca4lJx4DnuZlveQ2uM9iaJyZqgKxQYibOpupYleO999opKmZn79KgibkeBGdX2DhL87g/300?wxtype=jpeg&amp;wxfrom=0"/><p>工作地点：北京/上海收件箱：houmengchao@xiaohongshu.com算法工程师-画像方向工作职责1、负责优化小红书社区上亿用户的用户画像；2、应用数据挖掘方法和Multitask Lea</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441534&amp;idx=3&amp;sn=31e92e0403fe8e396a48bef3080e4300&amp;chksm=bfb711a01311dfebf870a534ba08884def56a013af2a53349775405bed448de918d33f197d18&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 27 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[生成模型大道至简｜Rectified Flow基础概念｜代码]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/vtIvcrPJjh7sn8o32iciaaBkpSCU6Fx8QzJOQVX904plwCewZv6x4UAFwVkucWWx3NFmAl5mjyImFv2picO0Wy5Mw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近看了下SD3的论文，里面用到了Rectified Flow，之前没有接触过，了解了下是项有意思的技术。值得推荐，这里记录下Rectified Flow的基础概念和代码实现。详细的原理和深入理解建议</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441534&amp;idx=4&amp;sn=408e997771da40a527cfb6160a8d6ecc&amp;chksm=bf1ec3caa72314d315c8dcebb6b37d0c376e64f7e8911c5a4b405362901ceae88b61c2c68872&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 27 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[为什么语言模型的本质是压缩器？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BAVX0pafImn4deViaa4kKDibasaupfNtw2tgsryYPkSZbUFIZFQ3RMZlFlDrOYM7txdqcW9mLfffBicBDrNlQwaWQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>最早听说语言模型的本质是压缩器的想法是在黄仁勋和Ilya的围炉对谈，当时只是直觉上觉得这个说法很有意思，但却没想明白原理是什么。2023年9月，DeepMind写论文进一步论证了语言建模与压缩的等价性</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441534&amp;idx=5&amp;sn=a3f6c2f17d7b6e3e433563bda6f5207e&amp;chksm=bfe0cbd1feefc3a7f9b0779f0976d3641d74823de07a8fca5de8fa78bce1be4c5c78fd897938&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 27 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[整理了2024年最新顶会论文【附PDF】]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLryynjoWcgOVLUtHe6TPhIPL6BFYib4micZaCNr8yySg84cM7qHCQzibk5Vz02s2yW8z7UGkRpFAV6g/640?wxtype=jpeg&amp;wxfrom=0"/><p>ICLR 作为机器学习领域的顶级国际会议，每年都吸引了全球众多顶尖学者和研究者的目光， AAAI 人工智能会议在AI领域极具声望， CVPR 是计算机视觉方向的“顶级流量”。现在会议论文审稿结果也已经</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441503&amp;idx=1&amp;sn=a6fffc4c0e753904b433b97908a04ad6&amp;chksm=bf10daaecce4bc4872efcfa45ad5a3c6e167da149fe4a0aeff2890431345a06814c2f3fbdfb0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 26 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[RAG与Long-Context之争—没必要争]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5lbP3QtkAdeYzoxVajibBtXQEowGWbjwdb57Q9BApHTiaI9sgHZVrg6odiaBcncRCIOeG0liceCY7WOPQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面随着大模型可以支持的上下文(Context)长度越来越长，网上（好几个群里都在聊这个话题，也来聊几句）竟然出现了RAG与Long-Context之争，是真没必要。。。主要是两者不冲突，并不是非</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441503&amp;idx=2&amp;sn=557bdf8f2ced3315a4332db28b759c4c&amp;chksm=bf0637a5bb044720ac5444eeb4f155be674bf01d6dd3488c040af3fd0380aa6828797f395c42&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 26 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[transformer中normalization的二三事]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW464icRJNKxxaiaQYn9XW6nth9Ez9IFYbBody7tGoxb02qib0KgiaMe5EjJm5Qiafu5niaDzOFthyE4AFY1icA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Normalization在模型中，相对于attention这种经常被魔改的结构，受到的关注度似乎没那么高，但它对模型能否顺利训练，却有很关键的作用。在此简单梳理下normalization相关的背景</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441503&amp;idx=3&amp;sn=7e9dfc241ca6e2525e542a40d8ceb93d&amp;chksm=bf691d08588ca3b3d16a3f400efc3c9dcdc94bf14fc49f9da6e019ad49fa877da97dc93f3fd3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 26 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[百川Dynamic NTK-ALiBi的代码实现：无需微调即可推理更长文本]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgy2fJK3Eu7hcY8AoHcHW3Ep8BJMiba2ibU36Rbhxryxy9DlG7M6pFJShneynTrMIhNgzf0a9eGgTWzw/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言NTK-ALiBi原理：NTK-ALiBi：通过插值实现大模型ALiBi位置编码的长文本外推[1]代码实现打开百川模型文件夹中的modeling_baichuan.py1、增加build_dyna</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441503&amp;idx=4&amp;sn=a57364cfb4cb78b83e5339c68b3e37f4&amp;chksm=bff5f35da586b60bfd5cc784a9685b28836cc9453ffb0c955254b131e4587ba65133ef7bec22&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 26 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Echo embedding: 把文本重复两次，自回归模型就能生成更高质量的embedding]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKpuIRbwVtvfco2cdwibbGF5bwcQYPLjbBS8dRxD2Ras0tCVqVDpmlotVvyb7ib9J1c2MrKsBSUNzaEHQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲1 简介‍2 背景‍‍3 Echo embedding4 实验‍‍‍‍5 讨论参考文献1 简介    针对目前在生成文本表征时自回归模型架构的局限，卡内基梅隆大学的研究人员提出了“echo emb</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441503&amp;idx=5&amp;sn=910344262c0b7a2b7f3e128ff12c5757&amp;chksm=bfdee31920aea32e00432049b03c83ec6a4baafae506d2b5f25aff4496c73157cba012bc9788&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 26 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[研发大模型的血液--万字长文详谈数据工程]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLryynjoWcgOVLUtHe6TPhIDhXqJcDIGLaRln0cW7g1T5yEpOdqgPGkTowjqQ7zVY6MpicJHDSYkFg/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：西红柿牛腩原文：https://zhuanlan.zhihu.com/p/685077556整理：吃果冻不吐果冻皮最近1年研究大模型，有个很不好的现象，大家都认为做大模型，认为只要喂数据就行，甭</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441493&amp;idx=1&amp;sn=9f64ea38c75ad5d2db379e3f7f947ae9&amp;chksm=bf426d3179c33dc90428f67ac363bd8df6af6aa7e16576b839c55f18c08771ae485d298f169d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 25 Mar 2024 12:38:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[虾皮(Shopee)招聘资深算法工程师 - 智能客服/对话机器人方向]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLryynjoWcgOVLUtHe6TPhI6q2gmTXl3J4JsfM9mV0icMXdsmic3tovZkJLkib4EyTwKWagU5Nf4Igsg/300?wxtype=jpeg&amp;wxfrom=0"/><p>[电商业务] 资深算法工程师 - 智能客服/对话机器人 Marketplace Intelligence and Data部门介绍：Marketplace Intelligence and Data </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441493&amp;idx=2&amp;sn=1412c41ee9886089d3015c5dd76f38fd&amp;chksm=bfc170308d9dd1127b07efbb141658679df8f95b7c8d7f3cf224cba5d95e205de2ed121d10f0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 25 Mar 2024 12:38:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一篇新鲜出炉的RAG综述]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKptW5MX5pIe79PgWH74GxP0IqTianFO8HnaHAG3aTFZlCV2mCB4S8QUEDrL4MbEBrdCFcic2mYtxrSDA/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲1 简介2 RAG分类3 RAG增强4 讨论参考文献1 简介    尽管目前大模型取得非常不错的效果，但是依旧面临不少挑战，包括如何获取实时跟长尾知识，如何规避数据泄露的风险，以及高昂的训练跟推理</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441493&amp;idx=3&amp;sn=7d0d1c2fb5bc84595b3cddd0ee8a33f5&amp;chksm=bf235a5d4f9656270605576f8a35a0bdadced7aa79495fe6e6a5cdcd1f282b404e82301f3bdc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 25 Mar 2024 12:38:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[SentenceTransformer使用多GPU加速向量化]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgz9wicRes81YFsbvhuoiauS1I5NaaGFboSFmxVfuTPen85uoHS5zTAIukKDFIw5NzqcuT9wgemhNH4g/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言当我们需要对大规模的数据向量化以存到向量数据库中时，且服务器上有多个GPU可以支配，我们希望同时利用所有的GPU来并行这一过程，加速向量化。代码就几行代码，不废话了from sentence_tr</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441493&amp;idx=4&amp;sn=0d841cdcb016a62d834ea5d39b5d9ff5&amp;chksm=bf481cf820c6c4053d12915cefd89637a9d2293418ac10c00cf6ab6497ce462363816ed6f1d5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 25 Mar 2024 12:38:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[EMNLP 2023｜利用LLM合成数据训练模型有哪些坑？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gTSf9kr5zrMVV78xnqk4ZxY6wEVLUEouv4djTDrKPHRQLspc84zpGNV9GGXesicUypkz3QXQfbexmiaWVCE0G1CA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天我们将介绍EMNLP2023的一篇大模型（LLMs）生成文本分类任务合成数据的文章，标题是《Synthetic Data Generation with Large Language Models</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441493&amp;idx=5&amp;sn=5fd67806bbe2fb52e1871c2b1bef0b87&amp;chksm=bfd205215d639ef0c736c2486deeab5b2dc91a9aea022e763c2e1b1ec55eef2538a3aa59f667&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 25 Mar 2024 12:38:46 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
