<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5034e4edc067.jpg</url>
      

      <title>gh_5034e4edc067</title>
      

    </image>
    






















    <item>
      <title><![CDATA[知乎大佬解析Ilya最新言论：pre-train丸啦，搞agentic和reasoning吧]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJtpW8Eha7IODSyRqGY9PKw8D3fAiciaZs7VEAzq3Ifib9iarkQLxergLiagbtziapVZCA6uPhDnAoREgGg/640?wxtype=jpeg&amp;wxfrom=0"/><p>Author: 曹宇Link: https://zhuanlan.zhihu.com/p/12588939986Ilya 在 NeurIPS 2024 上演了一个名场面：在回望了自己十年前的工作的时候</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446520&amp;idx=1&amp;sn=a818ffaa84f20f785b5342fb52d64dfc&amp;chksm=bfaf9defef91d3dc2792864a75448482bf4951a5674c9f0e20c765d59498cbd554b284b9be37&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 19 Dec 2024 11:19:21 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[大模型Infra王朝2024]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJtpW8Eha7IODSyRqGY9PKwEVdEbUxPAoLib5Uk4uIJ45Udauib5RKoCyia6ZZ8RibMOEDYoJ0VFKIZDg/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：手抓饼熊（已授权）链接：https://zhuanlan.zhihu.com/p/12663989502记录一下2024做大模型Infra的一些破防瞬间。大厂All in大模型的历史背景不上称四</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446520&amp;idx=2&amp;sn=81c378eb18df01e48160de54815f8518&amp;chksm=bf56193c2c5e451eb9cd20227a480c11fe898ff5866091e33e898f229763cddc8cc0529e9e9f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 19 Dec 2024 11:19:21 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[NAACL2025研讨会征稿 | 主题：自然语言处理中的跨文化研究]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKsbExfKbIEV4GF2vavXOEtVLoSIjXeebEib4enKgEK9kppibwUBZqg9QLbgRPn9F3IrgFnCmtYXxPw/300?wxtype=jpeg&amp;wxfrom=0"/><p>研讨会信息第三届Cross-Cultural Considerations in NLP (C3NLP)研讨会，将于2025年5月3日在阿尔伯克基，新墨西哥州（美国）召开，研讨会同NAACL 2025</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446520&amp;idx=3&amp;sn=0e8a14b77f2f8a4355a70a70b212ef5b&amp;chksm=bf1c5a5e2712d8cfec10ef347654647322caf8da9d2cac770f90da3997b32f382f2cd58ed52a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 19 Dec 2024 11:19:21 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[机器推理的突破？田渊栋团队的关于增强大模型推理能力的热门论文]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/9MSPBmHaWGyoxVURS6Bmic7ergROXLsLmKiabAMn19brNuKGKnIuunjGIkrCjDk7flLgvrmA8IYtAOeXYfb6gLmg/300?wxtype=jpeg&amp;wxfrom=0"/><p>      由于本人这几天一直在整理有关增强大模型推理能力的论文，突然发现一篇新闻，就是田渊栋团队最近发表了一篇关于增强大模型推理能力的论文《Training Large Language Model</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446520&amp;idx=4&amp;sn=3566be449e35a44c79d11f05667445e3&amp;chksm=bf257307e29024f6eef049adfc6490301126c9f888c379759e5877a1ca188c8df6de0c72fe1b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 19 Dec 2024 11:19:21 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[模拟世界！OpenAI 王炸来袭！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJGao4HsKSkwlDibVn6HR3XiaU5frSWtpw297Dr28A0HiaEGaMJ8oRv3JF1hiaZFQfoTUnHz9fcBRoGsg/640?wxtype=jpeg&amp;wxfrom=0"/><p>开服就被挤爆服务器！OpenAI的Sora正式开放，带着革命性的AI视频生成技术，突破性地从文本生成高质量视频。新Sora功能突破不仅代表了视频生成技术的进步，也表明OpenAI在多模态生成能力上的技</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446478&amp;idx=1&amp;sn=2ef8388983b883338dd731ce3313f6db&amp;chksm=bf37beae3bc5e64a4260728f10c35dc546e2981a7b091888670506ce1e9c985dd645e299f013&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Dec 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[The Bitter Lesson（苦涩的教训）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJGao4HsKSkwlDibVn6HR3XiaodHAxZPAmlDdOariafzjLj6fR4ibk0s7UFI3NmJuEplSgKib9apf5GpibA/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言Ilya Sutskever（前 OpenAI 联合创始人兼首席科学家）在前几天召开的 NeurIPS 会议上表示，大模型的预训练已经走到了尽头。而  Noam Brown（OpenAI 研究员，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446478&amp;idx=2&amp;sn=02a3d7849cf2cb4d138f662878de3200&amp;chksm=bf23516e3ffa3a7854f79452e95d219bc26a693aa059c7939f5948b76a1e1c1a11725684e17a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Dec 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【从零训练Steel-LLM】模型设计]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/ic2h7M1BWibNnUXGOMWBIo461uwl9pgFGsshAFu5EhibChic0TgQ4IricgKEfH6aJZ82NeGWibpREmYmugVR7icwV99icA/300?wxtype=jpeg&amp;wxfrom=0"/><p>这是从零训练Steel-LLM的第三篇文章，于24年7月9日首发于我的zhi hu帐号：“战士金”，略有修改。目前正在进行模型微调和评估的相关工作，近期已经将训练过程中的多个checkpoint上传到</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446478&amp;idx=3&amp;sn=5fae012891bb01abe01d76c2acb4b472&amp;chksm=bf3955f67b100b317886742eb9a44e9fa3e69af1609dfe558e5b723a2fb7ab1e3b05abb89bf3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Dec 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[千问LLM：LLM的解码都有哪些方式?]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iabUOs2OBUhTJchV1800lWEhIq8F6xhCBBmI7mrYULAlSl0oCbTL3shIUt5ic9JRFtYZSMek7jTNicib53iakDz9dSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>千问LLM之三十一：LLM的解码都有哪些方式?“人生也有多个解法，轻松是一个活法，累死也是一个活法，不求人人都是一样的人生，但人人都做最有意义的事情。”上次博文介绍了 千问LLM之三十：什么是Post</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446478&amp;idx=4&amp;sn=9bd885df3f4ba45ce0274c6796e784df&amp;chksm=bfcfd7e518bbd42541b7ca9e2108f4adca7a73ca709cc41611d9dd032090e72cb08827a13b11&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Dec 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NeurIPS2024，LLM-Multi Agent 依旧火爆！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLxmB9ibsQMosXCkvicKeNsicCMuXQibpBPIJvG6GiaicJHEiaGyEae3yDfCpHQHtx5q75B9vt1DDwqPCJLg/640?wxtype=jpeg&amp;wxfrom=0"/><p>顶会NeurIPS‘24录取的4037篇论文中，LLM-Multi agent依旧火热，热度不断攀升。而ACL’24也是如此，LLM-Multi agent无疑是今年的热点词。国内外多个权威研究团队都</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446463&amp;idx=1&amp;sn=2c95bd8d098286a1de7f99400020984c&amp;chksm=bf8928d70404ab260cff37b6efa42a4dccefc97f881355e74f6188d6f6730868187cd9698ae3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 17 Dec 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[工业界主流大语言模型后训练(Post-Training)技术总结]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLxmB9ibsQMosXCkvicKeNsicCXxvIP79EGqW8Jicr7lfKzib8oIDTibOIIEFNYxvEnKoHnnBmJtsbsDGRw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者丨唯亚@知乎来源丨https://zhuanlan.zhihu.com/p/987052830编辑丨极市平台导读 本文整理工业界主流开源LLM的后训练方案，着重介绍训练算法和数据处理部分 前言今年</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446463&amp;idx=2&amp;sn=3e2061a18d7509cc605b36fb4197a7d7&amp;chksm=bfebed82b15f4534a49f027232fb02b4d9fe390f7bf685d09a3290867ce1385b9830b7465a2d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 17 Dec 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解OpenRLHF中基于Ray的分布式训练流程]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkNm8wIw4A1k1R4xmpIBGt8odIEZiafnOxHXedNnWcv0aleCNL8aSzx1dAGGfbmIIrD1CSyiaqbqiantQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文着重分析OpenRLHF中的PPO-Ray训练架构设计，没有使用过Ray的朋友也可以通过本文快速上手，本文共分成四块：1. 为什么用Ray2. 使用图例抽象出整体训练流程3. Ray核心知识速过4</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446463&amp;idx=3&amp;sn=a3cc0bd44fbd5d4828b7325b7368eb6d&amp;chksm=bf2525c59ec9efd0c397165bbc2b0e1a2b92df545c72b7e54cd7c66f8c0fa0928c04f82d3c63&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 17 Dec 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[模仿、探索与自我提升：类 o1 慢思考推理系统的复现之路]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLxmB9ibsQMosXCkvicKeNsicC2bqRhBdbU9ru9MqGtc7IClvRcBud7iarZhGdAmVdicjvp8sRh5LMt2HQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>© 作者｜蒋锦昊，陈志朋，闵映乾‍‍机构｜中国人民大学研究方向｜大语言模型与推荐系统近年来，类似于 OpenAI 的 o1 等慢思考（slow-thinking）推理系统在解决复杂推理任务方面展现了卓</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446446&amp;idx=1&amp;sn=a6a27ee83cef0cd1f4f5b71c4a94a6fb&amp;chksm=bf53acf91ae589dd8e84023e2c67d2fc627610c9f369f9de463542b58d613af560485631f058&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 16 Dec 2024 10:29:24 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM模型微调】LLMs-微调经验-SFT总结v9.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdCP0XlmKKJdiaZk7gUGAufmoW0zkwjP6dlCMM87CLic0Gib9iauZ7xX0l5oWo3Ic3XWicg9BP1kVNa1ibCA/300?wxtype=jpeg&amp;wxfrom=0"/><p>【1】大模型微调到底有没有技术含量，或者说技术含量到底有多大？老生常谈的一句话吧：有没有技术含量取决于这个工作你怎么做，尤其是 llm方向，上手门槛相比传统 NLP变得更低了。我举一些例子吧，针对大模</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446446&amp;idx=2&amp;sn=034b485a5dd13e5617be6d933a83b5e2&amp;chksm=bf19c0b7df5b39b2ed8345fefe807bef047570115670c1ba2910b0cf003ffe679528e4add704&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 16 Dec 2024 10:29:24 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[聊聊对强化微调（RFT）的理解及看法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5nxYicQntALI7B9EibEjqOVGA8x15FwqM8CqvyspyLClPhJqehRzJiaHSO4zvIicoibx9qMarEZzogsO1g/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来一篇好友 知乎@ybq的文章，聊聊对RFT的理解及看法。作者：ybq 知乎：https://zhuanlan.zhihu.com/p/12328929529在看了 OpenAI 的直播，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446446&amp;idx=3&amp;sn=d0d0cf2ef705391f993c18635f230899&amp;chksm=bf9a2b9b8a50e59845ce276fb4f4841970232eec454653d9c2713b9852a3afed0f9396a3406e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 16 Dec 2024 10:29:24 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[雷军大学时候的论文，不需要参考文献]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLheGkhkPXeaqicuTUdes8MQQwj3dKqDWajS6SmSYk5ARHn8icrhJkZ4ia19uvluPQnicC1XibzAzlX2NA/640?wxtype=jpeg&amp;wxfrom=0"/><p>来源：程序人生那个科技圈上热搜如喝水的男人，他又“回来”了。继“雷军1994年写的代码像诗一样优雅”之后，“雷军大学时候的论文不需要参考文献”这一话题就爆火了。在 2023 雷军年度「成长」主题演讲中</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446363&amp;idx=1&amp;sn=c849caddbf6f06e4d15260934f384963&amp;chksm=bf18553a48f0631186c5fb6ddc8faa2a17e08a358f5b4b4db843fdef8505b8a7194b416e3eef&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 15 Dec 2024 14:03:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[清华大学刘知远团队新作《AI群星闪耀时》，文末赠书！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLheGkhkPXeaqicuTUdes8MQYzPEy7SybF12XDqpLC82GbTzY3XtrAqJ26B8XXccoc7pjQ3iaPJjhEA/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注我们丨文末赠书历史书很小，装不下一个人的灿烂一生；但是星空很大，容得下所有人在历史长河中闪耀。今天小异带来一本新书，由清华大学刘知远团队创作的《AI群星闪耀时》，这本书讲述了AI发展历史上，那些让</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446363&amp;idx=2&amp;sn=91ada7cd358f9aa56f2caf2f85b1421e&amp;chksm=bfd2fa899d9b8024203a78846aa7751c3b2c39344695233772ccf7b4576dd8146ea68d0eac0f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 15 Dec 2024 14:03:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NeurIPS 2024 | MIT学者歧视国人!]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiageIlPFLeA8uPkxb5DCfqvEBZbng7gLKfFeiaCwUxML0OPweialzs9tdWfzqv9NKmIEwszHr4aw0uA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在2024年NeurIPS上，一位来自麻省理工学院媒体实验室的教授发表了涉及种族歧视的言论，引发了学术界的强烈反响。该事件不仅引发了对教授言论的谴责，也对会议的伦理审查机制提出了质疑。演讲者在讨论AI</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446363&amp;idx=3&amp;sn=a6b1036b47ed84f7c78ffa7ab7c542ab&amp;chksm=bfb1e63d0adc6587e66f157eb1eeb62c1d6287c8cb5dff49bb56b5c62ccf2c5e21f4cc0321ec&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 15 Dec 2024 14:03:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[千问LLM：什么是Postion Encoding?]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iabUOs2OBUhTJchV1800lWEhIq8F6xhCBBmI7mrYULAlSl0oCbTL3shIUt5ic9JRFtYZSMek7jTNicib53iakDz9dSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>这次我们详细介绍一下目前的 LLM 输入的时候是如何考虑输入字符的位置编码的，希望这次可以彻底明白了。 01—什么是位置编码？在LLM中，我们的输入是有顺序的。如何让LLM识别到输入的各个字符的顺序呢</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446363&amp;idx=4&amp;sn=60525bdf4edd7e90303ea773b9d262c6&amp;chksm=bf353f76bbcc6d7acdfed0612ae8ab51a2621ac634746f3e5723140b88602206e254812ad462&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 15 Dec 2024 14:03:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NeurIPS神仙打架：李飞飞180页PPT谈视觉智能，Bengio同OpenAI员工吵架，何恺明谈AI宿命论]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIfHUsejAwkFXQ2d9TajPn58QiafIPvFgTibUDGCNU6vuCUOAqHBmEUr7kE0p3NTc0uvEy3vIktvorg/640?wxtype=jpeg&amp;wxfrom=0"/><p>来源 | 量子位作者 | 白小交我们无法忽视世界是三维的，解决三维智能是根本性的。李飞飞最新采访来了，继续延伸她在NeurIPS有关视觉智能的话题。她表示，解决空间智能问题是迈向全面智能化的基础和关键</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446347&amp;idx=1&amp;sn=d8830c3c779ce7d768b7196a9fe14860&amp;chksm=bf8a6589d1dce259f33f323ca00a4fc104620b34a0d6ba011eb75bf0c6e29a88bc9f1afebb62&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 14 Dec 2024 14:48:42 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Ilya NeurIPS 2024演讲视频及全文：预训练即将终结，接下来将是超级智能-代理、推理、理解和自我意识]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIfHUsejAwkFXQ2d9TajPn5all9ibTEtYeMaNyuh9W3IHK9AdUjpTXGYpO8wUgMUcXPZ99ib0j1lPvw/300?wxtype=jpeg&amp;wxfrom=0"/><p>IIlya NeurIPS 2024演讲视频及全文：预训练即将终结，接下来将是超级智能-代理、推理、理解和自我意识以下文字部分来源于微博高飞：Ilya Sutskever：预训练模式已经走到尽头。这个</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446347&amp;idx=2&amp;sn=47d1ac9b18bd9a73683e7ead147b09d3&amp;chksm=bfae5db1b346dca19bc831b8502db007d252ae4793c2f54c33163fb2185a6bbd8003cefd842b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 14 Dec 2024 14:48:42 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
