<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5034e4edc067.jpg</url>
      

      <title>gh_5034e4edc067</title>
      

    </image>
    



























    <item>
      <title><![CDATA[OpenAI华人VP翁荔离职：北大校友，掌管安全，最近B站分享被热议]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJRY2UCs9t2CxbOKlzoYxQqS6BAjjvhQz5oThhezVU2lNbE5kmMwj4Ns9NaXXbIFs1qkRuXxEbrOw/640?wxtype=jpeg&amp;wxfrom=0"/><p>金磊 发自 凹非寺源 量子位就在刚刚，那个掌管OpenAI安全的北大校友，OpenAI研究副总裁（安全）翁荔，离职了。翁荔是OpenAI华人科学家、ChatGPT的贡献者之一。北大毕业后，翁荔在201</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445878&amp;idx=1&amp;sn=f76d4b60fa2026b2801caf386d3cae5e&amp;chksm=bf00f7dda0a4d6471ad39ec313ed3426025298a7235689edbf1631f718f44759ba9b6f70edc3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 09 Nov 2024 14:56:57 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【文末赠书】4种革新性AI Agent工作流设计模式全解析]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJRY2UCs9t2CxbOKlzoYxQqUTwPQCsHJSuXxSYxfhz2Zy1U80u2QyhlVtDpsiaPoXgOQrNFB4vWbdQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>导读：AI Agent是指能够在特定环境中自主执行任务的人工智能系统，不仅接收任务，还自主制定和执行工作计划，并在过程中不断自我评估和调整，类似于人类在创造性任务中的思考和修正过程。AI Agent的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445878&amp;idx=2&amp;sn=d2a74abca76996d283c652e8fd2e0ecf&amp;chksm=bfd39aec1cd0e8219d1fd2f898ab238f1681677e605c8980719c75b8645236e3b505dd3765c1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 09 Nov 2024 14:56:57 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[训练数据合成(一)]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW464XlhXB0LnljZuQ79pOaT1STRt7eygmicAHTFcF17Wb2rumvdzpibicAk8dElmbl9BPIxdmPxylR7t9Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>现在大模型的训练方法大部分都比较固定了，那么最重要的问题就是搞数据。真实世界的高质量数据虽然好用，但是成本高数量少，于是合成数据就成了一条很重要的路子。较新的专门模型如数学模型、代码模型或者阅读理解模</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445878&amp;idx=3&amp;sn=92337814ff6f81b6dcbb04a8b851d82a&amp;chksm=bfb6f971d0f3640249323f75e16e138c739ae9ddc90d2e9822ec6e439efbbf42e74ccd75d977&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 09 Nov 2024 14:56:57 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[LoRA与全微调：等价幻觉]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/UkaMPMaoibmiaelx6uq54RNXowyj1RHq9p4QaKDJ8Lts4KXTMbVU58R9ibPRcgZ2YIBIyGtzhcvuTVCkKzicmInVKw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近，像低秩适应（LoRA）这样的方法在各种任务上显示出与完全微调模型相当的性能，同时极大减少了可训练参数的数量。一些研究提出了内在维度假设，认为微调过程中学习的更新具有内在的低秩特性，这可能解释了为</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445878&amp;idx=4&amp;sn=ea010ee2fe29ec977296f07b8d70c6f4&amp;chksm=bfa1f499850379e90f800bf1dd14d753dbd1ab55c37e7e3ac2f07c8eab0ab7f595649fd8f892&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 09 Nov 2024 14:56:57 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[从虚构到现实！FAME助力模型编辑走向实际应用]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagXq9yefWrJkaiaGUDJKVYxdq2ssiaHwyMD1yFNQjotkxo37GgYWJB8qGmKQ37zlVAvDjPpjIxqWiahQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：FAME: Towards Factual Multi-Task Model Editing  链接：https://arxiv.org/abs/2410.10859项目：https://git</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445878&amp;idx=5&amp;sn=bf8477bbe1ccbd7ce9862688220291c0&amp;chksm=bfac5caf1179716767799b8c29ed560354f6e5b6044beae2776c1a5e29da1d90f156fb7db89d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 09 Nov 2024 14:56:57 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[LD-DPO：基于DPO的长度脱敏偏好优化算法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIOtRPnAvibFdFL73MfQOJCTraE1HAyUz4GHVBaEwbEmYhSHiaMBuzgXOAJUS4TnfsymvZGjv1pSy9w/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文题目：Length Desensitization in Direct Preference Optimization论文地址：https://arxiv.org/abs/2409.064111 </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445849&amp;idx=1&amp;sn=c991e4762c0409330787bea036d60a54&amp;chksm=bf46842c50d3317961b010f6eb8f1f3820e0f708e3b309f335415e0499bcd6c7b8799ecb47e9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 08 Nov 2024 09:28:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM实践系列—大模型的拒绝采样2]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5lgIOGr6FcFHxSlfbLae4MKAqkFwRkrLIOZDtkjeda2sUylblxHf9ibJkOjs47P527mvyIg8goyRwA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来知乎@真中合欢的大模型实践系列文章-LLM的拒绝采样。作者：真中合欢 知乎：https://zhuanlan.zhihu.com/p/4547529049拒绝采样是一种蒙特卡洛方法，和重</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445849&amp;idx=2&amp;sn=2d821dc84f4739233e49a577559217bf&amp;chksm=bf459730e2c06bad20c2029dd4b3e0f6036892b1a9b7af53d5f71bf94b1a983eebb7cc74d4b5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 08 Nov 2024 09:28:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[腾讯TEG招聘：机器学习平台高级算法研究员-大模型应用]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKiabbib5RoHKibQ3CWCzNXJUH2UXjEc9OI7jW4FPJ3Wxx0IkshhteaFxyVIT3Uthfr2h4bPGiaNWQfmg/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯TEG招聘：机器学习平台高级算法研究员-大模型应用（北京）岗位职责： 1.负责大语言模型在捜广推场景应用相关核心能力研发，包括大模型微调能力，相关模型算法调优以及性能优化等 ； 2.负责大语言模型</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445849&amp;idx=3&amp;sn=4b376b9830e917b1319c41d2669755b0&amp;chksm=bf22df1211fbad4af230667614a57d9827ef837e75dd33b600be5682b00ce2a680774fd853d7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 08 Nov 2024 09:28:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[答案搜索生成引擎现阶段局限性思考]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/yToxjhYT5ibZlC4Tce8xk7bMIdCwq2sxpjMfYdiaKxtU7QTXYQMiaiab7SB9adia9cVgqvwQj7NtXQkd5Rcy8FaF8yA/300?wxtype=jpeg&amp;wxfrom=0"/><p>基于LLM的生成式搜索引擎（Generative Search Engines）正在取代传统搜索引擎。答案引擎不仅检索与用户查询相关的来源，还综合引用这些来源的答案摘要。来自PSU与Salesforc</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445849&amp;idx=4&amp;sn=73d1e9c7e9f5b840e00339362eff9b2d&amp;chksm=bfca7942a89d3ed988180b3b44975ce745f027e8c29488cc323423d25ee4397d2636a0a984f3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 08 Nov 2024 09:28:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[告别随机采样！PRS：一种简单高效的数据采样新方法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajic9JLicM7eJt5ss0OfNNzFKk691b9PVOSYNrdHWicyMdkthvAf9MT0QZmgbONWSzibS41F1A2XZOI2A/300?wxtype=jpeg&amp;wxfrom=0"/><p>Hai Ye, et al. “Preference-Guided Reflective Sampling for Aligning Language Models” -- EMNLP2024论文：h</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445849&amp;idx=5&amp;sn=eaa7e5bc2558e3c66b086327f8f563fa&amp;chksm=bf8fe61b9b4c13c99c89c00e79ba53a66eb40140aafada5e897b5de92e9524e6940bbd5814b5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 08 Nov 2024 09:28:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[突发！ETH官宣制裁中国学生，国防七子、中科大、川大、北邮等高校均在名单内。。。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJ0O5U1aJmhjSUeQrmfews6Gmg52FPtfVyJ0SGXCjOlJRXkBMSp9qQ2xROndpZW3annrDMdpSBeLw/640?wxtype=jpeg&amp;wxfrom=0"/><p>转载自：募格学术 ｜整理自环球科学科研圈、洛阳理工学院官网、ETH官网、启德留学广州、英伦大叔等2024年10月24日，瑞士ETH（苏黎世联邦理工大学）官网发布了安全审查政策，更新了硕士、博士（以及更</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445818&amp;idx=1&amp;sn=673eadbc37aef6dca34bee7ae7571e73&amp;chksm=bf918d84be665995361d46baca329c23328c86753f405fefc262cd1fd06a88800debf6b31c2d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 06 Nov 2024 14:51:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen2.5 全链路模型体验、下载、推理、微调、部署实战！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/8ZLuyaibrZbnW2qfuGfhibjSoY7zRpLEfJqUxNbjLiarKQ7ON28zjPf2a8gHA1zRXU8dz09O2Zkwqrv1ly5QdGlRg/300?wxtype=jpeg&amp;wxfrom=0"/><p>01引言在 Qwen2 发布后的过去三个月里，许多开发者基于 Qwen2 语言模型构建了新的模型，并提供了宝贵的反馈。在这段时间里，通义千问团队专注于创建更智能、更博学的语言模型。Qwen 家族的最新</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445818&amp;idx=2&amp;sn=6e019c792c6abf2a00cf726a3ab04664&amp;chksm=bf4c8ecf130cd0cfe002b1f497603ae09c64cf21c995b12b056c514fa34f72e55628f3e1d83c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 06 Nov 2024 14:51:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解大模型训练系列：序列并行4，Megatron Context Parallel]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkNzBibbTprRN5ftPSHJh43eV1g1V1C3zDTZpQIpba3Uo4hUaqOY6sawgT7FBnNBhwO5Sr1rU3VHTQg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在序列并行系列中，我们将详细介绍下面四种常用的框架/方法：Megatron Sequence Parallelism：本质是想通过降低单卡激活值大小的方式，尽可能多保存激活值，少做重计算，以此提升整体</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445818&amp;idx=3&amp;sn=61eede931563d5adec447db065de6a71&amp;chksm=bf3684eba217dae4bb50394a2a7520a18125bf64340c08d5edc07c7372cd8a3767446d8d6fdc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 06 Nov 2024 14:51:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[遇上博大精深的中华文化，多模态大模型还能行吗？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajrjk193zib0Q1RG5e8pZ9uPiafVEAzd6U1ibpH16ibljQhtVOkWXW7VYu5HmRF5TVbibqoibqv5hYX4upw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：张辰皓随着多模态大模型（MLLMs）能力的不断提升，对其高阶能力的评估需求也在增加。然而，目前缺乏对MLLMs在理解中文特色视觉内容方面的高阶感知和推理能力的评估工作。为了探讨多模型大模型与人类</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445818&amp;idx=4&amp;sn=f15706bf9ba908636b717b868bd6a7cf&amp;chksm=bfb0958c832250ed4df41adad24130cd567bbd710862f2cb087adde6d137dc77f923cf51257b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 06 Nov 2024 14:51:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM之RAG实战（四十七）| GraphRAG：使用知识图谱改进 RAG 检索策略]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/N5aX12H1Sicl5MqtnzPeRpIictcy0QAHVyNKOtnfBhX8bWMnDZprCxWSNxWwVFO1T3J8Cgr9TXH8OMHnzgb40NIw/300?wxtype=jpeg&amp;wxfrom=0"/><p>       在 Retrieval Augmented Generation （RAG） 技术中，检索是直接影响生成输出质量的关键步骤。然而，基础 RAG 中的向量检索技术通常不足以满足所有情况。例</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445818&amp;idx=5&amp;sn=dddbc96ed26c91e2d8bb873961845608&amp;chksm=bf0adc909a7e59cd089e0a273f7b6d6ce2b8be16ca5119fc34b1912e3a33908c3c22d4626d8c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 06 Nov 2024 14:51:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型 vs 搜广推？算法工程师们应该如何选择职业方向？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/7YJVBU9FXkUcMWvxD2nhicLHibngXjrb5xZTBFApvou9c9ibbWHlSWu6YmlHMJumW7SibNplxJgTNSH0J3Es2icia2MQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>大模型 vs 搜广推？算法工程师们应该如何选择职业方向？这里是「王喆的机器学习笔记」的第四十三篇文章，很久不更新了，难得今天有空，跟大家聊一聊同行们比较感兴趣的话题，算法工程师如何选择行业。选择这个话</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445797&amp;idx=1&amp;sn=1d007e9aa1cc544c44dfa5ddc3aeb61b&amp;chksm=bf496b7dd453a3306172f3550890c70c30ae73d632944b2a1e279274610ded94bbb2c76ae53f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 05 Nov 2024 14:39:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解大模型训练系列：序列并行3，Ring Attention]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkOS1A7Y59KCysq2pG4H4SfEm5rdgSy6jyfuP4vPCWvCVX4rOiaFkMmrtW3P67icdXiazVgZSoZZ8dVpw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在序列并行系列中，我们将详细介绍下面四种常用的框架/方法：Megatron Sequence Parallelism：本质是想通过降低单卡激活值大小的方式，尽可能多保存激活值，少做重计算，以此提升整体</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445797&amp;idx=2&amp;sn=9ec7b302070689f367253a6238f23361&amp;chksm=bf975d840bb9ba9e5a6f0e07a642073986b7bb00a61a8bed8bdad7148f98f4e5463848e417fe&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 05 Nov 2024 14:39:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[阿里通义实验室LLM实习生招聘]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJUTuRzv7YuFibrNlP0lIKU5dWXgnibJZQFTtqjw8v8AOacVJk2rsbGG0BKZ8el9r9QyIfq3iam6Hhmg/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里通义实验室LLM实习生招聘(杭州)项目介绍：通义星尘角色对话，包括分身复刻、心理&amp;策略推理、长期记忆、社交Agent等方向，具体工作包括 CPT、SFT、DPO、RewardModel 等。‍ 职</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445797&amp;idx=3&amp;sn=0362df9e04c65c849c225157713f3a74&amp;chksm=bfa2f90b6363b4bcb0a16b103eec60a8335e6ec95ac5786fde8cf16f53ec50a95a9f97a336c5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 05 Nov 2024 14:39:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[从鼠标点击到自然语言：LLM based 文件管理系统怎么样]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaEoZB98J8rvHibVv0UCB75MsMZniblY1o9egA12ZXSrwSXxWrrSNeY2e9mB9ichq3lCzK4VZlFbZ4TQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>这篇论文提出了一种基于大型语言模型的语义文件系统（LSFS），通过自然语言提示实现了更智能和高效的文件管理。论文: From Commands to Prompts:
LLM-based Semant</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445797&amp;idx=4&amp;sn=eacaebf0a8eed8c77bd0d08539245c1b&amp;chksm=bfe3f3463e6785242b6817e02f8acb3f9cb5b84571b92fa752d23d1239ff815b69d0e673fc6c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 05 Nov 2024 14:39:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[实测腾讯开源的Hunyuan-Large大模型，感觉。。。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5nCZ2nKoiaUPic1iapfzyCdOOwzH92sb0l4A9lCYdwg88LpPITIrY2YftROrw6vTfz8tZvV3ZBxWu1xQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>下面实测内容没有任何个人观点，仅为测试结果。另外，测试用例可能不多，但都是之前常测得一些问题，今天突然发现腾讯开源混元大模型，十分震惊，腾讯也来挤开源赛道了，只能说大模型开源越来越繁华了。这次开源的主</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445797&amp;idx=5&amp;sn=e0e599861fd7f68667c83f91ee293fa8&amp;chksm=bf7c29c34324a1a634932c0eb4d1cfcf1e9e993a4eb71c00f08d55cc645a1d1b8bfe7bf6aee5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 05 Nov 2024 14:39:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型经典著作《大语言模型基础与前沿》]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJaMleiaXCicMffyib6icSRn1O2nhW1Fc9PkEHzYJOpjibI6B8v8O9n6H3rDDxNdykemEPpenM2UibrFztw/640?wxtype=jpeg&amp;wxfrom=0"/><p>介绍《大语言模型基础与前沿》是由美国明尼苏达大学双城分校电子与计算机工程博士熊涛所著。熊博士曾在多家中美知名高科技公司担任高级管理职位和首席科学家，在人工智能的多个领域，包括大语言模型、图神经网络等从</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445773&amp;idx=1&amp;sn=df3d8477a5fb7d8e085fe09d93108a7e&amp;chksm=bf28d77e8c156c0f26e13fa405287eafd84eb082cbc2b2fdd098643ca1d5fb2e30c6c5f85542&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 04 Nov 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[FlashAttention算法之美：极简推导版]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajzlLJaymiaSMgZzzytwlkmQjyhTia4iccZpZFkp91U0KVKo93a1CJ1H1pKsFb0pS6Y2W4ANz61PFUmQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：方佳瑞地址：https://zhuanlan.zhihu.com/p/4264163756FlashAttention（FA）是大模型训练和推理性能优化最重要的组件。从并行计算角度，FA算法设计</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445773&amp;idx=2&amp;sn=b29c02ff5f148a6ab86f777f6166a9f1&amp;chksm=bfc11d1835e0908370f35ffcfb98e58bdadfcf80fc63505daa8a2b1d5460c5ea2451308f2713&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 04 Nov 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解大模型训练系列：序列并行2，DeepSpeed Ulysses]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkNZyFCNKgX0mTpFKBzpNhW8bToraCteV2xnMTNFoTGszmUc8p4QM5WTvozicAMdDHK8EfD9H42UzxQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，在序列并行系列中，我们已经介绍过了Megatron SP，今天这篇文章我们来看DeepSpeed Ulysses。在正文开始前，请允许我吐槽一下，DeepSpeed Ulysses继承了DS家</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445773&amp;idx=3&amp;sn=43ed97e8b23da4e1f87729858eb1b31d&amp;chksm=bf535c4457993aebdaafcbc4c42d5d26b3ea8a89b8a8e3c205bc2abb3130684a0eca72346004&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 04 Nov 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[万字长文细说端侧大模型进展(综述)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/w3hibrVDUAib5BUNEBv4PpWpJ4Abcib6QibTmr54xVRK0iaWJlia5I1JN9AtrJF7icODkgRnCzo8oAFVIhywRbbbhibhBg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天小编将基于近期一篇关于端侧大模型的综述文章，介绍该领域的一些最新进展。随着端侧大模型的发展，这些隐私安全的顾虑有望得到有效缓解。鉴于篇幅较长，建议小伙伴们收藏以便后续阅读。论文地址：https:/</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445773&amp;idx=4&amp;sn=638d83455c5064c804cbde775dc644f0&amp;chksm=bfde5003e981314a21b8b8de7e600aff52ba8cf7a51e3cc92d7cd025d0ad4c56770fdd4ec6bc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 04 Nov 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【RAG】R²AG:将检索信息融入RAG，提升问答系统准确性]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGD3VTdauYKYmEtiaRH1HV433z24cIsxRorF5dnx1vKu6DGX0FEbuF9XsICQTvLkvg1NFdDpgtrZvag/300?wxtype=jpeg&amp;wxfrom=0"/><p>文章指出，传统RAG通过向量检索排序召回与Query相关的片段，通过prompt生成回复，LLMs与检索器之间存在语义鸿沟（LLMs难以有效利用检索器提供的信息）。下面来看看这篇文章引入检索信息增强R</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445773&amp;idx=5&amp;sn=ade404094df33550f089507c55127bbf&amp;chksm=bf3f6b525fd6b67223680288f99d5cc9ec7ce39024b4a0f964444f3d49bfee831cfc85fbd581&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 04 Nov 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[姜萍事件尘埃落定！阿里数赛出结果。。。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJaMleiaXCicMffyib6icSRn1O2ybIhXVtIYNwqtA681XNFSw3dtDSptSheb5g4Yw47aEY48OqnsM2qaQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>转自：机器之心刚刚，2024 阿里巴巴全球数学竞赛决赛结果正式公布！共有86名选手获奖，其中金奖5名，银奖10名，铜奖20名，优秀奖51名。与初赛不分方向不同，决赛设有代数与数论、几何与拓扑、分析与方</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445757&amp;idx=1&amp;sn=29b10d28b2ef79a9bf97109b29db1c09&amp;chksm=bffa0bb8a84ee017a569de38878e67d1c4491caf6701834b3a8b5c05364d1df51195abde121d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 03 Nov 2024 05:16:42 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
