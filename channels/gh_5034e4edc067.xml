<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    














    <item>
      <title><![CDATA[36岁当上985高校院长！女教授称“最强大的背景”是。。。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLmC7XupDBzUH8LCPfwV9VOkmrIdpPPaS6y46DIom0UAnwGvfGa8CSpdNGElb0NGzupQPRyEU02Zg/640?wxtype=jpeg&amp;wxfrom=0"/><p>转载自：募格学术 ｜ 整理自中国青年报、天津大学等一袭白色连衣裙，讲话坚定而有力。9月12日，天津大学2024年新生开学典礼举行，药学院院长刘秀云教授作为师友导师代表发言。图源：天津大学新闻网这位年轻</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445246&amp;idx=1&amp;sn=5a8f5b37607ba3b4807d222b56dbb229&amp;chksm=bf0570be6002d0213333561b73ffb6523b1f0e50a1537f327f0b33246c2061977fbc7542ebd0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 06 Oct 2024 06:45:34 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【文末赠书】内容透彻接地气的多模态大模型通识读本！国家队大模型紫东太初负责人王金桥力作]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLmC7XupDBzUH8LCPfwV9VOkTZ68QrOyHlcOF5gd2yAKgbObKcPU4DOsceK2kibJMo1TC00iaOBy74Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>--文末赠书--不得不说，如今的大模型应用只有具备多模态能力才更可能在这条赛道上脱颖而出，被更多人所使用！在人工智能的浪潮中，多模态学习作为一颗冉冉升起的新星，正引领着技术的未来。从ChatGPT的火</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445246&amp;idx=2&amp;sn=c32dfb91076d5850d1294eaa46a4aee3&amp;chksm=bf85b0c8ccd0ddda16ee2fc5bb25522d7ce7e7347070510cd5cd4436640fb682243003d2d211&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 06 Oct 2024 06:45:34 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[多模态大模型: 盘点&amp;Highlights part3——Gemini系列]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jT5Sp7MICPyhqhSGTqefbv3CtwPZCGJRlt35WYuzPmicHeytQ9qeYWe01wPavHcwU6DYgxABX4jkZ3AoZIjosCw/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言Hi大家好，我叫延捷，是一名计算机视觉算法工程师，也是叉烧的老朋友了。我们计划发布一系列关于多模态大模型的文章，帮助大家快速、精准地了解多模态大模型的前世今生，并且深入各个多模态大模型领域优秀的工</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445246&amp;idx=3&amp;sn=6bcc26cdefcd923ed3c245fe40e373ed&amp;chksm=bfac0979634c8d4697b6497048b0941f4ce49ee7f8b397dc1b29e34a85b74aa6d7ee9f44be5f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 06 Oct 2024 06:45:34 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【LLM模型量化】-官方教程-hf-Transformers官方教程v1.0]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdBNLaTxqVrRzg2mRJb209Vw8pcLKcXRCjwRXpVZOOqt3zl3BoW7JT1icsUjeoeu8eo8FQlfCI8sHicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>转载自：https://huggingface.co/docs/transformers/main/zh/main_classes/quantization量化 🤗 Transformers 模型-A</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445246&amp;idx=4&amp;sn=6600ff888bb5ed5fb42c29889aea0ace&amp;chksm=bf5c6dfea8d55f290004e923ca6f51cab3da0c303c26aab8be8584016705e566ee09d062b335&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 06 Oct 2024 06:45:34 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[KDD Cup 2024 Meta LLMs RAG挑战赛冠军方案开源]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/UkaMPMaoibmia9olzZnRkTqRbCl1QqBrwF3rGeAueJhs3BS742rjrU9KazYlbu1ibNn7XJmKnnKic2KvibCZcFpcZfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>先介绍下赛题：赛题背景研究表明，GPT4对快速变化事实的准确性通常低于35%。LLM（大型语言模型）基于AI代理可能出现幻觉性回应的频率取决于多种因素，包括训练数据中的偏见、缺乏上下文理解以及知识表示</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445246&amp;idx=5&amp;sn=8c3c96f34c54a1e49eab18bf6c7a6500&amp;chksm=bf41319a721a1fbf381a23ba1ac817551fd3fd68575e490802a680db397e73b840c26ca8369c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 06 Oct 2024 06:45:34 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[知识链=知识图谱+大模型+推理-幻觉]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIFN058Yaa2kstdtAsDY4ueHoMibYs4V5WHcK1ic9gRHka4WFtWIhNlgCXNchgGDLNnO96CEf47j9OA/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近由华东师大和香港大学联合提出了一种面向大语言模型推理的幻觉缓解方法Chain-of-Knowledge被ACL2024接收为长文主会。PDF: https://arxiv.org/pdf/2306</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445225&amp;idx=1&amp;sn=9efb520e27d39e0934331e64ee54cde5&amp;chksm=bfc799b2c52069038eefcce5dc4dae8c9532502f8d9a89fcfff99ffb72eb99635511204f1404&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 04 Oct 2024 12:06:10 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[什么！SFT完全没用！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiawBZfF689rxSflI0IpicsL07icfq5k0VeN6veIhkicI4vGTgtkU1BT4XMK8oHlAe1ENjrp9vKKX4DyA/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：莫笑傅里叶链接：https://zhuanlan.zhihu.com/p/744847498Google Deepmind: Training Language Models to Self-C</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445225&amp;idx=2&amp;sn=39274f196dc8b67bfc91b467cae48f07&amp;chksm=bfac856dbd547c6a4d9ea4320659b9b49a78560f5deba818a951071195fd7e4d0d3a5995251c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 04 Oct 2024 12:06:10 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen招聘：让我们一起点燃这支大火箭！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/JrHT8u594NG5pmullG4zBQdvHxKINP4RldgMtYd1WHC9SzvwvUvQzSWDrqLZfN6GbBVGGl4Gp7MIibOL02WV3Vw/300?wxtype=jpeg&amp;wxfrom=0"/><p>这是一条关于Qwen整个大团队的招聘帖，下面将拆分为多个部分来介绍我们在做的事情以及希望和什么样的同学合作。01Qwen开源现状伴随着Qwen2.5的开源和发布，Qwen系列模型在全球的影响力进一步扩</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445225&amp;idx=3&amp;sn=09ebbb51a5da51f29d30e3c74b51ff04&amp;chksm=bf42f6c1805f34939f5dce77f094d46770048519f2b70a3648646116104eaece2c344a92b9d4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 04 Oct 2024 12:06:10 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen2 源码解析]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKARpcFPLEDMBxoRYxIqVVNXmtE0CDjTsW8Luf4SXeCJ3JgIwosUxVoXicM9dbtBNxCTWMzCdMGvMw/640?wxtype=jpeg&amp;wxfrom=0"/><p>注：作者 wangs，毕业于985高校，曾在中国科学院国家重点实验室开展科研工作。从学期间，发表了1篇SCI论文、1篇EI论文，并申请了若干项专利。主要研究方向集中在大模型（LLM)和（RAG）等领域</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445209&amp;idx=1&amp;sn=bbba96cfe4fe9405f0d6274c1419d563&amp;chksm=bf76df200fcc021e2203e3b487b6699a79ecc9e214724fb27e2089c4e642c11e5805ad0c2c62&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 29 Sep 2024 13:42:57 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[避开复数推导，我们还可以怎么理解RoPE？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkO38Hh3kiaBp0W8SCQXcdG6uuZnKqvbsmgNrE1PxOHW2L7Iic4x9Ca47utibGj6HWejn2LpHqvyyrp4A/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，今天的这篇文章，我想避开复数的推导，从一些全新的、更好玩、更可视化的角度，来探究RoPE的原理和各种性质。这里所说的“可视化”，不仅仅是大家熟悉的“空间向量的旋转”，而是：具体能让你在调控Ro</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445209&amp;idx=2&amp;sn=4f32e7b928ae01d13e1c8b75c2ada70b&amp;chksm=bf8ef664ee49e7955bb8798bfb614c592c9048ef95ef30a0be18bf5c968d55a3b1a353ba76a2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 29 Sep 2024 13:42:57 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[希望这篇是最清晰好懂的 Layernorm 原理解析]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/LrbmPIAsVRUwTLfVZibN8DLbyhVWrickfotcibib8wQhPr747CP2Low4jblCTqP33geofukp0z4KRDGNxN7fTOprBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>这一篇文章主要讲讲 Layer Normalization。在本文里，Layer Normalization 统一都被称为 layernorm。字面意思就是层归一化，也属于数据分布归一化的一种。在神经</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445209&amp;idx=3&amp;sn=8499f97ee755083b01a3d36bfc19b068&amp;chksm=bfa0e31036817b6ab9a0847c329df802277b08462c60cdcf711dc9376209d40e3b3fda5ab1da&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 29 Sep 2024 13:42:57 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[搭建 RAG 系统的技巧和策略]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/BwrOLGIZh5WuZp613xvq7X9ib2Hu8Tj2LLVdPfktNFJ2iaXk7owCzXODrLuuj3Owm5ibibtytxwodAwdKeQSzSb4Sw/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文作者 | Yuan Shaozu【导读】RAG（Retrieval-Augmented Generation）是一种结合检索和生成的混合系统，在当前大模型的实际应用中具有重要意义。以下是我在之前分</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445209&amp;idx=4&amp;sn=5e481adddedc499fbba9a7d534380cee&amp;chksm=bf05b905d035e44e7ffae9d3d1b7663ec2fdd97cadad5ff5e71e0277c0d419230aa82cc4fdcd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 29 Sep 2024 13:42:57 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型位置编码概览及在图像视频领域应用]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/vImdeGStOOcicQuxInGN4EPrnAy1t8Auaqu01rMuaDj31GSPk39S7AAkrJgPBdlPyk867QOkJQI1ttZYRZHYJtA/300?wxtype=jpeg&amp;wxfrom=0"/><p>     本文主要总结了下大模型位置编码，以及位置编码在图像/视频上的应用及变种。一、  为什么要有位置编码？由于attention的设计，计算的是token的矩阵乘法，矩阵元素之间除了相似关系没有其</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650445209&amp;idx=5&amp;sn=bb2960329a7019d7c040d365cfad52d5&amp;chksm=bf21f551cbfb0427f1a7e05a24a44dc754c74f8862256ced5fcde1032c661643545f923ff28c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 29 Sep 2024 13:42:57 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[技术上，如何复现 o1?]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLnL1vTS0Gop09HAz1jYJATTG7fe4EoZhgCHvibXnQw52JKGRcnSibQuRx3EZXfExiaicz8sfwibDz4j3Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：周舒畅链接：https://zhuanlan.zhihu.com/p/720127190基础模型搞 o1 首先需要一个基模，这个基模必须是：能进行“长”生成。注意这和“长 context”不是一</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444938&amp;idx=1&amp;sn=51efa3f775a7f157d617c3ee1173d705&amp;chksm=bf02bcd87ecec0e6c5393ab9e834bbe7400765f140e590ba94eb49df9e0dd4279aa60f77bbd0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 28 Sep 2024 13:57:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[全量指令微调有害！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLnL1vTS0Gop09HAz1jYJATuxViawCndp2BicLTxsW3ib8X9UwbA20wzcSAZkNuSbonI9sowKoB6k4Iw/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：楠楠楠楠x  链接：https://zhuanlan.zhihu.com/p/721870518https://openreview.net/forum?id=XkHJo8iXGQ本文介绍一篇相</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444938&amp;idx=2&amp;sn=66709c5bea393b87e0db0f8b611027cc&amp;chksm=bf3bc06657d19094f4442ac4a6ebc6ce005e274c37c29d7efe4ff04bde8efabc08ce247fc96c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 28 Sep 2024 13:57:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen2.5-Coder 技术报告详细解读]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajR5iaVgyAYgBz3CGJd8icONwQXgkHcIl2ahNBlWpjv7vvGzAKITaeFThPH3MjfAmMauLO88hRg64LQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：Xode链接：https://zhuanlan.zhihu.com/p/7211894990. 前文1. 模型架构2. Tokenizer3. 预训练3.1 数据3.2 训练4. Post-Tr</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444938&amp;idx=3&amp;sn=09e7f0772ab035cf27614253f130848d&amp;chksm=bf418c00fbfcc942e1b9caa1138606b1f739f391ff09ac93c6b8ac582f30dbe5f3afaf509a82&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 28 Sep 2024 13:57:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Bge-en-icl: 当in-context learning遇上了text embedding...]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKpsBj3RsWAbywuTEXdljjM4wJibyvfCKMDHEdNTVPJrNGDW1fg4kURu5HZfwtibBZejVK9cl1lic4k6Ng/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲1 简介2 方法    2.1 模型输入    2.2 Pooling策略    2.3 训练方式3 实验4 实验结论5 讨论参考文献1 简介    In-context learning作为大模</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444938&amp;idx=4&amp;sn=60a8f31b80a33e8bc83083a66357cde9&amp;chksm=bf8ad969f4bc1b101fc3cd9b5f2d82261354c88887f9fb9e180961c55545af36b06e469fe182&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 28 Sep 2024 13:57:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[普林斯顿大学提出首个基于MoE的稀疏时序预测大模型，参数量扩展到2.4billion]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/dcUv9UF2OUWExicV2x7NVsdKYBsnczia0dOOP1Fx47wQlQBA26Sdh2ibDRNX4I6YeEA2Mu5t4SSd3sacfxv3icpwvA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一篇普林斯顿大学提出的时间序列大模型工作，是首个基于MoE的百万级别参数时间序列大模型，将时序大模型参数量扩展到2.4billion的水平，在多个数据集上取得了显著优于其他时间序列大模型</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650444938&amp;idx=5&amp;sn=4ecc2b8a65c801b19c10cb618a51c8c2&amp;chksm=bf530afbab88a64082858c926fd22f6b90dadbb6767cca8ed4aa96c17717ded97952bf149744&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 28 Sep 2024 13:57:03 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
