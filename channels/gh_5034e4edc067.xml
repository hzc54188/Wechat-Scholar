<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    









































    <item>
      <title><![CDATA[大模型“超级外挂”RAG详解：一文剖析 LLM RAG 关键环节]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLxomWAdm7cv4HvfPveOnELznZiaE4ymr3jqGIHJK8ichTl1x4Zm7ibTaKLqaEjIhOiarFibwRxesZzkEQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>LLM RAG（Retrieval-Augmented Generation）是一种自然语言处理领域的模型架构，特别适用于生成式任务。它结合了检索和生成两种方法，旨在提高生成式任务的性能。RAG模型在</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442161&amp;idx=1&amp;sn=365de158d571639e2dd2e56cf27fbe45&amp;chksm=bfd0ef7c7a909f4fbcc1dc67ffa2574cd31c4ba49ed8aec08c124b113f42322ca8bf9ed12a84&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 25 Apr 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Llama3 实战笔记]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/goiboxqfW2fY24vLibzkZaZpcPdZzWqISsUK9ncqJgnkYTgvBAN03HTX6QVnYZgtnPtJIegGlkJdALMoiciaibcZ6tA/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：lucas大叔原文地址：https://zhuanlan.zhihu.com/p/693407124当地时间4月18日，Meta在官网上公布了旗下最新大模型Llama 3。目前，Llama 3已</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442161&amp;idx=2&amp;sn=abff8760965a5480113fe58c2bc88ec3&amp;chksm=bf68a7779fabdc736fac9b954478d111dd39f9df16dd56a01c1d72eefef0b6042d4d3a88b7eb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 25 Apr 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[LlamaFactory进行llama3微调，有Colab教程可上手体验学习]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/aaN2xdFqa4HZ1FfPVEic7bfIoXGR1ct3E7DBD3DicSg170eKjRB7kDQpiaYmibDibeagFAQb4JuEoHxaqGOe9qckHVw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近，大模型领域最受关注的事件就是meta发布了llama3，前段时间我们介绍的LlamaFactory也第一时间支持了llama3，并且发布了自己的Colab微调实战案例，并对外推出了两个社区中文微</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442161&amp;idx=3&amp;sn=8122e9ea435293b2c3a56c98be627790&amp;chksm=bf57a2aabee4de365eb8e6de8bc83c2406e29162d887be715fed2704ad73f7d4cb854b5eafcf&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 25 Apr 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[RAG结构思考：搜索系统范式和大模型作用压缩]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jT5Sp7MICPwR2rt050wcr54pqVkMdpg8tbhc1YGkL2POFN7oV7F7G7QJpKv4WBvoCxcryBjpzu5rV9OMibsib1IQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>RAG的文章写的也不少了（心法利器[111] | 近期RAG技术总结和串讲（4w字RAG文章纪念）），除了原有知识的串讲，我还想聊的是在已经阅读的文章里带来的一些新的想法和思考，形成自己的方法论，我自</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442161&amp;idx=4&amp;sn=16840dec94e597c2241e3ce461970fb0&amp;chksm=bf3091f35226b1fc5f48e4a10361c6c1b6f3872de140389cd1a6f556ac39063b51a33d5b8c6c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 25 Apr 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[TIVE: 数据高效的视觉指令微调]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/G7ia3FZ0o0OrVbxmhbxMUws6gxs3WQxTIIwGakIT6ib5iajXHmDYyW1VxTz9g1AkVSAI7FrQaXZZmpwZQS48uhticA/300?wxtype=jpeg&amp;wxfrom=0"/><p>© 作者｜刘子康机构｜中国人民大学研究方向｜多模态大语言模型视觉指令微调是构建多模态大语言模型(MLLM)的核心步骤。现有的视觉指令构造方法主要有两类：基于大语言模型自动化构造，或是基于已有的多模态数</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442161&amp;idx=5&amp;sn=464882e5beef6b19f5474372b85efd66&amp;chksm=bf26af44011dff003837a734238a19f625a16aab6fb93b04fed7ab5f330a15cc3cd3abf5d1d9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 25 Apr 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[超越GPT-4！可以在手机上跑的大模型火了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL4p2akjQhibicHnmfIkCm3fiapjavfdNadeXz3uVH0Gno7yp3ZKibvBp5opAPib7l1n6FQSQzY0jtAIvw/640?wxtype=jpeg&amp;wxfrom=0"/><p>近日，斯坦福大学研究人员推出的可以在手机端跑的大模型 Octopus v2 火了，受到了开发者社区的极大关注，模型一夜下载量超 2k。20 亿参数的 Octopus v2 可以在智能手机、汽车、个人电</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442143&amp;idx=1&amp;sn=58975a6548fb5ca2fb53e154df2bd6b7&amp;chksm=bfb7d1eebbe9c268ace78aa8189a3faaa269e366e2e7ef85a0dc9647d8d074bd4aa0dd2cbad4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 24 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[小身材大能量的Phi系列模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/fI41EfAgQvs0hATDmUOibllk0InNN3UgEuZ03WH6td4gyPAvyHZ5Mibh86ibTvdfl1OOJ2exK6Je6YCicFpCTdqLTQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天微软发布了 Phi3 模型，3.8B 的小体量做到了 Mixtral-8x7B 一样的效果，在社区引起了不小的轰动。fuyao 老师直呼不能李姐我前段时间曾经试过finetune Phi2 模型，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442143&amp;idx=2&amp;sn=cb70bfd5dc7beaae3d09c25ad5047f2a&amp;chksm=bfb95a4be7d03cff8bf728150a065134e889f092ae621b87f8d9ad45b15ab15acc1547442e91&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 24 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[腾讯混元招聘AIGC算法研究员（文生3D）（深圳/北京/上海）(社招/实习）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLxomWAdm7cv4HvfPveOnELftkX9OQOv9ibWscibk4C27sIjscuBIjJyyJ3hcVUKSQdcY0BGAQiazpRg/300?wxtype=jpeg&amp;wxfrom=0"/><p>混元AIGC算法研究员（文生3D）（深圳/北京/上海）（社招/实习)岗位职责1.通过对AIGC大模型（3D生成）的研究优化，提升模型的生成质量、速度、多样性、可控性；2.推动3D生成模型工业化部署和产</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442143&amp;idx=3&amp;sn=925af897ea8e552cd3595a6d69f2657a&amp;chksm=bf3fed863c8b46bafe081ec30520e1c2b7e816e8ccf914ced135ca27934fc96ba5648c80e723&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 24 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[逐模块解析transformer结构]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/hN1l83J6PhicDnd62Fp95Txq0VsMqNhQ6OaVSiaB2xRIHYlgCgtBQe8QN0PvWWucjibLm9BYK3fHSEe42RFzMvoibw/300?wxtype=jpeg&amp;wxfrom=0"/><p>transformer是一种编解码（encoder-decoer）结构，用于自然语言处理、计算机视觉等领域，编解码结构是当前大模型必包含的部分。编解码结构图：image-202402212212066</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442143&amp;idx=4&amp;sn=64cea6d91b4003623dcfd63120927245&amp;chksm=bf806715b7422a5a04bc8fd76ee745a342985fb2e81c8db1fcd10614b191c1a5107bd25e8b42&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 24 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[欢迎 Llama 3：Meta 的新一代开源大语言模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2qfRjsshU99yFbxqJO0PhcoHVXlWSnvVibTasbUa8jskpwkmwp2ibicaKreFiaU7t1nEkLDwV0MHR9Cgw/300?wxtype=jpeg&amp;wxfrom=0"/><p>介绍Meta 公司的 Llama 3 是开放获取的 Llama 系列的最新版本，现已在 Hugging Face 平台发布。看到 Meta 持续致力于开放 AI 领域的发展令人振奋，我们也非常高兴地全</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442143&amp;idx=5&amp;sn=98aaa3e9461406f04bb18452ea9c007e&amp;chksm=bfeb3519d7ffb48ce477dd6dcc8007043646e06db6a6e94215739e0bf0cb001fcf75d856ea7c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 24 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[时序Transformer/时序大模型：一文全面了解时序预测新利器]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLd7tbpyCOF60ibCOKAicm5qyT2KHWq0lPKnG8XvCezaJNoMeO7wjuGreWzAfJtccXE9H4LQ5dSuG9Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>时空预测引领了新的热点，时间序列预测领域的首个大模型 TimeGPT 引起业界热议，Transformer+时序，扩散模型+时序更是顶会新方向大热“种子”选手，时序+多方向正在成为这个AI界瞩目的黑马</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442131&amp;idx=1&amp;sn=07e874aba676af2b453c094d0424d12f&amp;chksm=bfdad7dd086e2983085ee7d5f6d3c1a6d77fb51263b872e814db20d11df2c1a78632f42a81a3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 23 Apr 2024 05:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[生成式模型的奇葩应用：生成式检索]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/fI41EfAgQvvp0Ftz1BiaxUBLd8ql4yBZsz8jDZGEGqY2ZZSlJlotOaibvIL25dz98ibBZ7x4D2x9vnfrYGyMsAXPg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近在学习一个奇特的技术，叫做生成式检索。生成式检索是一种利用生成式语言模型来检索的全新信息检索方法。不同于依赖外部索引的传统方法，生成式检索利用单个强大的模型来处理查询和文档语料库。在这个注重推理能</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442131&amp;idx=2&amp;sn=6fe0dad400b4dbde76c5edcfabe80774&amp;chksm=bf87e298c9b38952e38544afd120d93d185d03037557227834b576b6883ae3261a76c53596c1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 23 Apr 2024 05:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型综述出书了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/G7ia3FZ0o0OrMibKZD9j6kdJMSmWgDqbtMfbF3vRrBJ5WOmGt9SENj0xdicicKKKu7umPv6o953FKob8wCDB1DKX4Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>在2023年3月，我们发表了大语言模型综述文章《A Survey of Large Language Models》。这篇综述文章已经更新到第13个版本，包含了83页的正文内容，并收录了900余篇参考</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442131&amp;idx=3&amp;sn=d59b69e376de29a9a2a50d67cc89300b&amp;chksm=bf5bfcd4846070a079b3c8f11f8ce979cbf403f63c9b6197e20bc5dacc9c0037575fb6c07266&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 23 Apr 2024 05:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[TikTok商业化算法-大模型基础算法/多模态方向（上海/北京/新加坡/温哥华/杭州/深圳）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIPrhlC7uRGiaibAkPlGoicx4Ep35D1cMHa92Ox3qQvDwUnnXEC60u2GiaOG3lQPicUrKg5xU1qOaZhS1A/300?wxtype=jpeg&amp;wxfrom=0"/><p>TikTok商业化算法-大模型基础算法/多模态方向（上海/北京/新加坡/温哥华/杭州/深圳）职位描述1、负责foundation model和Generative AI的基础能力建设，追踪业界文本生成</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442131&amp;idx=4&amp;sn=c986e2cd2ac7d318bdd191ab1224ebbb&amp;chksm=bf85c7ea106ae7fcf592729a24c872a030d70dfc687194a01e154228138248c54366ce7e3acc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 23 Apr 2024 05:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[好样本，事半功倍：使用样本设计工程 (SDE) 来构造更好的大模型下游微调样本]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/QLDSy3Cx3YKiaYH0m8ooBMJH9TIjQHjjWlicN3bYfTq6NjOyET7Io4exHUuVyFI9WH7Fy8AWfaRib9MAmIYtRA6nw/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注我公众号的朋友们，抱歉了，转眼本号已经断更了9个月了，这大半年一直很忙，实习、写博士论文，更重要的是我角色转变了——当爹了！所以得忙着照顾老婆孩子哈哈，实在没空没心思提笔写文章了。很快就博士毕业了</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442131&amp;idx=5&amp;sn=8b4177780db397725888d73b87003cfa&amp;chksm=bf8acbd09b46189f46221dcab3029adbe04280e2bf2d718c5fa946c20f865a520bf7eb9170b5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 23 Apr 2024 05:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[总结！大模型微调（Tuning）的常见方法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLPouOjY3Pw6QbcLI6Fzj7icQnZ5rgt6pqNpuyS1pRZEYGVlardAANpW6Fg3iaIq2lX5PBNrhCabUBQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着大模型的飞速发展，在短短一年间就有了大幅度的技术迭代更新，从LoRA、QLoRA、AdaLoRa、ZeroQuant、Flash Attention、KTO、PPO、DPO、蒸馏技术到模型增量学习</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442104&amp;idx=1&amp;sn=de4eb499a064256dc2b4e4a95e52b779&amp;chksm=bfaf20fd22326c0aa7033359e9ef62f66f142a6358d2e9f3ac1fb6e1d7a8e1f919762324bf33&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 22 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLaMA3初步解读：ScalingLaw颠覆之作，弱智吧挑战及格！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hq9ANWCLRic02SrWsex3IWx5YHr8Ek0jb7kRqzEe00mPKf11mpGBbkLIg3Cf1NFdsG0tRJcX1Dkm0UOhw7lB3ng/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言4月19日，全球科技、社交巨头Meta在官网，正式发布了开源大模型——Llama-3。Meta 表示，Llama 3 是在两个定制的 24K GPU 集群上、基于超过 15T token 的数据上</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442104&amp;idx=2&amp;sn=f4e3ea9c00cc619e51c28ef120294e3d&amp;chksm=bfacfe6ca6bb198c2a046f8d4b284cbc0b62b3b70086441f14a7d51f31d149273450b2f87ed0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 22 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[分布式训练：DeepSpeed 与 Zero 数据并行]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HAFUHkn3vxtrDU1tcLmm3RMHzLrFIkTHoviaHEm2z6pDC5g9262RvA89V8H6OiasiaBNYFVGqpPUosX2gWar5qfCA/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言随着大模型时代的到来，数据规模，计算量，模型参数等各方面都有巨大的增长，这给训练大模型带来了一些挑战：显存的挑战：当前常见的GPU 显存如 A100 是 80G 显存，而如 175B 的 GPT-</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442104&amp;idx=3&amp;sn=86905a31ee9e4982f2e7361f4a912123&amp;chksm=bf527f5086c6dd5f20071813878716866bdc8a4efb74e4b13f4147b0c10bcdaccde75b87f270&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 22 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Adaptive-RAG:根据难度自适应检索方案]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jT5Sp7MICPwQwZMDRCQwSicjM2DVsibT96WeK6sn6NvMPqFEJYnRbkUulBtXGf8TIiapq2J5FEpoflPVNsJAEXCQQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近RAG的文章，我做了一个串讲，有兴趣可以传送过去了解下：心法利器[111] | 近期RAG技术总结和串讲（4w字RAG文章纪念）RAG的论文可谓是百花齐放，今天讲一篇有关自适应的RAG，这篇论文认</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442104&amp;idx=4&amp;sn=4a710f39eebdbf1c88166ad644bc2351&amp;chksm=bfdeceb11236e3fec07c0819ee6641befde4d093b58335cc2be481b237c6824c2bcebef5dde9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 22 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型算法题(4)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW465ibxFAt7ZWLho7dNSxqpOibfDFviciardImM09QYAjGmtmiaxhY5nWcDZiaUQQjo1UlRscvXdJQjib38tBQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>本系列将持续整理一些LLM中关键的、细节的、值得关注的内容，持续更新~如有错漏，欢迎指正~1.为什么Transformer用layernorm而不是batchnorm首先，NLP数据中由于每条样本可能</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442104&amp;idx=5&amp;sn=56d73923438e1b01a5bef2a46561e459&amp;chksm=bf592c6289d9ff55ad01c0e64bf6a5d3ba79feb6c4b027356456dbabee08ce6107b9a270d617&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 22 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[安徽省委书记：对中国科大有求必应、不讲条件，我和省长随叫随到]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLPouOjY3Pw6QbcLI6Fzj7icicy1xRIGia0fksicicHA5rP2yZN3RAm9XVzEuvLzdCX0uyVVGyf2cKv8Kg/640?wxtype=jpeg&amp;wxfrom=0"/><p>转自 | 机器学习算法那些事来源 | 第一时间、安徽日报3月6日下午，十四届全国人大二次会议安徽代表团举行开放团组会议，全国人大代表安徽省委书记韩俊接受采访。其表示，对中国科大有求必应、不讲条件，我和</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442094&amp;idx=1&amp;sn=72f798831f1be6289b71d503d2c55091&amp;chksm=bff6a2db565d777d0ef2f533b5b146e40a175465de9b5649b550b02aa038e4ec061a400d24af&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 21 Apr 2024 12:31:30 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【文末赠书】大语言模型：基础与前沿]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLPouOjY3Pw6QbcLI6Fzj7icpsQsMicL7RjPudmXesSA9VbGia0uaicl6wcoZJGVa3EFcIpCAoCTHBoEw/300?wxtype=jpeg&amp;wxfrom=0"/><p>文末赠书Part.1Devin真的会抢走你的饭碗吗？全球首个完全自主的 AI 软件工程师上线，它是来自 Cognition 这家初创公司的产品——Devin， 这个名字也随即引爆了科技圈。话说 Dev</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442094&amp;idx=2&amp;sn=899bfc005a320b4f77e5519b1e2edd4c&amp;chksm=bf31b808d0287a884eb81401a7babad1ebb88648e1eee0f99aaccb93f2ebc0a719b85567f57c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 21 Apr 2024 12:31:30 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[从代码实现看normalization-到底做了什么]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW467MBj30DaAfuJ11bcMns8ibD4Du0u9zNX8ibUroHicrM8v4d4ib8VNW0XQKmiaJUfspUaaUjWKvHbThkEA/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前在《transformer中normalization的二三事》从思路上梳理了关于常用的normalization的内容。发出之后收到了一些反馈，关于这些norm在实际使用中是怎么实现的，有一些疑</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442094&amp;idx=3&amp;sn=f912301d2e85815eeda81719172bd2ca&amp;chksm=bf3b78752efbf3cc68b910797121491ffb72503ba5a6e727da293a934598557a8bd51fe5fc7a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 21 Apr 2024 12:31:30 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一大堆Chinese Llama3正在袭来]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5kAtCrqMZn1zObKFd9JrC3WdjqICuNcLh6GALUodzDoUUuUvCztoxXIWgQsAUYbR7icQP03Z5uAMBg/300?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面Llama3模型已经开源，可以就在这短短的两天之内，就出现了很多Chinese-Llama3 repo，开源社区也是相当的卷。再看到Llama3相关报告的时候，就预料到会有很多Chinese-</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442094&amp;idx=4&amp;sn=4675fd40d3d3d436ef2d50c8f570cb4a&amp;chksm=bfce8b4aef6e1b26ce8ac98ba856f5cc818750fbdac79c0f359101c0a7e714811a2621ebc9d8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 21 Apr 2024 12:31:30 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Ask again, then fail--摇摆不定的大模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKpuh274J78Db2k1JQlWnbuqRasAd3jsW8kT2cpS0IibaFM5FXlMOSryIJHupkzk4qwFvgLc32YAfHEw/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲1 简介2 问题定义3 Follow-up Questioning Mechansim4 实验5 结论参考文献1 简介    研究人员观测到传统大模型在面对用户进一步追问下，经常会生成跟之前不一致</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442094&amp;idx=5&amp;sn=e32fb554887b1c04b49d47a5ad062024&amp;chksm=bfe7a3cc3dc3914fac7c077d573dbb94405add0530a2a908691ef843c1377981ae2881fc1a39&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 21 Apr 2024 12:31:30 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OS-Copilot：通用计算机智能体的自我进化之旅]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKuU4pEgMq2TUDB0OogETcMrMQ8RPH3cMjIddfq5ZHcVgNexNwxS5R4SeY7iaHATPdGR7so1pPbzvg/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文：https://arxiv.org/pdf/2402.07456.pdf项目主页：https://os-copilot.github.io/GitHub：https://github.com/O</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442063&amp;idx=1&amp;sn=9347061043202e594343ce779ab1b0c4&amp;chksm=bfa5b2b6b267f47577da0a8f316c9d76d4323760ac83f0f4ba7650cc0401958de60ee385b550&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 20 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[从啥也不会到Cuda GEMM优化]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkOa6nCcwjgzpqdtwDKcicWm2jYRRIKBA67Q3jO3GLic0EeKw59CcuAu3RuPibrG9nUQwYrFwoGotdI1w/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，这周本来是想写vllm的blockmanager的，结果在整理笔记时，看见之前入门cuda时画的一些手稿，一时手痒将它们整理成这篇文章。除了图解外，所有代码都配上了非常详细的注释，希望对于cu</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442063&amp;idx=2&amp;sn=28388a6bdf6010bdaf85b13d6db2bd95&amp;chksm=bffcb1878012f5df742937158fe5173cd87feed3ba7cbaaceb3184e8db93c4c87bd7226abe16&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 20 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[浅谈Llama3、大模型开源与闭源以及合成数据]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKuU4pEgMq2TUDB0OogETcMgicdw2ByX7PNpTBp1gxIHVtNRKhvN28JX5riaKhyzicpLf5HwM7YjK0jA/300?wxtype=jpeg&amp;wxfrom=0"/><p>整理：NLP工作站今天凌晨MetaAI发布Llama3，不少大佬纷纷发表看法，在这里分享一篇@张俊林大佬的想法。知乎: https://www.zhihu.com/question/653373334</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442063&amp;idx=3&amp;sn=6ba0b18bc658fc968d943a0006677c12&amp;chksm=bf9c60c82602de540a2f7ef43400faba882a5134ae819a87dd1df96192cd2e11698c49646d66&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 20 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型参数量都是7B，13B和65B等背后的原因是什么？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/aaN2xdFqa4G8AuF94LePm6obnfV5lq4gz2LnfxDxibt81MM3amKQhusbsKyNwv0totwcMU0lQrUwnvSmwlvpffg/300?wxtype=jpeg&amp;wxfrom=0"/><p>不知道大家有没有注意到现在大模型百花齐放，但是模型参数大小却非常一致，基本都是7B，13B，65B等。那么，为什么被设计成这么大呢？网络上有很多解释，笔者结合自己的理解，分享其中可能的原因。最直接的就</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442063&amp;idx=4&amp;sn=d08494e85343e7c96e4a2898b0c62a8d&amp;chksm=bf3311f534ed81602d108e46f2a0181b76635520fe02b816e22723c18960a16e6860d9861b05&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 20 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[考古RAG-20年RAG概念提出的论文]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jT5Sp7MICPyDlJN7J3JPfKMVXM0fckbibicyeBibcFaFYicpYjQvjgF7hFJB5MkT5joiaHWkxFTjNNm6MdLhKo7csNQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>上一期是写了最近RAG文章的小结（心法利器[111] | 近期RAG技术总结和串讲（4w字RAG文章纪念）），里面提到RAG比较早的一篇论文，可见RAG这个概念并非大模型之后才有的，早在2020年就已</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442063&amp;idx=5&amp;sn=b6f079ecbb3cb70dbfbc1b067616e0a4&amp;chksm=bf3cb0a7d6e6e41f66874f0fb06d3850179c371edcf35bde6afc092284effbe024404efd4697&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 20 Apr 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLama3重磅开源，上车！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKuU4pEgMq2TUDB0OogETcMVFserT3QFXALlzc0GgqAL5kBYbmbic9eibIXriaI5SLeGicF5mXyYicWJcQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>Llama3 今日发布，提供了8B和70B参数的预训练和指令微调语言模型，而且这些模型很快将在AWS、Google Cloud、Microsoft Azure等主流平台上可用，得到了AMD、Intel</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442014&amp;idx=1&amp;sn=dee5f54024d77528978d76c5e19dc144&amp;chksm=bf113398915cb9bce3cafd471bc24f4098f47d9f7d824d5f8e963240793fab49b2aaa232627c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 19 Apr 2024 03:07:42 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[迄今为止最强大的开源 LLM，15 万亿 Token 预训练的 LLaMA3 强势来袭]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/J0mLianhFicBFKF5WgMRG4iaToCBQOPpdAmcscic40fZZezhkNMnJq93M0Kj3jibW9AjInYhrVKov5aMyicFxs5y9vTQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>刚刚 Meta LLaMA3 强势发布，迄今为止功能最强大的公开可用的 LLM。此版本是在 15 万亿个 Token 上预训练的语言模型，具有 8B 和 70B 两种参数规模，可以支持广泛的用户场景，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442014&amp;idx=2&amp;sn=0db3bd3ab350228d0afaffa83e620d8c&amp;chksm=bf4d52e535fcb7a333abf5309b1b373555ec5f3a4434b6fc0c1e88e9b6e2f9e1a9d4d70a96bf&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 19 Apr 2024 03:07:42 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型：训练时GPU显存不足怎么办]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HAFUHkn3vxsxzia9YJ5suxelcyZtb0UDC4Gd7ZXHxzibVHlNc4QeVofJqS9oQ51ncvfzR9pVRguAOedPjz7PlnzA/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言大模型时代对显存的要求越来越高，之前在BERT刚诞生时候写过一篇：GPU 显存不足怎么办？，新的这篇文章主要是重构之前的文章，来聊聊大模型时代显存不足时怎么办，没有看过的朋友直接看这篇即可。 训练</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442014&amp;idx=3&amp;sn=f568e810ce5a6862dc9140ae2a9130bf&amp;chksm=bfd4b0c9782df4839cc0a42b257e2e4d788fcc74c83d686317418df77347e447e29480e4f90c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 19 Apr 2024 03:07:42 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【社招】NewsBreak北京招聘：多模态内容理解算法工程师（​北京）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKuU4pEgMq2TUDB0OogETcMtsXwbFXeKsJ6PZgEsPR7OvUwoZIvaDpyRLHOic4UVdrcic9JQGj9kUog/300?wxtype=jpeg&amp;wxfrom=0"/><p>【社招】NewsBreak北京招聘：多模态内容理解算法工程师（北京）1、NewsBreak是北美市场Top1新闻信息流APP，2019年开始持续盈利，北京团队负责产品研发，目前DAU千万级别，产品规模</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442014&amp;idx=4&amp;sn=0c3935c846bcd52bd1579bd71131a368&amp;chksm=bf83de3a12b4fb26544ca08663930f505aa4fdf5abebeca932b07c1b62eb6b01bb8aa9207356&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 19 Apr 2024 03:07:42 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[近期RAG技术总结和串讲（4w字RAG文章纪念）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jT5Sp7MICPxANVIITnSE6nB4gskBl3XicmVWcSM16bFESbNEHvt8wibmZgA7vptcRXoU3xtWCbUmgyLd6iaS04JwQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近写的RAG内容已经挺多了，然而内容逐渐变得零散，我今天给大家总结一下RAG的有关内容，同时给大家把有关内容串起来。当然，串起来的更多是概述和摘记，让大家对RAG的基础有更整体的了解，详情大家可以根</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442014&amp;idx=5&amp;sn=83541e9d48168d3e6f2999db69ae766a&amp;chksm=bf9577969b07dcd7ef0917cd2eacb848cf0a458e0856bcc5791899e6190f1efb9ab6127f537e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 19 Apr 2024 03:07:42 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
