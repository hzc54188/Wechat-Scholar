<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5034e4edc067.jpg</url>
      

      <title>gh_5034e4edc067</title>
      

    </image>
    



















    <item>
      <title><![CDATA[阿里、中科院等发布CodeArena: 基于人类偏好的代码大模型评估与对齐]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJITFDJywQjVQLXf1PSEELMUFEyAjuG66ThCXLs0Vuiaw6ZFOdPiaw2ic3GTFEheZywq0A5jAetBMX1A/640?wxtype=jpeg&amp;wxfrom=0"/><p>当前CodeLLMs已经成为开发者的得力助手，为了更好衡量生成代码对人类偏好的满足程度，本文提出了一个应用场景广泛、编程语言全面、问题来源真实的基准测试集，CodeArena，以及SynCode-In</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446331&amp;idx=1&amp;sn=0659634898ade7aa3461ec2a003aee21&amp;chksm=bf5e4692f011617753ee0c3a9049eab83509d17e8ff724cec20e8cf4771399cca22a2a11492a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 12 Dec 2024 10:50:01 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[吴恩达主题演讲：前瞻AI AGENTS，颠覆未来想象]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJITFDJywQjVQLXf1PSEELMa8Bibbgza1yeYMianib247lZ4R9xILcoB25B6iagibED1c5rZC4mGUxk3ibw/300?wxtype=jpeg&amp;wxfrom=0"/><p>吴恩达主题演讲：前瞻AI AGENTS，颠覆未来想象。中文GPT翻译版本，仅供参考：如果觉得上面的版本翻译的不够好，可以直接学习英文原版：进技术交流群请添加AINLP小助手微信（id: ainlp2)</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446331&amp;idx=2&amp;sn=65799748cd506226a68d4271837da3ea&amp;chksm=bfd78cae739140e43b92cd8562d832e63e9f07f1c89ac2de333c25664d37bd0c0e37c607be1b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 12 Dec 2024 10:50:01 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[Idea也能自动生成？|  浙大阿里联合提出科研Ideas自动生成工具SciPIP]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJiaGpzSia4W0t6tjAmxABibjSlGPk1kGicffCJz090WXPuHOHsccmd5ZqAQZsrdxkbGzb5cqlgYbdAKw/640?wxtype=jpeg&amp;wxfrom=0"/><p>创新是推动科学研究进步的核心动力。然而，面对庞大的知识体系和日新月异的技术发展，如何打破思维的局限，激发真正的科研创意（Ideas），成为了科学家们亟待解决的难题。如今，人工智能大模型的发展正在为科研</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446304&amp;idx=1&amp;sn=0f280b3b31d6a4df978c0afed534f462&amp;chksm=bfb119913852d1b8c699ba893e4ddb930287263aa0b2610086215dd89ed8f5eec055bd70c56e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 11 Dec 2024 11:04:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[EMNLP 2024 | 大模型对齐中的低冗余优化]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/G7ia3FZ0o0OrDbYdvXkZgExsp74V8jAXJypZLx4J9DFFaRY4pZfIm28FgbKsHswxpry587mk1uXDCoGriaKia5fzg/300?wxtype=jpeg&amp;wxfrom=0"/><p>© 作者｜陈志朋机构｜中国人民大学研究方向｜大语言模型低冗余优化是大语言模型（LLM）对齐训练中的一项关键挑战。本文提出了一种新方法——ALLO，通过优化最相关的神经元以减少训练过程中的冗余。具体而言</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446304&amp;idx=2&amp;sn=4e7649405eab1520ed2ceac3f9f00d4a&amp;chksm=bf4f87a41dca725c3f832abf95085443a5a9feaae1ad3cbbe737ca2a3d66c0d833757fb60448&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 11 Dec 2024 11:04:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[千问LLM：什么是Pre-LayerNorm 和 Post-LayerNorm ？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iabUOs2OBUhTJchV1800lWEhIq8F6xhCBBmI7mrYULAlSl0oCbTL3shIUt5ic9JRFtYZSMek7jTNicib53iakDz9dSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>千问LLM之二十九：什么是Pre-LayerNorm 和 Post-LayerNorm ？“Normalize to Optimize 归一化是为了优化。”这次终于明白了。我们再看看什么是 Pre a</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446304&amp;idx=3&amp;sn=6212a26d411aa0d1a7fc167c64a74de7&amp;chksm=bf53ca5b17f1b7b147866784065c0e359e7bc79b544b5a249b69c53dd6a7042c5f756d9becd3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 11 Dec 2024 11:04:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[英伟达被立案调查]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKdIxzGdYrPZBt6gwoT1UolILU37ibv6EP8RLLYib41iboQ3GURM98EdmeM7IQOL5nK4piafjdbMo6lZg/640?wxtype=jpeg&amp;wxfrom=0"/><p>英伟达公司涉嫌违反《中华人民共和国反垄断法》及《市场监管总局关于附加限制性条件批准英伟达公司收购迈络思科技有限公司股权案反垄断审查决定的公告》（市场监管总局公告〔2020〕第16号），市场监管总局依法</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446277&amp;idx=1&amp;sn=2be153c709ace9452c587c40a61de76f&amp;chksm=bf7d9f5d0610776057ba1ac5a77bcd87faae0a1dab5a157487532be2811a3d72cec9dda4842e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 10 Dec 2024 10:32:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[别吹Sora了，实测一言难尽。甚至分不清人脸和猪？？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qElwgCKdzgY4wOdpicf1haqX5VKO7wME2qsaR6SX3Fsr9vANFTDIj5w5lAUDQ4tXMbgdnloiatyicF2Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>毫不意外的，Sora今天全网刷屏了。Altman直接穿着带Sora logo的卫衣没错，Sora来了，立即可用。Sora官网：https://sora.com/先来看看官方划的重点：现在的Sora性能</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446277&amp;idx=2&amp;sn=828650bb6cead0ea04b8064f3db0cd62&amp;chksm=bf01a64b6ba3d0ca585c9230d611fdc81e5e7fde43f3ee289bf62e8ec28014309c9ccb07f554&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 10 Dec 2024 10:32:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[让大模型自我进化成理科优等生]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/9MSPBmHaWGwSToFrVF8pmc54rwU2T4jJzfL1XOW0g4Hic8YramTC41UfKicxCTtWmkWps8dTUdyNyD5lDtOEM3qA/300?wxtype=jpeg&amp;wxfrom=0"/><p>01团队介绍    ai-altman-win团队成员共两人。队长是戴志仕，组员是叶晓蒙。    队长戴志仕是一名资深AI架构师。拥有十多年人工智能算法研究和产业落地经验，成功实施过多个AI项目。同时</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446277&amp;idx=3&amp;sn=c33c350f3b6a6a96c9eab9e6f450c548&amp;chksm=bff9578c9332328fc01a126941f0b7a36c84173aaca7d56517ec68b07879e82c679416bd326f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 10 Dec 2024 10:32:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NLP入门必读—复旦大学《自然语言处理导论》PDF]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJLLR9P18DWdLzwWfgCSHeslkdZZRR8phubMicXmAIneO4v6o8DnaPpnX2J5KvQicjcdib1LFEICxQLA/640?wxtype=jpeg&amp;wxfrom=0"/><p>介绍大模型大火，这个风靡全网的 AI 应用的各项能力是从何而来，它是如何演化至今的，未来又将走向何方？ChatGPT是通往通用人工智能的未来吗？还是像Yann LeCun说的那样，大模型解决不了自然语</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446267&amp;idx=1&amp;sn=f6c4ef1023b3baeec635e43cedcdccc0&amp;chksm=bf4beb8a74119df96e78e1463c48539e2f315bde2c5324a629461ba138640ea9d77c39e13de5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 09 Dec 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[傻傻分不清？一文彻底说清Agentic RAG的前世今生！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/wT3y8Vg9pFF8oejUibdmbWHRqn4FmhJicedzz67ia6YSdkhkws3XtiawOSJwiboZP6QW2qsJZGa8fdmylKLicYtJRCjQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>生成式AI的发展日新月异，一不小心你就会淹没在新的概念中。RAG（检索增强生成）、Agent（智能体）作为主流的大语言模型（LLM）应用形式已经广为人知。这不还经常听到一个词：Agentic RAG，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446267&amp;idx=2&amp;sn=07a3572f28d34630b9399c9a68d5353f&amp;chksm=bf3a2da6b95499e93ac9d008bfd687f526e6a17a9645f92bf5d615b0ac42c615107f432473b7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 09 Dec 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Huggingface 大模型的下载与上传]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/uuUZMmZ5aQCeuJXRh6jibiblOHFwRwKalLQg9eAbC14yMRWibE9szxOwlYEDthGibBt4HoIoyhwPxiaibTtdibocqOUSA/300?wxtype=jpeg&amp;wxfrom=0"/><p>下载假设我们需要从 Huggingface 下载 Qwen2.5-0.5B-Instruct 模型1. 使用 git lfsGit LFS 是 Github 开发的一个 Git 的扩展，用于实现 Gi</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446267&amp;idx=3&amp;sn=81ea1745ffa78563b6385eec3df00e06&amp;chksm=bf6e29f752931ccf9ab8c5ee6a94d75bbbd42c860e6cdb30f1bcfbd8e7282ac9fbd606d3844a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 09 Dec 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[google search: 用emb模型做个性化语言prompt]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jT5Sp7MICPwtJliaZGsjsyewxHUzkPT8VxPZahIsaGIJicngj2gIgicx2y4nctqgC9bWcEDbpovLa0T1ibOibn4hZeA/300?wxtype=jpeg&amp;wxfrom=0"/><p>大模型具备很强的信息推理能力，但在很多实验经验看来，直接把特征通过文本prompt的方式扔进大模型内，大模型的理解并不是很好，一方面是对特征并不能有很好的理解，另一方面现有特征到具体任务目标的映射关系</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446267&amp;idx=4&amp;sn=ab8771d68663a7d84abed549affef96d&amp;chksm=bf331631e2e662906c0d9db2932ec31a76e3912ae13f3a41fa9ddc39dffc7bc514817d539939&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 09 Dec 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[华为IDLE-Adapter:LLM融合稀疏ID完成推荐任务]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hg6UPGp0Hib56T8yEmxdVLmOavHo60uzhkTIkSeOWJKrrickvQhGSdOMemQovmSJIA2gbgXCLCUUk0SN0ttO1nmQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文标题: Break the ID-Language Barrier: An Adaption Framework for Sequential Recommendation链接: https://</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446267&amp;idx=5&amp;sn=47a6c5a147bfbfa4d1352a3e54bf28d8&amp;chksm=bf3dca2fc39b24325eb3434026f073fee361648529a035d6d2a623ae655615160228618276b5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 09 Dec 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OpenAI发布强化微调技术，SFT退出历史舞台？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKAbKiaeBAE63zNh5flibftS53O2icNnHiaUcLwQd78zHFN2LsYovSVTp8kW6BZVK4Vhoppgicgr0CPPlQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>来源：包包算法笔记大家都听说过监督微调SFT，强化微调是个什么东西？这次为期12天的OpenAI发布系列的Day2，就搞出了一个让开发者震惊的玩意儿。强化微调（Reinforcement Fine-T</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446258&amp;idx=1&amp;sn=5fa0bbde9c4ed43effc3c8ce705bfd69&amp;chksm=bffb72ed30d7e4ed97c9556662dc98ae8636a8f852c0482a4af04ad68e10df8e6fbaac20e251&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 08 Dec 2024 12:47:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[PyTorch显存优化小技巧——Gradient Checkpointing | 文末赠书]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLoj1IoZicnjWw6picltiaxyGiaQg41RVBRwblWE72Q5Hubj6sWJJLibViaibOyibgmyMejrIZocepndqPrlA/300?wxtype=jpeg&amp;wxfrom=0"/><p>文末赠书          各位被显存溢出困扰的朋友们，是不是有时候会有这样的疑惑，明明两个模型参数量接近、大小相似，但训练的时候，一个模型动辄显存溢出，另一个跑起来却毫无压力？           </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446258&amp;idx=2&amp;sn=b42e2a814b80f66771391fbb95433cc9&amp;chksm=bfd3eb4b831d306f18c2bde3756a9e8b6e43c1b8bb496c6feb7ad6c5426673e3c5e6d0d212e7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 08 Dec 2024 12:47:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM不会CoT隐性推理，只会显性推理！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bah8ia2Tb5tVvK9Vq6sua8bMZfa43eE7HAwtmGymzZ9T36HzeEfriaSrlibAfkic7Yh9vibzJXle48ic8ohw/300?wxtype=jpeg&amp;wxfrom=0"/><p>这篇文章探讨了大型语言模型（LLMs）在隐式推理中的表现，发现尽管隐式推理理论上更为高效，但实际上并不等同于显式推理链（CoT）。研究表明，LLMs在进行隐式推理时并未真正进行逐步计算，而是依赖于经验</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446258&amp;idx=3&amp;sn=f90c83d7efd33d49352fa7f0bf7f9b58&amp;chksm=bfbce25c70eeb2f3d9bae986ebaa1841fce6030d97f67918357e8586cbabfe64adf62d6840c3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 08 Dec 2024 12:47:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【重磅】2025年IEEE Fellow出炉！ 300多位新晋升会士！国内多名学者当选！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKAbKiaeBAE63zNh5flibftS5A2jIvuY6HdZkuQ5lVbpIAeBu2ogzFMdY7OvsHoM8z5sXKpFJm0IQaQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>来源：专知最近，美国电子电气工程师学会（Institute of Electrical and Electronic Engineers，IEEE）发布了新一届 Fellow 名单。当选的IEEE F</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446234&amp;idx=1&amp;sn=9f4a1754d030ff6847e81fa01b1586f0&amp;chksm=bfe47c0f202d8d630125e8b7ad753609bb370307d02bc254eabe0b6f51305f8a14b633326b03&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 07 Dec 2024 12:54:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[本科生大作业给8分，iclr评审机制的失灵？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baj9UNxfkzBKLNYMPCJOArsQnHQ7VHTrAIbYBkIE9d8qp1ndN80Wnqca5XdysNT62XiaXtia693Nzo5w/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：难赋——以前看见个评论说ai的十分制会议中的10分指的是“如何这篇文章没有中，我将断绝与该会议的一切联系”，要是今天讲的这篇论文中了iclr的话，没准这句话对于iclr来说可以改成对8分的评价了</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446234&amp;idx=2&amp;sn=9f6778bd101d751ea7996e0dc9a917b8&amp;chksm=bf82655e28f69bf656c1070db45eda100aa1a3992bd0e21a32dab7fdb3c043dc06ec105837f7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 07 Dec 2024 12:54:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[千问LLM：三大AI助手的“奇葩说”：ChatGPT、KiMi和Claude的对决]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iabUOs2OBUhTJchV1800lWEhIq8F6xhCBBmI7mrYULAlSl0oCbTL3shIUt5ic9JRFtYZSMek7jTNicib53iakDz9dSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>千问LLM之二十七：“奇葩说”：从一个大模型输出错误中，看出它需要改进的路有多长？亲爱的网友们，今天我们不聊明星八卦，不聊政治经济，我们来聊聊那些比肥皂剧还精彩的AI助手们——ChatGPT、KiMi</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446234&amp;idx=3&amp;sn=091a3d0effbf319e9452cd7516ab2368&amp;chksm=bfd3777dae13a0ae977c06736b27f8784c60218c3a136a14a94a1fba5ce9b6468b21fd0f001d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 07 Dec 2024 12:54:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[vllm 中量化模型的推理速度对比]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/uuUZMmZ5aQABYSzYvcOja4cqsQkpO340JSichlBvia3qQSxsmZGcY7JgNicsBl7emjEiaB1aHDocs7uD8JfNtRCKDQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>从 moss-003-sft-data 数据集中采样 2052 条中英文用户输入数据，基于 vllm 0.6.1 推理框架，分别测试了 Qwen2.5-7B-Instruct，Qwen2.5-7B-I</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446234&amp;idx=4&amp;sn=1bdb151b40ad4c23135bbbdb8eae825e&amp;chksm=bfdec9d583a14434583f0d15ad4482b03a03bb13ab8dfd8a1d60a283c7248839123bf819a328&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 07 Dec 2024 12:54:19 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
