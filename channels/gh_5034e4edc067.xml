<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    





















    <item>
      <title><![CDATA[博士第五年，我还没有找到论文创新点?]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL3K3oMA2Qkibu6LSBpQdl4bTKME60vlKso2PYDx6UeuGs2ANsZL9V2MuoKhpicG9WfMCsOZLtu9guw/640?wxtype=jpeg&amp;wxfrom=0"/><p>写论文之初最难的是找到一个不错的idea，这是非常重要的。因为如果你有idea的话写起来其实挺快的。主要是多看领域内顶刊文章，模仿别人文献的框架和写作思路，找几篇文献一段一段的模仿写作各个部分！但是说</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443367&amp;idx=1&amp;sn=b0a79daba2389b76935019f0a2951e62&amp;chksm=bfa94aebc978a42fda0cfbd2e329543a7876647671248d259b36dad207fb85c2ac324218f334&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 03 Jul 2024 02:10:44 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[详解这一年多模态视觉-语言大模型的架构演进]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJBjALrmcKhJBOkDNCr72ibPA10NpmW55To8GTQgGIy0kA5KjXOWJDJic3hDtn9IickmflOqCdo5uSrg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：Dreamweaver，SJTU × AIGC/LLM，腾讯公司 · 多模态应用研究 (实习)声明：本文只做分享，版权归原作者来源：青稞AI原文：https://zhuanlan.zhihu.c</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443367&amp;idx=2&amp;sn=af2e4e8d80c51f4fd2ea2c46127ee979&amp;chksm=bf513a559f5093411ce32bcc8b199100836fab5309fbc5a75fcc0390ad065cace660837dc84c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 03 Jul 2024 02:10:44 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[幻方&amp;深度求索DeepSeek 核心岗位实习生招募]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJBjALrmcKhJBOkDNCr72ibPMRdouxRKicbu5EibthoSgibaKAIEEvbGCB5OM8VbG0fFdmUNPNzcGBcWw/300?wxtype=jpeg&amp;wxfrom=0"/><p>幻方&amp;深度求索DeepSeek 核心岗位招募公司简介：我们相信大模型是科研 + 工程 + 组织的优雅艺术。我们正在寻找并长期培养优秀的 AI 人才，与我们一起进行高水平的科学研究和工程实践。如果你对人</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443367&amp;idx=3&amp;sn=77787c5941aeb9b8267df60245883144&amp;chksm=bff07fe51acae9c779438fcf3b4815fa4b0a39bc828f9f18eeaebe5207ec89c3396b756d8a6e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 03 Jul 2024 02:10:44 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[成本10w刀的JetMoE]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW4679JTaaic8JeQ9vIJWaa0ibc1ryjVC2NicdKjNZicjHicrjVDiaJTx6wZvoyibgs41EoDrZ7fTL0YicSbOc5g/300?wxtype=jpeg&amp;wxfrom=0"/><p>JetMoE是由MIT、Princeton等几个学术机构发布的MoE模型，其总参数量为8B，激活参数量为2B。训练JetMoE的总花费约为10w美元，而JetMoE在各个benchmark上都有不错的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443367&amp;idx=4&amp;sn=ce0fe297f2f07c8d24023b7fa8ffeef5&amp;chksm=bf84ba967d50eafed8d10a19021863bf46fc1529554306cc8cdebd050b967ed195960e38df0c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 03 Jul 2024 02:10:44 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[再读deformable detr，还有多少细节是你不知道的]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkMT6icFF1npz4SMWfTwKIczgFH2Nsx5icQGNmFSJW32GVYbrFOVg95soRhuoTE80XZYy86kcRhbvaTQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，今天来写写基于Transformer架构的端到端检测模型：Deformable Detr。如果你也读过Deformable Detr的论文和代码，你可能会发现相比于原生detr，它确实不好理解</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443367&amp;idx=5&amp;sn=25a76d14c1f485d6935d9b72edc59956&amp;chksm=bf6e8717d2c4f1163572c89292d1eff276c9917650ebf6618f63e7824b8d0a6b6e38fe9304b2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 03 Jul 2024 02:10:44 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[多模态大模型，彻底爆发了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIN3EPicAEiay4NMTKLS5LmMlVhbxdeialTPB6YU5AqeAfoXkQWdux0Z3nL952jlticKEyvKBSaundoog/640?wxtype=jpeg&amp;wxfrom=0"/><p>自从ChatGPT和其他大语言模型的出现，人工智能领域发生了巨大变革，尤其是视觉语言多模态大模型的研究和应用。（文末有顶会idea分享）这次我将重要的多模态大模型资料包括670篇多模态大模型论文、14</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443346&amp;idx=1&amp;sn=f2a84c47b26c70dce11b6eca26f27da4&amp;chksm=bfe57433dae36516a124e79449e960913e1565a0989fbb8f1db8bdb8cba237a67cc2f2ee8a19&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 02 Jul 2024 02:09:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型训练十戒]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuwh5Oh4u8kQEV0Q7GBicSdkwOl08M4a3GKJG5fIw99YztD05JIW2XY9QibLCGWo5BCqTAf49dMibNwYw/300?wxtype=jpeg&amp;wxfrom=0"/><p>注：之前发过一个简洁版：大模型微调十诫，这篇算是一个带原始信息比较完整的版本今天看到一个很有意思的东西，言简意赅，字字玑珠。加了注解，与大家分享。新造的LLM，感谢尊者开悟～1.切勿微调（Thou S</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443346&amp;idx=2&amp;sn=e39328797b18f786760e44a5cc909a0b&amp;chksm=bfbcae1db57d1cbc67cd3d5eb98d6ff2d1ecdd038a188341141f834eca704bd92d543b831a52&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 02 Jul 2024 02:09:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型上下文长度扩展中的检索增强技术简述]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/58FUuNaBUjodxT3b8OjYSyFMPZCrgIFzesXshZtW7um11xlfu9zYzx1x3DibodY9eZXgGiaeoiaJdSI2dln1SdMMw/300?wxtype=jpeg&amp;wxfrom=0"/><p>笔记作者：刘议骏，徐阳出处：哈工大SCIR背景介绍基于Transformer的语言模型在众多自然语言处理任务上都取得了十分优异的成绩，在一些任务上已经达到SOTA的效果。但是，经过预训练后，模型能够较</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443346&amp;idx=3&amp;sn=80005f3bd3c1c8280744450af0d41ce3&amp;chksm=bfd4eba5f825129dea86fd7f3e66411dc05935e477728c81793e62b72ac28d9c1cf2c3a8b53c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 02 Jul 2024 02:09:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[XTR检索模型简介]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BAVX0pafImmXiafibfaV7VlKohmeynS9SZlsjwTtJRhZKGfDO7GmVib2VLTOFpr9iboTWroRIjOkxkqMOTCv05CicyQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前写过深度检索模型的介绍：# 深度文本检索模型：DPR, PolyEncoders, DCBERT, ColBERT，今天来看看DeepMind在NeurIPS 2024上的文章，对多向量检索模型（</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443346&amp;idx=4&amp;sn=10345ddd1f22274b44672700489bbacb&amp;chksm=bf72a0e61ccf837a44965f90a8597374f6fe6e46fd9716ab32fbf03aee5b2d1aa28a138620c4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 02 Jul 2024 02:09:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[BigCodeBench: 继 HumanEval 之后的新一代代码生成测试基准]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2r0KXvibdsDP6u1bDzDMhH7NmezMNkQ17X06LEu6VhicibZibeuj6QmxpXzrjBEGunQ3tyibunvCdWibJBg/300?wxtype=jpeg&amp;wxfrom=0"/><p>HumanEval是一个用于评估大型语言模型 (LLM) 在代码生成任务中的参考基准，因为它使得对紧凑的函数级代码片段的评估变得容易。然而，关于其在评估 LLM 编程能力方面的有效性越来越多的担忧，主</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443346&amp;idx=5&amp;sn=9b02993c12a94ebaeb374dade1368ecc&amp;chksm=bf5cde8835936adccd432a365eca4bf68f1ff650ab4dae893badcc28ba2c633de704c238ca16&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 02 Jul 2024 02:09:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024 年了，你的长文本训练数据真的够长吗？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIN3EPicAEiay4NMTKLS5LmMluhANuzdTiaia89zJqJyZwf2xUnSMrC6XQka3g4mQXibTPmdnxcx9k1uww/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文标题：Long Context is Not Long at All: A Prospector of Long-Dependency Data for Large Language Models</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443336&amp;idx=1&amp;sn=009f49aeee7e4f4cc5903bf85d2d641a&amp;chksm=bf7a38571daaeb6049c5f3ed8b26df73bbfd99269f1a5a402c61049b7b9d910907493909840d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Jul 2024 14:01:28 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[月之暗面kimi底层推理系统方案揭秘]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuxe5SBIw9qaAr5TDcgtpiaFBaWrEaiczwSogfnx8akps5MN7fibOcQ3F41DuibrT6ezpvvQG9SnGLxGxw/300?wxtype=jpeg&amp;wxfrom=0"/><p>太长不看版（作者大佬自己的在知乎碎碎念）：本论文与很多 Prefill/Decoding 分离的论文不同的是，这套方案已经在大规模集群上进行几个月的验证并证明了方案的有效性。目前这套系统承载了 Kim</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443336&amp;idx=2&amp;sn=ff8a2773a5bb2bbbd2722babf6ef2bb6&amp;chksm=bfa22c96eef8708ae399c328d640ec528c54e41143980fea519e1dbad905081419813f85d588&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Jul 2024 14:01:28 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Hugging Face Accelerate 两个后端的故事：FSDP 与 DeepSpeed]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2q4zkWrSBs9FJnBuEVmExTheMebSct2qta6dqg8hlaqiaIOs7nWZQ8P2F2Pc7GwHMQPfnh7FxjeEwg/300?wxtype=jpeg&amp;wxfrom=0"/><p>社区中有两个流行的零冗余优化器 (Zero Redundancy Optimizer，ZeRO)算法实现，一个来自DeepSpeed，另一个来自PyTorch。Hugging FaceAccelera</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443336&amp;idx=3&amp;sn=5972bcf2e987b2c2b4e424dc1348e7fe&amp;chksm=bf156a5fe0043ddb743f9e9b2c910a81e81d6d4ebc83c017ea8c5b707ff2359b8f0d56423478&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Jul 2024 14:01:28 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Multi-task Hybrid Loss Training：因地制宜，充分利用数据信息]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKpvTic1FcPFgVHjqObjWIIrlIOibLSmPY0ibtRApXlKDjTviag7LRiamOyLF4l5ulJ4SMIsqQkkskDWn6eg/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲‍‍‍‍‍‍‍‍‍‍‍‍1 简介2 Multi-Task Hybrid Loss Training    2.1 Retrieval and Reranking Loss    2.2 STS a</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443336&amp;idx=4&amp;sn=50cc9b707353fdc001400cd192d70bc6&amp;chksm=bfe6d841966147d69de2b885bfbc190161b2f7c039db8ff8169ca3acdce25333c7dd62e6199a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Jul 2024 14:01:28 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[深度文本检索模型：DPR, PolyEncoders, DCBERT, ColBERT]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BAVX0pafImm4UvL6oG2x5VZurZKMg8vptiahHX4YFCVqBFyns9n6iaXCjvAGLlfPSU7fqqoibeOjXHk9McDzVoHtQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>文本匹配与检索是NLP中的经典问题，主要研究两个文本的主义相似度，通常用在检索系统的召回阶段。传统的召回方案如tf-idf和BM25具有速度优势，但在语义匹配方面有所欠缺。随着预训练模型的发展，使用深</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443336&amp;idx=5&amp;sn=2884c1d7434f2fc3d0d493531e67f213&amp;chksm=bf8d00a4a422b72150f3f455320b381c5af97b2c77bf3cc8406ef035a9976b5179de304c29d9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Jul 2024 14:01:28 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[GPT-4o炸裂登场！大模型仍是最大赢家！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIA1W521D3d1eUZQOGBDKA1TFUwJMbRVLPSZQfr3eHrHb6ESLiadNoyNOTLKCfb60WfV6y6e4eKBicQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>从一年前ChatGPT突然爆火，到不久前文生视频大模型Sora以霸屏之势吸引全球舆论，再到OpenAI发布的王炸GPT-4o，与AI大模型相关的议题越来越多地被大众所讨论，如果说2023年的大模型风暴</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443290&amp;idx=1&amp;sn=bb3c4a517629f9e59813573a88739704&amp;chksm=bf6095931c0fcd88dee71c6baa0a18f9ddc41033ac0e68de1b4538f419cffac7c7cc11094bae&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 27 Jun 2024 01:29:31 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解MoE是什么，以及大模型为什么需要？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLJafiaSCI5sfmEUB5x6SrRIeeOl3SlH6k8EmeCRL2ZocFSPic1r6UH0SeX5IKfTVrG7SG1LBge3ic1A/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：蓟梗，北京邮电大学声明：本文只做分享，版权归原作者来源：青稞AI原文：https://zhuanlan.zhihu.com/p/694826485MoE，全称 Mixture of Expert</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443290&amp;idx=2&amp;sn=a5674706a2ebcca8333b211056c0959b&amp;chksm=bfd87467e0d91df52062ecfcccba56f3ccb9dd81ad55372661ea4693b2f80f101353f8d2e463&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 27 Jun 2024 01:29:31 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[更难、更好、更快、更强：LLM Leaderboard v2 现已发布]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2oQRQku1E1icBklls2AGo56twsHe2nQCfJVZxJKIQhibRNXeD1FatcFd10bzsDfNRfUQU4zibxuKlL4g/300?wxtype=jpeg&amp;wxfrom=0"/><p>评估和比较大语言模型 (LLMs) 是一项艰巨的任务。我们 RLHF 团队在一年前就意识到了这一点，当时他们试图复现和比较多个已发布模型的结果。这几乎是不可能完成的任务：论文或营销发布中的得分缺乏可复</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443290&amp;idx=3&amp;sn=309c93fae0d036fc98b2750eed7bd734&amp;chksm=bfa5f920e199a11d2ed744c49c68aba63085035b57baeec28c6d0bfca4ded20d3e241df8765a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 27 Jun 2024 01:29:31 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【RAG论文】通过HyDE提升检索效果]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVeWCCMYFhPDicrl1ufG0TibKmBzoKdh4RdaxTc8CbYZgEsuvXqJibpgvUoibESo5H2texbkdSoNrxu4wA/300?wxtype=jpeg&amp;wxfrom=0"/><p>paper：https://arxiv.org/pdf/2212.10496code：https://github.com/texttron/hyde这篇文章主要做zero-shot场景下的稠密检索，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443290&amp;idx=4&amp;sn=80d314463d570591cca8edfab7945db8&amp;chksm=bfb3576c3d4c703b375819bcabcc2206a97610f6fa5f2c4bb8f12d9dae88e4d2977320f1a68b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 27 Jun 2024 01:29:31 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【TKGQA】关于时间知识图谱问答的一篇综述]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGDiaDkY5InpbL3LmQibUDMgbKDzjwJoVdDyOnx3elxzPQtXX99YSPXs4S5EfjR9ITD53py3htZiapjXw/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言时间知识图谱问答（TKGQA）是KBQA中一个关注时间问题的重要子任务。时间问题包含时间约束、需要时间标记的答案，反映了现实世界事件的动态和演变性质。一、TKGQA1.1 概述时间知识图谱（TKG</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443290&amp;idx=5&amp;sn=9fb8e519de23339d3886574a7ec7d15c&amp;chksm=bfe636a74e81b7ba67b0db691ad9d7299ba24995c0c45f9aa82667e0838668d8b870ae5cd187&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 27 Jun 2024 01:29:31 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[无需人类标注！在环境交互中实现LLM的自我进化]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIA1W521D3d1eUZQOGBDKA1ZZUxaEDXycgsxLY81SmvBHuugKdzIIUU3NuXvoicsiaf6sHlB5KYqtzA/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文题目：Interactive Evolution: A Neural-Symbolic Self-Training Framework For Large Language Models论文地址：</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443269&amp;idx=1&amp;sn=d0cfd9ac4bbd16e0e4ec0313cfe210de&amp;chksm=bf2db3facedfcc25b588d093ef30a98ca36786522949d67681a87f38ede24c70094b7dbfaa37&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 26 Jun 2024 13:38:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[文末赠书 | 24岁提出图灵机，38岁定义机器智能，70年后重识图灵，人工智能之父的传奇人生]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIA1W521D3d1eUZQOGBDKA1u7cuf7VibTcGsJwtboQO0EjGWHoCylcw4facUVScibGK6o9xtTBEUShg/300?wxtype=jpeg&amp;wxfrom=0"/><p>“Sometimes it is the people who no one imagines anything of who do the things that no one can imagin</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443269&amp;idx=2&amp;sn=d5260cb1f9805a527fdca8c0dba7a736&amp;chksm=bfb31bf60d5b0dac7ef89dd6cc2ed412c9a35b1b52695e0bf7b24c8c5db4073dc8ef027a109c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 26 Jun 2024 13:38:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[RoPE的远距离衰减]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW4679JTaaic8JeQ9vIJWaa0ibc1hkIP2sfZ3zDTPjC3MIvQicGJugybnGAicgOYDFR8tPiaRpUtQRaN6nohQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>有朋友问到了关于RoPE远距离衰减的问题，这里给出几个示例，提供一个直观理解的视角。之前对RoPE的梳理参考 理解LLM位置编‍码:RoPE。1.公式回顾一下RoPE的实现。RoPE通过在q和k上分别</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443269&amp;idx=3&amp;sn=cc73685229140fe3f46b016719738ec6&amp;chksm=bf280f675bcb5ba64b31e34e0ecc9ce829eb1db9c4e8f64dd750a758636004e9a7b740934e71&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 26 Jun 2024 13:38:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型面试之MoE高频问题]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/s7YKINJYHDBtI8xU7iaZibGqQEZwaQ0HZ3QIsTkfFs0rYV2nlicwnJJArvZbRrETzucS3LAicF9n6b32lkXzChZU0Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>MoE原理回顾MoE 是用稀疏 MoE 层替换前馈层。这些层包含一定数量的专家（例如 8 个），每个专家都是一个神经网络（通常是 FFN）。然后，路由器/门网络负责选择要使用的专家。MoE 的一个显著</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443269&amp;idx=4&amp;sn=2c44520e8be9e9802f4690854645dcda&amp;chksm=bf184abb03f9e6525c84cda9b744e5390bad8ab26bae9106be2ce6854252588736fe29006b12&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 26 Jun 2024 13:38:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Meta生成式推荐模型GRs关键问题探讨]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/TnZw73HawgmbOTibiaOFCHtZ51pWJd5iaWU0KqEd4BvMia4p7ibujfINRPOzqicE8ZmnHpsaLrdutzojUSr5KQUYz3lQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>此前我们解读过Meta生成式推荐新作: 行动胜过言语: Meta落地工业界首个万亿级别参数的生成式推荐系统模型，整体工作很棒，但有一些关键问题没有交代特别清楚。在和作者交流的过程中了解到不少信息，同时</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650443269&amp;idx=5&amp;sn=144aaf27301fe00b5bf5ee2898896a1c&amp;chksm=bf903272ab4e999cfac48275fc656df769bbbe21adeed4b322c77a24c1955764424d26cbdb30&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 26 Jun 2024 13:38:43 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
