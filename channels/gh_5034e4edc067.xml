<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    




































    <item>
      <title><![CDATA[终于不用为GPU算力发愁了，请低调使用！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKMLxS3B7FLiccokFuo1FpSuBZlCXCr5zzZUJHrZl3goJN10iakzLicUDYQvLyMrpNSBpFEMDqh7Xr0g/640?wxtype=jpeg&amp;wxfrom=0"/><p>价格全网最低算力租赁价格，搭配高端 GPU 机型 H800、A800，等你来体验！潞晨云网址：https://cloud.luchentech.com功能Colossal-AI镜像潞晨云服务#特别活动</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442869&amp;idx=1&amp;sn=67ccd1e2026e68e9fc424bc926dd03d3&amp;chksm=bf03c8b6edec8da475b7b1dcd4024c1dc24f431a25e252ee3ba788e83b137bb190630911a829&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 05 Jun 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[关于Scaling Law、合成数据、MOE及长文本的看法及未来]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSICxBS4fqNHH4unelJlqnFOEMIboNfVV79kvyIzvhztK6Zzicwc552ytGc2JRG5yX5ZEiarV5ULtZDg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：张俊林，新浪微博新技术研发负责人整理：青稞A原文：https://zhuanlan.zhihu.com/p/700622253以下内容是5月15日甲子光年圆桌论坛讨论内容，涉及Scaling L</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442869&amp;idx=2&amp;sn=348e2e295cc8d1b0e34cd9a37bf3245f&amp;chksm=bf6d6bcd7661495d4c0aad3806f5a15946ee324cf4d765e421075161d46df71a710aec7c6ee8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 05 Jun 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[KAN 会引起大模型的范式转变吗？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ica8cfOI46squbUTVBNHm68afScLk7WGVsK1Al2LgV9ITScydgicxxbyYToMPnADfQibhdLdz6GviatKibMmSJR1icpg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者 | 李维   高佳KAN 网络算法，如同在 AI 技术圈投下了一枚重磅炸弹，让 AI 界震荡不减。发布一个月的时间内，FastKAN、 FasterKAN kansformers等基于 KAN </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442869&amp;idx=3&amp;sn=fe34557c9ee2f48e82cd37b2dbca69ad&amp;chksm=bf17adebff37311718d978e87ddccc4c40d5d26e93e668876d2a1da0f439b150ac320244bbe1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 05 Jun 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[3万字详细解析清华大学最新综述工作：大模型高效推理综述]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bags6JYaA1MgpcHCnReDuYIlY2Qx2ZVrtvOA5Gbs8oUtb7qwWAQsoImrQuAPhGyPSuibzZvkDk8rNww/300?wxtype=jpeg&amp;wxfrom=0"/><p>大模型由于其在各种任务中的出色表现而引起了广泛的关注。然而，大模型推理的大量计算和内存需求对其在资源受限场景的部署提出了挑战。业内一直在努力开发旨在提高大模型推理效率的技术。本文对现有的关于高效大模型</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442869&amp;idx=4&amp;sn=22f5d8fcb4c7b7276eaefff46f97bfef&amp;chksm=bf3da23269bb7479adc29917ed126660a66c7d9f4b3e7ec3b715246aa1cf2e39c74fcb74dc7a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 05 Jun 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[北航x百度：大模型RAG遇到幻觉内容怎么办？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuytEE4LNzgkMuDgCUn5iaGXoRY3jA6S89Fuu1DT18c4NCiaibKyMCu5huI7PbfFPJerwhx8bDQicRIS0w/300?wxtype=jpeg&amp;wxfrom=0"/><p>大模型用于文本生成对话表现不错，但是一旦应用到需要密集专业知识的场景中时，就没有办法准确回复。好像一个没来听课的学霸考生，不可能什么知识都背下来（知识注入型预训练成本太大），因此这种情况下一般依赖他室</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442869&amp;idx=5&amp;sn=b2cfac9400fe4513841ab6478734aecb&amp;chksm=bfc306c509c3696333ccab999a660bbffcce7da674caa218e7da3a9eebec229d33e5960d234c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 05 Jun 2024 02:10:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[LLM最新方向：多模态大模型新SOTA来了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLbBVjUcvkl8J8SKvKz5yVfcxcg7kevqV4j7xkj5DJwQSfaZiaP1Tn2S9NbDlSUg6AuoLg6GWFyZ8w/640?wxtype=jpeg&amp;wxfrom=0"/><p>当前，多模态大模型（MLLM）在多项视觉任务上展现出了强大的认知理解能力，也成为CVPR2024备受瞩目的热门领域之一。我整理了210篇多模态最新研究成果，140份多模态和大模型报告、多模态大模型最全</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442848&amp;idx=1&amp;sn=3d848af033dec32e89905fc5ee598470&amp;chksm=bf215a799b0940aa51ae147beba757d0e74538e601cc1d0b18858ce8dc7675f148eb1e3f1960&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 03 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[浅谈RAG的十大挑战]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSICxBS4fqNHH4unelJlqnFO50LOXbFTuqjRQmqbI7a2zmGMICx9Zib97CWOk4Ayd8DeibheZgo0vmiaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：王磊原文：https://zhuanlan.zhihu.com/p/696904158整理：吃果冻不吐果冻皮背景介绍ChatGPT的火爆问世，让人们对问答机器人重拾了信心，有了大模型的加持，Ch</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442848&amp;idx=2&amp;sn=19aaf3bf2543e580901a3d4078043786&amp;chksm=bf79c6942099e01bca4a21083813f711c6ddf2387b6a47ef182d743482773421e69f9777bee2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 03 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型偏好对齐-simPO]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW465xeR8Yxcx79NMvdWIaibVdYM2ibQIq5jVbgPbJ3b9CqU97iaASYKQ606OTibJHQJ5RicPhibqooK4YeyibQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>前面我们对DPO和ODPO的思路做了整理：大模型偏好对齐-DPO，大模型偏好对齐-ODPO。最近新出的simPO受到了很多关注。相比DPO，simPO不需要reference model，并且有更好的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442848&amp;idx=3&amp;sn=c8084e486fa7e4cde3a7d4b40ff8628c&amp;chksm=bf4c2242cde82d9ffaf3efba30dac7f8c5ef4d41dd0e0547514a43e49b5a646830bc712ac507&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 03 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[蚂蚁&amp;清华：多粒度纯MLP时序预测模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/dcUv9UF2OUVzWnROo2rSGXwiapKKmbcdpHHECibVLufbXAfZQ22Yohu4qB8OQ9YWZZty4RliacKOurUjthicSFT4Rg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一篇ICLR 2024中，蚂蚁和清华联合发表的多粒度时间序列建模工作。这篇文章的整体模型结构比较简单清晰，通过将时间序列聚合成不同粒度，每个粒度的预测结果进行ensemble，实现预测效</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442848&amp;idx=4&amp;sn=1fc9229aa86f0152d79339ad281ca9c0&amp;chksm=bf739f641821d4baf38a2ed2575c88f236c97c091fd4c145baf537c427fc469aa1fd1cde2f35&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 03 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[BM25Retriever检索器实现]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVe2BCpicHs7AK0sqJV2eRKjrIichtp93llIlNMSaDraaoKoGA2VbOmopWWJTuSfO5VcfGYZnAUCmhXw/300?wxtype=jpeg&amp;wxfrom=0"/><p>原理下一篇讲，先贴出代码https://github.com/gomate-community/GoMate/blob/main/gomate/modules/retrieval/bm25_retri</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442848&amp;idx=5&amp;sn=d06a84f8b98df4f6911a82ce7643bb1e&amp;chksm=bfbef5fb142343a847d027994c29b1b0f049f439399e6603351fbe522e81c832dd0819cc55e8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 03 Jun 2024 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[最近，大模型岗位爆了。。。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSICxBS4fqNHH4unelJlqnFOWricen0jcngdpAGjJiaDAHXAQbT3nL54vq6iaGGt1LERS6iaBH9P0JJKew/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着GPT大热“AI大模型”无疑是最火爆的话题！Google、百度、腾讯等等巨头互联网公司，无不在布局人工智能技术和市场，甚至还有60k*16的高薪，挖掘AI大模型人才！作为普通程序员，如何不被时代抛</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442830&amp;idx=1&amp;sn=856f331013c2741257c4574e61108f72&amp;chksm=bf8e58e06a5d606e29802380769c96742b73890d2c60a790f8b38b33a1c025d8f35ff43f3802&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 02 Jun 2024 02:12:48 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型预训练中的数据处理及思考]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSICxBS4fqNHH4unelJlqnFO10JfUEMu72V8qE1NwUb8bJpPF908HKE7mhGyiaXk344BSKNgcJ28iaIg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：赵亮，NLPer；昆仑万维 · 预训练。 原文：https://zhuanlan.zhihu.com/p/641013454整理:  青稞AI大模型预训练需要从海量的文本数据中学习到充分的知识存</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442830&amp;idx=2&amp;sn=f52c9ab4485c3be0bdf46056504bc7b5&amp;chksm=bfe73c8e017bda16638422607502afce7182d1937eabdab1ca0f1225ace7390304e5f4c28393&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 02 Jun 2024 02:12:48 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【社招】【校招】字节大模型基座团队]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSICxBS4fqNHH4unelJlqnFOR8CQJnrV0T1eIQSkHYJOfibDlnUAfqicjNAU7sqO660nulOMLO1Zs41g/300?wxtype=jpeg&amp;wxfrom=0"/><p>【社招】【校招】字节大模型基座团队团队介绍：字节跳动豆包大模型团队成立于 2023 年，致力于开发业界最先进的 AI 大模型技术，成为世界一流的研究团队，为科技和社会发展作出贡献。豆包大模型团队在AI</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442830&amp;idx=3&amp;sn=97fa1bfafd2324d412e4491dad9e3c00&amp;chksm=bf37975bdcc5485b7fff2a5ea37adc26ce5e92216454cf3000bf8f8ea09fbb63d3f2fe31d16d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 02 Jun 2024 02:12:48 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Text2SQL之不装了，我也是RAG]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgwIeiblGHZ5OL94NeRhhlTXYxcQMd1rSpgMSjA1muGXoiczbRxqfPbuCqccrwicc7ic1ha7xibDnSAXAicQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>背景对业务数据库中的表实现问答。输入是用户的问题，输出是该问题的答案。这是很典型的Text2SQL的应用场景了，为了实现这一需求，很容想到的是把创建的表和表的描述都放进prompt里，让LLM去根据表</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442830&amp;idx=4&amp;sn=18cb281425dde074a313566fecdb9909&amp;chksm=bfac76276ed075f38875d8621411e387ba1223f6a9aa5abbd257099777cb2db7f8c0627bef18&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 02 Jun 2024 02:12:48 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[tree2retriever:面向RAG场景的递归摘要树检索器实现]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVfxreeynzukXOGdgrIhVEwzicUHbbSIyGDicKr7DPg8r9jzicIrSR9zZfGibE9aQVaqSXqFU70s2Rjn2g/300?wxtype=jpeg&amp;wxfrom=0"/><p>tree2retriever面向RAG场景的递归摘要树检索器实现Recursive Abstractive Processing for Tree-Organized RetrievalGithub:</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442830&amp;idx=5&amp;sn=707fd52ed45a565a412c8716de84c7a3&amp;chksm=bfa44f0df50f50dda3efa99e19c68006397750808f4c266af02f140d4e178dab7be819a8a549&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 02 Jun 2024 02:12:48 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[牛皮！我被银行码农的工资惊到了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSICxBS4fqNHH4unelJlqnFOiaBCudVyZgoNv0LBVCSQa2aLiaOcxKhWfUQpYCbaB9OKG86Po9WbtPIg/640?wxtype=jpeg&amp;wxfrom=0"/><p>来源：公子龙近几年银行信息科技岗是许多大学毕业生热门的岗位，银行越来越重视数字化、智能化的进程，信息岗在银行有很大的舞台，而且从事信息岗的人员也有比较丰厚的薪水。银行对于信息岗人才的需求是全方位的，不</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442804&amp;idx=1&amp;sn=56d3263e321aca6ff29815f6c27181ac&amp;chksm=bf27964ecabf39894d67af6d6343e0d753e48ab4f3dc612195252f77a20af28dc58b6a706f8c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 01 Jun 2024 12:53:52 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【文末赠书】解构大语言模型：从线性回归到通用人工智能]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSICxBS4fqNHH4unelJlqnFODibWXd3hVoZrY1fFU3zksd8ypN4oLlvut2azYlHeeA5Y4ZF6x7G4WSQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>--文末赠书--在大语言模型问世之前，尤其是在ChatGPT出现之前，人们几乎没有认真讨论过“人工智能是否具备自我意识”这个话题。尽管人工智能在某些方面（例如图像识别和语言翻译等领域）的表现陆续超越了</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442804&amp;idx=2&amp;sn=7c36e5cec2fe279df2b77f6bd4fd44e6&amp;chksm=bf3421c88a7e6872f42e1903a1fcb341a3ad5d09c51c4127ea27be20f31ed9270f8b7b16729a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 01 Jun 2024 12:53:52 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[垂域LLM训练经验之谈]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgwIeiblGHZ5OL94NeRhhlTXYBcMZKWvt64fPibtibmslHsgQdVGxk23GUIMTYaZVfAdTa73zwFgS0W1A/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言本文将按以下几个部分进行叙述：•全参 SFT•Lora SFT•Lora 继续预训练•Llama pro 预训练 + SFT数据说明：•预训练数据：由SFT数据的Query 与 Answer 的拼</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442804&amp;idx=3&amp;sn=6cc31cb9e5db37095f00eec3511fe7ec&amp;chksm=bff5913cc90b301b2403fbd5bf6f8f7877ef45ddedcf827b44fb9a0fa8255f4bb6d1f01fc55a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 01 Jun 2024 12:53:52 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型偏好对齐-ODPO]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW464qUnytfOG3UK1sr2guicBHKPEusIlL3Ftlu7IRtNz7JbOIhS6pIuhqfea0smEHMY3DScia5WrwyvibA/300?wxtype=jpeg&amp;wxfrom=0"/><p>前面对DPO的思路做了整理：大模型偏好对齐-DPO。DPO把RLHF的两阶段训练，变成了一阶段训练，降低了训练成本。而ODPO（DPO with an offset）在DPO的基础上做了一点改进，在几</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442804&amp;idx=4&amp;sn=39a5d13d5d2e8657d0b5cc219238c43f&amp;chksm=bf665678af84603d8ad6cc63d69673329302b6cd665597568c20042698b7477de65d58884e18&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 01 Jun 2024 12:53:52 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【RAG论文】文档树：如何提升长上下文、非连续文档、跨文档主题时的检索效果]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVfaaSLr4icM49JukA5Mas5ADYSq07ITTYY1FVico64k22pl0TZm7yRC4XI5LDttyc4JHGicl4lUpkfAA/300?wxtype=jpeg&amp;wxfrom=0"/><p>RAPTOR Recursive Abstractive Processing for Tree-Organized RetrievalICLR 2024 Stanfordhttps://arxiv.</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442804&amp;idx=5&amp;sn=41337592e22dc1d293d16e5e52fcbeab&amp;chksm=bfcea802cab0723d5d98ea7f53cfcfc2ec573bd0eaa0802d9e8854f19e0826e2f6181d2866f0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 01 Jun 2024 12:53:52 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM之王：多模态大模型的技术实践与思考]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJ5FLcps7pKNGCznkaHYg5tE1AcicZNCpPdWPmVLLD0Atth1VnQ6Eic8l2lUhybjSaYQNA2VYjsrRaA/640?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，随着大算力、大数据和AI算法的快速发展，GPT-4、Sora和Gemini为代表的人工智能大模型的成功标志着人工智能从以专用小模型训练为主的“手工作坊时代”迈入到以通用大模型预训练为主的“工业</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442779&amp;idx=1&amp;sn=a8886e0cc274a0a705f80268c3396c15&amp;chksm=bf780735330a310765435c9dc29640c34089f193ca76101845329b3eb2d6cadea9cf84c60285&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 30 May 2024 02:37:47 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[面试通过，背调凉了。。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/icmWrEONNM8VRzY030GFSViaia7chonEbiaicMYQyxz9BPsdPUK7rgfm0BicSnc6icHic44ulnZbG0ZWyrNtsOiagicVynmw/300?wxtype=jpeg&amp;wxfrom=0"/><p>有读者发消息说很苦闷，面试通过，但背调凉了，我问了事情经过，发现他还是太掉以轻心了。读者之前是在一家互联网中厂工作，这几年公司效益不如从前，薪资待遇原地踏步了很久，因此最近几个月趁着业务清闲一些，请假</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442779&amp;idx=2&amp;sn=49fbdf48d9c9eaf37a07fa9222907c51&amp;chksm=bfbc3073cade4038189460f7d1398b04abf02f2b8dd7427558e1c9ee125a5e8ced523144f322&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 30 May 2024 02:37:47 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型偏好对齐-DPO]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW466UoNmoOMVOxSWz1DibOJ7L8c3KrMcePQtqKpcTkbgaMt7JmeMR9jmA2I1ib1awqVxjsnUic3wIReYGg/300?wxtype=jpeg&amp;wxfrom=0"/><p>【本文已在同名 微信公众号 / 知乎 / 个人博客linsight.cn 上线】【点击左下角阅读原文可跳转知乎阅读】要对齐大模型偏好并不容易，从预训练的数据内容、模型的结构到SFT数据配比甚至数据格式</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442779&amp;idx=3&amp;sn=d21570a608a94032067455a4091e2308&amp;chksm=bf30271d91a1ff18037d3e3e190011cd59493327f4fce00b78e4ce06609b9719e6724e0a162e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 30 May 2024 02:37:47 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[长文 | 大模型偏好对齐全家桶 - RL侧]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5kAMFDSUOwEjZbqNfibneJzUianHtRjXWeoxELw287ZADlk4pbtw58euctmAAeAMCMRyzmV6ncvGblw/300?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面今天给大家带来一篇Reinforcement Learning from Human Feedback的全家桶，来自知乎@何枝（已授权）。随着 Llama3 的开源，人们对 Alignment</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442779&amp;idx=4&amp;sn=f6027c122ca1d185fcb41ed06d700982&amp;chksm=bfb629cc10926a4aff3f12ce0599645c85d8d449039688bc035a335e7d9aeb13de684615bf1d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 30 May 2024 02:37:47 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【RAG论文】检索信息中的噪音是如何影响大模型生成的？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVcbzqmc6GOKvudTrCkrdAsjObLg7xSXhc7NX1fy6icT5whNlgBtpGt3FjG14cibHYDxk14BMBubmYbA/300?wxtype=jpeg&amp;wxfrom=0"/><p>前些天看到的两篇论文，论文标题为：《The Power of Noise Redefining Retrieval for RAG Systems》《How Easily do Irrelevant </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650442779&amp;idx=5&amp;sn=4a110a1152186645e9977482458936d8&amp;chksm=bf45fa88dacb681dce3ae04258540ba1d629a60a617d79b517c8814b2ba654ff78fa7fb46d2f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 30 May 2024 02:37:47 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
