<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[OpenMMLab]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[OpenMMLab公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_38469f01690f.jpg</url>
      

      <title>gh_38469f01690f</title>
      

    </image>
    







    <item>
      <title><![CDATA[NeurIPS 2024 | 真实世界复杂任务，全新基准GTA助力大模型工具调用能力评测]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/ialW0xobVWP55XppcUa0YlYOhJHRQrpG44lwafWh4vUgPdic4T6oYsMulO9IB7VhGpb7k0icNUUQRvTicqPhg050dA/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文转载自机器之心本篇论文已被 NeurIPS 2024 Dataset &amp; Benchmark Track 接收，作者来自上海交通大学 IWIN 计算智能团队和上海人工智能实验室。其中，第一作者王骥</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI4MDcxNTY2MQ==&amp;mid=2247531553&amp;idx=1&amp;sn=1cf821115b22a555aa6baaf5c45cb269&amp;chksm=eaa8de028a98e7f03f50c324cb31600c6811c8b2d6f4ee3a9ea1acefe12077bb42ad67ffb243&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 06 Nov 2024 10:22:44 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[直播预告丨揭秘新一代大规模声音克隆TTS模型MaskGCT]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/ialW0xobVWP4M61A7jdNBaomUIXbT5Yu54pqlCFsNg4CzSNIAUwiaGGhXn41bMG4TK7I7IVeEbCkktQ2OBoQtDeA/640?wxtype=jpeg&amp;wxfrom=0"/><p>（实战营第4期正在火热进行中，欢迎报名）【社区开放麦】开播啦！！！技术下饭番追起来，每周一个新芝士。欢迎广大社区同学加入直播间参与讨论的同时，也非常鼓励社区同学拿起话筒登上舞台，社区知识开放麦等你来玩</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI4MDcxNTY2MQ==&amp;mid=2247531537&amp;idx=1&amp;sn=b4bb0d0c2810dc727ca7858fabc71626&amp;chksm=ea67a057a6c35fcac446b63030dca14ecb993bf45d36c5aaa965d65019ad27e7a448b8e5fa8b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 05 Nov 2024 09:02:38 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[突破短视频局限！MMBench 构建中长视频开放问答评测基准，全面评估多模态大模型视频理解能力]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/ialW0xobVWP4MoYFZ1PxGzhMbHBygPGQODdgfdTxhADdwuMX1XIsZx4DrJ6zFo5YxIsECYdK0ks67JWC1kXtOCw/640?wxtype=jpeg&amp;wxfrom=0"/><p>（实战营第4期正在火热进行中，欢迎报名）本文经量子位（公众号 ID: QbitAI）授权转载，作者：新宇GPT-4o 四月发布会掀起了视频理解的热潮，而开源领军者 Qwen2 也对视频毫不手软，在各个</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI4MDcxNTY2MQ==&amp;mid=2247531507&amp;idx=1&amp;sn=bf08370c5f8e1893d8d91af1159094e1&amp;chksm=ea885fc45292654d5ff3828205f1eb2543c51edd6305fb39aa6d536d9b1bb75c3d1ff96bf38a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 04 Nov 2024 10:38:48 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[「AI 科研团队」VirSci，创新能力超过AI Scientist]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/ialW0xobVWP5LwpxibdQcNRglP72FnWka6BcwXzIUhFFM2SgwUh9S9xJ5nh8Fby3GW07fATIsBxZh4O6rT5WkYiaQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>（实战营第4期正在火热进行中，欢迎报名）由上海人工智能实验室提出的 VirSci（Virtual Scientists）系统是一个基于大语言模型（LLM）的多智能体协作平台，专注于模拟科学家团队的合作</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI4MDcxNTY2MQ==&amp;mid=2247531484&amp;idx=1&amp;sn=d14eeca3bd1d6f99e0c2d22729e9482a&amp;chksm=ead818c1386e4ebd45d32f4d705f3c7db3c2ca1b4abc3666abe86b836f4e7ddbd22ed4abdf0e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 01 Nov 2024 10:19:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[InternLM2.5系列模型正式上线OpenCSG]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/ialW0xobVWP4AuWNr5KXuMDhK47Dc6y5kz32a7xzuLn119Qia3hRjdzEeX20om4jdVPtInTf3xyibrjmlAHTibQiaPA/640?wxtype=jpeg&amp;wxfrom=0"/><p>（实战营第4期正在火热进行中，欢迎报名）InternLM2.5 系列模型现已在 OpenCSG 社区以专区形式正式上线，大家可以灵活选择算力，快速启动推理服务，或利用平台提供的丰富数据集进行模型微调。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI4MDcxNTY2MQ==&amp;mid=2247531463&amp;idx=1&amp;sn=1d041bf092170f8c6e58cec42a034c6e&amp;chksm=ea85e251b46178e4d0a7e1a1ddbd9d6b4e5dda0c0540dc2ad6999601eef851a3154202b5a905&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 31 Oct 2024 10:12:38 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[InternLM2 RLHF 技术解读（一）：奖励模型理论篇]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/ialW0xobVWP7KA8L8xDmcTwIVEaPAEicARicesBIKKlq4xWF2UW4QBKsDziboAdU1HiaOBboA3HlKZHeYAJCdibnNnbA/640?wxtype=jpeg&amp;wxfrom=0"/><p>（实战营第4期正在火热进行中，欢迎报名）本文来自社区投稿，作者李宇，书生大模型实战营第2期学员原文链接：https://zhuanlan.zhihu.com/p/689967866有幸参加了第二期的书</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI4MDcxNTY2MQ==&amp;mid=2247531436&amp;idx=1&amp;sn=c2e0caffbee1feb0969b5bb6946dc694&amp;chksm=ea9eea54f3e449c354e6556f1cb1e1b9ee4c0e3cea93aaedf3654655cbeda75c7d6a5327c23d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 30 Oct 2024 10:03:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[探索基于状态空间模型的语言建模技术丨H3论文解读]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/ialW0xobVWP7ZyBo2AicYyTkHSibsrF5ulrqCDhklEX41PvHLAtNqLX2omeDPUOXGPmGkKTCW7zv0IyY0ZgdtvV6A/640?wxtype=jpeg&amp;wxfrom=0"/><p>（实战营第4期正在火热进行中，欢迎报名）本文来自社区投稿，作者 GYH状态空间模型 (SSM) 已经在序列建模的一些领域有优秀表现，例如 S4 等等，但在语言模型上仍然比 Transformer 不足</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI4MDcxNTY2MQ==&amp;mid=2247531433&amp;idx=1&amp;sn=2ee283e115fc6f8b553839f05b13abb8&amp;chksm=eac200ac6b2bd62b2e6e04923310f50b624ba4710714cdf79302dbacaa58cb2a002bbeaf6b71&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 29 Oct 2024 11:19:25 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
