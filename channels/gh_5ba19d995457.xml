<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIGC Studio]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIGC Studio公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      

      <title>gh_5ba19d995457</title>
      

    </image>
    





































    <item>
      <title><![CDATA[AI时光机上线！用MyTimeMachine一键体验从童年到白发的神奇旅程，让AI带你穿越时空。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enDXLyhv5gUBA9w7NggpzadXQzDTPawT0bfoK6ibr2LeHFQlxEcvjESOibkicIb6YJEiawdBI58gLItSA/640?wxtype=jpeg&amp;wxfrom=0"/><p>AI时光机MyTimeMachine正式上线！只需上传50张照片，AI便能根据你的面部特征，模拟不同年龄段的你，无论是重回青春、见证中年风采，还是预见未来的老年模样，统统轻松实现。想知道自己20岁时的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489200&amp;idx=1&amp;sn=c03b085dc1088a2f7275ff4c9a4b9420&amp;chksm=fd29d19a79bdee7d122e9605b44a793213f3dddbe5a0f13e140cb3f97087fd999323a51b0526&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 05 Dec 2024 16:02:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Siggraph Asia 2024 | Adobe发布MagicClay：可通过文字引导对3D模型特定部分进行雕刻！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eldYoicjqyr71olTXNsd2FpJRUrSFOicVlJ9EDVptvjqu3DXUX2qZCR4C6D35wDfPGjSibEhSk8DyhGQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Siggraph Asia 2024 | Adobe发布MagicClay：可通过文字引导去对3D模型中的特定部分进行雕刻今天给大家介绍一篇来自Adobe研究人员在Siggraph Asia 2024</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489200&amp;idx=2&amp;sn=d21798b627fdae88e7f31df7d3eacf07&amp;chksm=fd661e60020bbb0090dcd5658ccb1864c6ae2ccd6af7b037c821093ec5fa8e3a7fb74dcbf786&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 05 Dec 2024 16:02:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[腾讯发布HunYuan-3D，支持文本到3D和图像到3D，10秒即可生成高分辨率细3D模型。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elMhPFZCKibTiaBKrjL4Yql4lFH5tVlYMlAnW2RYL3JiaF4vHrEFr3z5TWpyzCAENlicH9DuH5PnpYic3g/300?wxtype=jpeg&amp;wxfrom=0"/><p>HunYuan-3D支持文本到3D和图像到3D功能，包括网格和纹理提取在内，整个过程在 10 秒内完成。文本到 3D：用户可以通过简单的文本描述生成 3D 对象。例如，描述一片绿叶或一把棕色吉他，模型</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489200&amp;idx=3&amp;sn=d744c6248929a6990fa1cfea8b086209&amp;chksm=fde17fb4e04e1222a38fc55f28571928d27319b37e83543465bf2caf1c54307b62efb6107f37&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 05 Dec 2024 16:02:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[升级版本的EchoMimicV2来了！一张半身照+音频，就能生成带手势的数字人视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emwVPXqNlN4T1anTjic9RlprbaDXZrG9liaHmF4qP4TqeGSFB4j1aqeAaysqA48YKP0ibTgb4E8ic61Bg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经给大家介绍过蚂蚁集团的开源数字人项目EchoMimic，感兴趣的小伙伴可以点击下面链接阅读~蚂蚁集团放大招！EchoMimic来袭，音频+面部标志，让你的肖像“活”起来，直呼效果逼真</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489200&amp;idx=4&amp;sn=54a570e07e40a5e38a686f919e78faad&amp;chksm=fddc3e66c5493bdcf8083eab231d3a294af6247a2724ff06c4f82e18160ee1f2e03b2ac36b25&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 05 Dec 2024 16:02:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[超越Hallo和AniPortrait？音频驱动肖像动画新方法LetsTalk,可生成与音频一致的逼真视频。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elS0nh744Xc7tB6W08RA4SgfkcDFOIyH4xJ5xG8Ar9Y0Uvicw6xicJzbmEtb2yOzCDNqYMjzkS4eYpw/640?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中已经给大家介绍过许多关于音频驱动的肖像图像生成动画方法，感兴趣的小伙伴可以点击下面链接阅读~复旦开源Hallo：只需输入一段音频和一张照片就可以让人物说话。开源EMO再升级！复旦|百度|南</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489162&amp;idx=1&amp;sn=f57624bb544e0990e16bdb2db92c84e6&amp;chksm=fd2c76ffb0f770f7d97f6253c968476aec6515f61c34dd1efcea1f759d9f72200a7d0ff17a5e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 04 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[告别大头娃娃，东京大学开源数字人TANGO：能根据目标语音音频生成同步全身手势的视频。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en6pFnDNvWHLiaftE66MEoWpW84gLODaQtSQ9LfJlyThsRQM3P6M7VVqstMXBRlYemO0FShZxQIGrA/300?wxtype=jpeg&amp;wxfrom=0"/><p>目前已经有很多面部和唇形同步的数字人项目了，但大多只支持头像和上半身，前几天介绍的Hallo2音频驱动图像生成视频小伙伴们都非常关心，后台也有留言问有没有支持全身视频生成的方法。开源EMO再升级！复旦</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489162&amp;idx=2&amp;sn=211d99016a9a22076ed219c9820f7a10&amp;chksm=fdfac4f4a1c01b50bdcda54b86f7814601d174babea59f189210c61617df12943236c84e5d01&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 04 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[开源EMO再升级！复旦|百度|南大推出Hallo2：可以生成4K，一小时的音频驱动的视频。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eltJu44TqnY7VwyFHlz5hNmzgFx5WXQibibH6vJRBJhBmhnZYZKxgXcibPxaACh1nF70mRz6kzVMSZuw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过复旦大学开源的Hallo项目，感兴趣的小伙伴可以点击以下链接阅读~复旦发布开源版本的EMO，只需输入一段音频和一张照片就可以让人物开始说话。复旦开源版本EMO:真实人物效</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489162&amp;idx=3&amp;sn=d80bba8108adbcfd32d0365d1db816a9&amp;chksm=fd8a30127f8916fd4888e18dbc5e677ec183dc905535fc7868ade7e2a98e9d2df01cdc8b0a77&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 04 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[复旦开源Hallo：只需输入一段音频和一张照片就可以让人物说话。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emmX3AJiczS9uocCYrX3Enlaia0e7A5oBvt6Ejqza4BfEXLNSyWs0q80XhcU9QMoTln8FqIUtNe5ibHg/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前和大家介绍过阿里的EMO和腾讯的AniPortrait，用户只需要提供一张照片和一段任意音频文件，EMO即可生成会说话唱歌的AI视频。最长时间可达1分30秒左右。感兴趣的小伙伴可以点击下面链接阅读</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489162&amp;idx=4&amp;sn=12a48f598dd36644d88285b31f010710&amp;chksm=fd86c99c4cbe0d0c30703b09065c3c411fe55cc335dd5a643a6150b0b30c24a6f78b3f9bc5f1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 04 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[腾讯提出AniPortrait：音频和参考肖像图像驱动生成高质量动画。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekGB20aoopfDW9Ia72SmdXIicTEOSQdNotOKRQycycAchbz7X13BECiaz9Sb46TEia25wWuBVJMXSaOQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯提出了一种新颖的框架-AniPortrait，用于生成由音频和参考肖像图像驱动的高质量动画。通俗讲，就是给张照片生成说话的视频。类似阿里的EMO，大家先可以简单看下效果。相关链接论文：arxiv.</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489162&amp;idx=5&amp;sn=f9fa2a12e41b791de2d5adc1d6cefa1c&amp;chksm=fdbed370f0e40bc1e3b12cb44facdf0bba0c0db12a88e7cf8f7d6ae769924ed335043832d1d9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 04 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[阿里EMO：强哥也能上刑法课了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>只需要输入图片和音频就可以生成富有表现力的视频，并且嘴型是可以跟声音匹配的。支持多语言、谈话、唱歌以及快语速的适配，可以根据输入视频的长度生成任意持续时间的视频。强哥也能上刑法课了！</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489162&amp;idx=6&amp;sn=3009c52d8e867c3aecf8118fb1e0ab8f&amp;chksm=fdaf7effb7e462b47c4c4adc78b5717ef4d42950e1de714873bf622c3823b6935e19663118b0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 04 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[腾讯 | 中科大提出Make-It-Animatable：一秒内可将任何3D人形模型变成动画角色]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elS0nh744Xc7tB6W08RA4SgeG73PxwM4k72wVClKXaAf0yPYtOtKUjLgb02frh2Xh9vAawfNd5XlA/640?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯联合中科大提出了一种用于动画 3D 角色制作的新型框架Make-It-Animatable，可以在不到一秒的时间内使任何 3D 人形模型准备好进行角色动画制作，支持各种 3D 表示且生成质量和速度</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489142&amp;idx=1&amp;sn=afdbc6e7883d833117fd4f0bea80f32f&amp;chksm=fd30e78f1d02dc667509fe1e3a3e01e312ab9fe79828e6c0eada98783cf0bb37c9c7227d7299&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 03 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OminiControl：一个新的FLUX通用控制模型，单个模型实现图像主题控制和深度控制。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuCwIlu7cc4lHd3hwJicoyYEn3PFyv0qTxQYEgq8VntmUj91vEEYPJjMADiamfkH94icSBs7fF1Tn1A/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中和大家介绍过Flux团队开源了一系列工具套件，感兴趣的小伙伴可以点击下面链接阅读~AI图像编辑重大升级！FLUX.1 Tools发布，为创作者提供了更强大的控制能力。OminiContro</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489142&amp;idx=2&amp;sn=48538eb4bd255f2cf3e0439968b22280&amp;chksm=fd876fa92b78582703b41cd2ddfa984cd4f887d7d73d42399db3e65978bac25e31be918c0ddb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 03 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[终于！ComfyUI官方桌面版正式发布，适用Windows/macOS/Linux，免费向所有人开放。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emFSyib6eJvfckn9qtbFXKmI6ybr39dw3U5vwoMsaPPndtuKxZufMlnEMa3f8OuXnwLibJKMxEj2cyw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Comfyui 官方桌面版本正式向所有人发布，支持Windows（NVIDIA显卡）和macOS（M系列芯片），旨在为用户提供更便捷的设置导入、日志集成和模型下载功能，尽管仍处于Beta阶段，但未来将</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489142&amp;idx=3&amp;sn=fc125bba1008a9d9f1c2ed0f8fa58d13&amp;chksm=fdb4f78d547307d67b54c82286dbcb254ca75b07b24f2cee8f69526fcc4f296350aa82c71377&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 03 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[AI图像编辑重大升级！FLUX.1 Tools发布，为创作者提供了更强大的控制能力。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eltYhV1JmK1ib9FbmIt2gIyPDOrcibpBhOX3OVdibquclM6ib7Tsxn7qhfDiclnY9wlicfpKLJib4fLuY7Og/300?wxtype=jpeg&amp;wxfrom=0"/><p>AI 图像编辑昨晚迎来了一次重大升级！ BlackForestLabs 发布了 FLUX.1 Tools套件，为创作者提供了更强大的控制能力。FLUX.1 Tools套件介绍这次发布包括四项新功能：F</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489142&amp;idx=4&amp;sn=fb2c8e00f9ea98515a9eb3d3b15e4cea&amp;chksm=fde06bcfb24b5871230c45b4feb250bff508f2d3e375404f02b0d1a8aa8b85a5560ab0125062&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 03 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多模态图像生成模型Qwen2vl-Flux，利用Qwen2VL视觉语言能力增强FLUX，可集成ControlNet]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuCwIlu7cc4lHd3hwJicoyYHx9RLCm1u1zJr61WGBPZZicviaGPyXN8y5ZTaZE9jpPcdNSX1nmUlib5g/640?wxtype=jpeg&amp;wxfrom=0"/><p>Qwen2vl-Flux 是一种先进的多模态图像生成模型，它利用 Qwen2VL 的视觉语言理解能力增强了 FLUX。该模型擅长根据文本提示和视觉参考生成高质量图像，提供卓越的多模态理解和控制。让 F</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489121&amp;idx=1&amp;sn=71a225e551715d1923a94b02a5af200a&amp;chksm=fd0e01b604036926a41dcb452366ce853c85df78352c0ed154ed5c820a93d45e34d1ec0638ed&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 02 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[文本转视频模型Allegro，可以生成长达 6 秒、15 FPS 和 720p 分辨率的高质量视频。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXSHQPic5rJ8IBKiaNosJKl47LGniaXW6NGticOnwCibeK5T8qlic4oPfsd5XwpM5KFOOqbuSEJIUictd6A/300?wxtype=jpeg&amp;wxfrom=0"/><p>Allegro 是一个强大的文本转视频模型，可以通过简单的文本输入生成长达 6 秒、15 FPS 和 720p 分辨率的高质量视频。主要特点• 开源：完整的模型权重和代码可供社区使用，Apache 2</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489121&amp;idx=2&amp;sn=404c513739c737124a0c5d8166ae3a3c&amp;chksm=fdf93dd2da1e1d3f3028d5cfc910e48d6e862a30eadb1406fcaff567a0c825bfe4eda3af6d4f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 02 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[开源文本转语音工具 F5-TTS，一段音频+文字就可以模仿任何声色。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXSHQPic5rJ8IBKiaNosJKl4QQWgqW0Vjia1wZ7KjB0bJZhC8sUt9Nknjh8xHMh9TGk0ibRKE6OQykwA/300?wxtype=jpeg&amp;wxfrom=0"/><p>F5-TTS是一种完全非自回归的基于流匹配和扩散变换器 (DiT) 的文本转语音系统。无需时长模型、文本编码器和音素对齐等复杂设计，只需用填充标记填充文本输入，使其长度与输入语音相同，然后进行去噪以生</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489121&amp;idx=3&amp;sn=19cf10ba209c794d1976929efc5250ac&amp;chksm=fd7e2d9e9b693edee3d4c9f45ed05656b65c719f82f97785f516dbb30422685cf28ab94f8ec0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 02 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Adobe发布TurboEdit：可以通过文本来编辑图像，编辑时间<0.5秒！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elKcprhHqENugIHSUTwb3EOiaaqictMa8fmmNEDqsoISMhGDZH4oZmh7vtMn5sov6khPdhIypPkhDZQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍Adobe研究院新的研究TurboEdit，可以通过文本来编辑图像，通过一句话就能改变图像中的头发颜色、衣服、帽子、围巾等等。而且编辑飞快，<0.5秒。简直是图像编辑的利器。相关链接项目</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489121&amp;idx=4&amp;sn=0e723ec829c05e44c99910c8d6740b42&amp;chksm=fd9c03a9a5803bfa3bebe1b9ac3b6bc41e5798ae77279b15f53ebd48620c4328424a4da8432e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 02 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ICLR 2025满分论文，ControlNet作者新作IC-light，控制生成图像照明，代码模型已开源。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enrJ6ibDPoiaQXzhMdZU8spAicfF8vgRl2qenVGz9ZkJkJgBYXd26ys3WTPnNDJtK81bRSE1Xia412nbQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>罕见！ICLR 2025 惊现了一篇满分论文，4个审稿人同时打出了[10,10,10, 10]，这是什么炸裂的存在？！这就是ControlNet的作者张吕敏，继ControlNet 后提出的IC-li</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489120&amp;idx=1&amp;sn=5ce1c60e99556e3daf23414de26875be&amp;chksm=fd2f0acef6d77154441020c5a469edd01a30f8515dbdb694a70e87ecfe365df0207e54396fee&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 01 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[InstantX 重磅开源 FLUX.1-dev-IP-Adapter 模型，文中附模型和comfyui工作流下载。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eltYhV1JmK1ib9FbmIt2gIyP6xwE5MPwewm6kG9gwsXpPEaHHTOicBN3XsV2LsRvJ5qWf00gn2UwKaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>InstantX 团队的研究人员开源了 FLUX.1-dev-IP-Adapter，这是一个常规 IP-Adapter，新层被添加到 38 个单块和 19 个双块中。使用siglip-so400m-p</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489120&amp;idx=2&amp;sn=75b57ca6dbc89a3ce56b0fb87ab02203&amp;chksm=fd800517dec6f0da7b38ed93291ff450f8e1de6d9ecf8b926f8eeea0ca36da10328512cfbb4d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 01 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[腾讯发布HunYuan-3D，支持文本到3D和图像到3D，10秒即可生成高分辨率细3D模型。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elMhPFZCKibTiaBKrjL4Yql4lFH5tVlYMlAnW2RYL3JiaF4vHrEFr3z5TWpyzCAENlicH9DuH5PnpYic3g/300?wxtype=jpeg&amp;wxfrom=0"/><p>HunYuan-3D支持文本到3D和图像到3D功能，包括网格和纹理提取在内，整个过程在 10 秒内完成。文本到 3D：用户可以通过简单的文本描述生成 3D 对象。例如，描述一片绿叶或一把棕色吉他，模型</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489120&amp;idx=3&amp;sn=7d5b3eb3119099b80d1b2d07aba5c552&amp;chksm=fd39675c0e00aa8f01351d6b29aa67a35ab0bbf49587e483ee5f0186e0b4a930d2f7c701f6b9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 01 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OminiControl：一个新的FLUX通用控制模型，单个模型实现图像主题控制和深度控制。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuCwIlu7cc4lHd3hwJicoyYEn3PFyv0qTxQYEgq8VntmUj91vEEYPJjMADiamfkH94icSBs7fF1Tn1A/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中和大家介绍过Flux团队开源了一系列工具套件，感兴趣的小伙伴可以点击下面链接阅读~AI图像编辑重大升级！FLUX.1 Tools发布，为创作者提供了更强大的控制能力。OminiContro</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489120&amp;idx=4&amp;sn=b47a1a1dc9d3a6e530c33ac10c393344&amp;chksm=fd44fae10beda64060d7586094407a7ea15d29c0e7989d45e055224184623801cb08a659cac2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 01 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OminiControl：一个新的FLUX通用控制模型，单个模型实现图像主题控制和深度控制。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuCwIlu7cc4lHd3hwJicoyYEn3PFyv0qTxQYEgq8VntmUj91vEEYPJjMADiamfkH94icSBs7fF1Tn1A/640?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中和大家介绍过Flux团队开源了一系列工具套件，感兴趣的小伙伴可以点击下面链接阅读~AI图像编辑重大升级！FLUX.1 Tools发布，为创作者提供了更强大的控制能力。OminiContro</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489108&amp;idx=1&amp;sn=cc4f339f67a3c795b77edbe523739612&amp;chksm=fd687cba3fb94a70c0306a186d7fa7f10df1fe3398657c7430ec21cedd6aee3d32208d73f711&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 30 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[阿里发布新ID保持项目EcomID, 可从单个ID参考图像生成定制的保ID图像，ComfyUI可使用。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elnGoicbmLL47YzLd4HWhjwazEmicf1F7ZjrxQSj4JNP3x3icluxM84Et2UYGdsdxfDOXnd9OlZYFCwg/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里妈妈发布了一个新的ID保持项目EcomID，旨在从单个ID参考图像生成定制的保ID图像，优势在于很强的语义一致性，同时受人脸关键点控制。EcomID 方法结合了 PuLID 和 InstantID</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489108&amp;idx=2&amp;sn=5c625299d99849acf5900db65f01dd98&amp;chksm=fdfce06ffb6148d836ba7493e06b0afc7dfc494d1c155c521a691543df0bb488f8e111865acd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 30 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[文生图像编辑来了！英伟达提出Add-it，无需训练，可根据文本提示向图像添加对象。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emmkDiagtskaHJodPFibMTUYJZY50N6JpzSdpSqpDMMdhm1JHxUv7E3vPPDa6XmXuygFoa0eiaBct3Bg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Nvidia提出了Add-it，这是一种无需训练的方法，可根据文本提示向图像添加对象。Add-it 适用于真实图像和生成的图像。该方法利用现有的文本转图像模型 (FLUX.1-dev)，无需额外训练。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489108&amp;idx=3&amp;sn=c5672c101db5e61765b9b06a1e31541e&amp;chksm=fdfbc83ae39b24f15dc76023edcd05d500b6b7206ca83ec2cb61f5c81fa01929e4eaf3b0b62d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 30 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ComfyUI | Flux实拍与卡通风格lora推荐, 一键生成创意图像。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enzia0AxvG3w5jnu5Q1nyOUw7TQJFGYa2znHnNaWuO6u1JkCEEpxpul3G7pL6Igu3mLQyxXGM5cvPg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家分享一个非常可爱的flux lora，FLUX.1-dev-LoRA-One-Click-Creative-Template:能够一键生成4张同一角色的真实版图片+一个中间的卡通版Promp</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489108&amp;idx=4&amp;sn=1dabec88edf36d4cdc495678a07ccc05&amp;chksm=fd325d99f01cd3ae39732207e47dc7727be6270f3e9c0aeb527b27f01cc572756101f074b7a1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 30 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CatVton升级版？CatVton-Flux：AI虚拟试衣方案新选择。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuCwIlu7cc4lHd3hwJicoyYW6IaEp7gbVv0yHQMOcuZ65LzSPaIPcK5ZBqJ9AhEjNULUK7MKY05CQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面：本公众号已经给大家介绍总结了一些列关于虚拟试衣的文章和方法，小伙伴们可以在公众号菜单栏点击AI虚拟试衣查看，也可以直接在公众号内搜索"虚拟试衣"之前的文章中已经和大家介绍过虚拟试衣方案Cat</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489107&amp;idx=1&amp;sn=fe9a2e6b77e9071702197d6b9dd88bbf&amp;chksm=fd5e7b6abfa698bedb4717e7f86498d1b66cc9518e41b43bf0d2a232f92b0f664edca90d87b2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CatVTON：轻量化架构与高效训练，助力虚拟试衣技术落地应用！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enM9EmGpEygEm1sRYerx5zs4mgMPgDicoDS6emdT0nVUdvTwqYibENyLL2gg3X7xs5yMuia7FRkm9zRg/300?wxtype=jpeg&amp;wxfrom=0"/><p>本篇文章来自粉丝投稿，文章内容是关于虚拟试衣技术。本公众号在之前已经介绍了许多关于虚拟试衣技术的文章，感兴趣的小伙伴在公众号中搜索“虚拟试衣”阅读相关文章~近日，中山大学和 Pixocial 联合发布</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489107&amp;idx=2&amp;sn=f2d843f6f723cebd74439dd26def1a72&amp;chksm=fd97d072f136d559abdfd4cd0e5125b37fe48806bb739686d2328285e5ec84d07662a78dce66&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[超级智能“试衣镜”！GarDiff：高保真保持目标人物特征和服装细节，虚拟试穿技术新SOTA！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekibUN5oqyRgSButjKACUwRIef94PhQmUMcfJSkj4W9NicELKlw377icJuhpfjx2VUNPWKHMM0Gqib5Eg/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前已经给大家介绍了很多关于虚拟试穿的文章，本公众号也总结了虚拟试衣专题在公众号菜单栏，感兴趣的小伙伴可以在公众号内搜索“虚拟试衣”阅读～今天给大家介绍一个最新的虚拟试穿技术GarDiff，它可以分析</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489107&amp;idx=3&amp;sn=707cff8697d037e7bdfc8bccf8323f49&amp;chksm=fd3615ac692996b0e2dc254f79d16e15bbd3d13bee69d22caa25ed8f965db15307e1835f7d64&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Boow-VTON，无需训练即可进行试穿，解决野外试穿任务难题！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elkkuWrNlw62n8iayUtU0k8ylNWLA8s3GygmDIvkMMozsRJV3j6OdhM9D45R5ibKHqZgjgenJNePSicA/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前已经给大家介绍了很多关于虚拟试穿的文章，本公众号也总结了虚拟试衣专题在公众号菜单栏，感兴趣的小伙伴可以在公众号内搜索“虚拟试衣”阅读～今天给大家介绍阿里最新提出的虚拟试衣方法BooW-VTON，结</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489107&amp;idx=4&amp;sn=25175857de75032cb26f6ed695b0462c&amp;chksm=fd3190343933b6595255200bb8d3f1919439c1878f43f8c80faa251783196b2b582c9c4dfeae&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ClotheDreamer：3D数字人也能实现穿，脱衣自由！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emPnvPXL7KLqPvkIAqtoJ3wAARpkHstN4O33m9M1haEAL9bqcv7I3brE6IfBs4EUXTjOuq6l2WvZg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天,给大家介绍上大、腾讯等提出的3D服装合成新方法ClotheDreamer,它以其革命性的能力,从简单的文本提示直接生成高保真、可穿戴的3D服装资产,正在重塑电商与空间计算领域的未来。数字人也能实</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489107&amp;idx=5&amp;sn=04ca5ea642a8db7ad8b6e742e300bb72&amp;chksm=fdf9b718f78fdf084da817ce7863d7a3cae2c9b6585963c827f574a2e04cdaad9634f0d32234&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
