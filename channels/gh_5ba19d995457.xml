<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIGC Studio]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIGC Studio公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      

      <title>gh_5ba19d995457</title>
      

    </image>
    



















    <item>
      <title><![CDATA[混合专家模型 (MoE) 详解]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emOmPkEN8wch4M3txAeFlUKiaJVQDmPia8vwoiccAOopcuhcVyF7mZX5Oa03m0QFQpQxO4NicicCvicnbyw/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着 Mixtral 8x7B (announcement, model card) 的推出，一种称为混合专家模型 (Mixed Expert Models，简称 MoEs) 的 Transforme</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488814&amp;idx=1&amp;sn=97482b175fcb34cafbe65e8ae8a1402f&amp;chksm=fd85cbfec9e615eee2d84056a0f37f66d74e7c4d9660a9e7cc1e785b0c9a1bbe9c630a9b0a48&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 07 Nov 2024 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[统一图像生成模型OmniGen：可由多模态提示直接生成各种图像。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enjwj4Ry2OH6auaAn9DU954RGLVLiaJQhnSsUOPiaYkiaE5VPAB4AUAtmLI24PhQm9bK4JduBhT9ZjTQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个北京市人工智能研究院 提出的统一的图像生成模型OmniGen，可以使用它来执行各种任务，包括但不限于文本到图像生成、主题驱动生成、身份保留生成、图像编辑和图像条件生成。OmniGen</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488814&amp;idx=2&amp;sn=abd2b31fb9f16f038e4bf790b3521c0a&amp;chksm=fd38baa4e4e1de996e775471047d00e83da572de22b61f69c56c49411761f1786fb882b7002c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 07 Nov 2024 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[NeurIPS2024 | OCR-Omni来了！字节&amp;华师提出统一的多模态生成模型TextHarmony。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enzia0AxvG3w5jnu5Q1nyOUw9icM2HlibUyI4RtyIsiaB9FOY9taoKCFlibTeImBZT585GC3ias7FialR6UA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在人工智能领域，赋予机器类人的图像文字感知、理解、编辑和生成能力一直是研究热点。目前，视觉文字领域的大模型研究主要聚焦于单模态生成任务。尽管这些模型在某些任务上实现了统一，但在 OCR 领域的多数任务</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488814&amp;idx=3&amp;sn=9821b297fc93dd6351a7ca88002155fb&amp;chksm=fdcb7867cbd617d238bf53a1ebb94e79f2b0faf0c3aa85d6223595757b67437f32eb34dd6d01&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 07 Nov 2024 16:00:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[腾讯发布业界最大开源MoE模型：Hunyuan-Large，具有3890亿参数，在长文本处理、常识推理、数学能力等方面表现出色。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emo5W5SskRqTMcQ39iaLjtibd6J8s54Iu3pUT6mLLnbic6sYmEEkC7TkRkQKSSVTg6VtPoZogicQCHTgw/640?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯发布开源 Mixture of Experts（MoE）模型：腾讯混元大模型（Hunyuan-Large），这是目前在业界是规模最大的开源 Transformer 专家模型，具有 3890 亿参数</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488790&amp;idx=1&amp;sn=b99000f43374054ba84a7239ca056342&amp;chksm=fdea95e56c1b06b57aa0546ac9ffb9a37a0cc6a20cfc4355a4d55b0b1f4c6b981e047690663b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 06 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[登顶Hugging Face文生图模型榜首！Recraft V3可精确处理复杂长文本和手指等解剖学细节！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emo5W5SskRqTMcQ39iaLjtibdfWiaulu8SLia1CmOhUK8o1DFXv1ZuIO9wgBw4mH09eF6uw4vAzibRT3rQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>Recraft推出了其最新的图像生成模型—Recraft V3。通过引入设计语言思维，Recraft V3为图像生成树立了新的卓越标准。在Hugging Face 人工智能文本转图像模型排行榜。它以 </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488789&amp;idx=1&amp;sn=00bd975be576f39119dfc98be2a85c0e&amp;chksm=fd0b5a4ade0de5906f69aa87ee309cb8736db086774a9681124a61452c8f8ce29351b7c3dfde&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 05 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[刚刚，阿里重磅开源基于FLUX的In-Context LoRA，可一次生成多张风格和ID一致的图片集。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elnGoicbmLL47YzLd4HWhjwaZq27QklGnm2euIIenh9a4vvHuaekrpqk2PuGae3ghYQjGRse85BXsA/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍In-Context LoRA 这个项目太强了，前几天发布的时候就引起了许多小伙伴的关注，但是当时还没有开源，就在刚刚，作者开源了In-Context LoRA项目。它基于FLUX训练，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488724&amp;idx=1&amp;sn=8db864e5b1098b3e661805547439293e&amp;chksm=fd78c7d59b25760d6483cab92f446ff28bca67952f718fb50e66e99aaf71a95bfbb8d204f96e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 04 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[超火的开源文本转语音工具 F5-TTS，一段音频+文字就可以模仿你想要的任何声色。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXSHQPic5rJ8IBKiaNosJKl4QQWgqW0Vjia1wZ7KjB0bJZhC8sUt9Nknjh8xHMh9TGk0ibRKE6OQykwA/640?wxtype=jpeg&amp;wxfrom=0"/><p>F5-TTS是一种完全非自回归的基于流匹配和扩散变换器 (DiT) 的文本转语音系统。无需时长模型、文本编码器和音素对齐等复杂设计，只需用填充标记填充文本输入，使其长度与输入语音相同，然后进行去噪以生</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488704&amp;idx=1&amp;sn=43aec685fd757cfdc670f1e68280cc96&amp;chksm=fdfc6c5b36f474f72c7da7e01264edfd25b27c8183e65aded726d6b8ba0bd39ddc913f3db61a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 03 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ChatTTS：对话式高可控的语音合成模型，最强文本转语音工具！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeHe6LRGvmFzc5YNEYkO9c1cFSsR6eODR1H7cQTYwnRxnVtWMtNFHZJhcBia8MQvH4ApUYFKcibZkA/300?wxtype=jpeg&amp;wxfrom=0"/><p>ChatTTS 一夜爆火， 极速出圈， 3 天就斩获 9k 的 Star 量， 截止 2024.06.04， 已经 19.3k 的 star， 极速接近 GPT-soVITs 当天的 26.2k 的 </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488704&amp;idx=2&amp;sn=64fbbd1b88d41e818e9f598749dd6495&amp;chksm=fd50f3dcda3b8f2003aac99bfe5e4569e436ed646dc4a865a35f50945f4fc17c5f841a036adf&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 03 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Seed-Music：字节跳动开发的音乐生成模型 支持多种数据输入生成和编辑音乐！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elIm6icxMVSQ1CxgxFiaRZRxgIpSB6lVKMSWd1DpYwO7bNGaOdrtXY1KXTzkCV8N36E83o4z8JLtxBQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Seed-Music是一个由字节跳动研发的音乐生成模型，用户可以通过输入多模态数据（如文本描述、音频参考、乐谱、声音提示等）来生成音乐，并且提供了方便的后期编辑功能，比如修改歌词或旋律。Seed-Mu</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488704&amp;idx=3&amp;sn=d0bbed958f92b8c952516e9f840bf496&amp;chksm=fd8bfade1b8f35752bf2d6ecfea105f98d11a4be0728efe1235129e2ccba9567d7cd9ac46d64&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 03 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[​Controlnet作者新作IC-light V2：基于FLUX训练，支持处理风格化图像，细节远高于SD1.5。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXSHQPic5rJ8IBKiaNosJKl4zjuJBWaX5OT2Lf7ZUfribJIKIVPQd63HVFcGOR4owDUYVuia3JgZoueg/640?wxtype=jpeg&amp;wxfrom=0"/><p>IC-light V2：支持处理风格化图像“IC-Light”全称是“Imposing Consistent Light”，IC-Light 是一个操纵图像照明的项目。目前已经发布了两种类型的模型，两</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488703&amp;idx=1&amp;sn=20c443d99caac8474a7e65b3fa6d4044&amp;chksm=fd82800e4f576ce86568b576d9751d4a04462cd5565b45c3ee4f130a01ab2ff92b4e70fb7b8f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 02 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[IC-Light，可以操控图像生成时的光照，光照难题终于被解决了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXSHQPic5rJ8IBKiaNosJKl4D4jiaGaa5GeibYBiaoVp4eKPOAz9ez3Mj92SalvXYF357u7eaShMkxejw/300?wxtype=jpeg&amp;wxfrom=0"/><p>IC-Light代表Impose Constant Light,是一个控制图像照明的项目。可以操控图像生成时的光照，对内容主体重新打光生成符合新背景环境光照的图片。这下商品图合成这种需要最大程度保持原</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488703&amp;idx=2&amp;sn=ca474593a963d550f1089b62b3b82802&amp;chksm=fd1eed3aec5167b8a95dbfdeab7e095b09e2442b9aaa298555e5ee1ef8e7df6dfd4896f8ec6a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 02 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OpenFLUX.1：去蒸馏版本的FLUX.1-schnell，可进行微调，文中附模型下载地址。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em63XUns9BWribhLaZgPeFEF68DHq3end31f9ZeHc7bJm8s1bVHfwoVODQFRw7YKRY0IS5kLxL8nvA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Flux Schnell 是经过 Apache 2.0 许可的，但它是一个蒸馏模型，这意味着无法对其进行微调。然而，这是一个很棒的模型，可以在 1-4 个步骤中生成令人惊叹的图像。近期，开源社区上有人</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488703&amp;idx=3&amp;sn=2805a0daca9e6c1fcbca4396f6978501&amp;chksm=fd62c1f2cdc2ef755fa00d1d54fb596fc530315f93ded534a748c4c9a849a956fdef7037b209&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 02 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[零样本主题驱动图像生成新方法！EZIGen：在保持灵活性的同时保留主题身份！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en4dVnOT75Vve5gBZeAMAcqamPTNAwic2GwjgfabapQsxHL8u80ejLQBuGvbmR6PKA9PETicI3UQ5UA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个零样本主题驱动图像生成方法EZIGen，它可以从提供的主体图像中提取出重要特征，就像是给图像做一个“身份识别”，确保生成的新图像能够保留主体的独特特征。接下来，EZIGen会根据你输</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488703&amp;idx=4&amp;sn=c35663c123f57a0ef121eb0758c8ceef&amp;chksm=fdc992f4d78d66615d80de2ee442de0a36dcf9be5de00b3496bd31322ef9edc739f16f8dc1d5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 02 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Flux Lora｜可以和二次元合影啦！RealAnime-Detailed V2，可将动画与真实人物风格融合！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enzia0AxvG3w5jnu5Q1nyOUwqgvk05w7f8uadCgfhevafdaLgHvO27pEwiaeOFibIj2ibunwDjv1xj7oQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个很有意思的flux Lora：RealAnime-Detailed V2，可以合成二次元和真实人物混合的图片！它一个使用LoRA技术开发的Flux模型，专注于将动画角色与真实人物风格</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488702&amp;idx=1&amp;sn=70107543f5c0ecbb94ec501b8f18468a&amp;chksm=fdcdf3ed3dfa9f13dbb3c6b4eb3b0e2e2c9f5470222953cacd16d27fafd28626aa6cc34621a3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 01 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[免费开源 AI 证件照制作工具：HivisionIDPhoto，文章附下载和使用教程。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emVz5IyibD56YfAMqS63ibnE79C90fGSNkrr3zcFjBAhZUiaoYiavM4pxriaRyhXia9icULucAbSTWvL812w/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家推荐 GitHub 上一个轻量级的 AI 证件照制作工具：HivisionIDPhoto。实现了对多种用户拍照场景的识别、抠图与证件照生成，并提供不同尺寸规格的标准证件照。感兴趣的小伙伴可先</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488702&amp;idx=2&amp;sn=00801667fb4311c409904ba0eae09bb6&amp;chksm=fd9a9143659ad5b05812f514b2335dd70adf4ea8369474e114e9732c54768d23ef4280031f86&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 01 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CustomCrafter，可保留动作和概念合成功能的定制视频生成框架！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emy0sTwEr46sY1TPQUca24qEr6a2p0foxbK63246N9Qkew62Ao8GWBjoAlibINQt95oRPfFzA5ia4wA/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯联合浙大提出了一种定制化视频生成框架-CustomCrafter，它能够基于文本提示和参考图像生成自定义视频，同时保留运动生成和概念组合的能力。通过设计一系列灵活的模块，使得模型实现了无需额外视频</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488702&amp;idx=3&amp;sn=4fb3dd74b48a215afa43a62ee653c9b1&amp;chksm=fda2d958a46a4c6b3378ca46b1f37ad3aa0b7dd2be24cba639fa38c4791c50c47ca37a08b1ca&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 01 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Glyph-ByT5-v2，支持10国语言图文海报生成，效果惊艳！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekUlTbakAQ9PkRVtjuPOYtMklfrlDVxgTLUqQxQB6Xzp3hd7zxxMa0HXnBhpURAxPhMlClBWcF7eQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>清华&amp;北大&amp;微软&amp;利物浦大学联合提出Glyph-ByT5-v2这款工具支持多语言图文生成，包括英语、中文、日文、韩文、法文、德文、西班牙文、意大利文、葡萄牙文和俄文。以下分别展示中、英、日、韩图文的视</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488702&amp;idx=4&amp;sn=5a7939b9d1925e89f8558fc4dd96d69e&amp;chksm=fdb06100462eba112fcde0c50b4ff3c93d19961788711f4b4c1ee8bc99528a255c94ba44aaaa&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 01 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[阿里巴巴推出升级版AI翻译工具：Marco MT 性能超越Google、DeepL和ChatGPT]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekDYMeOJw6PMrPrgUmBfVvICGVGwvK1ZowHkm5otQN1GWBq1oKgOpXCvFcU6T8e0WgLCSBUqvcfmg/640?wxtype=jpeg&amp;wxfrom=0"/><p>阿里巴巴的国际业务部门于推出了一款升级版的AI翻译工具，名为Marco MT。这款工具在翻译性能上超越了Google、DeepL和ChatGPT的同类产品。该工具的目标是帮助商户更好地在全球市场销售，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488701&amp;idx=1&amp;sn=f0e0cb37d36aa42baf94d3f364d36589&amp;chksm=fd9800798a6f3705c79c21e2d26ea5fc57dada8e46537196a78e3d3b72f52bd0138b13cd91c3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 31 Oct 2024 22:11:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[UIUC提出InstructG2I：从多模态属性图合成图像​，结合文本和图信息生成内容更丰富有趣！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekx1e8oxA3YKibkhot7h9UJZqBubdMgx3yBMfDK8JGL4YYX3hw4kJVRCHjFaqvVYYc7nEPXjibpCEug/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的这项工作是伊利诺伊大学厄巴纳-香槟分校的研究者们提出的一个新任务 Graph2Image，其特点是通过调节图信息来合成图像，并引入了一种名为InstructG2I的新型图调节扩散模型来</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488701&amp;idx=2&amp;sn=2d5783cb36385536df2759642354117f&amp;chksm=fdbd12834e1417a1b08e002d76ef94d0eefe212d170a8035da44e62deb112e97eb370b1ecfda&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 31 Oct 2024 22:11:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[港大和字节提出长视频生成模型Loong，可生成一分钟具有一致外观、动态和场景过渡的视频。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eny4Iriba5NSXkHvLxicLITJD5gFTkWLoBqMSNfUicQxXgibIh9n6vokK5ia5EOh7ZDJLVHGEsbaLz86XA/300?wxtype=jpeg&amp;wxfrom=0"/><p>HKU, ByteDance｜⭐️港大和字节联合提出长视频生成模型Loong，该模型可以生成外观一致、运动动态大、场景过渡自然的分钟级长视频。选择以统一的顺序对文本标记和视频标记进行建模，并使用渐进式</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488701&amp;idx=3&amp;sn=9bf506f3fabe0199361a53a5868384a7&amp;chksm=fd2177eb6b71d6b9b1c6c3af545e06684f31493f36641bb5fc15e0f57c24e513d1d2e753676d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 31 Oct 2024 22:11:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ScribbleDiff：使用涂鸦精细引导扩散，实现无需训练的文本到图像生成。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en4dVnOT75Vve5gBZeAMAcqnHFQnQNTu2jZ3gdtvtEhgfeuBiawdPpo4eRXb4xIj7t0TCyfMVB3Rhg/300?wxtype=jpeg&amp;wxfrom=0"/><p>ScribbleDiff可以通过简单的涂鸦帮助计算机生成图像。比如你在纸上随意画了一些线条，表示你想要的图像的轮廓。ScribbleDiff会利用这些线条来指导图像生成的过程。首先，它会分析这些涂鸦，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488701&amp;idx=4&amp;sn=27a4add445756a40a03fe744b202923a&amp;chksm=fd09450a8a6006c2fde53a5bb6215ad48682978e8c6639704b0dc1d2c21ecd101813dc0138ea&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 31 Oct 2024 22:11:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
