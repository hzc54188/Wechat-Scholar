<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIGC Studio]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIGC Studio公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      

      <title>gh_5ba19d995457</title>
      

    </image>
    




























    <item>
      <title><![CDATA[你要跳舞么？复旦&amp;微软提出StableAnimator：可实现高质量和高保真的ID一致性人类视频生成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elcSnOoT1icicSWQibicicqfkyEg0pWxDqMplvkr6CkMHxsZoRegYlaQmYz6ah0rQewI1UFbTMjpYhWh4Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>由复旦、微软、虎牙、CMU的研究团队提出的StableAnimator框架，实现了高质量和高保真的ID一致性人类视频生成。StableAnimator 生成的姿势驱动的人体图像动画展示了其合成高保真和</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489536&amp;idx=1&amp;sn=7b608cfbaa080786a0104a65070ca564&amp;chksm=fd4659a89b841753c630ad6fd4a96680cb25aa9c2f2e1cc6d2ada812a97e6fd5faa908ecf6f8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 20 Dec 2024 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[FLUX.1 Tools，为创作者提供了更强大的控制能力。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eltYhV1JmK1ib9FbmIt2gIyPDOrcibpBhOX3OVdibquclM6ib7Tsxn7qhfDiclnY9wlicfpKLJib4fLuY7Og/300?wxtype=jpeg&amp;wxfrom=0"/><p>AI 图像编辑昨晚迎来了一次重大升级！ BlackForestLabs 发布了 FLUX.1 Tools套件，为创作者提供了更强大的控制能力。FLUX.1 Tools套件介绍这次发布包括四项新功能：F</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489536&amp;idx=2&amp;sn=674c72c869791006aa9e7a62a2df76fd&amp;chksm=fdd0f1cf8c9cfec103b5826488276acb6df4e154de922a8365e529834d740819e4fe8f37f09e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 20 Dec 2024 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[英伟达发布Edify 3D生成模型，可在两分钟内生成可用于生产的 3D 资源、UV 贴图、4K 纹理和 PBR 材质。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elxgthgBxxwQlaTIxWuApiamicib5ZgIVOibFe3QVhqnvlTZsicUc8Qic16ZXdmpShcAV4jbk9vZib9Yh0MA/300?wxtype=jpeg&amp;wxfrom=0"/><p>英伟达发布 Edify 3D 生成模型，可以利用 Agents 自动判断提示词场景中需要的模型，生成后将他们组合为一个场景。Edify 3D 可以在两分钟内生成详细的、可用于生产的 3D 资源、生成有</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489536&amp;idx=3&amp;sn=4158fc78e9df141cfb1d9628997b42eb&amp;chksm=fd1ad5510025a87a55316dfd6bae0c3a39e5f1a53b77081bf1cbd5f1eb316ee5fa9fe6d78227&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 20 Dec 2024 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Adobe提出RGB↔X：可由图片直接输出AO、法线、roughness等，再也不用PS分层了！已开源]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2el2gcPqyiclMWPWUZdmfKRIs9kMSga9RK7vVJdYR3SezDnSGSKr5S8MYpXvQLTvOxa2LothopykbpQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家推荐一篇今年 ACM SIGGRAPH 的论文《RGB↔X: Image Decomposition and Synthesis Using Material- and Lighting-a</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489536&amp;idx=4&amp;sn=0db2a90c9c3207e168ac8be466fb54fe&amp;chksm=fd8642ec94cdbc8c319f9b21ae05497af5fdd87651c5a83e0a358d3d723e9259772f1851a242&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 20 Dec 2024 16:00:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[北航 | 第一个多功能即插即用适配器MV-Adapter：轻松实现多视图一致图像生成。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en3n1j1LLVnKmKxjJUkVMkfSL2lH1ru1uCJuUuA21YKHU5ia5SLlWu0BztQtHU3YSeZIYv3K9nGSHQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>北航提出了第一个多功能的即插即用适配器MV-Adapter。可以在不改变原有网络结构或特征空间的情况下增强T2I模型及其衍生模型。MV-Adapter 在 SDXL 上实现了高达768分辨率的多视图图</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489490&amp;idx=1&amp;sn=2f5ceaf10f43bd2074c45735daa26d91&amp;chksm=fd5675a3ba0a0a41c410f790cbad2610d58f0372db6fcbc13c8863f4869607153260ad0bfcaa&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 19 Dec 2024 16:05:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Google发布Gemini2.0，“Agent时代”最强大的AI模型！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5NbyjcY6R4PICML3ylBblKicx7wRU9ODC5RRyTZ42g2sxvzcC94gF7pTZHDYqh28rqf1tJxsLUiaK5TA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Gemini2.0是“Agent时代”最强大的AI模型，这是Gemini2.0自己给自己做的定义。起初我是有点质疑，但是！！当我看了一上午，慢慢的去了解它、与它接触，我又想起来Gemini2.0给自己</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489490&amp;idx=2&amp;sn=0646ed3e771ddad08c72762447b90d43&amp;chksm=fd02f288c2f925166b3ef9c5450b2caff803431397f9d5dec5f9ce74d1c9dd90ed943336a8c2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 19 Dec 2024 16:05:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[音频驱动肖像动画新方法LetsTalk,可生成与音频一致的逼真视频。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elS0nh744Xc7tB6W08RA4SgfkcDFOIyH4xJ5xG8Ar9Y0Uvicw6xicJzbmEtb2yOzCDNqYMjzkS4eYpw/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中已经给大家介绍过许多关于音频驱动的肖像图像生成动画方法，感兴趣的小伙伴可以点击下面链接阅读~复旦开源Hallo：只需输入一段音频和一张照片就可以让人物说话。开源EMO再升级！复旦|百度|南</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489490&amp;idx=3&amp;sn=8ba78d17cda32016c840b193621de181&amp;chksm=fde4cad7a3cecf8002b41350cdcc9bd9adf436b34c19ffb84bd6c4656c21c0c9d30e9fc81ba2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 19 Dec 2024 16:05:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[港大&amp;Adobe提出通用生成框架UniReal：通过学习真实世界动态实现通用图像生成和编辑。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en3n1j1LLVnKmKxjJUkVMkfcOvKg4alghJicfViaQXPN3cGVy3SYtSRiaWE0jyTlhQNs1mRy2lUoe0Pw/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的文章来自公众号粉丝投稿，由香港大学，Adobe提出的统一图像生产与编辑方法UniReal，将多种图像任务统一成视频生成的范式，并且在大规模视频中学习真实的动态与变化，在指令编辑、图像定</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489489&amp;idx=1&amp;sn=44c3de6d8d1c84e7bd014b7b633c07ff&amp;chksm=fd71fa407e9462d0803bd516b1a054a692d49b133b9da5522bfed419025b520b716aecf713c1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图像标注神器 X-AnyLabeling v2.5.0 重磅发布 | 通用视觉任务全新升级，交互式视觉-文本提示功能全面上线！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en3n1j1LLVnKmKxjJUkVMkf8Z9lY7oElmcEW2kBcjsiaJsWqzefPRerKj3OicsmT6iaDAia7GEuk905NQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 0. 导读X-AnyLabeling[1] 是一款集众多主流深度学习算法模型和丰富功能特性于一体的强大图像标注软件，其专注于解决实际应用。该软件能够显著提升标注效率和精度，为学术界和工业界提供高效的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489489&amp;idx=2&amp;sn=89024b24e6162bba14f90833e47b40db&amp;chksm=fde173f58fd7845da718d11f570044b57745802d90e9e4cf1b3c23787aeba29648fdac77f7d7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ComfyUI | OminiControl：Flux全能P图神器，乾坤大挪移&amp;重绘&amp;CN控制。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BRxta5juGS928SFwicoPauL4ibcxwsF4icAfHoM5E7cWZ0wl5nuhYicsQUn71uBkyCNWp59IAOeeibwgFZEtUKvapg/300?wxtype=jpeg&amp;wxfrom=0"/><p>OminiControl：FLUX.1的极简通用控制器点击关注上方公众号并添加公众号小助手加入官方读者交流群，一个有趣有AI的AIGC公众号:关注AI、深度学习、计算机视觉、AIGC、Stable D</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489489&amp;idx=3&amp;sn=358c9bbaa486e6f1a333247a945624a4&amp;chksm=fd76a25b3caa3c5e796f5654405b46c96c95a98e0943f609cb88ef5b412eaf0f9c0eec7bfd70&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一个LoRA同时处理内容和风格？UIUC提出UnZipLoRA，可同时训练两个LoRA，与原有LoRA兼容。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekK8oWGMLQzxWWfB4pkH8CCntib22WMYOGLwrnJpjeM7SCyxLnkZxmUEMEJADyvx3g4ZicOs12gOU1Q/300?wxtype=jpeg&amp;wxfrom=0"/><p> 一个LoRA可以同时处理内容和风格了？UIUC提出UnZipLoRA， 可将元素从单个图像中分离出来同时训练两个LoRA，与原有LoRA兼容。伊利诺伊大学厄巴纳-香槟分校的研究者们提出了一种将图像分</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489489&amp;idx=4&amp;sn=22f72de6c602fc53258e9f802c0b10da&amp;chksm=fd3b5378a0f8545026646e3db09bbf4908cd0769a5c60c1841358ae1c760a822c27681ae4259&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Face2QR:可根据人脸图像生成二维码，还可以扫描，以后个人名片就这样用了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enDXLyhv5gUBA9w7NggpzadO1jATGuCxxia6dLEgQBFVb37eWtav37qYkiabubYa9vGGTHlEWmbql9w/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的是一种专为生成个性化二维码而设计的新方法Face2QR，可以将美观、人脸识别和可扫描性完美地融合在一起。下图展示为Face2QR 生成的面部图像（第一行）和二维码图像（第二行）。生成的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489488&amp;idx=1&amp;sn=7fdd4637cd70eac6a6ce81699e4c3165&amp;chksm=fd711f9a1c59001a8d62478dc498b1d5df139a89f8c1a64e49aef6087d5b02c9f6aec9f5df86&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 17 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Flux LoRA | Then and Now：可将历史照片和现代场景融合，实现不同时间点的对比展示。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elnGoicbmLL47YzLd4HWhjwa5IZKDYBAO7LLOlXfTp24Tpqlh9Q3AG0qQKRWByqvmjXWQzoSf3LVqA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家推荐一个我最近发现的特别棒的概念 LoRA 模型-Then and Now，能生成过去和现在的照片相匹配的图像，可将历史照片和现代场景融合在一个画面中，实现不同时间点的对比展示。作为概念训练</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489488&amp;idx=2&amp;sn=19508db9a89d74462be6aa215bdbd0bf&amp;chksm=fd14d11fff109b204c01fa6279a46e74fa4996865262778675c7d7974ce812729acc1958e770&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 17 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[AI生成大片，Movie Gen可以生成长视频并配上完美的音效，带给观众更好的观看体验。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en7hMnHYqLSuapj6C0Hn0mXm2ceUm9LDTsGCA6gVbwy08k2trThGZg7tajWXlicmTHopRclOZ90icwQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中已经给大家介绍了一些关于长视频生成相关的技术，AI生成大片已经越来越近了。感兴趣的小伙伴可以点击下面链接阅读~《泰坦尼克号》AI大片重生！浙大&amp;阿里发布MovieDreamer，纯AI生成</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489488&amp;idx=3&amp;sn=e7c83aa3c6f89a3ae23bcc27a5414548&amp;chksm=fdab250cc4396859964f385178804037076b48e9f176e7ae0412de31ce91eef443823c3a6cb3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 17 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[英伟达提出ComfyGen：通过LLM来生成匹配文本的工作流。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eny4Iriba5NSXkHvLxicLITJDqnLYd3byQhrC0bKwIGSOFEPvibmO8gTicw8bg8Y16oLT3TR7jWM7j2AA/300?wxtype=jpeg&amp;wxfrom=0"/><p>ComfyGen的核心在于通过LLM来匹配给定的文本提示与合适的工作流程。该方法从500个来自用户的多样化提示生成图像，随后使用一系列美学预测模型对生成结果进行评分。这些评分与相应的工作流程形成了一个</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489488&amp;idx=4&amp;sn=e3718db1970c381b9ae2cfabe9172d16&amp;chksm=fd3ab1b05c3c9e4cf1dd7d8134c88b5601cc2a6f8e74fd24efde5e50ac4aca79b3ebe7d3fed0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 17 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[谷歌DeepMind重磅推出多视角视频扩散模型CAT4D，单视角视频也能转换多视角了。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emYIXZcOoWmiamNNy78gGxDxw4uWDBzPA32XByk1moUtrt0vCzrccsjPryianfay5w8IibgLtxibuRokQ/640?wxtype=jpeg&amp;wxfrom=0"/><p> 单目视觉4D重建再突破！谷歌DeepMind推出多视角视频扩散模型CAT4D，单视角视频也能转换多视角了。单目视觉4D重建再突破！谷歌DeepMind等团队，推出了多视角视频扩散模型CAT4D，它支</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489450&amp;idx=1&amp;sn=7851ba01590a76d477fac52cba8aca30&amp;chksm=fd2775915fbb675cb500d85048ad1797442887d051b66c1ddf15e4e12fd17aa91953f1bcb6d0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 16 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[文本转视频模型Allegro，可以生成长达 6 秒、15 FPS 和 720p 分辨率的高质量视频。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXSHQPic5rJ8IBKiaNosJKl47LGniaXW6NGticOnwCibeK5T8qlic4oPfsd5XwpM5KFOOqbuSEJIUictd6A/300?wxtype=jpeg&amp;wxfrom=0"/><p>Allegro 是一个强大的文本转视频模型，可以通过简单的文本输入生成长达 6 秒、15 FPS 和 720p 分辨率的高质量视频。主要特点• 开源：完整的模型权重和代码可供社区使用，Apache 2</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489450&amp;idx=2&amp;sn=28d1f03cfcb84fbb86f0668a57626a78&amp;chksm=fd7ad852685570429d07a97cfbf1697a9759502dd40da475e225ed2d74d4f8066bcf95369674&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 16 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[可控视频合成框架MIMO：可以模拟复杂运动并进行物体交互。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em63XUns9BWribhLaZgPeFEFgoPib1ZtNgvOGwxMrocc8qUiaTicFia2PrtUPkF5ux4TTfzxpOAuHia69uA/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里提出的MIMO是一种可控视频合成的通用模型，可以模拟任何地方任何人的复杂运动，并进行物体交互。给定参考图像，MIMO 可以通过几分钟的推理合成可动画的头像。它不仅可以通过简单的用户输入合成具有可控</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489450&amp;idx=3&amp;sn=eb712eed9199266ffc3d7d0a9a6d065e&amp;chksm=fd9c3fa474ab5e919a96ee3683f01e50f4a7216931511dcbc5aa5bc8d7b1a16bb78bd21549db&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 16 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[港大和字节提出长视频生成模型Loong，可生成一分钟具有一致外观、动态和场景过渡的视频。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eny4Iriba5NSXkHvLxicLITJD5gFTkWLoBqMSNfUicQxXgibIh9n6vokK5ia5EOh7ZDJLVHGEsbaLz86XA/300?wxtype=jpeg&amp;wxfrom=0"/><p>HKU, ByteDance｜⭐️港大和字节联合提出长视频生成模型Loong，该模型可以生成外观一致、运动动态大、场景过渡自然的分钟级长视频。选择以统一的顺序对文本标记和视频标记进行建模，并使用渐进式</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489450&amp;idx=4&amp;sn=03f7991ec725479ac365f2e593a36d6f&amp;chksm=fdba8d7332ea9ddf818507735d117943fa076ccc208ba7bd47332afc35894afd427408333807&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 16 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一图看尽AI文生图未来，北大发布文生图十年综述：超440项工作回顾。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enDXLyhv5gUBA9w7NggpzadRrialXnXJ0hpkUPylInNS5ibB5unS9uBgxThVxDiaMNn2QsZM4tTQg5Fw/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的文章来自北大发布的文生图十年综述，文章回顾了超过440项相关工作，重点探讨了生成对抗网络（GAN）、自回归模型（AR）和扩散模型（DM）在T2I任务中的应用和演变。还涉及了T2I技术的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489410&amp;idx=1&amp;sn=49d2a180ed2e8e04f11583ed6067eaa3&amp;chksm=fdbaf41cdb4c68adaa06592a5ee06319eecd652131e280d9a969a3c546a787257d735c6584ab&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 15 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多模态图像生成模型Qwen2vl-Flux，利用Qwen2VL视觉语言能力增强FLUX，可集成ControlNet]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuCwIlu7cc4lHd3hwJicoyYHx9RLCm1u1zJr61WGBPZZicviaGPyXN8y5ZTaZE9jpPcdNSX1nmUlib5g/300?wxtype=jpeg&amp;wxfrom=0"/><p>Qwen2vl-Flux 是一种先进的多模态图像生成模型，它利用 Qwen2VL 的视觉语言理解能力增强了 FLUX。该模型擅长根据文本提示和视觉参考生成高质量图像，提供卓越的多模态理解和控制。让 F</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489410&amp;idx=2&amp;sn=58aca5f9ec80f84ee30d84b44fcd0989&amp;chksm=fddd2cc339cf3b1c8c44bfa5120911b0d71e2c20a8f5761fb489d8e4fe82c617d4b8d9e289d4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 15 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OminiControl：一个新的FLUX通用控制模型，单个模型实现图像主题控制和深度控制。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuCwIlu7cc4lHd3hwJicoyYEn3PFyv0qTxQYEgq8VntmUj91vEEYPJjMADiamfkH94icSBs7fF1Tn1A/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中和大家介绍过Flux团队开源了一系列工具套件，感兴趣的小伙伴可以点击下面链接阅读~AI图像编辑重大升级！FLUX.1 Tools发布，为创作者提供了更强大的控制能力。OminiContro</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489410&amp;idx=3&amp;sn=5f228f6148037bec3ebb954d2733d3d6&amp;chksm=fdfacc6108ea2fc643053635f2ae5d122c29074522939beb98c36b3797e8ca5579f480aa17cf&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 15 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[文生图像编辑来了！英伟达提出Add-it，无需训练，可根据文本提示向图像添加对象。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emmkDiagtskaHJodPFibMTUYJZY50N6JpzSdpSqpDMMdhm1JHxUv7E3vPPDa6XmXuygFoa0eiaBct3Bg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Nvidia提出了Add-it，这是一种无需训练的方法，可根据文本提示向图像添加对象。Add-it 适用于真实图像和生成的图像。该方法利用现有的文本转图像模型 (FLUX.1-dev)，无需额外训练。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489410&amp;idx=4&amp;sn=fb84276718fa115a4b4300a3d8fac1f1&amp;chksm=fd7060319ec2da894c68bee5ad914cb4231fdf8a6ee8c6bccc0e21c024c595a2ee19686d35f8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 15 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[万众期待，谷歌正式发布 Gem)ini 1.0 ，包含三个版本：Ultra、Pro 和 Nano。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2el4eIaML40rNcaURA3WTSibqvHsHMchQTkJGsGjibUAC9vHubXy9en1avzJH5dic3qgdVAMXIKKmrLXg/640?wxtype=jpeg&amp;wxfrom=0"/><p> Gemini 发布一周年, 万众期待，谷歌正式发布 Gemini 1.0 ，包含三个版本：Ultra、Pro 和 Nano。Gemini Ultra——最大、最有能力的模型，适用于高度复杂的任务。 </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489408&amp;idx=1&amp;sn=988453237b24c69bc8d95d2e25ecc0db&amp;chksm=fd5017904ecb1be9f4e5f37b8ede8f2ab79be327a60326a331bd087465b588d10355c55c5678&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 14 Dec 2024 16:08:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Mistral AI 开源 Pixtral 12B 多模态 LLM，多场景能力理解，支持中文指令遵循！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekz6brgZd8MLzCQaTHcS8fyr4AQVZYW5XicicYO0FJtMDtMHtrnYOrMFWqicrbq1hkwWuJJFah4YbZlw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Mistral AI 开源了 Pixtral 12B 多模态 LLM。具有自然场景理解，代码生成，图像转代码，图像理解，多图指令跟随，图表理解与分析以及复杂图形推理等多项能力。从效果演示来看模型的能力</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489408&amp;idx=2&amp;sn=8123fe719f1843b45a966c19a8610599&amp;chksm=fd39c88ce92e5e73f758196920e3414724edc83128cd5491c31b955cfe87bf1cc67befe93774&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 14 Dec 2024 16:08:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[EAFormer：场景文本分割新SOTA，图像文本擦除无痕迹！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enWwUtW60pCT5iccd79FiakHIjXQOCEnv6AoiaoS0khCUKncrp8Xpp3mPYm7VNByYYo7TBDhcFnZ8vRQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>文章链接：https://arxiv.org/pdf/2407.17020 git链接：https://hyangyu.github.io/EAFormer/亮点直击为了在文本边缘区域实现更好的分割性</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489408&amp;idx=3&amp;sn=7b15a1fd9f8af950a957fc7753226380&amp;chksm=fdab42d6e2e5e96f64f111cb36e066b7b03b1600ff9525ef0b18554ba3d0d34c6740135d2233&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 14 Dec 2024 16:08:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ViewCrafter：一张图像就可以制作影视特效和游戏画面！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elPOajsP01qNvmwKPWKzicOsEEbzBxMRtYWNicS7fSTCWsMB1YH3tWIYmKrNLzGfsI0qOR2rIwTbN4g/300?wxtype=jpeg&amp;wxfrom=0"/><p>北大和港中文联合腾讯人工智能实验室提出了 ViewCrafter，这是一种利用视频扩散模型的先验从单个或稀疏图像合成一般场景的高保真新视图的新方法。可以简单理解为将复杂的图像转换成新角度的图像版本。首</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489408&amp;idx=4&amp;sn=da310383a01b736a7d7f02677a860482&amp;chksm=fddcc81ffaf4409430344073a387ddab594ab17e3f0c478834fd1a57af444195e88eec950e24&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 14 Dec 2024 16:08:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
