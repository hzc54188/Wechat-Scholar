<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[统一的图像生成模型OmniGen：可以根据多模态提示直接生成各种图像，无需额外插件。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enjwj4Ry2OH6auaAn9DU954RGLVLiaJQhnSsUOPiaYkiaE5VPAB4AUAtmLI24PhQm9bK4JduBhT9ZjTQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个北京市人工智能研究院 提出的统一的图像生成模型OmniGen，可以使用它来执行各种任务，包括但不限于文本到图像生成、主题驱动生成、身份保留生成、图像编辑和图像条件生成。OmniGen</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488661&amp;idx=1&amp;sn=03c0bea287c9a21b54aea5905084fea4&amp;chksm=fdc29a2d1f521af3390daf4e0ab4e8b1ac3c50c1b17dc07cad0e8f771dd89e57c5ef6d28fc64&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 28 Oct 2024 23:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[GroundingBooth：一个用于文本到图像的定制框架，支持多主题和文本联合接地定制！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekibUN5oqyRgSButjKACUwRIxoR4VWqymzeNXHxsW4rxM6qoeicJM6XkODXXx3zP4H0duuNP0vk91Sg/300?wxtype=jpeg&amp;wxfrom=0"/><p>GroundingBooth是一个用于文本到图像的接地定制框架。首先提取文本描述和图像的特征，然后通过一种特殊的注意力机制来控制这些特征的结合。这个机制就像是一个精密的筛子，确保每个对象和背景之间的信</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488661&amp;idx=2&amp;sn=e73709276ae072cde9c53c3509201af0&amp;chksm=fd3df8b30249ae945e91aff907dfe6efa0d403de5b7e6c30a0fba6b0fe4ca8eeeb82537e224e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 28 Oct 2024 23:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[NeurIPS2024 | OCR-Omni来了！字节&amp;华师提出统一的多模态生成模型TextHarmony。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enzia0AxvG3w5jnu5Q1nyOUw9icM2HlibUyI4RtyIsiaB9FOY9taoKCFlibTeImBZT585GC3ias7FialR6UA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在人工智能领域，赋予机器类人的图像文字感知、理解、编辑和生成能力一直是研究热点。目前，视觉文字领域的大模型研究主要聚焦于单模态生成任务。尽管这些模型在某些任务上实现了统一，但在 OCR 领域的多数任务</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488661&amp;idx=3&amp;sn=248eb2405292d3b0b6a5d2abeba6643a&amp;chksm=fd669af48b120c7e4745b8902f382a16593adbb333dc6eafe501d5ac27cecc1335acec3615ed&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 28 Oct 2024 23:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[零样本主题驱动图像生成新方法！EZIGen：在保持灵活性的同时保留主题身份！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en4dVnOT75Vve5gBZeAMAcqamPTNAwic2GwjgfabapQsxHL8u80ejLQBuGvbmR6PKA9PETicI3UQ5UA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个零样本主题驱动图像生成方法EZIGen，它可以从提供的主体图像中提取出重要特征，就像是给图像做一个“身份识别”，确保生成的新图像能够保留主体的独特特征。接下来，EZIGen会根据你输</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488661&amp;idx=4&amp;sn=58a12e99c2ebc6c29616442707e7162b&amp;chksm=fdb1ab17c440527f88fa952f9d496ae33bd1bdd7dceee825c218fbe6e025d69416d39758868d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 28 Oct 2024 23:00:00 +0000</pubdate>
    </item>
  </channel>
</rss>
