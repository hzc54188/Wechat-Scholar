<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIGC Studio]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIGC Studio公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      

      <title>gh_5ba19d995457</title>
      

    </image>
    






















    <item>
      <title><![CDATA[InstantX 重磅开源 FLUX.1-dev-IP-Adapter 模型，文中附模型和comfyui工作流下载。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eltYhV1JmK1ib9FbmIt2gIyP6xwE5MPwewm6kG9gwsXpPEaHHTOicBN3XsV2LsRvJ5qWf00gn2UwKaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>InstantX 团队的研究人员开源了 FLUX.1-dev-IP-Adapter，这是一个常规 IP-Adapter，新层被添加到 38 个单块和 19 个双块中。使用siglip-so400m-p</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489018&amp;idx=1&amp;sn=c67bb32c5a655ffe6d9c2357a0810ffd&amp;chksm=fd026fb8059a932dca3a1e9971b4f32fc5876b225f368112b612c733b3045461ae924c119980&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 24 Nov 2024 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Adobe提出RGB↔X：可由图片直接输出AO、法线、roughness等，再也不用PS分层了！已开源]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2el2gcPqyiclMWPWUZdmfKRIs9kMSga9RK7vVJdYR3SezDnSGSKr5S8MYpXvQLTvOxa2LothopykbpQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家推荐一篇今年 ACM SIGGRAPH 的论文《RGB↔X: Image Decomposition and Synthesis Using Material- and Lighting-a</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489018&amp;idx=2&amp;sn=2a37abc26c4ffa1f3494df528da70c43&amp;chksm=fde54a495337bf9747276579a82bbb3af693d3ebb2bab61a6f2d2cfe700245afe22ee0e90e24&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 24 Nov 2024 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Flux Lora｜可以和二次元合影啦！RealAnime-Detailed V2，可将动画与真实人物风格融合！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enzia0AxvG3w5jnu5Q1nyOUwqgvk05w7f8uadCgfhevafdaLgHvO27pEwiaeOFibIj2ibunwDjv1xj7oQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个很有意思的flux Lora：RealAnime-Detailed V2，可以合成二次元和真实人物混合的图片！它一个使用LoRA技术开发的Flux模型，专注于将动画角色与真实人物风格</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489018&amp;idx=3&amp;sn=e155a35b8f582fd0d25b7aa2845127e1&amp;chksm=fdb559659db4f9d14ad649ffbe467641bde4c79b96e0f9bd3d079abd974d239f4e84f85209fe&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 24 Nov 2024 16:00:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[AI图像编辑重大升级！FLUX.1 Tools发布，为创作者提供了更强大的控制能力。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eltYhV1JmK1ib9FbmIt2gIyPDOrcibpBhOX3OVdibquclM6ib7Tsxn7qhfDiclnY9wlicfpKLJib4fLuY7Og/640?wxtype=jpeg&amp;wxfrom=0"/><p>AI 图像编辑昨晚迎来了一次重大升级！ BlackForestLabs 发布了 FLUX.1 Tools套件，为创作者提供了更强大的控制能力。FLUX.1 Tools套件介绍这次发布包括四项新功能：F</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489017&amp;idx=1&amp;sn=9f7fd8f7e7a89798a0d66ffb68390c9f&amp;chksm=fdd0315faebb3ed5ca1afeb42508925be1aba0eb09206a7b41983537507a71ba8100d9aac15a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 23 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ComfyUI | OmniGen-ComfyUI：简化多任务图像生成和编辑操作,一键生成任意你想要的效果！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek3AzrrMoNWTaibIOp0yQxuUdhncrj6uxibR6BDtnnc5GUloGNfcX0jbZfEnkb7yqhSkm5IicnKTPlfA/300?wxtype=jpeg&amp;wxfrom=0"/><p>还记得之前的文章中给大家介绍过的OmniGen么？感兴趣的小伙伴可以点击下面链接阅读~统一图像生成模型OmniGen：可由多模态提示直接生成各种图像。今天给大家介绍OmniGen的Comfyui实现，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489017&amp;idx=2&amp;sn=16957a3998b77c0fb541baa6bf8548cb&amp;chksm=fdd967ab39a184ab2748bd5913b39e0b33592119b061903d5cd05305b195bc0e55925668b09e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 23 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多功能图像编辑框架Dedit:可基于图像、文本和掩码进行图像编辑。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekDYMeOJw6PMrPrgUmBfVvIibC8Suae7poAtMSSVAkicNMibK5CyJB4RLSAKFiajeuqXiaiaib0vMibRiaSKCQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个基于图像和文本的编辑的框架D-Edit，它是第一个可以通过掩码编辑实现图像编辑的项目，近期已经在HuggingFace开放使用，并一度冲到了热门项目Top5。使用 D-Edit 的编</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489017&amp;idx=3&amp;sn=f416a453049ff7154c46794241c4c9e1&amp;chksm=fd4a0ac205abaac88958d50c23fb8bb9ad37f3aeb98d367d36d1027b0df56585527c83ded5c8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 23 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[文生图像编辑来了！英伟达提出Add-it，无需训练，可根据文本提示向图像添加对象。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emmkDiagtskaHJodPFibMTUYJZY50N6JpzSdpSqpDMMdhm1JHxUv7E3vPPDa6XmXuygFoa0eiaBct3Bg/640?wxtype=jpeg&amp;wxfrom=0"/><p>Nvidia提出了Add-it，这是一种无需训练的方法，可根据文本提示向图像添加对象。Add-it 适用于真实图像和生成的图像。该方法利用现有的文本转图像模型 (FLUX.1-dev)，无需额外训练。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488996&amp;idx=1&amp;sn=2ca852758cae5d40427340998a557aee&amp;chksm=fdb3596272d8279d17d1d02df0c3f1dab4f42c15b2f115a2ab6a7cf2dcac011019779aaf7d9c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 22 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[中科大提出StableV2V：专注于「人机交互一致性」的视频编辑方法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elNNtPM78ZGthS1v10E8SuJjJZJ1jpxeT4mMS1ZD6HJQCcaHpCiaAWWDQj0oagrpmlt4viaVru4zsvA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天的文章来自公众号粉丝投稿，跟大家分享中科大在视频编辑领域最新研究成果StableV2V。随着OpenAI在今年年初公布了Sora的demo，video generation/editing的工作呈</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488996&amp;idx=2&amp;sn=2a22553af812e823588cdf5713c72b1a&amp;chksm=fd958c8c7837040d9ec16a976f8909a1bb0b18c168ea3b795e625b83c80f3742993609efbbc7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 22 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ComfyUI | Flux实拍与卡通风格lora推荐, 一键生成创意图像。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enzia0AxvG3w5jnu5Q1nyOUw7TQJFGYa2znHnNaWuO6u1JkCEEpxpul3G7pL6Igu3mLQyxXGM5cvPg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家分享一个非常可爱的flux lora，FLUX.1-dev-LoRA-One-Click-Creative-Template:能够一键生成4张同一角色的真实版图片+一个中间的卡通版Promp</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488996&amp;idx=3&amp;sn=75af9fc3eebf0a8a967f1a4dd2aed8e4&amp;chksm=fd7162740e8aa060f39800742f8c205ad7aab579eec05ded8ca79c611f3edbe3bb60272df1bc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 22 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DrawingSpinUp：让纸片人动起来!]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emwWYXMMSaEwzmib2YOZ13hLFISOPqwe4xL0jpPic818xD2dJibLZZF1ibk6vgTViaDQNLUJ7n2kJz585Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个非常好玩的应用，这个模型可以让你任意的纸片人动起来！效果也是非常的可爱！火柴人也能自由旋转、跳跃，甚至执行复杂的舞蹈动作。下图所示为DrawingSpinUp产生视觉上生动的3D角色</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488996&amp;idx=4&amp;sn=f635134239d2b239f1dee00f4ba962f5&amp;chksm=fdcfe93fefc0345194d19855d69228da12b40a6533fe7cf943cdfb13b4e3bf0afd31ff16c3bf&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 22 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[中科大提出StableV2V：专注于「人机交互一致性」的视频编辑方法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elNNtPM78ZGthS1v10E8SuJjJZJ1jpxeT4mMS1ZD6HJQCcaHpCiaAWWDQj0oagrpmlt4viaVru4zsvA/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天的文章来自公众号粉丝投稿，跟大家分享中科大在视频编辑领域最新研究成果StableV2V。随着OpenAI在今年年初公布了Sora的demo，video generation/editing的工作呈</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488974&amp;idx=1&amp;sn=aa4a0e7c58d28f7902df06cf6709a46c&amp;chksm=fdfa97ed310d9cc320dcdfb7c4fed5fcfb5d376bbd4214e24316c9b1bfb13dc9a87b8a00fe4e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 21 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Siggraph Asia 2024 | Adobe发布MagicClay：可通过文字引导对3D模型特定部分进行雕刻！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eldYoicjqyr71olTXNsd2FpJRUrSFOicVlJ9EDVptvjqu3DXUX2qZCR4C6D35wDfPGjSibEhSk8DyhGQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Siggraph Asia 2024 | Adobe发布MagicClay：可通过文字引导去对3D模型中的特定部分进行雕刻今天给大家介绍一篇来自Adobe研究人员在Siggraph Asia 2024</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488974&amp;idx=2&amp;sn=49981f88834d9a93125af2957668637d&amp;chksm=fdf5dfada59388a3db6b3839eee8489b0c5ec636c448acf60b9c0556b70983c2cc42006b8bf8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 21 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[突破T2I模型界限，组件可控个性化生成新方法MagicTailor：生成过程中可以自由地定制ID。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en5zm71fQSgV6aaqPJln47UM68LBoxEpKSBewPN29AuBHv1SMicLD8losQPDWSsMKunkqyr9HuAUvA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天的文章来自公众号粉丝投稿，文章提出了一种组件可控的个性化生成方法MagicTailor，旨在个性化生成过程中可以自由地定制ID的特定组件。相关链接论文阅读：https://arxiv.org/pd</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488974&amp;idx=3&amp;sn=586ac8c08bb3c3e30acc349f65a7e066&amp;chksm=fd088a98cf463fd1f7159fac7a9a2ff0ffefdc1a797c1cb747192b4b16a5a277e67b8d9d7a41&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 21 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Siggraph Asia 2024 | Adobe发布MagicClay：可通过文字引导对3D模型特定部分进行雕刻！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eldYoicjqyr71olTXNsd2FpJRUrSFOicVlJ9EDVptvjqu3DXUX2qZCR4C6D35wDfPGjSibEhSk8DyhGQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>Siggraph Asia 2024 | Adobe发布MagicClay：可通过文字引导去对3D模型中的特定部分进行雕刻今天给大家介绍一篇来自Adobe研究人员在Siggraph Asia 2024</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488937&amp;idx=1&amp;sn=511b6ea2363040ca5c64998c0ca859e4&amp;chksm=fd95de0e21069575ee12e340f646c6b41e03d6fbc3d7c219e28cd74abf19d7fd7080641435c1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 20 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[突破T2I模型界限，组件可控个性化生成新方法MagicTailor：生成过程中可以自由地定制ID。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en5zm71fQSgV6aaqPJln47UM68LBoxEpKSBewPN29AuBHv1SMicLD8losQPDWSsMKunkqyr9HuAUvA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天的文章来自公众号粉丝投稿，文章提出了一种组件可控的个性化生成方法MagicTailor，旨在个性化生成过程中可以自由地定制ID的特定组件。相关链接论文阅读：https://arxiv.org/pd</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488937&amp;idx=2&amp;sn=31a297acb31c8714d50a8719df3ef59e&amp;chksm=fdff978b928abe685f7d42aaef9849e32681f3a3938817262b461c35624ff6e086079d11959a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 20 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[统一条件生成模型框架BiGR：专注增强生成和表示能力，可执行视觉生成、辨别、编辑任务]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekDYMeOJw6PMrPrgUmBfVvITRuqwPj90UibQyKicRP7LocBbpMH4SUBfB12lzjOp2qj10noNYgEFHicQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>BiGR是一种新型的图像生成模型，它可以生成高质量的图像，同时还能有效地提取图像特征。该方法是通过将图像转换为一系列的二进制代码来工作，这些代码就像是图像的“压缩版”。在训练时会遮住一些代码，然后让模</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488937&amp;idx=3&amp;sn=66be625fe14451d7a3b7fd5547f47d66&amp;chksm=fd58326518e1b9dfea44e95e5e44a75d14155dadd395e7442892611550aaff34e9444431dc4f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 20 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[可控视频合成框架MIMO：可以模拟复杂运动并进行物体交互。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em63XUns9BWribhLaZgPeFEFgoPib1ZtNgvOGwxMrocc8qUiaTicFia2PrtUPkF5ux4TTfzxpOAuHia69uA/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里提出的MIMO是一种可控视频合成的通用模型，可以模拟任何地方任何人的复杂运动，并进行物体交互。给定参考图像，MIMO 可以通过几分钟的推理合成可动画的头像。它不仅可以通过简单的用户输入合成具有可控</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488937&amp;idx=4&amp;sn=144c609e9404e8eeeb9820b4dcf4c144&amp;chksm=fdf479eac1f4fbea99c96a2c26788ef0928d873755d6e9965a504feb28c0e6e8cefee60359af&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 20 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ComfyUI | OmniGen-ComfyUI：简化多任务图像生成和编辑操作,一键生成任意你想要的效果！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek3AzrrMoNWTaibIOp0yQxuUdhncrj6uxibR6BDtnnc5GUloGNfcX0jbZfEnkb7yqhSkm5IicnKTPlfA/640?wxtype=jpeg&amp;wxfrom=0"/><p>还记得之前的文章中给大家介绍过的OmniGen么？感兴趣的小伙伴可以点击下面链接阅读~统一图像生成模型OmniGen：可由多模态提示直接生成各种图像。今天给大家介绍OmniGen的Comfyui实现，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488936&amp;idx=1&amp;sn=ada2232d5d2650344d0da9783f8a492b&amp;chksm=fd6b004327f85ce6e6353eab44b287dbb08100a9154108db1bc62ab916e16b1e7f3c18b44c8a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 19 Nov 2024 13:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[统一图像生成模型OmniGen：可由多模态提示直接生成各种图像。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enjwj4Ry2OH6auaAn9DU954RGLVLiaJQhnSsUOPiaYkiaE5VPAB4AUAtmLI24PhQm9bK4JduBhT9ZjTQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个北京市人工智能研究院 提出的统一的图像生成模型OmniGen，可以使用它来执行各种任务，包括但不限于文本到图像生成、主题驱动生成、身份保留生成、图像编辑和图像条件生成。OmniGen</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488936&amp;idx=2&amp;sn=e215415486fc144a459a629a8a4abfe5&amp;chksm=fd1da9e4d711fe845151b4f7ea5d5dde72231a6437da1ed9141019d75255039ffa02a30ba3e1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 19 Nov 2024 13:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图像编辑大一统？多功能图像编辑框架Dedit:可基于图像、文本和掩码进行图像编辑。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekDYMeOJw6PMrPrgUmBfVvIibC8Suae7poAtMSSVAkicNMibK5CyJB4RLSAKFiajeuqXiaiaib0vMibRiaSKCQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个基于图像和文本的编辑的框架D-Edit，它是第一个可以通过掩码编辑实现图像编辑的项目，近期已经在HuggingFace开放使用，并一度冲到了热门项目Top5。使用 D-Edit 的编</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488936&amp;idx=3&amp;sn=57812370766175d17e0f3d5335180163&amp;chksm=fd3a3f70d9a5ee03e3efb86d9ce3457f7557f2786c708dc513869df89b5c3541978645b04585&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 19 Nov 2024 13:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[百度发布文心iRAG技术,大模型终于知道如何去掉“AI味儿”了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek3AzrrMoNWTaibIOp0yQxuUg66Wl5pVrueNkiaPJXXZuPC7YY4zEJoVC86CSNyG385XSML8wHlKjMw/640?wxtype=jpeg&amp;wxfrom=0"/><p>11月12日，李彦宏在百度世界2024大会上，发表了主题为《应用来了》的演讲，发布两大赋能应用的AI技术：检索增强的文生图技术（iRAG）和无代码工具“秒哒”。文心iRAG用于解决大模型在图片生成上的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488933&amp;idx=1&amp;sn=78ed40b60a384acfb77ca45af4241a5a&amp;chksm=fdecf2066f0832fb3acb00c5e164b94a23a66f4523a55481863c6378d65d399c74e3cafc1b50&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 17 Nov 2024 16:37:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
