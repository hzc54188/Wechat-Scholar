<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIGC Studio]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIGC Studio公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      

      <title>gh_5ba19d995457</title>
      

    </image>
    




























    <item>
      <title><![CDATA[刚刚，阿里重磅开源基于FLUX的In-Context LoRA，可一次生成多张风格和ID一致的图片集。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elnGoicbmLL47YzLd4HWhjwaZq27QklGnm2euIIenh9a4vvHuaekrpqk2PuGae3ghYQjGRse85BXsA/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍In-Context LoRA 这个项目太强了，前几天发布的时候就引起了许多小伙伴的关注，但是当时还没有开源，就在刚刚，作者开源了In-Context LoRA项目。它基于FLUX训练，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488724&amp;idx=1&amp;sn=8db864e5b1098b3e661805547439293e&amp;chksm=fd78c7d59b25760d6483cab92f446ff28bca67952f718fb50e66e99aaf71a95bfbb8d204f96e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 04 Nov 2024 16:00:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[超火的开源文本转语音工具 F5-TTS，一段音频+文字就可以模仿你想要的任何声色。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXSHQPic5rJ8IBKiaNosJKl4QQWgqW0Vjia1wZ7KjB0bJZhC8sUt9Nknjh8xHMh9TGk0ibRKE6OQykwA/640?wxtype=jpeg&amp;wxfrom=0"/><p>F5-TTS是一种完全非自回归的基于流匹配和扩散变换器 (DiT) 的文本转语音系统。无需时长模型、文本编码器和音素对齐等复杂设计，只需用填充标记填充文本输入，使其长度与输入语音相同，然后进行去噪以生</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488704&amp;idx=1&amp;sn=43aec685fd757cfdc670f1e68280cc96&amp;chksm=fdfc6c5b36f474f72c7da7e01264edfd25b27c8183e65aded726d6b8ba0bd39ddc913f3db61a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 03 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ChatTTS：对话式高可控的语音合成模型，最强文本转语音工具！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeHe6LRGvmFzc5YNEYkO9c1cFSsR6eODR1H7cQTYwnRxnVtWMtNFHZJhcBia8MQvH4ApUYFKcibZkA/300?wxtype=jpeg&amp;wxfrom=0"/><p>ChatTTS 一夜爆火， 极速出圈， 3 天就斩获 9k 的 Star 量， 截止 2024.06.04， 已经 19.3k 的 star， 极速接近 GPT-soVITs 当天的 26.2k 的 </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488704&amp;idx=2&amp;sn=64fbbd1b88d41e818e9f598749dd6495&amp;chksm=fd50f3dcda3b8f2003aac99bfe5e4569e436ed646dc4a865a35f50945f4fc17c5f841a036adf&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 03 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Seed-Music：字节跳动开发的音乐生成模型 支持多种数据输入生成和编辑音乐！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elIm6icxMVSQ1CxgxFiaRZRxgIpSB6lVKMSWd1DpYwO7bNGaOdrtXY1KXTzkCV8N36E83o4z8JLtxBQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Seed-Music是一个由字节跳动研发的音乐生成模型，用户可以通过输入多模态数据（如文本描述、音频参考、乐谱、声音提示等）来生成音乐，并且提供了方便的后期编辑功能，比如修改歌词或旋律。Seed-Mu</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488704&amp;idx=3&amp;sn=d0bbed958f92b8c952516e9f840bf496&amp;chksm=fd8bfade1b8f35752bf2d6ecfea105f98d11a4be0728efe1235129e2ccba9567d7cd9ac46d64&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 03 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[​Controlnet作者新作IC-light V2：基于FLUX训练，支持处理风格化图像，细节远高于SD1.5。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXSHQPic5rJ8IBKiaNosJKl4zjuJBWaX5OT2Lf7ZUfribJIKIVPQd63HVFcGOR4owDUYVuia3JgZoueg/640?wxtype=jpeg&amp;wxfrom=0"/><p>IC-light V2：支持处理风格化图像“IC-Light”全称是“Imposing Consistent Light”，IC-Light 是一个操纵图像照明的项目。目前已经发布了两种类型的模型，两</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488703&amp;idx=1&amp;sn=20c443d99caac8474a7e65b3fa6d4044&amp;chksm=fd82800e4f576ce86568b576d9751d4a04462cd5565b45c3ee4f130a01ab2ff92b4e70fb7b8f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 02 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[IC-Light，可以操控图像生成时的光照，光照难题终于被解决了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXSHQPic5rJ8IBKiaNosJKl4D4jiaGaa5GeibYBiaoVp4eKPOAz9ez3Mj92SalvXYF357u7eaShMkxejw/300?wxtype=jpeg&amp;wxfrom=0"/><p>IC-Light代表Impose Constant Light,是一个控制图像照明的项目。可以操控图像生成时的光照，对内容主体重新打光生成符合新背景环境光照的图片。这下商品图合成这种需要最大程度保持原</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488703&amp;idx=2&amp;sn=ca474593a963d550f1089b62b3b82802&amp;chksm=fd1eed3aec5167b8a95dbfdeab7e095b09e2442b9aaa298555e5ee1ef8e7df6dfd4896f8ec6a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 02 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OpenFLUX.1：去蒸馏版本的FLUX.1-schnell，可进行微调，文中附模型下载地址。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em63XUns9BWribhLaZgPeFEF68DHq3end31f9ZeHc7bJm8s1bVHfwoVODQFRw7YKRY0IS5kLxL8nvA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Flux Schnell 是经过 Apache 2.0 许可的，但它是一个蒸馏模型，这意味着无法对其进行微调。然而，这是一个很棒的模型，可以在 1-4 个步骤中生成令人惊叹的图像。近期，开源社区上有人</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488703&amp;idx=3&amp;sn=2805a0daca9e6c1fcbca4396f6978501&amp;chksm=fd62c1f2cdc2ef755fa00d1d54fb596fc530315f93ded534a748c4c9a849a956fdef7037b209&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 02 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[零样本主题驱动图像生成新方法！EZIGen：在保持灵活性的同时保留主题身份！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en4dVnOT75Vve5gBZeAMAcqamPTNAwic2GwjgfabapQsxHL8u80ejLQBuGvbmR6PKA9PETicI3UQ5UA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个零样本主题驱动图像生成方法EZIGen，它可以从提供的主体图像中提取出重要特征，就像是给图像做一个“身份识别”，确保生成的新图像能够保留主体的独特特征。接下来，EZIGen会根据你输</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488703&amp;idx=4&amp;sn=c35663c123f57a0ef121eb0758c8ceef&amp;chksm=fdc992f4d78d66615d80de2ee442de0a36dcf9be5de00b3496bd31322ef9edc739f16f8dc1d5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 02 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Flux Lora｜可以和二次元合影啦！RealAnime-Detailed V2，可将动画与真实人物风格融合！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enzia0AxvG3w5jnu5Q1nyOUwqgvk05w7f8uadCgfhevafdaLgHvO27pEwiaeOFibIj2ibunwDjv1xj7oQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个很有意思的flux Lora：RealAnime-Detailed V2，可以合成二次元和真实人物混合的图片！它一个使用LoRA技术开发的Flux模型，专注于将动画角色与真实人物风格</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488702&amp;idx=1&amp;sn=70107543f5c0ecbb94ec501b8f18468a&amp;chksm=fdcdf3ed3dfa9f13dbb3c6b4eb3b0e2e2c9f5470222953cacd16d27fafd28626aa6cc34621a3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 01 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[免费开源 AI 证件照制作工具：HivisionIDPhoto，文章附下载和使用教程。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emVz5IyibD56YfAMqS63ibnE79C90fGSNkrr3zcFjBAhZUiaoYiavM4pxriaRyhXia9icULucAbSTWvL812w/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家推荐 GitHub 上一个轻量级的 AI 证件照制作工具：HivisionIDPhoto。实现了对多种用户拍照场景的识别、抠图与证件照生成，并提供不同尺寸规格的标准证件照。感兴趣的小伙伴可先</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488702&amp;idx=2&amp;sn=00801667fb4311c409904ba0eae09bb6&amp;chksm=fd9a9143659ad5b05812f514b2335dd70adf4ea8369474e114e9732c54768d23ef4280031f86&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 01 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CustomCrafter，可保留动作和概念合成功能的定制视频生成框架！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emy0sTwEr46sY1TPQUca24qEr6a2p0foxbK63246N9Qkew62Ao8GWBjoAlibINQt95oRPfFzA5ia4wA/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯联合浙大提出了一种定制化视频生成框架-CustomCrafter，它能够基于文本提示和参考图像生成自定义视频，同时保留运动生成和概念组合的能力。通过设计一系列灵活的模块，使得模型实现了无需额外视频</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488702&amp;idx=3&amp;sn=4fb3dd74b48a215afa43a62ee653c9b1&amp;chksm=fda2d958a46a4c6b3378ca46b1f37ad3aa0b7dd2be24cba639fa38c4791c50c47ca37a08b1ca&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 01 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Glyph-ByT5-v2，支持10国语言图文海报生成，效果惊艳！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekUlTbakAQ9PkRVtjuPOYtMklfrlDVxgTLUqQxQB6Xzp3hd7zxxMa0HXnBhpURAxPhMlClBWcF7eQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>清华&amp;北大&amp;微软&amp;利物浦大学联合提出Glyph-ByT5-v2这款工具支持多语言图文生成，包括英语、中文、日文、韩文、法文、德文、西班牙文、意大利文、葡萄牙文和俄文。以下分别展示中、英、日、韩图文的视</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488702&amp;idx=4&amp;sn=5a7939b9d1925e89f8558fc4dd96d69e&amp;chksm=fdb06100462eba112fcde0c50b4ff3c93d19961788711f4b4c1ee8bc99528a255c94ba44aaaa&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 01 Nov 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[阿里巴巴推出升级版AI翻译工具：Marco MT 性能超越Google、DeepL和ChatGPT]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekDYMeOJw6PMrPrgUmBfVvICGVGwvK1ZowHkm5otQN1GWBq1oKgOpXCvFcU6T8e0WgLCSBUqvcfmg/640?wxtype=jpeg&amp;wxfrom=0"/><p>阿里巴巴的国际业务部门于推出了一款升级版的AI翻译工具，名为Marco MT。这款工具在翻译性能上超越了Google、DeepL和ChatGPT的同类产品。该工具的目标是帮助商户更好地在全球市场销售，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488701&amp;idx=1&amp;sn=f0e0cb37d36aa42baf94d3f364d36589&amp;chksm=fd9800798a6f3705c79c21e2d26ea5fc57dada8e46537196a78e3d3b72f52bd0138b13cd91c3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 31 Oct 2024 22:11:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[UIUC提出InstructG2I：从多模态属性图合成图像​，结合文本和图信息生成内容更丰富有趣！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekx1e8oxA3YKibkhot7h9UJZqBubdMgx3yBMfDK8JGL4YYX3hw4kJVRCHjFaqvVYYc7nEPXjibpCEug/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的这项工作是伊利诺伊大学厄巴纳-香槟分校的研究者们提出的一个新任务 Graph2Image，其特点是通过调节图信息来合成图像，并引入了一种名为InstructG2I的新型图调节扩散模型来</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488701&amp;idx=2&amp;sn=2d5783cb36385536df2759642354117f&amp;chksm=fdbd12834e1417a1b08e002d76ef94d0eefe212d170a8035da44e62deb112e97eb370b1ecfda&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 31 Oct 2024 22:11:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[港大和字节提出长视频生成模型Loong，可生成一分钟具有一致外观、动态和场景过渡的视频。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eny4Iriba5NSXkHvLxicLITJD5gFTkWLoBqMSNfUicQxXgibIh9n6vokK5ia5EOh7ZDJLVHGEsbaLz86XA/300?wxtype=jpeg&amp;wxfrom=0"/><p>HKU, ByteDance｜⭐️港大和字节联合提出长视频生成模型Loong，该模型可以生成外观一致、运动动态大、场景过渡自然的分钟级长视频。选择以统一的顺序对文本标记和视频标记进行建模，并使用渐进式</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488701&amp;idx=3&amp;sn=9bf506f3fabe0199361a53a5868384a7&amp;chksm=fd2177eb6b71d6b9b1c6c3af545e06684f31493f36641bb5fc15e0f57c24e513d1d2e753676d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 31 Oct 2024 22:11:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ScribbleDiff：使用涂鸦精细引导扩散，实现无需训练的文本到图像生成。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en4dVnOT75Vve5gBZeAMAcqnHFQnQNTu2jZ3gdtvtEhgfeuBiawdPpo4eRXb4xIj7t0TCyfMVB3Rhg/300?wxtype=jpeg&amp;wxfrom=0"/><p>ScribbleDiff可以通过简单的涂鸦帮助计算机生成图像。比如你在纸上随意画了一些线条，表示你想要的图像的轮廓。ScribbleDiff会利用这些线条来指导图像生成的过程。首先，它会分析这些涂鸦，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488701&amp;idx=4&amp;sn=27a4add445756a40a03fe744b202923a&amp;chksm=fd09450a8a6006c2fde53a5bb6215ad48682978e8c6639704b0dc1d2c21ecd101813dc0138ea&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 31 Oct 2024 22:11:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图像编辑大一统？多功能图像编辑框架Dedit:可基于图像、文本和掩码进行图像编辑。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekDYMeOJw6PMrPrgUmBfVvIibC8Suae7poAtMSSVAkicNMibK5CyJB4RLSAKFiajeuqXiaiaib0vMibRiaSKCQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个基于图像和文本的编辑的框架D-Edit，它是第一个可以通过掩码编辑实现图像编辑的项目，近期已经在HuggingFace开放使用，并一度冲到了热门项目Top5。使用 D-Edit 的编</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488699&amp;idx=1&amp;sn=85b41adad2e418d1817c9f3b452c28a8&amp;chksm=fd9dc0e29c917c55cf31f893f694d34949f076de2003e3848405059f90ae5d14c8eaf68f0335&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 30 Oct 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[自动生成ComfyUI工作流？英伟达提出ComfyGen：通过LLM来生成匹配文本的工作流。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eny4Iriba5NSXkHvLxicLITJDqnLYd3byQhrC0bKwIGSOFEPvibmO8gTicw8bg8Y16oLT3TR7jWM7j2AA/300?wxtype=jpeg&amp;wxfrom=0"/><p>ComfyGen的核心在于通过LLM来匹配给定的文本提示与合适的工作流程。该方法从500个来自用户的多样化提示生成图像，随后使用一系列美学预测模型对生成结果进行评分。这些评分与相应的工作流程形成了一个</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488699&amp;idx=2&amp;sn=17107037158b0dc638a3a9821c92a664&amp;chksm=fd77543a8033e36921a18c0cf81d58ba9fc00f5655f5ad85dc3a759e1f2911977bf6ff8ba2cf&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 30 Oct 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[长篇故事可视化方法Story-Adapter：能够生成更高质量、更具细腻交互的故事图像。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekx1e8oxA3YKibkhot7h9UJZSKKULxCTzezvw8wSOvf1jqib40MePuLWQamEVrmH3RC3HsKvOkJ9S3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前已经给大家介绍过关于故事文本生成图像的相关内容，感兴趣的小伙伴可以点击以下链接阅读~字节&amp;南开提出StoryDiffusion：生成一致的图像和视频来讲述复杂故事，图灵奖得主Yann LeCun亲</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488699&amp;idx=3&amp;sn=af0b42380e5b570520e14a730d5a8ceb&amp;chksm=fd026e536578bb032b3655936b0a35e20726719298f6401191f2809a65012dcb292ba92f9ad0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 30 Oct 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CVPR 2024 | 英伟达发布新一代视觉基础模型: AM-RADIO = CLIP + DINOv2 + SAM]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vgev6PHxuZ0Dvab3vYyROyU9ESg3n8zG0anOa04cV0GwicWOGAJ4dG0eXAYscczTvCEPaibXFictDib936FdbCMoww/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击关注一个有趣有AI的AIGC公众号:关注AI、深度学习、计算机视觉、AIGC、Stable Diffusion、Sora等相关技术，欢迎一起交流学习💗～标题：《AM-RADIO: Agglomer</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488699&amp;idx=4&amp;sn=5ad85e49fd868257f051727402d5a47e&amp;chksm=fddf098f78cc1ee96b0e7b790a63c7fd9c68cc3bf3db0346b281d5fd75d965345c2c0f2b5236&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 30 Oct 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[做游戏不用建模了？微软提出DIAMOND：AI可根据玩家行为自动实时合成下一帧画面！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enzia0AxvG3w5jnu5Q1nyOUwt2qWt9shOGw9sxyFMLh9xibEGauevCtfMZJhxjvescfqkeFTwyalPicg/640?wxtype=jpeg&amp;wxfrom=0"/><p>DIAMOND是一个完全在扩散世界模型中训练的强化学习代理。上图显示了在扩散模型中玩耍的代理。DIAMOND的扩散世界模型还可以训练来模拟 3D环境，例如下图中的《反恐精英：全球攻势》（CSGO）。并</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488662&amp;idx=1&amp;sn=1f3848988c69dce00e3efc62b81e7532&amp;chksm=fdb6fe7c81a1e307327b72b448ed469cda9ae1f0707542239d817006a424e31b94239792bb6e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 29 Oct 2024 16:03:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Story-Adapter：能够生成更高质量、更具细腻交互的故事图像。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekx1e8oxA3YKibkhot7h9UJZSKKULxCTzezvw8wSOvf1jqib40MePuLWQamEVrmH3RC3HsKvOkJ9S3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前已经给大家介绍过关于故事文本生成图像的相关内容，感兴趣的小伙伴可以点击以下链接阅读~字节&amp;南开提出StoryDiffusion：生成一致的图像和视频来讲述复杂故事，图灵奖得主Yann LeCun亲</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488662&amp;idx=2&amp;sn=0df72236d6c2585906d3f72fdf044b94&amp;chksm=fde488b0194cf63b1f4d80b842b71a38fa5209c06a7e508eadc396308db58291cc523170124e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 29 Oct 2024 16:03:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ComfyUI 轻松实现二次元线稿上色，快速生成精美动漫图像。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE43ZhibNumWwPfbNYseGEicjXGtYQia6kicWCRv6eS0GlIiaZkGh8JUPFH5UibjRzVKH3qNK6YYfu8LiadVw/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击蓝字关注我吧！ComfyUI轻松实现二次元线稿上色，快速生成精美动漫图像在数字艺术创作领域，效率和品质一直是创作者们关注的焦点。ComfyUI为创作者们提供了一个灵活且强大的图像生成工具，它不仅可</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488662&amp;idx=3&amp;sn=270381deb42690e929612e2d78210137&amp;chksm=fd499474c27c5870fdd9939af10322a480a2a701a7788ee45afecb1f125e44ad4a1a262ee39d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 29 Oct 2024 16:03:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[阿里开源MIP-Adapter，可将IP-Adapter推广到多个参考图像！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en553ETYWe4BYUv7R7Iibote1AADVDfRBnkq3JPLgRiclNJjwcPXztGYwW8ChWH8NjEcr9ibKS4asmjg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍阿里最近开源的个性化图像生成的新方法MIP-Adapter，将无需微调的预训练模型（IP-Adapter）推广到同时合并多个参考图像。MIP-Adapter会根据每个参考图像与目标对象的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488662&amp;idx=4&amp;sn=6812c45302cf97385439dc7ce9cffe05&amp;chksm=fd286dff4458c9135c00972bc8823805aa112bb2192ca8952234e45e411e7afece2f9d7fe163&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 29 Oct 2024 16:03:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[统一的图像生成模型OmniGen：可以根据多模态提示直接生成各种图像，无需额外插件。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enjwj4Ry2OH6auaAn9DU954RGLVLiaJQhnSsUOPiaYkiaE5VPAB4AUAtmLI24PhQm9bK4JduBhT9ZjTQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个北京市人工智能研究院 提出的统一的图像生成模型OmniGen，可以使用它来执行各种任务，包括但不限于文本到图像生成、主题驱动生成、身份保留生成、图像编辑和图像条件生成。OmniGen</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488661&amp;idx=1&amp;sn=03c0bea287c9a21b54aea5905084fea4&amp;chksm=fdc29a2d1f521af3390daf4e0ab4e8b1ac3c50c1b17dc07cad0e8f771dd89e57c5ef6d28fc64&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 28 Oct 2024 23:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[GroundingBooth：一个用于文本到图像的定制框架，支持多主题和文本联合接地定制！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekibUN5oqyRgSButjKACUwRIxoR4VWqymzeNXHxsW4rxM6qoeicJM6XkODXXx3zP4H0duuNP0vk91Sg/300?wxtype=jpeg&amp;wxfrom=0"/><p>GroundingBooth是一个用于文本到图像的接地定制框架。首先提取文本描述和图像的特征，然后通过一种特殊的注意力机制来控制这些特征的结合。这个机制就像是一个精密的筛子，确保每个对象和背景之间的信</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488661&amp;idx=2&amp;sn=e73709276ae072cde9c53c3509201af0&amp;chksm=fd3df8b30249ae945e91aff907dfe6efa0d403de5b7e6c30a0fba6b0fe4ca8eeeb82537e224e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 28 Oct 2024 23:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NeurIPS2024 | OCR-Omni来了！字节&amp;华师提出统一的多模态生成模型TextHarmony。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enzia0AxvG3w5jnu5Q1nyOUw9icM2HlibUyI4RtyIsiaB9FOY9taoKCFlibTeImBZT585GC3ias7FialR6UA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在人工智能领域，赋予机器类人的图像文字感知、理解、编辑和生成能力一直是研究热点。目前，视觉文字领域的大模型研究主要聚焦于单模态生成任务。尽管这些模型在某些任务上实现了统一，但在 OCR 领域的多数任务</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488661&amp;idx=3&amp;sn=248eb2405292d3b0b6a5d2abeba6643a&amp;chksm=fd669af48b120c7e4745b8902f382a16593adbb333dc6eafe501d5ac27cecc1335acec3615ed&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 28 Oct 2024 23:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[零样本主题驱动图像生成新方法！EZIGen：在保持灵活性的同时保留主题身份！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en4dVnOT75Vve5gBZeAMAcqamPTNAwic2GwjgfabapQsxHL8u80ejLQBuGvbmR6PKA9PETicI3UQ5UA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个零样本主题驱动图像生成方法EZIGen，它可以从提供的主体图像中提取出重要特征，就像是给图像做一个“身份识别”，确保生成的新图像能够保留主体的独特特征。接下来，EZIGen会根据你输</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247488661&amp;idx=4&amp;sn=58a12e99c2ebc6c29616442707e7162b&amp;chksm=fdb1ab17c440527f88fa952f9d496ae33bd1bdd7dceee825c218fbe6e025d69416d39758868d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 28 Oct 2024 23:00:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
