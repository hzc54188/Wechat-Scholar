<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIWalker]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIWalker公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_db54cfe1dbf6.jpg</url>
      

      <title>gh_db54cfe1dbf6</title>
      

    </image>
    



















    <item>
      <title><![CDATA[超越CogVideoX-5B、Pika、Kling 和 Gen-3！苹果再发新作，视频生成大模型全面报告]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoiaU9gb3fBukUg9eaI0qvSaia3kNdR1HUxsOicru0rR8O60GvFibdeqicxKazSdn41hVwGneucAjwu1qicg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Zongyu Lin 等    解读：AI生成未来 论文链接: https://arxiv.org/abs/2412.07730HuggingFace</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699465&amp;idx=1&amp;sn=3b4e865b759cd7f3ad13935f5ec0d719&amp;chksm=f27ee3fe0c97ebc359030743fecc41ce69a1070c6b221bdbe6db2d2638e03d90bbb2b8d8ae2b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 22 Dec 2024 14:01:08 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[VILA-U：统一多模态理解与生成模型！多模态任务新架构！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5IqN6LmUo0fdib09eyT1m3vNpnpvmiag90TaETdpiblFBx79hRansXeE1JPgNpOI8MZ0KVoOxGcyn49Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AI妙妙房，作者妙妙房论文名：VILA-U: a Unified Foundation Model Integrating
Visual Unders</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699465&amp;idx=2&amp;sn=9f5c18741379b435463b5c9f48c9338d&amp;chksm=f288e42497bc68ea5477b07c531becab0a01d7b67f64bd4335ea57255d35cc047b3056bb6e3a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 22 Dec 2024 14:01:08 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[释放你的想象！支持25种复杂编辑类型！浙大等提出AnyEdit：统一高质量图像编辑框架]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogvQmU85Kosfv2RDCta999EbyF8VGjNflEKL8rzY2kCTLkHufbCjRTU5ianGMict4uibvsA4bKvfblyA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Qifan Yu 等  解读：AI生成未来 文章链接：https://arxiv.org/pdf/2411.15738 项目链接：https://dc</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699463&amp;idx=1&amp;sn=786ce6f9506d277be400ab00f845130c&amp;chksm=f28a665589eb94c27b15913be801b9d95a3428dca8f0f90a68395e3516353a379b367471d391&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 21 Dec 2024 14:09:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[InstructSeg来了！全面的指令性视觉分割新方法！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5JXJ2jNsoPbZYaxuh3c3VmG7Y9icaDDxk3DWLyFrtibDPsQDfWYxQgZmkozdvpzPviaEibfKNGrGjODhw/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AI妙妙房，作者小源论文名：InstructSeg: Unifying Instructed Visual Segmentation with Mul</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699463&amp;idx=2&amp;sn=317b29d1f83ed9dce9e7b73ce294341d&amp;chksm=f2106c91e3db0f5b05afbb575e5c8f728cc56a8de1abdeffbf51fab942ae615aaa8c3dc7277c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 21 Dec 2024 14:09:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[BiSeNet之忆往昔 | BiSeNet用AI新语言交出了自己的答卷，BiSeNetFormer依旧大杀四方!]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVW1dajAo3kYXqaur3qMyNY3bWFKVAhTRtiaic37syfZqtC7RTicwHRyG3GPicvnMnOnRdjhFxn8M2x30A/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AI视界引擎，作者AI引擎近期在图像分割领域的进展主要集中在提高模型的效率，以满足实时应用的需求，特别是在边缘设备上。然而，现有的研究主要集中于单任务</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699461&amp;idx=1&amp;sn=268a5f9a0e92dd1a5f62172e7a3ed821&amp;chksm=f2b27c983edd220577f9b09e48707550582a57edd31f80d2a92ccc5c2f79a55e25d2786421ae&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 20 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[训练扩散模型比你想象的更简单！谢赛宁老师：Representation matters！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfo6MHfL6rh1U7d9022CaPm7e9HXRDxjnVfb8Waf4W3EtcPo9pzWGTHl96cFzbtNmsDEEBX3q0CQ7w/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者丨科技猛兽    编辑丨极市平台极市导读 表征的对齐真的很重要！之前我们训练扩散模型的路可能是错误的。 太长不看版训练扩散模型可能比你想象的更简单。纽约</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699461&amp;idx=2&amp;sn=9255d5e013ba933e58617bf2adf46947&amp;chksm=f29e13f4a90f2e3f2b39c3a161fdc372e3d26153885acf8ce7a4f6db79a2e22131b9fa18a5c1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 20 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一文看尽2024年主流11种注意力机制]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiaXicJR3DBH33uCibYFbichXEFQTVa3iaaVBWBRS2viaSEMyhYACN5Jjt58cphX8xxGYibyLuXYUicpl22nQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>注意力机制已经成了模型设计的基础架构，现在模型里没个Attention都不好意思发出来。从注意力机制发布到今天，学术界一直在对Attention进行各种魔改。魔改后的Attention能够提升模型的表</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699459&amp;idx=1&amp;sn=401633a52c358f8097a5fb7bf4d2af63&amp;chksm=f26bf61d5b0b2e03b68e9fdd38e3b8282c87d2d60a0b4f3577ec87fe5b951b0930b99d1432ed&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 19 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图像修复和编辑大一统 | 腾讯&amp;北大等联合提出BrushEdit：BrushNet进阶版来了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoj5y5tcjbKa8WBL9PiayXJ6EyibgRP0vDtog3Of2MQjEfqSjduF7yiaOYwNmVOSfmTFQJ1OSVP7TTZ0Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Yaowei Li 等    解读：AI生成未来 文章链接：https://arxiv.org/pdf/2412.10316项目链接：https://</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699459&amp;idx=2&amp;sn=6148140407fd952838ea2c470041db37&amp;chksm=f2ea57a7a9388179aa517a7656329d0d91ef00d3d8e8046e481824f881011378249b83f5a001&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 19 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图像标注神器 X-AnyLabeling v2.5.0 重磅发布 | 通用视觉任务全新升级，交互式视觉-文本提示功能全面上线！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vgev6PHxuZ364K0zUNtscY3Md7MrnU43iaM2ibPqCRCJl6XzuEXibaNOyHDT0JQXd92Agwetiag4b5mY8W0dgPw5fw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | CVHub   链接 | 派派星0. 导读X-AnyLabeling[1] 是一款集众多主流深度学习算法模型和丰富功能特性于一体的强大图像标注软件</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699458&amp;idx=1&amp;sn=bde432067980362b4adf62b35e601881&amp;chksm=f23234d7a97b658afff5692398ebddba59b0300bf4c505996c5dcc032481dbb15fbbedbfd27c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[鹏城实验室提出MoH | ViT、DiT和LLM上MoH只使用50%左右Head即可完成超越]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/2VBsQebGdeRKnKsZticPmqULUclU39fqq3hUgBDgrvHouh23EGiaTCD0r9UWWFN0HH0QagYCv0fUJjHXcNLqNUxg/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | AI落地之芯    链接 | AI芯落在这项工作中，作者将Transformer模型的核心多头自注意力机制升级，以提高效率，同时保持或超过先前的准</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699458&amp;idx=2&amp;sn=48461bc3d3e7a65bb38ea4e68d767bdd&amp;chksm=f2a2021addb32dd34907a71313333d20b2e8af03b903e41dc21ba499388ad12cf378bb734eb8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[恺明新作Fluid：文生图质量刷新纪录！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogmGicd2icrNU7grbicTGvw3XuxY9s1sbE8LXTA38tN9zarA3e6OiaibEQSicjrXKHgfE6BOCqF2EYnqwdQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Lijie Fan等    解读：AI生成未来 文章链接：https://arxiv.org/pdf/2410.13863缩放法则（Scaling l</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699448&amp;idx=1&amp;sn=bd07b8406eff7d0bf90ac2b707dcbb51&amp;chksm=f23e7f041aab0221dae0150a84c356e1de778be636b578384218c785c997cb676b6f38a6d292&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 17 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[风格控制水平创新高！南理工&amp;InstantX&amp;小红书发布CSGO:简单高效的端到端风格迁移框架]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogvOuicVruQPPXwbCSmgjRn3yHyRicjlLicVlFoDdw4SsjYNQicrQ2FhUZcGWH5JYsWkSdDJnLiaEvumgA/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：Peng Xing等    解读：AI生成未来     论文链接：https://arxiv.org/pdf/2408.16766 项目链接：https://csgo-gen.github.io</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699448&amp;idx=2&amp;sn=beed876645ed313cac21442edbc59d8d&amp;chksm=f27bbae424601cf402b968fd72b48fb6e11ef5bc401e3363c952a17655bcc671ab43529b7d47&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 17 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[首次实现8K图像生成！FreeScale让扩散模型解锁更高分辨率！| 南洋理工&amp;阿里&amp;复旦]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoiaU9gb3fBukUg9eaI0qvSaiadaB1UniaCLPhicQ2l9mibaXbiaiaxC2ajyRQib68PG4IOlIibkkd7fr3aRDKA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Haonan Qiu 等    解读：AI生成未来 文章链接：https://arxiv.org/pdf/2412.09626 项目链接：http:/</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699446&amp;idx=1&amp;sn=7614d04675b7b7b37a5e3fb4d3603a5b&amp;chksm=f22ee7dcfe8741eb632817a3a0fe68ae6c943bc3899712c646ce5261b0a175369d66b6889698&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 16 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ECCV'24｜清华黄高团队提出Agent Attention：无缝集成Softmax和Linear的注意力机制]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfo3qv46xrQ9XnqDiae6E41BtTg8oKliaOy9SshdAVMpLVuPRiaoLNfsicxCfniavicuEZZTFia4vEFEiaJVkw/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者丨科技猛兽    编辑丨极市平台极市导读 本文介绍了一种新型的注意力机制Agent Attention，它结合了Softmax Attention和Li</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699446&amp;idx=2&amp;sn=963b39112b0aaac8f422bbe97330268e&amp;chksm=f2f58272af2d954613662dd6753d39b8d52793d2cb0471bf1d2bb74a99ffafb32ec48abd9bab&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 16 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[codebook从崩溃到高效利用！南大&amp;清华&amp;腾讯联合打造IBQ：自回归生成最强视觉分词器]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogpCiarFsHVrfQGiaHApawVKraoNzZKKr9eciab4gUsvHwyvz2R7K1XX56XiazrV6ranCtkVW3hua6pTQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Fengyuan Shi 等  解读：AI生成未来论文链接：https://arxiv.org/pdf/2412.02692github链接：http</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699444&amp;idx=1&amp;sn=447acb46d4e19ba588bc735ffbeb1430&amp;chksm=f2edea4a05cafd95dbfafef76565bf1d1cea00051383af2c473616c2bda81bf39e13e0f9d3d3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 14 Dec 2024 14:11:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[4K分辨率拿下！超强杀器SANA：线性扩散模型+文生图+高分辨率+从头训练的极佳范本！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoB3wnvyicAeBiapGlk1QnaYXZCPH1FA4Apdk4C3vqMN8BfEfMegdgP6t7cVx4fib32z9ht9PSdcFiaNQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者丨科技猛兽    编辑丨极市平台极市导读 Sana通过32倍压缩率的AutoEncoder、线性注意力机制、Decoder-only的文本编码器以及高效</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699444&amp;idx=2&amp;sn=9ad5bb5d117b39feb64117c0a372fdce&amp;chksm=f294cc90c387946bcf41ee3353fe5d8f1c282b1c03331c53a46cab90d78f2e1df6ed7dfb4691&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 14 Dec 2024 14:11:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[MobileNetv4 震撼来袭 | 汇聚轻量化设计方法之大成，统一轻量化模型生态]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/2VBsQebGdeT3PAmRr0D8fF3Tz2bWnTPCibIAm6HFKvH5ibVMn2wdf6KVdeslMTkTBv1V2Z2gibiaHGvia5TRuEtGLrA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AI落地之芯，作者AI芯落随着深度学习技术的不断发展，其在图像处理领域的应用越来越广泛。本文提出了一种基于深度学习的图像分类与分割方法。首先，利用卷积</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699442&amp;idx=1&amp;sn=ac4184c702b989d615f36a724d218708&amp;chksm=f2258e32244db5a169fc677f014ed29f7c17187a6ed5f75ccf32e15b3f56b4cb1f7c3c47fe41&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 13 Dec 2024 14:05:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[最强最快ViT诞生 | CAS-ViT 提升图像分类、目标检测、语义分割等任务性能，可部署到手机端！！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tgnHM7b4wWTtsxbDGn9SFd0o0xFoZ8RVjIPolbrIujmQw01UQiaAw36GJ6icxjJxIlnqcVoZFh28iazxw/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于集智书童，作者小书童视觉 Transformer （ViTs）与它们的标记混合器的强大全局上下文能力标志着神经网络的革命性进步。然而，标记之间的双向亲</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699442&amp;idx=2&amp;sn=40fa2292999b9a5bb7a8fb85ea0366a3&amp;chksm=f21e1efe3b21b3586a08c9d5180c4a798e9d5d4083b8d60621a6ee2d90e772406571521e8c64&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 13 Dec 2024 14:05:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[被导师放养，我是这样逆袭的。。。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiax1wtkyNF60IH1KJLVLc1j471cibUk2R5Zf55ictPCtxYf9OLn9qwe6rQx4udiaziaNwVGGuMCYYFw6Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>被导师放养，你以为是没有压力，自由自在。实际上很多人没有自制力，被放养后没有方向，根本设计不出实验方案。甚至临近毕业，连论文都不会写。这就是放养最严重的后果：写不出论文，没法正常毕业。后面找工作/升学</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699416&amp;idx=1&amp;sn=3a4b2db1c50ac3a7c1af89b6e021b64c&amp;chksm=f2585234191caee345eda10c68b7e83b301da32c246a37b18e51dc3771a631ea298638d1ca37&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 12 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CVPR 2024 | 英伟达发布新一代视觉基础模型: AM-RADIO = CLIP + DINOv2 + SAM]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vgev6PHxuZ0Dvab3vYyROyU9ESg3n8zG0anOa04cV0GwicWOGAJ4dG0eXAYscczTvCEPaibXFictDib936FdbCMoww/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于CVHub，作者派派星标题：《AM-RADIO: Agglomerative Vision Foundation Model Reduce All D</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699416&amp;idx=2&amp;sn=06f7d6bbabd59baa3b81e9b228f75aea&amp;chksm=f226b101f83d238e3cc3b6c9ef68c12bd81f7651e74574ff6943df8fe835c9ee4ef831cb5037&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 12 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
