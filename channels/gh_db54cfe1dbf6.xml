<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIWalker]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIWalker公众号]]></description>
    

    <language>zh-cn</language>
    






    <item>
      <title><![CDATA[LSTM又火了！最新52个创新思路+全部开源代码！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDjbGXqZJ6qRq4DuG8U5IOsYpjiaUJt8dj1joQjNa27sudN6vvc7W7a9f9JwoDIBPh6s3HyZ8RXaAIg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今年上半年，LSTM火了！LSTM原作者分别提出xLSTM和Vision-LSTM，解决了以往的局限性。同时，LSTM+Transformer登上Nature；LSTM+CNN、LSTM+Attent</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698401&amp;idx=1&amp;sn=fdf8bb0bd6a97c3e1aff4a904975784d&amp;chksm=f2006468fb3a1ebb812844d31dda587bff059663433874354ba61858b4a043ffa8dd8a7a36b7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 18 Jul 2024 11:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[用ViT取代Encoder！VIM：使用 ViT 改进的 VQGAN 进行矢量量化图像生成（ICLR 2022）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfqYNbKKpnMmpFrmmvqmxxnibhFUFzVlU4oEPvRgKjkFAiaRGCsrNb6djtamptHfr7lnhicRIrX6b6aeA/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者丨科技猛兽    编辑丨极市平台极市导读 本文探索了在 VQGAN 里面，把图像的 Encoder 换成 ViT。本文改进之后的 ViT-VQGAN 进一步改进了矢量量化图像建模的任务，包括无条件</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698401&amp;idx=2&amp;sn=94b175712c84203d77dcefcbd7a73c97&amp;chksm=f21961e6f26deb9370265cb1f3e2cd704c2d445e560f82cd8080baaf70d0e0dc82bf19563dc6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 18 Jul 2024 11:00:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[HAFormer：融合 CNN 与 Transformer 的高效轻量级语义分割模型 ！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVVicxRd6Fj48RzbHqtfVVkRffrzHrvnRj0Jd02klaGiabPqpOW6wiaeRCNpYGyydicnA7FmNlpj1flnKg/640?wxtype=jpeg&amp;wxfrom=0"/><p>在语义分割任务中，卷积神经网络（CNNs）和Transformer都表现出了巨大的成功。人们已经尝试将CNN与Transformer模型集成在一起，以捕捉局部和全局上下文交互。然而，在考虑计算资源限制</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698374&amp;idx=1&amp;sn=d7f985062522a93daaca5204f8d1f20a&amp;chksm=f2edcd7de78ec28f6538703dd5eaf3b530045c8d7dd0250f5923f0f94fba38f93ac5efc620f9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 17 Jul 2024 14:24:12 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[英伟达也对 Mamba下手了  ，视觉 Transformer 与 Mamba 的完美融合 ！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVVPdWMSoIl2eAlGnGInAOfww03F8ciboW0VRLoia1ic6J2J8QW5VoFuAenrezDqMrgFGYnLjfThqyA2w/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者提出了一种新颖的混合Mamba-Transformer架构，称为MambaVision，这是专门为视觉应用量身定制的。作者的核心贡献包括重新设计Mamba公式，以增强其高效建模视觉特征的能力。此外</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698372&amp;idx=1&amp;sn=6848ab228bf814ffed2cf9bd72b11548&amp;chksm=f23841031d47b63a41f3a4d2d3765ca1e6d05530c4a85755745c21562388ab775d1af4a2e643&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 15 Jul 2024 14:54:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[扩散模型的低比特量化方案探索，Q-DM：性能比肩全精度模型相当｜扩散模型经典解读]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfq3s71lOFGiadwqQuKK6tOrYavJaicyTK93iaT8jra10FhSEn93fCXBYao3QauzmdZxTz8ZKr206qrMg/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者丨科技猛兽  编辑丨极市平台极市导读 本文提出 Timestep-aware Quantization (TaQ) 方法减少输出分布的振荡，提出 Noise-estimating Mimickin</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698370&amp;idx=1&amp;sn=d04888cfecc09717d98c8d86785497db&amp;chksm=f2c79f771bf8505a806d3b04113bd108414d1979f8a8aacd7fe2e6210a57918971e86ee2187b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 12 Jul 2024 13:46:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[缝合怪系列 | 82个必备即插即用缝合模块！附下载]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiaa9F6OD1qnnK7KqruBRPicQmK5s2N0sKUEwzpwn2JR9iaiaj1rtrZNdOgFqlB4E4zwVaCIs065f4aYg/640?wxtype=jpeg&amp;wxfrom=0"/><p>有创新点，就能顺利发paper吗？当然不是！有了创新点只是开始，模型的编码、调试才是重头戏。很多小伙伴都是改了大量的模型和代码，实验结果却没有多少提升，白白耽误投稿时间。今天就分享一些发paper必备</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698368&amp;idx=1&amp;sn=49cab5006e681cdaba042e6741bf6b85&amp;chksm=f2b2c6b9530c4196f9364b23636cf950aa3bbd92a3c050ba25a3866daafcda53e748b0fc1e8d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 11 Jul 2024 10:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[绝地归来！英伟达等提出JeDi：无需微调,个性化图像生成新SOTA！[CVPR 2024]]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoia5Ra17hBayxO2WZmJbRePic7zkaCrkLt5XibWJSeH0SianEYBMhT3teuFo4Y1EXgd58mqmOR4tvUNaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Yu Zeng等    解读：AI生成未来文章链接：https://arxiv.org/pdf/2407.06187 github链接：https:/</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698368&amp;idx=2&amp;sn=3c65e7fa03d2529f7900c2d1b37621eb&amp;chksm=f24e909fdcbdc4d922673bbaf1d4ee458ded0ef962acae202ed0dd7c8ac199738eb896af26e9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 11 Jul 2024 10:00:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
