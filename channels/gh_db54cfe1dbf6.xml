<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIWalker]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIWalker公众号]]></description>
    

    <language>zh-cn</language>
    


















    <item>
      <title><![CDATA[YOLOv10开源｜清华用端到端YOLOv10在速度精度上都生吃YOLOv8和YOLOv9]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDgB9sLM36mh1xmFaJqOJiaX0EGZCwNFtByP7qOh56WiaM5LcPQy9ISl082Ban2R7mEbibVphXyyibx1tw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注「AI视界引擎」公众号在过去几年中，YOLO系列模型已成为实时目标检测领域的主导范式，这得益于它们在计算成本和检测性能之间的有效平衡。研究行人探索了YOLOs的架构设计、优化目标、数</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651697877&amp;idx=1&amp;sn=d7f30e352011b78abe84d30bb151fa0e&amp;chksm=f2ff6a331163e2749204996d749d1f70255f17d90f1907292f35eb136ffd46dc010e5063654e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 27 May 2024 14:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[魔搭开源推理引擎 DashInfer，助力CPU服务器解锁大模型超强推理]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/8ZLuyaibrZbm1kPxO7yCxApo22qrdzn38uHab8JYNt6ib2RPtHPbthxYVqrtWSc701F6HvWa2pSz0OLBZIzG2Yqw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在CPU上高效推理大模型，是当前加速生成式AI应用广泛落地的核心命题。就此，ModelScope推出了预训练大语言模型（LLM）推理引擎DashInfer，采用C++ Runtime编写，提供C++和</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651697877&amp;idx=2&amp;sn=33fecea95f39babf89334924d2059613&amp;chksm=f2c38d007000c170f3456aed4d9cdf58a5e09a22adf08f4ccf3f386d31366295fb16f8bba3f4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 27 May 2024 14:00:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[单步图像生成！Adobe提出将Diffusion Models 蒸馏到 GANs中的新方法Difusion2GAN！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KhcNVCpiaAFr81Had0dQvhxAFSzPUeZT0qeuYjDfN5BIO2O9EuTrSW59eAdwEqx4vmqw2c4nZ30LQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AI妙妙房，作者妙妙房计算机视觉最新论文今日论文推荐论文名：Distilling Difusion Models intoConditional GA</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651697867&amp;idx=1&amp;sn=70740b11bdb58703375b87f80c9de9e9&amp;chksm=f218e7f37777ce628c88c9c01c3c5ac33489fddfd006b15d6ef2c94938a9e8a6c3529507e389&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 16 May 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[迈向统一扩散框架！Adobe提出RGB↔X：双重利好下游编辑任务 | SIGGRAPH'24]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icojiaNYpLOMt9Dv1GicBINu7HfDDkB5LeHHWwkILexEhbc43qVfCWxiaeicz6jeAiconpz7uiaOApPrx6icFQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Zheng Zeng等  解读：AI生成未来     文章链接：https://arxiv.org/pdf/2405.00666 最近的研究表明，现实</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651697867&amp;idx=2&amp;sn=2dd609e585ea6755ac037549d3ff66bf&amp;chksm=f29e7b312dd17ed22c7886e036a0ee5609a5f68b93bbc7bf01c94987966303a597ab8adacabb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 16 May 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[底层视觉之美｜无中生有的真相与假象——论生成式图像复原]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiaI9L76Ych3ibRPAkObbKEIsJG9yApIdtmOrEGicfzrAz2ychpia4ciateFCfDCcBybv0UoEILEC222Hw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者 | 董超 来源 | XPixel视觉团队   推荐 | 推荐各位同学关注XPixel官方公众号现在请我们闭上双眼，回想一下蒙娜丽莎的画像，你曾经无数次</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651697865&amp;idx=1&amp;sn=0ebfb9721379979bd0757adecbcf728c&amp;chksm=f28bb928b1cf337901c35e36dad520c3678e42aedba26c39068dcbed5ef8cda0e40193ac52e0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 15 May 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CVPR 2024 满分论文出炉！这些方向爆火！【附下载】]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiaI9L76Ych3ibRPAkObbKEIs7ZBbPu7yk8HYdIQbIiarhIsMiaMQQ50P5ialLCJianEEUeo3PCyAicQ9fPw/640?wxtype=jpeg&amp;wxfrom=0"/><p>众所周知，论文是人工智能学习的基石，因为论文展示了不同方向最新的研究成果，了解并且掌握这些学习成果，会对自己写论文助力不少。这次我整理了AAAI 2024 / CVPR 2024 / ICLR 202</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651697863&amp;idx=1&amp;sn=2ccd1d52e585d8729972ce3734256677&amp;chksm=f2e0c0d18872bc82efbc654a2359ec09d4d74e8308f6e472908dcb421574239dbdb0edaa88b9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 14 May 2024 10:22:42 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[力压Transformer？首篇Mamba综述来了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VnDXQzNf28jC3PJibUibibxicrQhLDJFicWZXTsAEDN27M8l2LyMHeGpp5BGU3VcfDvMxTaea8cvzjic4q89o2jh4qQA/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路论文作者 | Rui Xu    编辑 | 自动驾驶之心写在前面&amp;笔者的个人理解Mamba是一种新的选择性结构状态空间模型，在长序列建模任务中表现出色。Ma</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651697863&amp;idx=2&amp;sn=c4633aa9b565a230dfc5f7d0205e57e5&amp;chksm=f255914bcf482176c8248d28353c62a21b57549fa74fe103ae8d13c9695d213031fa68609c02&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 14 May 2024 10:22:42 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[StarNet：关于 Element-wise Multiplication 的高性能解释研究 | CVPR 2024]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/s1ZNq0rdQe4U6A1bCibqJrbsPia1ws9QiabsFMvOt05yVAXeibibx9PYZoD7U3Xt0G9fradCIxJFXUqlickpApN5tvng/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文揭示了star operation（元素乘法）在无需加宽网络下，将输入映射到高维非线性特征空间的能力。基于此提出了StarNet，在紧凑的网络结构和较低的能耗下展示了令人印象深刻的性能和低延迟来源</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651697817&amp;idx=1&amp;sn=3e7b0d7ffdba5a0409c4ff7fba9389b9&amp;chksm=f23d938b5460269b3a5f47b9e498da4e62d22267d0e0c53482d01fdf15b835342a455dda5431&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 13 May 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[既要又要｜SemanticFormer时空关系和空间关系都不放过，性能超越一众SOTA]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVUvaNtWmPqDN0bftLVbPAftbyb6NKPrV8ZibI47iakf78gnMvqASicWIicvgoqhEZ2QLK0ictJxYybPodQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路文章来源于AI视界引擎，作者AI引擎自动驾驶中的轨迹预测依赖于对驾驶场景中所有相关上下文的准确表征，包括交通参与者、道路拓扑、交通标志以及它们之间的语义关系</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651697817&amp;idx=2&amp;sn=ddea01af643cda30da132d3d6cb717fa&amp;chksm=f2101cd81d47e9eace4bb0183f52be20703e992db441ba4e5cab5b608d63c4939636f83ada32&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 13 May 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【图像分割数据集汇总】字节发布 COCONut 入选 CVPR 2024，立即体验 Segment Anything 分割万物！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/QkCvnz083Ahgv4OhZbulNO443bCicd3u58X3Sia1KLKCHT1X2F96CFrichsI6qPx1eBlOCAo5Q5U4mSt8ulbtw9UA/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着计算机视觉技术的不断发展，图像分割在诸多领域展现出重要的应用价值。近年来，各种图像分割数据集如雨后春笋般涌现。上个月，字节跳动发布了首个大规模全景图像分割数据集「COCONut」，为这一领域的研究</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651697811&amp;idx=1&amp;sn=fe22b6683d4a1820833d40e1ba8bc414&amp;chksm=f23e6036b10ae4525aba7819aafc73e78af52bfc2b1e729b0dcfc41406a89e04908ca20aefeb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 09 May 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[媲美Sora！可生成16s 1080视频！清华联合生数提出视频生成新模型Vidu！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5Lzmln3hFfbZvKu7PM59HWs6LkFc0o6as2mgl4dibbC6YhiakP9ApHoOamcwlHDibOluGGJaHe9p29rw/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AI妙妙房，作者妙妙房计算机视觉最新论文今日论文推荐论文名：Vidu: a Highly Consistent, Dynamic and Skille</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651697811&amp;idx=2&amp;sn=e33dbe54321770cdd686281b71008c09&amp;chksm=f2d6b8c2070fc6c0188f07d7f8d4c516f657e2a165125bffa4fb856267b82bf0e8910901d885&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 09 May 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[窄带高清画质增强之生成式细节修复]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Ua9PWyGDDPhtmvicNxGdURibSL2lFQXQ3y9NJLQx1sz6pt61SpKL7PA44wrtib3icDgQZ6Gib6OBFj3mzZeEYLfcJgw/640?wxtype=jpeg&amp;wxfrom=0"/><p>让最佳视觉感受更广，更普惠。兮墨｜技术作者IMMENSE｜内容编辑Cloud Imagine阿里云窄带高清本质上是一种转码质量优化技术，是一套以“人眼主观感受最优”为基准的视频编码技术。研究的是在带宽</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651697809&amp;idx=1&amp;sn=d3f61853bd09277c5ed2ab9019dc1519&amp;chksm=f2a99cd8726a658b4e1b7e0b891c2f74ce2e5c8f419f19449cd1c5dbfdc6de7e87395ed29700&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 08 May 2024 13:36:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[BiSeNet之忆往昔 | BiSeNet用AI新语言交出了自己的答卷，BiSeNetFormer依旧大杀四方!]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVW1dajAo3kYXqaur3qMyNY3bWFKVAhTRtiaic37syfZqtC7RTicwHRyG3GPicvnMnOnRdjhFxn8M2x30A/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注「AI视界引擎」公众号近期在图像分割领域的进展主要集中在提高模型的效率，以满足实时应用的需求，特别是在边缘设备上。然而，现有的研究主要集中于单任务设置，尤其是语义分割，这导致了针对不</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651697809&amp;idx=2&amp;sn=00d71762805df9017382b113758b7efe&amp;chksm=f2da1827ef641929982dad5fa3d34812b14e7bf6da95af5a95c45c3d4dfbf46dd3d14da14542&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 08 May 2024 13:36:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多模态融合的56种创新改进，助力CV顶会！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDhKwWlKtG5XjSfKWtwdib1VSCMKwqM4hk0SqqSMs8BaXTRicTuODcwOKAgnJyunFaTdxVCl2Kk5sI8g/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，今天分享一个我认为未来最好发论文的方向：多模态融合。我总结了56个多模态融合的创新点，并整理了对应论文，来自ICLR2024、AAAI2024等顶会。想发论文的同学们赶快扫下方二维码下载资料合</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651697807&amp;idx=1&amp;sn=8455c29727a2fb493eb0c492149004ca&amp;chksm=f2c603d3fb82335c1db75ab8eaa5e7ab768430690d5f5611a0c0077cff75aea1a5b98bce3a22&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 May 2024 10:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[虚拟试衣 | 商用级别 | IDM-VTON：改进扩散模型实现的高保真换装]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VFicX5Qfj1eAknTXuzRicWSpWxdicWavnpn9zjYA2FBCxACTdfm9tDuTIq2iaQfLZt4mQ7GpmNNEuuUG8DXd2ycazA/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AICV与前沿，作者雨沐林风项目地址：https://github.com/yisol/IDM-VTON文章地址：https://arxiv.org/</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651697807&amp;idx=2&amp;sn=7ee83dbf38d3b1448b425a61dc628147&amp;chksm=f24214073813137d8401bca362717fa9e3057df5a469e8c97103bec4685a7b4d4d1a7959e350&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 May 2024 10:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CV届的GPT， ImageGPT：使用图像序列训练图像 GPT模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfrxge4MkbNugqDMdCDgzibWDYJia2fPQy7X4TKqhEvY2ReIgOKbz7iapAT4QP9iahDWJs6aGRkaOMpiaXQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者丨科技猛兽    编辑丨极市平台极市导读 在 CIFAR-10 上，iGPT 使用 linear probing 实现了 96.3% 的精度，优于有监督</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651697806&amp;idx=1&amp;sn=dcf59116696ff5c80a72cae2a3e295b3&amp;chksm=f22368051600496db17056ed77f322ee782610bd410ef4cba911b85b55e484d2109a258b6cbc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 May 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[微软新突破! VIDiff：第一个统一的视频理解和编辑框架]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoiaqBiciciat1CRxkwotm2xWvCCMHvMkKMxFdeEib7HX5W5AzpHj0bBEfokf81ETicd7DSs721n114ljyKA/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AI生成未来，作者AIGCer扩散模型在图像和视频生成方面取得了显著的成功。这激发了对视频编辑任务的日益关注，其中视频根据提供的文本描述进行编辑。然而</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651697806&amp;idx=2&amp;sn=62e14945dbb10ed93cf2fa7e750dec50&amp;chksm=f24e248304deb8da54b59fc6aee330a41bc4b454d5368d8b2d863d250eeaec5bcbc676688065&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 May 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CVPR 2024｜大视觉模型的开山之作！无需任何语言数据即可打造大视觉模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoMOVgJNT1ws4tOK50yIPdwImXRMvcTSGBaLePeCiasGNsV9ruFTD3EK64myIzWibsSO0x6d71pltBQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者丨科技猛兽    编辑丨极市平台极市导读 本文提出一种序列建模 (sequential modeling) 的方法，不使用任何语言数据，训练大视觉模型。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651697798&amp;idx=1&amp;sn=bd4dad467cdc64a06667104d6bd530cb&amp;chksm=f215f8cd3a8c40932c1cf1d895105b74b2a92612b898b6371c0d126e717655ce6b69e8e49df5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 05 May 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ID-Aligner：要真实还要好看，结合美学评分的高保真身份保持生成方法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/MRJiclxHSU3aEqAicGoHC4Z923OoTicGJrOiaw3LqhLGbxqVGOk450SOLnjDRBRhdPksJTEfD8tMPyOt47qV4gB2Cg/300?wxtype=jpeg&amp;wxfrom=0"/><p>“ID-Aligner: Enhancing Identity-Preserving Text-to-Image Generation with Reward Feedback Learning”项目</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651697798&amp;idx=2&amp;sn=584d2e665508b49493a746b9e84539b0&amp;chksm=f29c4f3baeae97bb42f1cdb5879ef9e91c0e4e4d1dd12fbfff9f9e96755af0af1931d2119fda&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 05 May 2024 14:00:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
