<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIWalker]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIWalker公众号]]></description>
    

    <language>zh-cn</language>
    










    <item>
      <title><![CDATA[开源！优于Domo AI！！阿里Diffutoon：端到端的高质量视频动漫化方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VFicX5Qfj1eCP9qjjqnSNkG2g55IpBL2PiaJpwweldeeI9WhGXzQqEiacRA2h9oVoNOiaUGVicfDJOJAuia11dxxjOibw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AICV与前沿，作者雨沐林风文章地址：https://arxiv.org/abs/2401.16224项目地址：https://github.com/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698262&amp;idx=1&amp;sn=3c7fbe3e937d26c440fd2389ba66be8e&amp;chksm=f2f9e3c7df31a4a20572681b8da7dd02877a0902387d0bd29ab20c844ec1d3b5254c985e402e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 26 Jun 2024 14:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[跳过不重要，关注关键点 ！ ToSA ，优化 Transformer 层的标记处理，为密集预测任务削减计算成本 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVUJ780kicFHfU7TunzVmqJDe9GmUhvQdovzP75iccJZibicsdDARpNsEVIdYjszhb28PIKvAqQ1iamoOZg/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AI视界引擎，作者AI引擎在本文中，作者提出了一种新颖的标记选择注意力方法，即ToSA，它可以识别需要关注以及可以跳过 Transformer 层的标</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698262&amp;idx=2&amp;sn=1930973df80626e46ef7dd6f49972048&amp;chksm=f2616a9759680975399ce60a95d29f0cb9a3405484f971ae62e61103b7dd3bd015d0a694e904&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 26 Jun 2024 14:00:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[45个开源的多尺度注意力创新点，顶会都在用！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiauzzV1Qg33C9jgXw0Dfyt6pVLuLhoSZsbASfQn9tsuzdOXLwiaZ4boYhVTA8SRbHqHKAwPYW12GEw/640?wxtype=jpeg&amp;wxfrom=0"/><p>分享一个顶会都在用的模型涨点方法：多尺度注意力。在CVPR2024、ICLR2024、TMM2023都有多篇基于多尺度注意力的改进创新。因为它的应用面真的很广：你可以用它来提升模型的泛化性、鲁棒性和效</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698252&amp;idx=1&amp;sn=3b2c218f11f508bf3b5e72393829e944&amp;chksm=f2d207a8c3c2c8792a722032ce092dd0a9ba61cdba0d3f7ef94bae2da7bdfc88599db84bc1f6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 25 Jun 2024 12:56:37 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[拳打开源SOTA脚踢商业闭源的LI-DiT是怎样炼成的？（商汤/MMLab/上海AI Lab）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icojhGksxPcuzzcs6IGgx9ulYhCMoicQnMA6YdoUjib7x7o8bNPlGpEaVwGWLA5Yo2luuxFxHdCSgNr3Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：Bingqi Ma等   解读：AI生成未来   文章地址：https://arxiv.org/pdf/2406.11831今天和大家一起学习的这个工作展示的效果非常好，对提示的理解能力达到了新</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698252&amp;idx=2&amp;sn=03fb5f4a9b13c593797a2c51287987c0&amp;chksm=f2b69d3c98e13f98d0f3bc499e98a24c7dfd5bae7132f3d8c1018cb0d070da965bb4725c53d8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 25 Jun 2024 12:56:37 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Mamba终结Transformer、Transformer力压RNN，浅谈我站Transformer的原因]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiauzzV1Qg33C9jgXw0Dfyt65dKBE4F2qUWUMfZzgqsyBk1zd4qEClAsibT20bv12vtwSnFknibUnpwQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近面试大厂算法&amp;开发岗，不仅让手写Transformer代码，甚至手撕BP算法，面试八股也是标配，总结了一下面试官必问的10个问题：解释多头注意力机制；简述常见注意力机制；介绍Transformer</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698247&amp;idx=1&amp;sn=0a5ba32f8690a0b238c97ad24803c873&amp;chksm=f23611b610d190b28500a4384aa4389be9be8f89aa5088bc172dd2a11d37f046be91b6253235&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 24 Jun 2024 10:59:29 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[视觉 AI 的「Foundation Model」，已经发展到哪一步？丨CVPR 2024 现场直击]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/cNFA8C0uVPvmYWT2umEI8dcFlemq21OrjJAvoyJC46InDC7ruDmtLk8AR7VQy93efhVDKWvib2NLY3M1Gp3bC7A/300?wxtype=jpeg&amp;wxfrom=0"/><p>CVPR 不再只是一个纯粹的学术会议，也是产业发展的嗅觉源。作者｜房晓楠编辑｜陈彩娴2024 年美国时间 6 月 17 日至 21 日，IEEE 国际计算机视觉与模式识别会议（CVPR）在美国西雅图召</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698247&amp;idx=2&amp;sn=e2124aebb0ac56546ccf5b483001caa1&amp;chksm=f224743d34d665770bbb86eaf82f4a5f040b23f1108fd1c20d5499701760b856caf291bc3c47&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 24 Jun 2024 10:59:29 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[从数据采集到部署，手把手带你训练一个高质量的图像分类模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/ialW0xobVWP7dtLBkqnPgaJwfS9BfA2f6COZdOuDU5Z9l9N0cto1auyCOwrvYKoydMOk4LN2oSAibBze0NWUC3jQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于OpenMMLab，作者李剑锋MMPreTrain 是一款基于 PyTorch 的开源深度学习预训练工具箱，本文将从数据采集到部署，手把手带大家使用 </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698237&amp;idx=1&amp;sn=baa226d7140b24bb0f3f392d57b3d98c&amp;chksm=f227171244ad17ed2b1a48c78b03903b3a98e76e0a6dee99e117b76cce7f37c58c4c3697b6d5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 23 Jun 2024 14:02:59 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DiG：使用门控线性注意力机制的高效可扩展 Diffusion Transformer]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfpF7iasHVh1clxQkfYUYFaIkT2GrJx0kicFt577APfOYwPmv6vCG7PCAT5DCibUL1uicibtryVkyYIyX7Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者丨科技猛兽    编辑丨极市平台极市导读 在相同的模型尺寸下，DiG-XL/2 比基于 Mamba 的扩散模型在 1024 的分辨率下快 4.2 倍，在</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698237&amp;idx=2&amp;sn=1a9c0992f5625702533e6ac6d2537128&amp;chksm=f226dcf733906dfc48a682aa647a4e29bace6e3bf588a763c5d52a89237ea6bac82fbe7d9a23&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 23 Jun 2024 14:02:59 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[华为诺亚提出 MoPE-CLIP | 让小模型也有大能量！有效利用教师模型的知识并极致压缩模型！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVUmnBMzKQGNdafmzN0B4V42B8oQF6DW3AlibCTjtFgpfYtTvp1YcMleEicVSwTNcibGSnQyAXr1Jtbew/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AI视界引擎，作者AI引擎视觉-语言预训练模型已经在各种下游任务上取得了令人印象深刻的性能。然而，它们庞大的模型尺寸限制了在计算资源有限的平台上的应用</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698235&amp;idx=1&amp;sn=ba12cb533c9e4c10730acd9ae7f37961&amp;chksm=f2c2ff6ee3a084ce339a3dc0308e53c2e6161ad82150df86c942b6d3544504ef1b42138ae2dc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 20 Jun 2024 13:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[上海交大&amp;阿里巴巴推出虚拟试衣新里程碑式工作——AnyFit：任意场景、任意组合！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icojXic1NYz0eArRWN0giaPwPnV8WjJEXQ2nLOP47ssLj7ugH0BLsibV51Z3kDYibocxdTAgwhLR4Qb0Wnw/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Yuhan Li等       解读：AI生成未来文章链接：https://arxiv.org/pdf/2405.18172 工程链接：https:/</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698235&amp;idx=2&amp;sn=1377e8ffceea01ad7651d6d087d8358c&amp;chksm=f217e1dde699d7a95d24428b076e0981540f3593fa028c86d7857eb01276201d278a2c34c9bd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 20 Jun 2024 13:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[就在刚刚，南理工开源IMAGDressing-v1代码和权重，助力虚拟穿衣生成技术！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAdzLQ2A2hnMfKDZKLNG8y0micpppP2u5HxRF0J1NfSBfZD5MmJE9CqjKphNMbEfdzvp9KdqLP0zGEA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于数源AI，作者小源项目主页：https://imagdressing.github.io/开源代码：https://github.com/muzish</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698233&amp;idx=1&amp;sn=e8852e7e5e3149b00861163c01dee835&amp;chksm=f2c952f7dda395415e10297984962fa9a304964d54cb8d5448acb03b7191986103a3bad24aae&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 19 Jun 2024 09:54:39 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
