<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIWalker]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIWalker公众号]]></description>
    

    <language>zh-cn</language>
    















    <item>
      <title><![CDATA[Retinex-RAWMamba 桥接去镶嵌和去噪，用于低光照RAW图像增强 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDgADe32JwMJ0F3e4lavibrgqibgm5fEkP3ErLl3Fq2E7pPicLKGNRlFE3HpDMBlqVGQu39hncrKOTqOw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | AI视界引擎降低光照图像增强，特别是在跨领域任务（如从原始域转换到sRGB域）中，仍然是一个重大的挑战。近年来，为了解决这个问题，已经开发出许多基</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698972&amp;idx=1&amp;sn=7c2845a60c398793e4302dd8a4c753a8&amp;chksm=f2015b504eacd661c32bb01924ca92646d71024f10abbb4d590cb7f0405df752458a3b410e3d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 10 Oct 2024 14:03:30 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[盘点当前主流注意力机制，第一名papers引用居然1.8w＋！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5S6MszKwYWyMwwwicMVD1g9RBkueJ0qpWr89w88ju0quDaAozCia6YAwuVy8JsfrSxg0ia5ysEj0gVMEB0S997ZibA/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于计算机视觉工坊，作者小张Tt在深度学习和神经网络领域，注意力机制已成为不可或缺的重要组件。它们不仅在自然语言处理（NLP）中展示了惊人的性能，还广泛应</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698972&amp;idx=2&amp;sn=4a6a3fd23e78466bda5b3a2173f9a88b&amp;chksm=f22a4ea4d23193f90c731affee8cad3252ec62839b0a8cd06adbdad43088855e04c1196357b8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 10 Oct 2024 14:03:30 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[11种主流注意力机制汇总与实现]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDgw0zBeHdlF5DjMK6JgrLDwzhL4ePIgbgf7nVaK9NlmeecXNHWNVSbh47UXGjRz5q3UlNZuRxIE3Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>现在搞人工智能，真是离不开注意力机制。发论文，模型里没点魔改Attention都不好意思叫创新。面试算法岗，简单的让你讲讲几种注意力，或者让你手撕个注意力函数、MQA算法之类的。所以各位小伙伴，尤其是</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698952&amp;idx=1&amp;sn=bcc8595496b55efe448937de47215938&amp;chksm=f2a6a07de1ed448e130b433804cf18150663c2f3ebd23cda426ea4e864308aa42fb8835247dc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 09 Oct 2024 10:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Jeff Dean点赞谷歌新研究：鲸鱼生物声学模型，可识别8种鲸类]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/QkCvnz083Ahdg2TicwwofOCicialsupXhUR3EiaPzOdADE1iceELLbQUPgLJfCqjlYQxrlnEN8cmu2U0O1M70SH7v3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：李姝编辑：李宝珠Google Research 团队开发了新的鲸鱼生物声学模型，可以识别 8 个不同的物种，其中包括 2 个物种的多种叫声，还收录了最近刚被确认为是布氏鲸叫声的 Biotwang</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698952&amp;idx=2&amp;sn=3bd96f1a2538958d8a2370f5815141bf&amp;chksm=f2597c821b739802f6d4c2ce30ebe85736a6e61bcbdf4090ab5f8bb67afbb266898d1a057dcf&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 09 Oct 2024 10:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[号称YOLO终结者？一探究竟RT-DETR]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfrg3jz1GiapBFGGu5lB1xEhxeziaicQFldvcxnB9lCnuKZJPbylgibiamHvVRo8QECFg9OUpBa64GvXIpw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者丨迪迦奥特曼    编辑丨极市平台极市导读 实时目标检测中击败YOLO家族？来看看百度飞桨的PaddleDetection团队提出的 RT-DETR究竟</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698946&amp;idx=1&amp;sn=3038bcad5a313fff2285a068e0df77de&amp;chksm=f2abbd60433f0bf1d3f090e1d763a917cb9e920dab26b93c98c0a7f08bb279b7225c8f62ece2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 08 Oct 2024 14:17:08 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[解读：物理诺贝尔奖为何颁给了 HNN 之父和深度学习之父？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/cNFA8C0uVPvv17uBmY1sVBvFTXUzjwSjBCdrKLgAbY9kuyiciacYUsX8veIicialqEVdovkXo4pT6rHADb37YA3abw/300?wxtype=jpeg&amp;wxfrom=0"/><p>瑞典皇家科学院认证：AI就是物理的一部分。作者丨刘洁、郑佳美编辑丨岑峰来源 | AI科技评论就在刚刚，瑞典皇家科学院决定将 2024 年诺贝尔物理学奖授予约翰·J·霍普菲尔德 (John J. Hop</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698946&amp;idx=2&amp;sn=b612c9457adcbe270b7211e2cdc43ddb&amp;chksm=f2cbc3cd1b4f273936c84ad9510cc86ae9d1b5dc91188c7893866197c5a0ef4643b5819a5395&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 08 Oct 2024 14:17:08 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Ultralytics YOLO 11终于来了！重新定义AI的可能性！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>Ultralytics型号的下一个演变：YOLO 11！基于之前YOLO模型版本的令人印象深刻的进步，YOLO 11带来了一系列强大的功能和优化，使其更快，更准确，并且功能多样。凭借其创新的架构，YO</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698933&amp;idx=1&amp;sn=861b39f5f523aebf57d620402f06c7ba&amp;chksm=f2c23dc49b63e0dd6c0cb672af1e8292231d0c51082872f2cf485a6505317828f6e7ca5e3a0a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 30 Sep 2024 00:55:10 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[基于DINO最强多模态检测器！超越YOLO、DETR！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDhF3IuRWs9ePbzbYY7pB0hSVNyaqC7MYjpXL26PGt1ZaAsA8kv7AVicPJOkB3HX3QamIrDCWXRlSIQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>清华大学、IDEA研究院联合提出的Grounding DINO，采用了目标检测器DINO的Transformer架构，并借鉴了多模态GLIP的预训练方法，深度融合语言和视觉信息后，可根据文字描述检测任</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698918&amp;idx=1&amp;sn=8a7323279577988b1074a2067075eded&amp;chksm=f2ec0a088e534689959071c946f3d85fa3aee371793ca10c0fcd3c7ada86d91d0116cd4f9895&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 24 Sep 2024 03:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen2-VL全面解读！阿里开源多模态视觉语言模型，多项超越GPT4o与Claude 3.5-Sonnet]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icohWgmjBYHrErRmUQmFC7GB7TrictyRUAY66vt8Rg5JOBhI9QJ1MGPcicu8uPo36UOiccHVaFzu1UWbWw/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Peng Wang 等    解读：AI生成未来      文章链接：https://arxiv.org/pdf/2409.12191Github链接</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698918&amp;idx=2&amp;sn=9330c147a4ab10888d70df3a90b4eb8e&amp;chksm=f2f1b08182f7f53a3726dad65c3f1557a95c410415af92bb56dad083509d6a7ba28019f5a453&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 24 Sep 2024 03:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Segment Anything 2 (SAM2) in X-AnyLabeling: 构建快速精准的图像和视频标注对象分割工具]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vgev6PHxuZ13fox5rr0xtlNSKfAiaIgxibFrqkUDKJcl8oytib4Rj79iaPCrgEdqIstu1sX9fD1tAXkJ7cYibId8Reg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于CVHub，作者派派星导读Segment Anything 的初次发布受到了广泛赞誉，在 ICCV 2023 上获得了荣誉提名，并吸引了行业领袖和学术</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698917&amp;idx=1&amp;sn=67934d6794f90484fd40f70c0877e62c&amp;chksm=f2488d44da483372149d36c29fd4dcc7f8a4c4c10c4c6daf469255aeb6b9c52a7e62c010d667&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 23 Sep 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen2.5 全链路模型体验、下载、推理、微调、部署实战！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/8ZLuyaibrZbnW2qfuGfhibjSoY7zRpLEfJqUxNbjLiarKQ7ON28zjPf2a8gHA1zRXU8dz09O2Zkwqrv1ly5QdGlRg/300?wxtype=jpeg&amp;wxfrom=0"/><p>01引言在 Qwen2 发布后的过去三个月里，许多开发者基于 Qwen2 语言模型构建了新的模型，并提供了宝贵的反馈。在这段时间里，通义千问团队专注于创建更智能、更博学的语言模型。今天，Qwen 家族</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698917&amp;idx=2&amp;sn=dc25154a78c1184fe7c43a1e4750c96b&amp;chksm=f249ece174a3b6a5878d000a9e20ece42ed0f54ab6c1b56e71d3e8a70f136c36604c07e672d0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 23 Sep 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CVPR 2024 | 英伟达发布新一代视觉基础模型: AM-RADIO = CLIP + DINOv2 + SAM]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vgev6PHxuZ0Dvab3vYyROyU9ESg3n8zG0anOa04cV0GwicWOGAJ4dG0eXAYscczTvCEPaibXFictDib936FdbCMoww/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于CVHub，作者派派星标题：《AM-RADIO: Agglomerative Vision Foundation Model Reduce All D</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698892&amp;idx=1&amp;sn=e0edac78ef5c399b68888ba16ee769ad&amp;chksm=f29af643852bd2da62d5094c54347346602ac424e73a4b06983f80e3dbd351bdddf4f1d1b2a2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 19 Sep 2024 14:24:16 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LinFusion：1 块 GPU，1 分钟生成 16K 高清大图]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoJKjibwO1WI0fErPpWiaWzo3a9iaicrkia1icz4k5yDgCKxUDtLFdibiaYDAZ64N5u5YfSMk5VCB2yGSTb2Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者丨科技猛兽    编辑丨极市平台极市导读 使用知识蒸馏策略，只训练线性注意模块 50K 步，LinFusion 的性能即可与原始 SD 相当甚至更好，同</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698892&amp;idx=2&amp;sn=39b8d844cabfe82522bd2bda1ac72d43&amp;chksm=f26127fb14f51daec7509b8dc5b1d31f6b5282f6f0aa42647cb5aa9ddbd61d0dc8c2cdb1442d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 19 Sep 2024 14:24:16 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[修改一行代码就能实现高效微调！上海交大&amp;腾讯开源SaRA：兼顾原始生成和下游任务]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogofuVCiapib1Utz9G0wdG8BVVaGpaLYWqLViaINU948pibC1xx9W4fWApCD4GCXv7hicLAZuTFmCGN5nA/640?wxtype=jpeg&amp;wxfrom=0"/><p>文章链接：https://arxiv.org/pdf/2409.06633 项目链接：https://sjtuplayer.github.io/projects/SaRA/1.引言SaRA是一种针对预</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698890&amp;idx=1&amp;sn=fd124c393e048dc5f4c1b4f847da919f&amp;chksm=f28570f7f50fc6f40502ea64defbbb519e7e102486301087ee4f0cd21157e523aa3898de3d44&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Sep 2024 14:34:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CVPR 2024｜NAT其实真的不输扩散模型！AutoNAT：全新定制训练&amp;生成策略拓宽性能边界]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfrgicsuXodsgZSPQBcTUK1yAnwPmVItL3m9UDrQzA5RmjItk4K6WgINkh8yk4yoduYNicJqXEYKUETA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者丨科技猛兽   编辑丨极市平台极市导读 本文将设计训练和生成策略的任务制定为一个统一的优化问题，并自动完成设计，本文方法因此称为 AutoNAT。Aut</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698888&amp;idx=1&amp;sn=2dc93eafe6d3173ee1b12c94720995a7&amp;chksm=f23877dc2df6fd0cd729ab3165ec123b7273c714786a82afd2ba063d3a80608fba244b6d0e47&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 17 Sep 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[SDM: 第三代神经网络和扩散模型强强联合！FID最多超基线12倍，能耗省60%，实力SOTA！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icohH43GvKlQOLV2vUia7ibW9ZFqEb8Wk9iboF55DmH2ib1w7uHyZ1bdQUibpfurzXq0B6gsHkT6Uibl3oqJA/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Jiahang Cao等    解读：AI 生成未来     论文链接：https://arxiv.org/pdf/2408.16467代码链接：ht</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651698888&amp;idx=2&amp;sn=022be7fd1008a2d395de53159b80f86f&amp;chksm=f220a7de025e21a51d8479b282cda90d7ab9526f732b9f3557975fae2ceea632a06f115ee60e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 17 Sep 2024 14:00:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
