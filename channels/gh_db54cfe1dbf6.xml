<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIWalker]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIWalker公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_db54cfe1dbf6.jpg</url>
      

      <title>gh_db54cfe1dbf6</title>
      

    </image>
    















    <item>
      <title><![CDATA[扩散模型部署有新解，直接量化为4bit？韩松团队等提出SVDQuant：16GB笔记本上加速8.7 倍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfqlcsSTbSptY6mia3icYPV8YicGNjSCEVLvuMPI1V20S7FGDP3ORCHGDmQRIbBRWWpFRibiclyZjrUH4RA/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者丨科技猛兽  编辑丨极市平台极市导读 在 12B FLUX.1-dev 上，与 BF16 模型相比，它减少了 3.6 倍的 memory。通过消除 CPU offloading，在 16GB 笔记</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699361&amp;idx=1&amp;sn=1fc6ff8cdf3abd9042a8f7100235c9fe&amp;chksm=f244af8f96cd04ae068935460d80bb741aac05af0adc49ef17ea97058ab6ba8662c4675e816e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 07 Dec 2024 14:12:27 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[FoundIR: 释放百万规模高质量训练数据，助推图像复原基础模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiaOyP9g77hmFACH3ib9GmUj6YCWlpw4yibEfPZHcrAQj48G5Wy5GSwd5WGN5Gu29tibfmDXu0JDkFvuQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路文章地址：https://arxiv.org/abs/2412.01427项目地址：https://www.foundir.net/简介尽管all-in-o</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699306&amp;idx=1&amp;sn=7c6f521f442f602c119a0c65e53a9a2e&amp;chksm=f26ce634ccbd5981768244d1498a3fac1ab25a8761ab17a97a771873af6c4eca696c29aad116&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 06 Dec 2024 13:57:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[YOLO大礼包，245个目标检测开源项目合集！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDjoItAxPCMHDavHeEzvrDnttgibQ42H1eDGektATicuTNGIIKUJLTHnHrAK7ZicPsQgoRBIw8Fficvibeg/300?wxtype=jpeg&amp;wxfrom=0"/><p>目标检测是计算机视觉领域最核心的技术之一，应用面非常广泛。这里总结了245个目标检测开源项目给大家练习。具体到人体、交通、医疗、工业、开放世界、3D目标、小目标等16个分类。其中包括多个基于YOLOv</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699306&amp;idx=2&amp;sn=5900d7245b3d3a42cb860eb46a28c51f&amp;chksm=f29dd76c8b83b99e86b061525a44eda32b53f0b2e918e267267c5a4ad235db282e0b06bd706c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 06 Dec 2024 13:57:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[YOLO大礼包，245个目标检测开源项目合集！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDjoItAxPCMHDavHeEzvrDnttgibQ42H1eDGektATicuTNGIIKUJLTHnHrAK7ZicPsQgoRBIw8Fficvibeg/640?wxtype=jpeg&amp;wxfrom=0"/><p>目标检测是计算机视觉领域最核心的技术之一，应用面非常广泛。这里总结了245个目标检测开源项目给大家练习。具体到人体、交通、医疗、工业、开放世界、3D目标、小目标等16个分类。其中包括多个基于YOLOv</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699201&amp;idx=1&amp;sn=e6e9d863c5bda177b4d5064bc4b555d2&amp;chksm=f2a74e0e5d0e1f98931915143a0771c40e2880d0f5dfd6435a7bd5172ccc78180b613c178084&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 05 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[去噪步数减少50%，图像生成质量反而更好！西湖大学等提出TPDM：自适应噪声调度]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icohGtOvYWFKfGY3H7OpjW7x0HAFk6wPyj2icPSN9UvF4wTa3W92WNzpx8QsJMOUicWEh4UialibwYLebqg/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Zilyu Ye 等    解读：AI生成未来文章链接：https://arxiv.org/pdf/2412.01243亮点直击提出了时间预测扩散模型</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699201&amp;idx=2&amp;sn=d073fca4299a9c3804608fb3c0eec922&amp;chksm=f23ecffb7f4823399df629cb03163036b16a90f79c7a90eaabb3234e2a240b8a1650d6222bcc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 05 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[中科大提出 D-FINE |  通过 FDR 和 GO-LSD 实现最先进的实时目标检测 ！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tgkEY0DXdcmpSibJ1w9GCpNXv4jfWZ3nJRq4XMmwyGgh8yibiaNpT3GSw7qxvQld2iaU9HuGiaibg701SoicQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者提出了 D-FINE，这是一个强大的实时目标检测器，通过重新定义DETR模型中的边界框回归任务，实现了出色的局部化精度。D-FINE包括两个关键组件：细粒度分布精炼（FDR）和全局最优定位自蒸馏（</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699200&amp;idx=1&amp;sn=56544ee14ec7db3184ef2112a67c3173&amp;chksm=f22e900d0f3537b2fc67f5635bf30dccae9bb41dc51b29a824d99428c49ed5331c2c650c274e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 04 Dec 2024 14:46:12 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ICLR'25 惊现满分论文！！！原来rebuttal真的有用]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDgQ0BkOJQTFW0gTEsSspsDEawOQVHoCl2Mdt9RgWHV5urYpAlHlbTfzsPXjzwicxpqN85d7kKtm8icg/640?wxtype=jpeg&amp;wxfrom=0"/><p>这两天，ICLR 2025 的 discussion phase 临近截止，截止目前，一篇论文同时征服了所有的审稿人，4个审稿人同时打出了10分、10分、10分、10分，都给出了最高档评级strong</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699162&amp;idx=1&amp;sn=3b9251819c7fb64cfd2fea06c893234a&amp;chksm=f2338bba31bec7dc9c7e86f7a8b1d0bb681a9b7d091711759eeea09147068978ace1327607d0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 03 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[支持20+视觉任务，多项SOTA！可扩展多任务视觉基础模型LaVin-DiT：融合时空VAE与DiT]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogsicibw9ficIyy0icvtII2YEmXqK8pLCrORJuo1lQQniakELtF52v3s3hRCwxMTvhTcxa0sNdasD0OyiaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路 作者：Zhaoqing Wang等    解读：AI生成未来 文章链接：https://arxiv.org/pdf/2411.11505 亮点直击高效处理</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699162&amp;idx=2&amp;sn=a77653b49bb6b503e29fa48f6c8ab120&amp;chksm=f2dadaa1e17c29427fc5030bf1ceb7134a9604eb07b3fef84fa3a7cb2ebbce6a4eede9942469&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 03 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[基于 Global-Local Vision Transformer的高频信息增强分割 ！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVX4u4SBeJ9JWjZ1U2I5Xj9Br7fcJKlAiaNJUCPXm0Z5rQmzeicE4chlia8zbiaaQdGyw5BoAC3SdPHJqA/640?wxtype=jpeg&amp;wxfrom=0"/><p>许多研究已经证明了基于视觉 Transformer （ViT）的方法在各种计算机视觉任务上具有强大的性能。然而，ViT模型通常很难有效地捕获图像中的高频成分，这对于检测小目标并保持边缘细节至关重要，尤</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699156&amp;idx=1&amp;sn=01c48d615709c3bd8299b543739c8f55&amp;chksm=f2bb39dae33a94d320211a6a29971b7d1db8bded7f9afb1382cf1042b7a4dd4c6e405bb8fb69&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 02 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[轻量化MobileMamba视觉模型来了｜浙大/腾讯优图/华中科大联合出品]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDhsOqQ5e8icYwgmpMmL5DK4B5EjGpYTJCbNiaEnticHwkBRIxficWdArNiaCkM8Xicy8s47L8uXF22R9tDA/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者 | MobileMamba来源 | 量子位 | 公众号 QbitAI浙大、腾讯优图、华中科技大学的团队，提出轻量化MobileMamba！既良好地平衡了效率与效果，推理速度远超现有基于Mamba</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699154&amp;idx=1&amp;sn=e676ea7fbbdeedd95450ea8587d28dc2&amp;chksm=f2652c9b3cd277cf55e24b980cf29c986897f90e41487d82a0dd74df941ad54dbe41377ffbc9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 01 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[融合 Mamba 与 Transformer |  MaskMamba 引领非自回归图像合成,推理速度提升 54.44% !]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVXO4tNQv62icIMIk7iarCaLVkSE2RicusD2uj1on55icbmvEgVoX0tC0XYgwnBWFAk9HbiamxnLte3t48w/300?wxtype=jpeg&amp;wxfrom=0"/><p>来源 | AI视界引擎，作者 | AI 引擎图像生成模型遇到了与可扩展性和二次复杂性相关的挑战，主要原因是依赖于基于Transformer的 Backbone 网络。在本研究中，作者引入了一种新颖的混</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699154&amp;idx=2&amp;sn=eb00b8a54cef2a78efe2b31e5ccac2ed&amp;chksm=f20140d9fae6eff29165b9b628e3e7ffb1982550942274379a825fc1197756c2b0ef7840ca1c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 01 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ETDS:等效变换与双流网络构建移动图像超分辨率(CVPR2023)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/ukw7ofNmxAOHicHIvJia91w2A5kzRrgD779xXOpDHSNChw2aLJEQJSvpFVfvPKSEMV5xe1UNqtxt71eCxicQcx2nQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文题目Equivalent Transformation and Dual Stream Network Construction for Mobile Image Super-Resolution</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699147&amp;idx=1&amp;sn=a431f2af303f91960f07dda9b18e81ed&amp;chksm=f28e7b772b3b5fa7065d7b460f8719450255715a00b08bdee8bcf2181883fa0edc8720dbcf64&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 30 Nov 2024 14:44:27 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[QuickSRNet：移动平台更快推理的图像超分辨率架构(CVPR2023W)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/ukw7ofNmxAO3WS9S3PoL6EbGVJ4TjcnKBmEzwektgJicZMT6OA8u3S7QkJleyz2ia0RFCcgia0ud2xqK15JhTgoWA/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文题目QuickSRNet: Plain Single-Image Super-Resolution Architecturefor Faster Inference on Mobile Platf</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699145&amp;idx=1&amp;sn=fbf536b651178019683190d92f163c7d&amp;chksm=f25c39f8410dc27cd9f1184cbb99aa4e20d8452891eb0f4dd43ecf4eb702284f71c41ccbbf94&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Nov 2024 14:25:24 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[PlainUSR：追逐更快的ConvNet以获得高效的超分辨率(ACCV2024)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/ukw7ofNmxAN57VRREPawMpOgegYpzUSib7KowjkkIN6gtpHX1Enj3mPWLdOQeVByLGfkQ7IXuj01lNP8nSFJAyQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于小小cv笔记，作者bochen论文题目PlainUSR: Chasing Faster ConvNet for EfficientSuper-Reso</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699143&amp;idx=1&amp;sn=f15417452e3efbee6d2de8e982080851&amp;chksm=f214a2822ad3b1c70e976c3268b714ed688ac83a2153d5a891e4e4219b426b7d22c1f584c32d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 28 Nov 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NeurIPS'24｜推理计算量减小10倍!MemoryFormer：华为提出存储代替计算的Transformer新架构]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDhGJKHwAHf9GaXkhoqnONavD5r2gN3dCw1HctssibwXtsCHjiamqsa80b00Hx4UFVbm8HY63u9PK3ew/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者丨王云鹤来源丨https://zhuanlan.zhihu.com/p/9264019510编辑丨极市平台极市导读 本文介绍了MemoryFormer，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699143&amp;idx=2&amp;sn=f4b05641df87a52d96249f77bde25977&amp;chksm=f29582cd10d8b3612dcdf6258d10a0381089876c4d7660550a33b5b991ae5f8bfd05e0162977&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 28 Nov 2024 14:00:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
