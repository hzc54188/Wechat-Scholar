<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIWalker]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIWalker公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_db54cfe1dbf6.jpg</url>
      

      <title>gh_db54cfe1dbf6</title>
      

    </image>
    










    <item>
      <title><![CDATA[中科大提出 D-FINE |  通过 FDR 和 GO-LSD 实现最先进的实时目标检测 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tgkEY0DXdcmpSibJ1w9GCpNXv4jfWZ3nJRq4XMmwyGgh8yibiaNpT3GSw7qxvQld2iaU9HuGiaibg701SoicQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者提出了 D-FINE，这是一个强大的实时目标检测器，通过重新定义DETR模型中的边界框回归任务，实现了出色的局部化精度。D-FINE包括两个关键组件：细粒度分布精炼（FDR）和全局最优定位自蒸馏（</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699200&amp;idx=1&amp;sn=56544ee14ec7db3184ef2112a67c3173&amp;chksm=f22e900d0f3537b2fc67f5635bf30dccae9bb41dc51b29a824d99428c49ed5331c2c650c274e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 04 Dec 2024 14:46:12 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[ICLR'25 惊现满分论文！！！原来rebuttal真的有用]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDgQ0BkOJQTFW0gTEsSspsDEawOQVHoCl2Mdt9RgWHV5urYpAlHlbTfzsPXjzwicxpqN85d7kKtm8icg/640?wxtype=jpeg&amp;wxfrom=0"/><p>这两天，ICLR 2025 的 discussion phase 临近截止，截止目前，一篇论文同时征服了所有的审稿人，4个审稿人同时打出了10分、10分、10分、10分，都给出了最高档评级strong</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699162&amp;idx=1&amp;sn=3b9251819c7fb64cfd2fea06c893234a&amp;chksm=f2338bba31bec7dc9c7e86f7a8b1d0bb681a9b7d091711759eeea09147068978ace1327607d0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 03 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[支持20+视觉任务，多项SOTA！可扩展多任务视觉基础模型LaVin-DiT：融合时空VAE与DiT]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogsicibw9ficIyy0icvtII2YEmXqK8pLCrORJuo1lQQniakELtF52v3s3hRCwxMTvhTcxa0sNdasD0OyiaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路 作者：Zhaoqing Wang等    解读：AI生成未来 文章链接：https://arxiv.org/pdf/2411.11505 亮点直击高效处理</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699162&amp;idx=2&amp;sn=a77653b49bb6b503e29fa48f6c8ab120&amp;chksm=f2dadaa1e17c29427fc5030bf1ceb7134a9604eb07b3fef84fa3a7cb2ebbce6a4eede9942469&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 03 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[基于 Global-Local Vision Transformer的高频信息增强分割 ！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVX4u4SBeJ9JWjZ1U2I5Xj9Br7fcJKlAiaNJUCPXm0Z5rQmzeicE4chlia8zbiaaQdGyw5BoAC3SdPHJqA/640?wxtype=jpeg&amp;wxfrom=0"/><p>许多研究已经证明了基于视觉 Transformer （ViT）的方法在各种计算机视觉任务上具有强大的性能。然而，ViT模型通常很难有效地捕获图像中的高频成分，这对于检测小目标并保持边缘细节至关重要，尤</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699156&amp;idx=1&amp;sn=01c48d615709c3bd8299b543739c8f55&amp;chksm=f2bb39dae33a94d320211a6a29971b7d1db8bded7f9afb1382cf1042b7a4dd4c6e405bb8fb69&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 02 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[轻量化MobileMamba视觉模型来了｜浙大/腾讯优图/华中科大联合出品]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDhsOqQ5e8icYwgmpMmL5DK4B5EjGpYTJCbNiaEnticHwkBRIxficWdArNiaCkM8Xicy8s47L8uXF22R9tDA/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者 | MobileMamba来源 | 量子位 | 公众号 QbitAI浙大、腾讯优图、华中科技大学的团队，提出轻量化MobileMamba！既良好地平衡了效率与效果，推理速度远超现有基于Mamba</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699154&amp;idx=1&amp;sn=e676ea7fbbdeedd95450ea8587d28dc2&amp;chksm=f2652c9b3cd277cf55e24b980cf29c986897f90e41487d82a0dd74df941ad54dbe41377ffbc9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 01 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[融合 Mamba 与 Transformer |  MaskMamba 引领非自回归图像合成,推理速度提升 54.44% !]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVXO4tNQv62icIMIk7iarCaLVkSE2RicusD2uj1on55icbmvEgVoX0tC0XYgwnBWFAk9HbiamxnLte3t48w/300?wxtype=jpeg&amp;wxfrom=0"/><p>来源 | AI视界引擎，作者 | AI 引擎图像生成模型遇到了与可扩展性和二次复杂性相关的挑战，主要原因是依赖于基于Transformer的 Backbone 网络。在本研究中，作者引入了一种新颖的混</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699154&amp;idx=2&amp;sn=eb00b8a54cef2a78efe2b31e5ccac2ed&amp;chksm=f20140d9fae6eff29165b9b628e3e7ffb1982550942274379a825fc1197756c2b0ef7840ca1c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 01 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ETDS:等效变换与双流网络构建移动图像超分辨率(CVPR2023)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/ukw7ofNmxAOHicHIvJia91w2A5kzRrgD779xXOpDHSNChw2aLJEQJSvpFVfvPKSEMV5xe1UNqtxt71eCxicQcx2nQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文题目Equivalent Transformation and Dual Stream Network Construction for Mobile Image Super-Resolution</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699147&amp;idx=1&amp;sn=a431f2af303f91960f07dda9b18e81ed&amp;chksm=f28e7b772b3b5fa7065d7b460f8719450255715a00b08bdee8bcf2181883fa0edc8720dbcf64&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 30 Nov 2024 14:44:27 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[QuickSRNet：移动平台更快推理的图像超分辨率架构(CVPR2023W)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/ukw7ofNmxAO3WS9S3PoL6EbGVJ4TjcnKBmEzwektgJicZMT6OA8u3S7QkJleyz2ia0RFCcgia0ud2xqK15JhTgoWA/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文题目QuickSRNet: Plain Single-Image Super-Resolution Architecturefor Faster Inference on Mobile Platf</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699145&amp;idx=1&amp;sn=fbf536b651178019683190d92f163c7d&amp;chksm=f25c39f8410dc27cd9f1184cbb99aa4e20d8452891eb0f4dd43ecf4eb702284f71c41ccbbf94&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Nov 2024 14:25:24 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[PlainUSR：追逐更快的ConvNet以获得高效的超分辨率(ACCV2024)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/ukw7ofNmxAN57VRREPawMpOgegYpzUSib7KowjkkIN6gtpHX1Enj3mPWLdOQeVByLGfkQ7IXuj01lNP8nSFJAyQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于小小cv笔记，作者bochen论文题目PlainUSR: Chasing Faster ConvNet for EfficientSuper-Reso</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699143&amp;idx=1&amp;sn=f15417452e3efbee6d2de8e982080851&amp;chksm=f214a2822ad3b1c70e976c3268b714ed688ac83a2153d5a891e4e4219b426b7d22c1f584c32d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 28 Nov 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NeurIPS'24｜推理计算量减小10倍!MemoryFormer：华为提出存储代替计算的Transformer新架构]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDhGJKHwAHf9GaXkhoqnONavD5r2gN3dCw1HctssibwXtsCHjiamqsa80b00Hx4UFVbm8HY63u9PK3ew/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者丨王云鹤来源丨https://zhuanlan.zhihu.com/p/9264019510编辑丨极市平台极市导读 本文介绍了MemoryFormer，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699143&amp;idx=2&amp;sn=f4b05641df87a52d96249f77bde25977&amp;chksm=f29582cd10d8b3612dcdf6258d10a0381089876c4d7660550a33b5b991ae5f8bfd05e0162977&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 28 Nov 2024 14:00:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
