<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[极市平台]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[极市平台公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_3bb902f05720.jpg</url>
      

      <title>gh_3bb902f05720</title>
      

    </image>
    





























    <item>
      <title><![CDATA[谢赛宁新作：表征学习有多重要？一个操作刷新SOTA，DiT训练速度暴涨18倍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoN5Hib0N56hRhdv82jJtcDFo50SCLr7OA2QOTreVFsnrQm1Xn3nVQI63cVP2pD3yL8z5m7dibU0uIw/640?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台作者丨新智元来源丨新智元编辑丨极市平台极市导读 在NLP领域，研究者们已经充分认识并认可了表征学习的重要性，那么视觉领域的生成模型呢？最近，谢赛宁团队发表的一篇研究就拿出了非</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697844&amp;idx=1&amp;sn=ce6d7bfdc94c642850d404efc5399b17&amp;chksm=ed097fe989d30c09b734a1dd2a3ebe8d77870b46e70f96e734aaaab1c88de666bc5d4c02155f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 23 Oct 2024 14:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[PointGST：点云分析精度卷到99%了，还只用了2M训练参数]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoN5Hib0N56hRhdv82jJtcDFY0pNQiaN5EfMLpic2LjBcKOB04zWzR9GeVtrNVTWvichxNtdJ7cRSltng/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台作者丨极市粉丝编辑丨极市平台极市导读 本文提出了一种全新的点云参数高效微调算法—PointGST，在极大地降低微调训练开销的同时，还展现出了优异的性能。仅凭 2M 可训练参数</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697844&amp;idx=2&amp;sn=02ff9db1548b21e7de6e3e3d6400bad3&amp;chksm=ed9d53332126b110c582a755533b40992df489ee82dc748a79c2efb2a4e36c767293ca81881d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 23 Oct 2024 14:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[一起理解下LLM的推理流程]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoN5Hib0N56hRhdv82jJtcDFVruuP92WPibqSITtKFKNHUW31B9wWCaSs0vbW5ibyHQy5c3fwaibuYsSA/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台作者丨oldpan来源丨oldpan博客编辑丨极市平台极市导读 本文介绍了大型语言模型（LLM）的推理流程，包括推理的两个阶段（prefill和decode）、chunked</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697844&amp;idx=3&amp;sn=0331496c37f2ed4cbc73b7ac2baf2434&amp;chksm=ed49a8ac33a162363d66c0dd3394af4ec83339344b7d0e275ed1052bc4a0d38c9fa4682855ad&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 23 Oct 2024 14:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[2¹³⁶²⁷⁹⁸⁴¹−1，GPU发现人类已知最大的素数，比第二大多1600万位数字]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoN5Hib0N56hRhdv82jJtcDFfVrYLGVjxAuMtSnXPQMvgicgJFjuuHEJ798nJvSnDJVOHwLFoGRcsibg/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台来源丨量子位极市导读 新的人类已知最大素数，被GPU发现！ >>加入极市CV技术交流群，走在计算机视觉的最前沿这个数就是2¹³⁶²⁷⁹⁸⁴¹ −1，如果展开会有4102432</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697844&amp;idx=4&amp;sn=7643e3253a510c82208b545f89fbf3e9&amp;chksm=edd79387660eb7b5decf1a1e483d6ad9df14929949529015f32eeff1131fdd9b6c6254f01689&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 23 Oct 2024 14:00:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[课程升级、资源加码！万人共学的书生大模型实战营第4期正式起航！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoprfEwHpLiacic7lZXhwkTlTn4DJEmLf1op3eUIjSyY6EbIHDn94lUea8VD1fJ48wGRGuCTLfgW8FQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台不知不觉间，书生大模型实战营已迎来第四期！回顾前三期，累计超过 15W 人次踊跃参与，涌现出像「InternDog」和「销冠——卖货主播大模型」这样的明星项目，感谢社区小伙伴</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697759&amp;idx=1&amp;sn=6a36bdc63881ee3701c972675a3c0650&amp;chksm=edb53334c3a2e4b3bf07e18ac01e46d8d0b166f32a59e080cf7f015eb376e7203229c54742aa&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 22 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Janus: 解耦视觉编码，引领多模态理解与生成统一的新范式]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoprfEwHpLiacic7lZXhwkTlTdjwRWn5YWYIFkCKTRdSpoKOaJXFaicm937Bbs14icx7pQcp7sfw8h0ZA/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台作者丨陈小康@知乎（已授权）来源丨https://zhuanlan.zhihu.com/p/2360185063编辑丨极市平台极市导读 Janus通过为多模态理解和生成任务解</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697759&amp;idx=2&amp;sn=ee81502a50a5512946286db1dbb80791&amp;chksm=ed4d0049b7e2105bbd7120080706ade6f42c4387b2c637bfcc65912389537662836d777d130e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 22 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[如何用一个统一的视角，分析RLHF下的各种算法？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoprfEwHpLiacic7lZXhwkTlTfmzicJ0oEr2W25jfES8IunTicT0NmUIcEwEn2rrcOrW74BxoLxaibK5icw/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台作者丨猛猿来源丨大猿搬砖简记编辑丨极市平台极市导读 本文探讨了如何用一个统一的视角来分析强化学习从人类反馈（RLHF）中的不同算法，包括DPO和PPO，以及它们在实现RLHF</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697759&amp;idx=3&amp;sn=a7974134508ab22b9e28d4de11b7c30e&amp;chksm=ed4ba439a2d8d506d9000f24705acf8fb4999916047b961cc83e0a5f3945b14768c7e6701dc9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 22 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型是否有推理能力？DeepMind数月前的论文让AI社区吵起来了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoprfEwHpLiacic7lZXhwkTlTKrvm1Bvxss2hB1eJxk7KQrH1vH8fNNUIOAibtQXGwVwdoDzOe2j9Ywg/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台来源丨机器之心极市导读 最近一段时间，随着 OpenAI o1 模型的推出，关于大型语言模型是否拥有推理能力的讨论又多了起来。比如苹果在前段时间的一篇论文中指出，只要给模型一</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697759&amp;idx=4&amp;sn=a1b488d9326180d5f771bcfd3337bd17&amp;chksm=edd77474c82e15468c06549b55459fa363f7966cdd5f1855fc10b833ec40799daf29e24f3ddd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 22 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[极市直播预告｜ACM Multimedia 2024 Oral-自动驾驶场景下面向真实世界布局的转变]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfrwmiauzoGGz7KjVg0dszN5zfoSHIIogAwmtIcpiaemuLqnJx9ujuJZOGeFScyNRWyjqcga2ZWg1NdA/640?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台|极市线上分享第136期 |一直以来，为让大家更好地了解学界业界优秀的论文和工作，极市已邀请了超过100位技术大咖嘉宾，并完成了135 期极市线上直播分享。往期分享请前往bb</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697680&amp;idx=1&amp;sn=509d337179b3f98b8af6b893199545c9&amp;chksm=ed777c34b00101c2ce88817fb38320e3f11ea70b1d1fed8c5fd50045da0670743e87554ff31b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 21 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ECCV'24｜ClearCLIP：倒反天罡，删除两个组件反而可以提升密集预测性能]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfr9mWCWVl6Rq9dTzo8ogFYPptSdoCpA4CZjAcBS8gcH60UzZxpWLibKoficeaI3NLNzr31xM8ta0iaBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台作者丨晓飞的算法工程笔记来源丨晓飞的算法工程笔记编辑丨极市平台极市导读 本文介绍了一种名为ClearCLIP的视觉-语言推理模型，它通过在CLIP模型的最后一层中去除残差连接</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697680&amp;idx=2&amp;sn=ebf4e35a05f26c4d28b60a09d8401590&amp;chksm=ed5496a79dae0138b9016a5e621bf3c1fd89112c49c57dfb38294a9509e0a6f03db64a952c67&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 21 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Linear Attention的cuda kernel实现解析]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfrMsbgQAkwcghNWdog2WCwID6zlqibl6qUgOvLegF2cI8WeSSmJm092aqibDAIiad6YWibJrY6J6sHqTQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台作者丨BBuf来源丨GiantPandaCV编辑丨极市平台极市导读 本文主要是对Linear Transformer的核心组件Linear Attention进行了原理讲解，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697680&amp;idx=3&amp;sn=f8ccad6e5c4ca7b4ef8d6283b8e1c8fa&amp;chksm=edbb47e74e45154e48fcf7324d048418262f08f9c8a8806135dbb805ddd12245433f5f02bfd0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 21 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Ilya预言成真，下一个token预测直达AGI！智源首发原生多模态世界模型Emu3，不用扩散]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfr9mWCWVl6Rq9dTzo8ogFYPhtPwic5NybH0Piauq7W3yhgRAibNTUGXXDcvHabEZDJwia4BlicvZdOsThw/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台来源丨新智元极市导读 最近，Ilya向黄仁勋描述「只要能预测下一个token，就能达到AGI」的视频再次爆火全网，他的预言刚刚竟被证实？智源研究院基于下一个token预测，发</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697680&amp;idx=4&amp;sn=29a6ebfd34a07537eea34e03138d132d&amp;chksm=ed393067dcefbd66c8c4b5f8d6b7cb6eec8bc377178a93204c497c8348b3c08b0245eeac88f7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 21 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[4K分辨率拿下！超强杀器SANA：线性扩散模型+文生图+高分辨率+从头训练的极佳范本！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoB3wnvyicAeBiapGlk1QnaYXZCPH1FA4Apdk4C3vqMN8BfEfMegdgP6t7cVx4fib32z9ht9PSdcFiaNQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台作者丨科技猛兽编辑丨极市平台极市导读 Sana通过32倍压缩率的AutoEncoder、线性注意力机制、Decoder-only的文本编码器以及高效的训练和采样方法，实现了在</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697639&amp;idx=1&amp;sn=872e2d1318feab3ae2a931d2ae253107&amp;chksm=ed6f548ef88b9108ef7bfff7e0898573a486f3a2fd682ba6027a649f57fe85459ec1f54bdf98&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 20 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NeurIPS 2024 Oral｜小参数，大作为！揭秘非对称 LoRA 架构的高效性能]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoJVXDQp5yqF5XZjss7dLfOB82zJkHqia4IptuSak7qPr4na3dd6kYdD1gecNp9K7HibW9tMLOgv0iaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台作者丨机器之心来源丨机器之心编辑丨极市平台极市导读 HydraLoRA 引入了一种非对称的参数微调架构，能够有效识别并适应数据中的 “内在组件”—— 即子领域或不同任务。 ></p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697639&amp;idx=2&amp;sn=ef5789d02828ef41a8a78c16b90ddd13&amp;chksm=edb0ee0f5b40c0029fd681e70ca66a94308a2d09faa81479c18fae2893c52b48bce603c1805c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 20 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[实践教程｜兼顾灵活性和性能以及调试的手搓TensorRT网络！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfrbey5c4yDx2PFzbEErw1VxEicQERIsvzkLHVcxku1CiaAuyJLWRKVC8hzwDD4HDIaejoQ5u7EbClicQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台作者丨Oldpan来源丨Oldpan博客编辑丨极市平台极市导读 同时兼顾灵活性和性能的TensorRT教程。 >>加入极市CV技术交流群，走在计算机视觉的最前沿用过Tenso</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697639&amp;idx=3&amp;sn=8b21b2cf5c88238a8b21c2e80d094968&amp;chksm=ede870d2ff1007a7e564b409bd91ac2521564a8487581b0bef184506380d83797788a407eaa9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 20 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[英伟达nGPT重塑Transformer，AI训练速度暴增20倍！文本越长，加速越快]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoJVXDQp5yqF5XZjss7dLfOdLwG6KpBiaXW2paaPYTFB3ZR8jPDXXTsxOqBoPDbNJibUG7lLToAQNWQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台来源丨新智元极市导读 LLM训练速度还可以再飙升20倍！英伟达团队祭出全新架构归一化Transformer（nGPT），上下文越长，训练速度越快，还能维持原有精度。>>加入极</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697639&amp;idx=4&amp;sn=ab1204a5eea5424a6f32564744612452&amp;chksm=ed8a14fa83736800bef3fe560aa0cc8ba1cc7d7c1deaef3a80116de9a78e4271f725ab57d0fa&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 20 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[来自非自回归模型的反击？全新文生图基座模型Meissonic：1B文生图Non-AR新范式，专为消费级显卡设计]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfo5LuxzWJBLQk6dR52ezG4G2ibQJuN947JOSc5zPR8icHVSh8B0Cric01R4PVw71vC7WYG9vGl0ibhrYQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台作者丨阿里、港科大、颜水成（昆仑天工）等作者编辑丨极市平台极市导读 Meissonic，一个基于非自回归掩码图像建模（MIM）的新型文本到图像（T2I）模型，Meissoni</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697582&amp;idx=1&amp;sn=5f279569133f0b844b1efe4a693adb74&amp;chksm=edafbd6f4d2e72156390ce7e19634a264ea7f8cd22c6980cb0ce7425e4909ed53e4df9a100b8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 19 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[又快又准，即插即用！清华8比特量化Attention，两倍加速于FlashAttention2，各端到端任务均不掉点！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfo5LuxzWJBLQk6dR52ezG4GRha3LianTNaozmQ6gD9VYqIBpv5Gm76HfFIBjV92A8ygfRPKJdWISbw/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台作者丨机器之心来源丨机器之心编辑丨极市平台极市导读 清华大学陈键飞团队提出了 8Bit 的 Attention（SageAttention）。实现了 2 倍以及 2.7 倍相</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697582&amp;idx=2&amp;sn=40f8931b21f0bc2ae8da9f167660ac62&amp;chksm=ed0a7a35d0a67f9074aafab257ab12d8b08e32c2ac224e4545fea89f1286a7887a4ed1254317&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 19 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[使用PyTorch进行小样本学习的图像分类]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfpSVPALg8pBNxz1vJ50e182sTaA8icbnicYyepPhYPPdKkQ410nHicdbQGQRVRwm1ibFXvoPgF2piaUiaLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台作者丨Aryan Jadon来源丨DeepHub IMBA编辑丨极市平台极市导读 本文简要总结了四种小样本学习图像分类算法的方法，并使用pytorch实现了一个简单的分类模型</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697582&amp;idx=3&amp;sn=12bcce7db63f706095ee89547746b3fe&amp;chksm=ed1e75bf0689ce980d8c33b11ece4f6537588a2400a7259c7dcf171f35ac3a6c3478845d1efe&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 19 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[苹果一篇论文得罪大模型圈？Transformer不会推理，只是高级模式匹配器！所有LLM都判死刑]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfo5LuxzWJBLQk6dR52ezG4GCwgEHZs4OAzwns3g9ibL4B9ibrkx1X8HgX1f6u5CKwvty9IxGgShja7g/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台来源丨新智元极市导读 苹果研究者发现：无论是OpenAI GPT-4o和o1，还是Llama、Phi、Gemma和Mistral等开源模型，都未被发现任何形式推理的证据，而更</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697582&amp;idx=4&amp;sn=8ade03574c8974da736dd2366b1df12b&amp;chksm=ed43068d5443e1208e28559bc625c3b5702e8354507a54ba1566053c9bc633fb5a65be9a4d7a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 19 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[现阶段的多模态大模型做不了医疗]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoB3wnvyicAeBiapGlk1QnaYXibv2BkwXibIUQYNDLGC4up0PtwIVUNTblibKwyU3pboFcJzdEEia5uvITw/640?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台作者丨廖方舟来源丨CVHub编辑丨极市平台极市导读 在当前的技术和数据储备下，多模态大模型在医疗辅助诊断领域难以取得重大突破。 >>加入极市CV技术交流群，走在计算机视觉的最</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697487&amp;idx=1&amp;sn=016899648319504146229a9c553261b2&amp;chksm=ed3b592743cc42ae8e202c00c0ee573533bf2c58fe6a4cb8a11f9d6d315717bba2645bb82515&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 18 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ECCV'24｜Plain-Det：同时支持多数据集训练的新目标检测]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoB3wnvyicAeBiapGlk1QnaYX2rjuV1V4QDdW5vXKmD1LYGFLPSQNSZhyfJHlicGkaMIVZLESxaJeMag/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台作者丨晓飞的算法工程笔记来源丨晓飞的算法工程笔记编辑丨极市平台极市导读 论文提出了Plain-Det，提供了灵活性以适应新的数据集，具有跨多样数据集的稳健性能、训练效率和与各</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697487&amp;idx=2&amp;sn=087005fc64f37831611de98eb664fd06&amp;chksm=eda617e0b2237f842d1981a9b2a82b6ec1a205e127931600dcccf1dfda2d3cb77b57a895c565&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 18 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NeurIPS 2024｜刷新SOTA！TopoFR：人脸识别新工作]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoB3wnvyicAeBiapGlk1QnaYXH2SmTh0uauE9eia9NUEgZJDT034QTeXJ9PpZpFPicMl82ooQicve57Chg/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台作者丨机器之心来源丨机器之心编辑丨极市平台极市导读 本文提出了一种新的人脸识别框架TopoFR，通过拓扑结构对齐和扰动引导策略有效提升了人脸识别模型在真实场景中的泛化性能。 </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697487&amp;idx=3&amp;sn=23bbb4cc0f60b7b9b14d618ea7a9d357&amp;chksm=ed7aa31652b70b9725183ba9f36ef1c4a23ab9f90d68723c4471a69246dc741969fa21b10a92&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 18 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DenseNet共一作者刘壮官宣新去向，将任普林斯顿大学助理教授]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoB3wnvyicAeBiapGlk1QnaYXnRuSb0nAyhLG53sUdof5zXA0Zby81GOsYVNAzjfNAOjlT5PibsDVibvA/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台来源丨机器之心极市导读 「还离这世界上最棒的地儿不远。」 >>加入极市CV技术交流群，走在计算机视觉的最前沿最新消息，DenseNet 作者之一刘壮将于 2025 年 9 月</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697487&amp;idx=4&amp;sn=6b59b4f411ccdb1509b1b5f7df8bd530&amp;chksm=ed5a33947ebb08519c3a6ec16f02db66518141c80e14aa61d43f19935e9664d9c381a3d08968&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 18 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[解锁视觉语言模型新高度！微信提出多模态大模型 POINTS: 简单高效又不失性能]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoAetOKZvvTJeTwgKWyco1G73WqwhN637hSl0qroc8fhEFWZ4OOl0iboIXlBz3C4GOibwkbCgHYbWlg/640?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台作者丨WeChat AI来源丨CVHub编辑丨极市平台极市导读 微信团队开发的多模态大模型POINTS，该模型通过创建强大的基线、预训练数据集过滤策略和模型融合（model </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697393&amp;idx=1&amp;sn=e6dbe7db3b584204d202695975a97fca&amp;chksm=ed9f6f2a1f44b5b3773412729fb4d5278749c4e67f74c10dbd09501e08dc830819dc19a8e5ac&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 17 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ICML 2024｜牛津提出合作图神经网络Co-GNNs，更灵活的消息传递新范式]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoAetOKZvvTJeTwgKWyco1GzAk4EicUhXpkEiceYS76hz0Snqib58VBzWTjuo4TPJS2sAxuz74179ptw/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台作者丨Xingyue Huang来源丨PaperWeekly编辑丨极市平台极市导读 本文提出了一种训练图神经网络的新框架“合作图神经网络”（Co-GNNs）, 其中每一个节点</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697393&amp;idx=2&amp;sn=7c6bd24f03ce2759ebc16d68d3109e62&amp;chksm=ed75d4607af6399c6e9dc709fa57f87ff803ac71cafd8f87690b8a178e56a9839509d5f8f09e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 17 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[如何从头训练大语言模型: A simple technical report]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoAetOKZvvTJeTwgKWyco1GsM5XRFvSKxHJONgL3knbQXuotyLLcORVMnKnYefq7aqS7CfpTz61dA/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台作者丨涮月亮的谪仙人@知乎 https://zhuanlan.zhihu.com/p/906819356来源丨深度学习自然语言处理编辑丨极市平台极市导读 本文作者对其训练1.</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697393&amp;idx=3&amp;sn=cc690b72c40aa511f15f780756126f9e&amp;chksm=ed9503685788b493f73e5755fd9a6c7d385f8307316edfd62df558ab3e5550fa16f4ebb7e998&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 17 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ICLR 2025钦定AI参审，11000篇总投稿数暴增61%！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoAetOKZvvTJeTwgKWyco1GGuyOfmXGTx7VRJGvkRktP3SdJk93W9ro8ABHuCFEHXsK29AVMibjIjQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>↑ 点击蓝字 关注极市平台来源丨新智元极市导读 ICLR 2025评审已经开始了，今年审稿人高达15000+名，为了提高审稿质量，多个大模型组成的智能体也要参与审稿了。>>加入极市CV技术交流群，走在</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247697393&amp;idx=4&amp;sn=ee8677bc324fd2494a0892ccf227da2e&amp;chksm=ed7989073867f21318386d05c62b008731d83f3d0524ca916288f3dde3a725c50382383c9938&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 17 Oct 2024 14:00:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
