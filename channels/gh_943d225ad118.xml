<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AI for Research]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AI for Research公众号]]></description>
    

    <language>zh-cn</language>
    














    <item>
      <title><![CDATA[语言模型能解决奥赛编程问题吗？| 如何快速估算微调大模型的GPU内存使用量？|  AlphaFold 训练时间缩短至 10 小时]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdeBbVQrFLflKxoia86bZmRVZD4p31TvBJ8dt4DOPbB5p2XjyyK2J5gmRVzqNFfiafDuxXP6txMpdeOg/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言：如果你想成为一只科学界的“独角兽”，那么看论文是必不可少的。只有掌握了最新的技术和理论，才能在这个竞争激烈的市场中脱颖而出，成为那只最闪亮的“独角兽”！1. 语言模型能解决奥赛编程问题吗？  标</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247485300&amp;idx=1&amp;sn=4a0cc8f6738a550384c0402b5930f07c&amp;chksm=c1279d2e1a4c55468fe1cc657f9d98db5e6a3cf0c168e0efed83f612236849a1144c1a42b73a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 18 Apr 2024 13:35:39 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Mixtral 正式官宣Mixtral-8x22B，推出模型详细介绍文档！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdeBbVQrFLflKxoia86bZmRVZFTq3e5z1MljTAa6xQyA7MuXR8Xgia6GWU1b1xfUWkGJ5rg1jes6dCFg/300?wxtype=jpeg&amp;wxfrom=0"/><p>以下是官网的正式介绍：Mixtral 8x22B 是我们最新的开放型号。它为人工智能社区的性能和效率设立了新标准。它是一种稀疏专家混合 (SMoE) 模型，仅使用 141B 个活动参数中的 39B 个</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247485300&amp;idx=2&amp;sn=0df1309a42caeaf71977ae6d9f068bfc&amp;chksm=c16b6b4d3e78df2a91a067a85ba1c87cef5c76bba097f13e79933f6201391adc0359edcab2ce&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 18 Apr 2024 13:35:39 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[DPO真的比PPO在对齐方面更优秀吗？一项全面研究 | Stability AI 发布5分钟时长歌曲生成技术...]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdfl6SglCfPLmvX64EomHib1CX6YodETR6iaeN4c5Xx8EHoRt4xy5prwxovdyUHda2VYmFWcRJKbybWg/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言：如果你想成为一只科学界的“独角兽”，那么看论文是必不可少的。只有掌握了最新的技术和理论，才能在这个竞争激烈的市场中脱颖而出，成为那只最闪亮的“独角兽”！1. DPO是否比PPO在LLM对齐方面更</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247485284&amp;idx=1&amp;sn=dbe1311f0c80564e54b1a0761874f082&amp;chksm=c1ff31fa5148bd2c474aeff72f06d60b39d3e0d9db133fbec6e009f9f8963412126a6b9e04f9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 17 Apr 2024 12:54:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[MT-Bench 榜单首个得分超越GPT-4的开源模型 —— WizardLM-2 发布！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdcCic9pTx4ic7NWNuicXiaFyB0PAnApHxMrUicll7pt8Wl7vAf5kNzzIPcHYnlv3mZAVCyP6goS2QtdHKg/640?wxtype=jpeg&amp;wxfrom=0"/><p>感觉大模型社区最近是越来越活跃了，5天前，Mistral AI 刚发布 Mistral-22B x 8 MOE模型，今天微软的 WizardLM 团队也更新了他们基于该模型的最新的进展：今天我们宣布推</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247485280&amp;idx=1&amp;sn=ee1fd65777fd9942d9262ba2829145cf&amp;chksm=c1dc00bc1730a3a36596b9bbc42721d9a0e5f1e18a439ee9530446bc8a12201c09ee0bcaffcc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 16 Apr 2024 14:00:37 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[语言建模等同于压缩！腾讯联合香科大再次确认 | 具有无限上下文长度的高效LLM预训练推理  | 大模型事实、毒性、偏见和幻觉评测]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdcCic9pTx4ic7NWNuicXiaFyB0P2T1DhYIL1cF9P68BChZ7xyzWgwReeQsWccTN0CxCXsDmy8odePJhFQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言：论文可以让你更快地了解最新研究进展，掌握最新的技术和理论。这对于自身的科研能力和竞争力非常重要，尤其是在快速发展的学科领域，下面小编带你来看大模型最近的研究成果。1. 压缩代表智能的线性关系  </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247485280&amp;idx=2&amp;sn=e8297be2cb2aac0a2a6362678544f8ff&amp;chksm=c1569d3c233bff221d73251b983af491d2b5318f5a7d293c9f74ee4dbdf062e535fdc8e7d2cc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 16 Apr 2024 14:00:37 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[微软提出DR-PO：基于数据集重置的RLHF优化 | Scaling (Down) : 有限计算预算下缩小规模时模型表现....]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdduPoLIqOjSW7MJxoXPiczjE4xgwZMN1nM3hulD8lUYJkP2iafCRI5ia7zafL46TicLXicF1NNzDPvLyQg/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言：平淡无奇的一天又来了，今天要分享的内容主要是关于大语言模型、语言模型、预训练的，喜欢的小伙伴赶紧去阅读相关论文吧。1. 数据集重置策略优化用于RLHF  标题：Dataset Reset Pol</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247485241&amp;idx=1&amp;sn=1d7331bc3ece9baa2ee689de57d94a4b&amp;chksm=c1f6743422f80585e216ca2f49d4ff5306b6a37cc8afbd2f5dfcf791bc7573b66939aeda3296&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 15 Apr 2024 09:59:47 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[今天，开源模型击败了 1年半前的闭源模型 ...]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdevbojcHnWFQwEjaPleXIUsHHBWf4FQB1p5aeDgYpyeffCN4ewQHGTcbOsEuXcsQc4elye2Ryp8ZQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>从 MMLU 上看，开源模型（绿线）正在逼近闭源模型（红线）三点：1. MMLU 最高1.0，所以自然会放缓增长。2. 重点！大模型在当前架构下是不是已经快走到尽头了？GPT-4的能力是不是快逼近天花</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247485234&amp;idx=1&amp;sn=aa6aed439c080689932918d20800407b&amp;chksm=c15bdd5deed9ae66fc8be26ddf038a40fbdd23a5593252298e8be24e7db14995f0680014dcde&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 14 Apr 2024 04:39:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[本周大模型Top热门论文精选【2024—第15期】]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdevbojcHnWFQwEjaPleXIUsrbiaXn139w16FmjLhtGEHJLSuaqxickeiastCibY3uibpo7L95n9TybLGhg/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言：论文可以让你更快地了解最新研究进展，掌握最新的技术和理论。这对于自身的科研能力和竞争力非常重要，尤其是在快速发展的学科领域，下面小编带你来看大模型最近的研究成果。1. 何时停止解码？文本生成中事</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247485234&amp;idx=2&amp;sn=91e1a977ed509249f3aa11c5619e3f1e&amp;chksm=c158e16b2a3372dd8052d543912cdfd715b381f9237b272b1a2d15f39a03be3fa6059c062c57&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 14 Apr 2024 04:39:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[现有的评估方法并不适合评估指令模型？OpenAI 无奈亲自下场了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdckRvaszicyPYNwAfeIMsBMUbpN3PnoK6B7ASWWN1EuTvxK8gX8bqPlpZ07qKRUYV1HHLOKNohagkw/640?wxtype=jpeg&amp;wxfrom=0"/><p>就在前两天，openAI上线了他们最新的模型 GPT-4 Turbo，该模型在写作、数学、逻辑推理和编码方面的能力都大大提升，在著名的chatbot-arena-leaderboard 对战榜上有开始</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247485223&amp;idx=1&amp;sn=bc8a6f8111e86a93d1d291da864e3484&amp;chksm=c13c5471fded010ea60859c241f65249bed630bd276b9bdb53ea463722e541e73ce47e557c50&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 13 Apr 2024 05:28:27 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[红杉发布2024年最有前景的前50 AI公司...]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdckRvaszicyPYNwAfeIMsBMUU1HbzibfaBaIf8zK1X9x93p4AB7Umj1cr0Yzlwpzoib5jfEIbjahITGg/300?wxtype=jpeg&amp;wxfrom=0"/><p>2024年的top50 AI 公司显示了通用人工智能如何开始转变企业生产力。去年，生成式人工智能从AI 50榜单的背景走向了前台。今年，它成为了焦点，我们开始看到企业客户和消费者的主要人工智能生产力增</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247485223&amp;idx=2&amp;sn=564ae8f5c3583cdd00579c7c7b71c8e9&amp;chksm=c10bf6692ba7f6b15d47c8ce182d4a0330efdf63a4062d33ae3481e1dfd3be8cc0fd72bf1708&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 13 Apr 2024 05:28:27 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[百度：GPT系列模型训练数据影响之探究 | 少样本准确率上提升30%，微软发布Rho-1 | 谷歌发布R-Gemma性能超越..]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBde2XTmBXAaccjYM0lwv3GcbyBy3BkgJggyweibSH4jdfdP6neA6stmalicvvtJPyhLymBUlh86YHFCw/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言：论文可以让你更快地了解最新研究进展，掌握最新的技术和理论。这对于自身的科研能力和竞争力非常重要，尤其是在快速发展的学科领域，下面小编带你来看大模型最近的研究成果。1. 关于GPT模型训练数据影响</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247485202&amp;idx=1&amp;sn=4fd9d1bae97920bee86e0239e4712c4c&amp;chksm=c1deab5f61624a29bfac5a3b93d65546b463a9ac0cc2eb61c9a97bc9e5c7621b90a2dd6dca1c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 12 Apr 2024 13:14:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[数据过滤规模定律--数据筛选不能是计算无关的！谷歌：高效的无限上下文模型如何实现？理解大模型何时会混淆]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdfiaiacnjic6SUEiajZ4iawE2Sb9piaoO2rCb2ia8ibibDrqKeqicd1e0zYw78p1Epce4ESnpJarXqcww1rqialw/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言：科研就像一场冒险，而看论文就是你的探险工具！只有通过深入阅读，才能找到宝藏，发现那些意想不到的科研奇遇哦！1. 数据过滤的规模定律--数据筛选不能是计算无关的  标题：Scaling Laws </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247485196&amp;idx=1&amp;sn=fa86121c5520ae4539ffef728c01a47d&amp;chksm=c14e86c309569d1ba2ab3f472d699c8546f5314d30db58146e846969a032dcabf029b4285a4a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 11 Apr 2024 09:42:16 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[谷歌发布CodecLM：用合成数据对齐语言模型 | RWKV进化至V6版 | 北大发布大模型中的幻觉排行榜.....]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdeVDwsbgv56CYHem7MflibwVgPVDTMibfqRosicW6KIbE3fTpf2Uxuczl4QK0OeNT6HNZCz3icXtbwqqA/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言：平淡无奇的一天又来了，今天要分享的内容主要是关于大语言模型、多模态、预训练的，喜欢的小伙伴赶紧去阅读相关论文吧。1. CodecLM: 用合成数据对齐语言模型  标题：CodecLM: Alig</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247485192&amp;idx=1&amp;sn=9de31b42bf9e36d283bbd70ea3a76ab1&amp;chksm=c16afdee9e5372efadac96544608a23bf7a5d918c638da87e72cec70c796d7485d9c32921e80&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 10 Apr 2024 09:23:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Meta: 大模型知识容量的缩放定律 | 探析并理解DPO的局限性——理论视角 | SFT多语种大模型到底需要多少语言？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdeW9VyV1aiadsFgE7u7KmJjbdAhRzp4uLFcE617UxVQicKZWA4oI843VFduDuqvsUgREI6sm9j4Cw1w/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言：看论文就像是一次美食之旅，每一篇论文都是一道不同的菜肴。有些论文会让你大快朵颐，有些论文会让你欲罢不能，而有些论文则会让你咬牙切齿。但是别忘了，只有尝试了各种不同的菜肴，才能成为一个真正的“吃货</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247485188&amp;idx=1&amp;sn=c8bffe6da62edaab21f6da8eadabac03&amp;chksm=c11a93b68d86119930fd151b3af747481285a913e0582e06c728cfc3df0bfc0bf531726aff3b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 09 Apr 2024 13:42:35 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[本周大模型Top热门论文精选【2024—第14期】]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdeLLwBeibm6syE8C9yQ3BV5WibqriaToROiacEWEmZz02Cwumaq5rypibdC8yM6WeJHRyKOWWUdHWjOhXw/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言：科研就像一场冒险，而看论文就是你的探险工具！只有通过深入阅读，才能找到宝藏，发现那些意想不到的科研奇遇哦！1. 探索大模型预训练过程中的细微差异: 基于下游能力的度量方法  标题：The Fin</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247485177&amp;idx=1&amp;sn=57c1c8883a76ebf5d2fd06b5a9ac053f&amp;chksm=c1597da4369594344f72b1b5ae24e7bce4e6bb06f72d3d3dedf1bb06b96e24c78a341051b98b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 07 Apr 2024 07:43:19 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
