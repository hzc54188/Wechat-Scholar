<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AI for Research]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AI for Research公众号]]></description>
    

    <language>zh-cn</language>
    













    <item>
      <title><![CDATA[推进小语言模型对复杂推理任务的能力 | 探索大模型训练中本地SGD的缩放规律 | 大模型中高效的知识卸载与编辑...]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdcqYdVzdicBfD4L0VibeatjruL00RjJ3Ljr1oTgXC2gAPpdO9EByXYfqhIicsvGvXD1ZbiagNZDdETbVg/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言：如果你想成为一只科学界的“独角兽”，那么看论文是必不可少的。只有掌握了最新的技术和理论，才能在这个竞争激烈的市场中脱颖而出，成为那只最闪亮的“独角兽”！1. Neural-Symbolic Co</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247486424&amp;idx=1&amp;sn=67f2238b78a425fd94196dca8d058565&amp;chksm=c112fed80f908dc937046bbbbbeda73a99b56d2fd5d83590ac541c58591ce25c85795b405e75&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 23 Sep 2024 14:57:02 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[语言模型会通过RLHF误导人类？苹果发布最新研究用小模型初始化加速大模型的预训练...]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdcqHUz1J9Z1BQg7ibSPf8AS5GEduKss7DWbJT6WSlOopDbwB67JAd3QlfAIicNA2TbdDagkVXCGRGJw/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言：科研就像一场冒险，而看论文就是你的探险工具！只有通过深入阅读，才能找到宝藏，发现那些意想不到的科研奇遇哦！1. Scaling Smart：用小模型初始化加速大模型的预训练  标题：Scalin</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247486420&amp;idx=1&amp;sn=c06aebf22f8d439f5ba7bf05b80e8e9d&amp;chksm=c143846c5d72452c7ae00afb3cd49b144b53027fce96348215463f6de09e5452c4243213bd10&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 20 Sep 2024 11:15:02 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen2.5系列模型论文发布：数学、代码、多模态全揭秘！长上下文扩展和大模型泛化的研究....]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBddJNa81Bu8nlF1Eo8R2CWSCibb0tdPbNZDwaLCm1gLPkgkrKYbOmC4tShM0qYX7ZpwrhKhFQeaABew/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言：如果你想成为一只科学界的“独角兽”，那么看论文是必不可少的。只有掌握了最新的技术和理论，才能在这个竞争激烈的市场中脱颖而出，成为那只最闪亮的“独角兽”！1. Qwen2.5系列数学专家模型：自我</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247486416&amp;idx=1&amp;sn=22f758b5e4d899ef0ad29b3699adb6e4&amp;chksm=c1133ebee5c8c599b530813eb275f19fcdfa8c5dd4c90c7f475ebb2f5c1c18f94cc80de2d101&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 19 Sep 2024 12:22:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[英伟达发布NVLM：最新前沿多模态大模型！GPT-O1能否消灭所有Bug？自注意力限制了基于大模型的工作记忆容量？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdfUdnice84d4IeT8IMUVHqlYOZXOZaWGc7uCApaZ3C5EAlFdGdqK7sF8AkGiad4j07lCqO6t4hJu32g/640?wxtype=png&amp;wxfrom=0"/><p>前言：论文可以让你更快地了解最新研究进展，掌握最新的技术和理论。这对于自身的科研能力和竞争力非常重要，尤其是在快速发展的学科领域，下面小编带你来看大模型最近的研究成果。1. NVLM：前沿多模态大模型</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247486412&amp;idx=1&amp;sn=f2fd0c516d229ca79e68b7ec658d40d2&amp;chksm=c1befc8cc030e26fa80f8728cfcd27010216360ab6e228b220ece8366a8e3248b120d1bf8dec&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Sep 2024 09:52:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CPL：关键规划步骤学习提升LLM在推理任务中的泛化能力]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdfUdnice84d4IeT8IMUVHqlYm1wGJ9vKiaVTZz9ac8qp9A1e5hXiarbax4tpicPKUZlicZxYKDZAZt5icCQ/300?wxtype=png&amp;wxfrom=0"/><p>前言：平淡无奇的一天又来了，今天要分享的内容主要是关于大模型、大语言模型、模型结构改进的，喜欢的小伙伴赶紧去阅读相关论文吧。1. CPL：关键规划步骤学习提升LLM在推理任务中的泛化能力  标题：CP</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247486412&amp;idx=2&amp;sn=32eb8397fabd581f0a0add3065cc5988&amp;chksm=c16289eb11b09465f7fec3d0d4a8ee7f744aad699a15b51edb8ea01c336ff853c73ccf766cbd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Sep 2024 09:52:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[斯坦福发布合成连续预训练方法！解决少样本学习特定事实问题 | 多模态模型的规模定律假设 | 复旦发布FuXi-2.0天气预报模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdd4xHibjwcz4ibYvvCb5FibDD1DWHgbC2CZ5nkM9ic7U32aGajvyql1SIQ9dl0kgM04kD7l2icODeDVHeg/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言：看论文就像是一次美食之旅，每一篇论文都是一道不同的菜肴。有些论文会让你大快朵颐，有些论文会让你欲罢不能，而有些论文则会让你咬牙切齿。但是别忘了，只有尝试了各种不同的菜肴，才能成为一个真正的“吃货</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247486404&amp;idx=1&amp;sn=ffb0a21ecc89ba36e8a484953b7a8220&amp;chksm=c1ba35f48e8266ac5cd7ee3c8f53e9413e30f50eebdd5096b9ad27e3f655dd11be1b72a86eda&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 14 Sep 2024 06:09:05 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[基于真实数据来生成合成数据与筛选的方法研究 | 稳定语言模型预训练方法 | 更快的Speech-LLaMA推理：基于多令牌预测]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdd4xHibjwcz4ibYvvCb5FibDD1o1wLfwCZhibgxicv63OxWq1hLHibwdMk9wvdMMlAg6Wc2D1127RyZUhsA/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言：平淡无奇的一天又来了，今天要分享的内容主要是关于大模型、扩散模型、模型结构改进的，喜欢的小伙伴赶紧去阅读相关论文吧。1. 基于真实数据源合成数据生成与筛选的方法研究  标题：Source2Syn</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247486403&amp;idx=1&amp;sn=cb7bd07ed7f1d84b6e9d2f70e184b199&amp;chksm=c1950200218e04ac2cd95f6e37ba041815b34a578fd408d9cfd0cba47a23f34ce91253dba4c6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 13 Sep 2024 12:26:12 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[谷歌发布20倍加速大模型的预训练方法：学习、专注和复习！LLaMA-Omni：与大模型无缝的语音交互...]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBddCXdibzxtaC2aNzWtbgjh5echonpywboHnp4Lj9PeuJr5AoAuTw5E9BKjfkfGnTKxkd20vqedFpbw/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言：平淡无奇的一天又来了，今天要分享的内容主要是关于大模型、大语言模型、视觉语言模型的，喜欢的小伙伴赶紧去阅读相关论文吧。1. LFR教学法加速大模型的预训练：学习、专注和复习  标题：Accele</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247486396&amp;idx=1&amp;sn=11f89c0212f7eed356466e1d5f354b12&amp;chksm=c1a3524e1130e0012ec67fcbe53cc473575b1eafab64765e23be2f9bf2a7eb5620b6b368b1f4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 11 Sep 2024 12:02:37 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[谷歌：代码预训练如何影响语言模型任务性能？提升预训练数据质量：基于困惑度相关性 | 突破规模定律：神经网络的模块化...]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdcUJeoYh36VzOwFLAST2ZvL9ACff9385icGuWHqEtmsVibAwQKjxibwN8JMq6CyibSlwuRXdwO89cVEbg/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言：论文可以让你更快地了解最新研究进展，掌握最新的技术和理论。这对于自身的科研能力和竞争力非常重要，尤其是在快速发展的学科领域，下面小编带你来看大模型最近的研究成果。1. 代码预训练如何影响语言模型</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247486392&amp;idx=1&amp;sn=c5749c8a6e14de0685f4240f0091f834&amp;chksm=c1ec0a2552990f793aee4f39333592e593424a28d742adf8c57c03ff1f6df1e8e5d250eb4743&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 10 Sep 2024 12:10:42 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[如何提高代码LLM的表现？基于高质量数据强化的代码指令微调 | Open-MAGVIT2:一种向自动回归视觉生成的开源项目...]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdctJoeqjD0XZE8T35wHTCUctPHdPM8fnribulgnTXr5iaK0bsLmqMLIEf0PmLbJEjTcD3icxBK3jl3yA/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言：如果你想成为一只科学界的“独角兽”，那么看论文是必不可少的。只有掌握了最新的技术和理论，才能在这个竞争激烈的市场中脱颖而出，成为那只最闪亮的“独角兽”！1. 如何提高代码LLM的表现？利用高质量</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247486388&amp;idx=1&amp;sn=0b1f17715389210c8fe2f1deb2cfb4e2&amp;chksm=c12102cac50a8ddbbb5c79f9723c359cb0d6708d8fc4da82d078fc3d71a5c06fa037fdb46d25&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 09 Sep 2024 15:38:12 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[仅需100条样本即可实现LLM在未知数据分布上的泛化？数据规模对语言模型表现的影响：以微调翻译大模型为例...]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBddpoo7xxuv1rkLmzduHib48lT8LISicYliaIzkmf4kkD0mdbibFge3Sz6Rc0BibbrnlFUdvxqszXIwQaxw/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言：科研就像一场冒险，而看论文就是你的探险工具！只有通过深入阅读，才能找到宝藏，发现那些意想不到的科研奇遇哦！1. 100 instances is all you need：通过在少量实例上测试预</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247486381&amp;idx=1&amp;sn=d4182559a14200d5cb9a8e4b5d06ca95&amp;chksm=c16d2bf9a269b6b1f19a16745266f1112cc476bc4ac2385e5e57e18e93add7898360060b7ebf&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 07 Sep 2024 04:32:10 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[代码预训练数据的秘密：高质量数据的定义和作用....]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBde4aYHJrEOl0DIfZXF9hDMDUlOxnkTLFVLe68OAtNictR006coicCvYD9AfKBYRgRNbZVpIWNEGOSBA/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言：科研就像一场冒险，而看论文就是你的探险工具！只有通过深入阅读，才能找到宝藏，发现那些意想不到的科研奇遇哦！1. 代码预训练中的数据揭秘：高质量数据的定义和作用  标题：Arctic-SnowCo</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247486376&amp;idx=1&amp;sn=b055fc631ab4d1a59aa04ff0dea5ce60&amp;chksm=c1892b9dfccacdb8ebdaf75d71e80571e4ef6e41875a0ca8fbefef423a0502407ffec0352107&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 05 Sep 2024 12:01:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[语言模型操作系统的压缩机检索器架构研究 | OLMoE：开放专家混合语言模型 | 统一端到端模型实现OCR 2.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/0XibHbUBQBdfYHoQjuHx6fhMlH6cI0TGHvtttczPwzdJ40xCSBjSia5Dc2cLkdCNYzyTjHlRRpRvYrpQ6M8vsYrg/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言：平淡无奇的一天又来了，今天要分享的内容主要是关于大模型、多模态、模型结构改进的，喜欢的小伙伴赶紧去阅读相关论文吧。1. 高效长语境泛化的大模型训练策略研究  标题：LongRecipe: Rec</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5OTkwMDY4Mw==&amp;mid=2247486372&amp;idx=1&amp;sn=6d9c3760aad2ab67ad728b5b08f03335&amp;chksm=c1508b3e39004227bf1f068fd84cd1faae983a4ed15eb3a6ef88868da93e1ac08ac92b8e7daf&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 04 Sep 2024 15:49:58 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
