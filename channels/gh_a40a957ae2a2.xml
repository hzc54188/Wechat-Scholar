<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[NLP工作站]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[NLP工作站公众号]]></description>
    

    <language>zh-cn</language>
    



    <follow_challenge>
      <feedId>71075630994113565</feedId>
      <userId>69694715808772096</userId>
    </follow_challenge>

















    <item>
      <title><![CDATA[LLM实践系列-拯救Continue Pretrain的数据]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5l29iaSsz4ibXE7KCILFDIdWvicghtOUYcMxjEPxUaxNhMq8nujL9a8tKYL41icW0mRWDNVxTEpln5P7Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来知乎@真中合欢的一篇文章，《LLM实践系列-拯救Continue Pretrain的数据》。知乎：https://zhuanlan.zhihu.com/p/721492096打分清洗的文</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247490612&amp;idx=1&amp;sn=0a9025eed834cb600f18c1e17044519e&amp;chksm=ce9c68c8eeffb86b6607198f89fa4e77b61ab661fc9f5723199ba936ef25dcbb38b19b6d184a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 18 Oct 2024 01:09:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[超全！一文详解大型语言模型的11种微调方法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5kFsc1MXu7YZnJIZSVUNaL2XzHibpkSDoFlsCZne0XuOtbH9ZgbrBtTvibFEuuIM2ic8t9Ouvh1Syhzw/640?wxtype=jpeg&amp;wxfrom=0"/><p>导读：大型预训练模型是一种在大规模语料库上预先训练的深度学习模型，它们可以通过在大量无标注数据上进行训练来学习通用语言表示，并在各种下游任务中进行微调和迁移。随着模型参数规模的扩大，微调和推理阶段的资</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247490603&amp;idx=1&amp;sn=cc5327a08875e60916aefa510ea7cfa3&amp;chksm=ce0f58032845f59fff22a03baa7541c5cb14f342b5952155148c2f400ea4d7d09266c9a7323e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 16 Oct 2024 15:23:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM实践系列-详谈Tokenizer训练细节]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5kTwdfR5hls6hgb6EAhd4ENPhmQPltSdlSFW054SlDbic5XaVWF1hNCuI2LJibib0ic1XzUrQm3OM0pBg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来知乎@真中合欢的一篇文章，《LLM实践--Tokenizer训练》。知乎：https://zhuanlan.zhihu.com/p/739078635经过了数据收集、筛选、去重，马上就可</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247490596&amp;idx=1&amp;sn=4b6eaa9b3717033b269282cdc8d59e4c&amp;chksm=ce2d1e69cf2cd65b6d72e7da2f78c00ef630db20078e9467fbd49b8c97dae5334a8d25772381&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 15 Oct 2024 01:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM实践系列-数据去重之Simhash&amp;Minhash分析与实现]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5kTwdfR5hls6hgb6EAhd4ENPhmQPltSdlSFW054SlDbic5XaVWF1hNCuI2LJibib0ic1XzUrQm3OM0pBg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来知乎@真中合欢的一篇文章，《LLM实践--数据去重：Simhash&amp;Minhash 原理分析&amp;代码实现》知乎：https://zhuanlan.zhihu.com/p/739101179</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247490588&amp;idx=1&amp;sn=f7178ca8b89462971f4a9bd6d9c29072&amp;chksm=ce6516e30fbdc10949a6e0742a015a5d368ee7588f3a27337f7e6576eb74982badae81a04e79&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 14 Oct 2024 05:13:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CodePMP：提升LLM推理能力的可扩展偏好模型预训练]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5nbQgT8S1l4BLjrkFXxvP4ia1QDwiaa5yJdhphnkRLTF0JPOwicfGiaAZblynlrhX564ibDsTnpYU1GK0g/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：鱼汇沐  机构：中国科学院信息工程研究所 paper: https://arxiv.org/abs/2410.02229在LLM（大语言模型）的对齐训练中，尽管RLHF（基于人类反馈的强化学习）</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247490553&amp;idx=1&amp;sn=41c4afa1c7734f17d958c3cfbb06884f&amp;chksm=ce3b2b2d54b4f5bc3b4de9d6f9fa0147e1dd706f605c061bbe11ba484aa79ed82c045af6ac8f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 12 Oct 2024 02:10:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
