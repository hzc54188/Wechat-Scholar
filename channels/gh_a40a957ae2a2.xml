<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[NLP工作站]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[NLP工作站公众号]]></description>
    

    <language>zh-cn</language>
    

















    <item>
      <title><![CDATA[如何获取高质量数据进行代码指令调优？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5lt6E6ibAicB8HVEXcezcs1lkOEYVhvE4rial4oicWYDHuDLgzFHufL8hhrmxRYyytng0JLPFgPc1vaSw/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，我是刘聪NLP。之前很多研究都是生成、发现、过滤高质量的通用指令微调数据，而大家对代码任务的越发关注，如何构建更好的代码指令调整数据也越发重要。下面给大家带来一篇筛选高质量代码指令微调数据的文</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247490038&amp;idx=1&amp;sn=6dd971bd19d60ca5c4f0330ffb851b1f&amp;chksm=ce1c37ab3f92c70d901c611181d4c9ea146a88d4367a99e407cc8b204d1b7035e784a32cf790&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 09 Sep 2024 16:00:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[浅谈大模型角色扮演：从当红炸子鸡到无人问津]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5lt6E6ibAicB8HVEXcezcs1lkOEYVhvE4rial4oicWYDHuDLgzFHufL8hhrmxRYyytng0JLPFgPc1vaSw/640?wxtype=jpeg&amp;wxfrom=0"/><p>带来一篇知乎好友@ybq 对大模型作角色扮演的浅谈，role play方向，从当红炸子鸡到鲜有人问津，感觉还是挺让人唏嘘的。知乎：https://zhuanlan.zhihu.com/p/718761</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247490017&amp;idx=1&amp;sn=7e873b323336eb3c316d4d4f619a5375&amp;chksm=ce9055f359441df665a61a8f8bd7aa39a08b962416aba88b5ef2f7816d86375393b64066c0a0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 09 Sep 2024 06:41:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[将端侧大模型进行到底-MiniCPM3-4B开源]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5m30p3KLGzlrXpdqIsRFCWmIoJ23xovWgYDp6eBkBibHcnhvRsPpkO7V9OSICPwLiapUSKzHUeMTD4g/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，我是刘聪NLP。面壁一直都在做端侧大模型，之前有文本系列MiniCPM-2B模型，还有多模态系列的MiniCPM-V系列模型，今天又开源了MiniCPM3-4B模型，真是端侧一路走到低。这次M</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247490005&amp;idx=1&amp;sn=a1685c8f18b571c48aee08735e30c1bc&amp;chksm=ce40924a77c3534eb04b0ffc2725d71e77bba8904595bac4b5ddecc2e0e6f38079c0d60fa4d9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 05 Sep 2024 14:57:07 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen2-VL：Qwen系列已在开源的路上一骑绝尘]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5mISTgTBRotAFockGXIkpnyIJib3vPczAVQmVE6yBHYCzDJOvnCe9gJWfQVzwZ0XBcRAib8gVejKpEw/640?wxtype=jpeg&amp;wxfrom=0"/><p>昨天睡太早了，起来之后，就被Qwen2-VL开源消息刷屏了。良心Qwen，开源了Qwen2-VL的2B和7B，72B需要API调用暂未开源。该说不说Qwen系列模型真的是在开源路上一骑绝尘，全全全！v</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247489996&amp;idx=1&amp;sn=9a3927a5ecd5ebe38ebd551eef79109e&amp;chksm=ce86e48abfcb027311bbeeedc9521c84f1fffc759f859a5e36a039add4105191173a1e8d1520&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 30 Aug 2024 03:11:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型微调终极指南]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5mmCzeP1tHbZ7SiaBE3AAZd7xXjhtU4LTSUmbwTyHsUAgibibMcBV46oAlWXSiaBP2uj2DA2RuJy5kffw/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，我是刘聪NLP。今天给大家带来一篇大模型微调相关的最新综述，主要大模型微调归纳为7个阶段分别为数据准备、模型初始化、训练环境配置、模型微调、模型评估与验证、模型部署以及模型监控与维护。Pape</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247489967&amp;idx=1&amp;sn=e54c0400a567d031eada986aaf127e1a&amp;chksm=cee257cce2757bf892e57f65e9285853f6f3626750fdb72ee1802ec4e40156df8bdccf55dec6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 28 Aug 2024 15:23:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[这段时间搞大模型的血和泪]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5m7xaFAUayiclBI8EoHkTF0qotaA06wic167BrLHtuYG63cFgYefd4qu9czkq1Ric56LwtRUQDKZKS8g/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家分享一篇好友知乎@赵俊博 Jake在这段时间搞大模型的心路历程。作者：@赵俊博 Jake知乎：https://zhuanlan.zhihu.com/p/716420396李沐大神最近分享了很</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247489950&amp;idx=1&amp;sn=df83a46174ff3d56d8187ca0921c2053&amp;chksm=ce65734a7a2224999adfab926c440cfa483929bdbb409a3d1ab945dd69801f33679309b4396c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 26 Aug 2024 03:11:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[综述 | 大模型的可控文本生成]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5mXg3ODDfFPWia6Dj5yojibdic16JEzicia5aONVLB19nkSm4pLvm9YckJXmStKs6TzUJm54iceibNaLg1QA/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，我是刘聪NLP。大模型已经展现出了较强的文本生成能力，但随着使用场景变得越加复杂和严格，除了避免生成误导或不当言论内容外，往往还希望可以满足用户的特殊需求。而可控文本生成就是为了在保持文本生成</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247489944&amp;idx=1&amp;sn=fa8ad226f7535ca49a1903661576d923&amp;chksm=cebac401360a8d2e36d220a7413003cb14b9150882be957dc71067777a20dd8a8742c6a47a5b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 23 Aug 2024 15:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型是泡沫吗？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5lxJECCOzWcqM0iabdRw2HZSwRqh3XHrCQMe7YsU3tN7R7g3WwRaI0PbaCl48bPSVqT6rJE2PlSLwg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来知乎好友@ybq（欢迎来关注），一篇关于从事大模型工作的感悟文章。不谈技术，只聊聊这两年从事 llm 工作的一些感悟。知乎：https://zhuanlan.zhihu.com/p/71</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247489927&amp;idx=1&amp;sn=e75b7b095a6b8efc17b73e17ac642226&amp;chksm=cea9d8da5a25392368786d1e5f3de28639f7ef16cf7740d2b6bfe5f0692b50b9c2658ccfd7df&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 21 Aug 2024 02:40:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型 VS 小模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5k1msNBGEHgM7s4ibSp3iaUG5lxQLTiclRjibFs3NSZTq6wicGAj8ZBfMYiaMc3IU7mBVQpYzjJLUDt2Aibg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来知乎好友@ybq一篇关于大模型和小模型讨论的文章。首先，我们思考一个问题，为什么 qwen2 基本上是当下最受欢迎的开源模型？说实话，相比于 deepseek、llama、minicpm</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247489921&amp;idx=1&amp;sn=f7f901cf24337836a7222c5f1ccdee1c&amp;chksm=ce53f21d6e0bab927fce3bba5197902720005e18e19b7dca6d8f2f97426c62fef748239f415f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 17 Aug 2024 04:08:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[探讨大模型预训练与微调之间的相互作用]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5k1msNBGEHgM7s4ibSp3iaUG5lxQLTiclRjibFs3NSZTq6wicGAj8ZBfMYiaMc3IU7mBVQpYzjJLUDt2Aibg/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，我是刘聪NLP。今天给大家带来一篇探讨大模型预训练与微调之间关系的文章，主要通过微调预训练阶段各个checkpoint，来发现预训练本身或对下游微调有哪些影响。大模型在预训练过程中的性能如何变</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247489916&amp;idx=1&amp;sn=82cf019e1ee6f9f828ae5a8b0de5b201&amp;chksm=ce77f8cff0bcc803c73f1171fd98cd90cbaef062b85f31ede5410a0daaeb1603ffba67416d38&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 16 Aug 2024 08:22:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型时代，什么样的算法工程师更吃香？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5mK4k7wfPQJPtaXoLPXO8tMTtXGicYDf0UUYUwPy1fmTJPLMbYZp1n1ZibDQ5HZLMgl4vyGTYt3Hkvg/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，我是刘聪NLP。毫无疑问，全栈型的算法工程师将更为抢手，如果你精通大模型从训练到应用的整个流程，你走到哪里都不怕。但往往人的精力有限，如果从数据、预训练、微调、对齐、推理、应用几个方面来看的话</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247489901&amp;idx=1&amp;sn=3f1dbfa6eafcfa5cccd797ec5eb7ab11&amp;chksm=ce732922f31a231942a4ebd7c8429e8698e7b0dc0cfda5758f7973e4b65dca72a5662da12390&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 15 Aug 2024 08:01:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[没有等来Qwen2.5，但等来了Qwen2-Math]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5nUZP2Z6sNhMm0353ajsgQOrPdfT1Z3iaeicEdiccTSexwJqOjxsmvP8vQZcmrLiaGudE2zOVaJ39oxOA/640?wxtype=jpeg&amp;wxfrom=0"/><p>Qwen2又出新作Math大模型，你值得拥有。我没有等来Qwen2.5，但等来了Qwen2-Math，在数学推理能力上大幅度提高，先来一张图阵阵场子，72B模型超过GPT4-o、Claude-3.5-</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247489897&amp;idx=1&amp;sn=a83e003d2b50b5279ed0dbd76bb10a1e&amp;chksm=cedfc729dbae6b95ba42ff92d1971ee11238a9e882caa9803c046d84ce5db7f1410a3b0f3087&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 08 Aug 2024 15:01:25 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[浅谈-领域模型训练]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5mfAIrW8ue81Nswicmj2An0IlFbtbLWvaQQ12Q1ic5iboQUIQyIxcZW6ib2WFiczAZDichjhFY7ic1qkeM0g/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来知乎好友@ybq一篇关于如何进行领域模型训练的文章，主要内容是对 post-pretrain 阶段进行分析，后续的 Alignment 阶段就先不提了，注意好老生常谈的“数据质量”和“数</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247489889&amp;idx=1&amp;sn=7f01a9a243ce9cb9f3391f709bed18b6&amp;chksm=cec4e5780703ff70abc0bc5dca9ff33439f12746e755128ce1913288f8a941fc2bf69de9f442&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 07 Aug 2024 04:12:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型微调到底有没有技术含量？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5mfAIrW8ue81Nswicmj2An0IlFbtbLWvaQQ12Q1ic5iboQUIQyIxcZW6ib2WFiczAZDichjhFY7ic1qkeM0g/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来知乎好友@ybq的一篇回答-大模型微调到底有没有技术含量，或者说技术含量到底有多大？知乎：https://www.zhihu.com/question/599396505/answer/</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247489876&amp;idx=1&amp;sn=5320c0693806f45f3b513c0ec1799a57&amp;chksm=ce218e7176328d546add17741b1dd568bf774894967d49791961368098dd28143d353faadb76&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 06 Aug 2024 06:14:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[MOE系列模型-浅谈]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5k7NozCj08zlh4MMk5Gb2W8nImwFgmvHKoUCncsVP6v08loI6scqcos4dVGqhFd6CAYTD0cpTQZcQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>在本文中，梳理了近期 （24年7月前）部分 MOE 大模型的关键信息，包括它们的主要特点、亮点以及相关资源链接。涉及模型  Mixtral 8x7B，Mixtral 8x22B，DeepSeek-Mo</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247489870&amp;idx=1&amp;sn=69b4e25ae5f4d7c6ab34b99f5b8e04c3&amp;chksm=ce93eb7d45c076fdfb1fa4c29b1a1c2d9fcd1b4c0a3aeaf2772d7b83da32bc7328aa4b2d9489&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 05 Aug 2024 08:16:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型预训练开源数据集-整理]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5kSNysgicOdjmicakickUMDqMuiaUozAsxdIgC9GrMHH2rcbSOnouq3mFrve5aJmHAWvdteMBHKUnpbIw/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，今天给大家分享一份大模型预训练开源数据集集合，具体如下：【001】Skywork/SkyPile-150B【002】togethercomputer/RedPajama-Data-1T【003</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247489791&amp;idx=1&amp;sn=fda900afd4ce9430ee82196d914eb295&amp;chksm=ceed0c4bbff7cb5a7ef01af01eaeeb025bbcf70c1b5bebb95dd613e52e7b339ad7c4f2c6477d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 01 Aug 2024 07:15:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一大堆Llama3.1-Chinese正在袭来]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5kuOUbz3AyNbp5qse4qsk9dFcK5tXRLkfWkRY8WjxSQiadlDzf5yfTxBiauzF6EiaXsDklvAItibicKFJw/640?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面大家好，我是刘聪NLP。Llama3.1模型已经开源，在这短短几天之内，也是出现了一些Llama3.1汉化的repo，开源社区也是相当的卷。主要是Llama3.1没有关注中文，虽然是多语言，但</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247489783&amp;idx=1&amp;sn=16c6898537e3a27f6d0883eedfb14f29&amp;chksm=ce4fcc4d416efe428e02a721b3ddcfb79f966501abd156e649b14874daf7517695aa814e2dd8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 27 Jul 2024 12:31:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
