<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLPer]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLPer公众号]]></description>
    

    <language>zh-cn</language>
    




    <item>
      <title><![CDATA[ICLR2024，微软 | 提出LLM剪枝方法-SliceGPT，参数减少25%，保持99%的性能！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYkjmzVH0kibNw1TsOlWWjwY79TJpYYrYDSa1ZG1chibjES2Vymroe6WesHrAF5rOJ8DCqrpDBF05Dw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达删除权重矩阵的一些行和列，让 LLAMA-2 70B 的参数量减少 25%，模型还能保持 99% 的零样本任务性能，同时计算效率大大提升。这就</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247497689&amp;idx=1&amp;sn=911de8625d98388718d1a627ea2e38e9&amp;chksm=fb8621a586f22e16b06a17ca0cfd7de9ad523f030aad071f1a36ea8fd3e6b72ad61e0f2adc3a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 30 Jan 2024 13:04:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[今天！Meta | 发布最大代码生成模型：Code Llama 70B，性能最好]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYkjmzVH0kibNw1TsOlWWjwY7C7dtoGIibU3OXa1orhOpS0IG12mkabY52jzVHDm7k9APWwicmNqicaLw/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达今天，Meta 正式发布 Code Llama 70B，这是 Code Llama 系列有史以来最大、性能最好的型号。我们正在开源一个全新的改</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247497689&amp;idx=2&amp;sn=222047e5a39c3c3b3665298fa51c0942&amp;chksm=fb0ae469916bc310466505d1e648b10b1d2549e3dabd60880d33a5725ca0933e78a8a75cefd5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 30 Jan 2024 13:04:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[分享10篇优秀论文，涉及LLM对齐、LLM评估、LLM隐私、RAG增强等热门话题！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaaGlVYnxYSMjYOMchzJtKDZ0MtW40KGvp9K8wNooTuwc7CdQ6D258ZibPzyWic5xnuoGAKPicK2UTopA/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言紧跟技术发展趋势，快速了解NLP领域最新动态。今天继续给大家分享10篇最新论文，其中涉及大模型幻觉、大模型对齐、大模型剪枝、大模型隐私、大</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247497639&amp;idx=1&amp;sn=8af98faee3b7d619da2965a69776f975&amp;chksm=fb28c1b6032d9ae204ac61aeda3fe8f194204331d52074ac757d3fb8c19e9b7f4f5998a76d00&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 29 Jan 2024 13:28:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[代码增强LLM！UIUC | 概述将代码数据加入LLM训练数据中的各种好处]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaY8mkQJv1tdXolV13RG6f4DZpajQibuexKVKdk4qOvMJR5n8aiaVzdrJOa2VHvdicic5CqZIBzEmCuI9w/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达大模型时代的语言模型（LLM）不仅在尺寸上变得更大了，而且训练数据也同时包含了自然语言和形式语言（代码）。作为人类和计算机之间的媒介，代码可以</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247497613&amp;idx=1&amp;sn=627115bff66a7af74260a4302872f48b&amp;chksm=fbbebc57be1f4fe611a91ecc1dffac3b68df6934708c3b1ca46b86861932d59755b5daedbaf2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 28 Jan 2024 13:29:02 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[揭秘！OpenAI新模型使用的：嵌入(Embedding)技术]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>‍点击上方“AINLPer“，设为星标更多干货，第一时间送达前几天，OpenAI 来了一波重磅更新，一口气宣布了 5 个新模型，其中就包括两个新的文本嵌入模型。我们知道，嵌入是表示自然语言或代码等内容</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247497613&amp;idx=2&amp;sn=c1fc0d492564df0e4a410c15992d259c&amp;chksm=fb8534019004d5fdca25fc5df6dc197f067400c056c57b2b5912ae4088db6e7c74ee606a8fe0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 28 Jan 2024 13:29:02 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
