<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLPer]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLPer公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_895a8687a10f.jpg</url>
      

      <title>gh_895a8687a10f</title>
      

    </image>
    





















    <item>
      <title><![CDATA[UIUC | 提出“提取-精炼-检索-读取”框架：ERRR，提升RAG系统性能]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaa7AnBGbq9NfSWCDJ5SRxwUDAHbb7joNwM9Rag2WnjGKAia45F6phJjGTzOd1spmmibU2CKZkqVdIxQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言大模型就像一个“历史信息快照”，无法及时更新信息是它的短板。而RAG技术可以将外部知识通过上下文学习引入大模型生成过程中，从而让LLMs生</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247502226&amp;idx=1&amp;sn=caec30cec03595e66ef9875e251bd7fe&amp;chksm=fbc23a28ba0520be3aef6216920d83afd87172afc8eab21aece66a849547e056e7797949a829&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 13 Nov 2024 14:16:02 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[今日爆款！Scaling Laws终结，量化无用，小模型或成未来？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaa7AnBGbq9NfSWCDJ5SRxwUmnmA1GV6NOlAOmZfEiaDvficxrQHcZ40kdlFueCkWFTy8OIF676qykAg/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达  最近几天，AI 社区都在讨论同一篇论文。UCSD 助理教授 Dan Fu 说它指明了大模型量化的方向。CMU 教授 Tim Dettmer</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247502226&amp;idx=2&amp;sn=fdec4f6963a9352f0221c53dd4a524af&amp;chksm=fb992955c946435ae597af5ce28cd2109f4e9d0782daf3f0381a281630d4d139a39b7e7261bd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 13 Nov 2024 14:16:02 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[蚂蚁集团 | 提出多任务大模型微调方法：CoBa，LLM最高性能提升13%！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYvNPuYBia2agwylHN8rcH4fB6oWiaIzKichVT07dzciaCPiaCibOxK3dM604cFzSokYxJRlvsFzoYJRCeQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言多任务学习（MTL）旨在让模型经过一个训练过程中，让模型具备处理多种任务的能力。简单来说，MTL能够在不同任务之间共享信息，有效提高模型的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247502180&amp;idx=1&amp;sn=ac3bdc0c77b5747b43c051d41997ca51&amp;chksm=fbfacb604d6e6740d183028f5b426732ed76237101a86bab8f8acb5f4ea534a7fccbf79d3082&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 12 Nov 2024 12:39:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[突发！美43只猴子从实验室逃脱，或携致命病毒，目前只抓回一只！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYvNPuYBia2agwylHN8rcH4fn30ppt8dxsCbk8Xs5JFic3leHT0m42fISwK62RnF6LrXmj2FZ0bAG7A/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达近日，据CCTV国际时讯、海外网报道，当地时间11月6日，美国南卡罗来纳州发生一起实验室用的雌性恒河猴逃脱事件。当地警方呼吁居民，关好自家门窗</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247502180&amp;idx=2&amp;sn=41ff3e9454a7d5806d6a63cc4f79d6ed&amp;chksm=fbc305eb1771b307544857ce82605c229ceebe44859b63f6dbfaf5ac7fa58bab68d49ef6ad44&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 12 Nov 2024 12:39:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NeurIPS 2024即将开启！一文了解NeurIPS国际顶会+历年paper整理分享(含源码)！！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYGwsRIia3dRC3a5ekH5YRDo02NccAAqS5fokXNPMXlgruOl4WzSz6j4jkzIDWp7leBRLmbFnADUdA/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言近日，国际学术会议NeurIPS 2024论文接收结果公布，各大研究机构、大厂也都开始毫不吝啬的晒出了自己的研究成果（年终奖就靠它了，嘘~</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247501911&amp;idx=1&amp;sn=31bb4fa24807b63376dc853de81e9130&amp;chksm=fba565c0b9633b15fc3bd8b75ea89709c2d416df6629ad450626de95449998820be4501aad60&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 11 Nov 2024 13:31:16 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[干货！来自一位资深大模型算法工程师的感悟——》RAG最佳实践]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYGwsRIia3dRC3a5ekH5YRDotJKybvmZicicUuJ7rJmGTibnK2gicsjuya0HXlGNmpCkibLsmGjzVZfdhiaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达‍|作者授权,出自-》AI纵横谈‍最近看到复旦大学的一篇探索RAG最佳实践的文章，很有意义。于是结合这篇论文和我常被人问到的问题，聊聊RAG最</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247501911&amp;idx=2&amp;sn=4688fd0cecd7a02c1b3f7542ab9b36bf&amp;chksm=fbec63fe33efc6126096ad5edff97ac648ca3f5c48f82203c89f78269cbbc57c9d49a96d3571&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 11 Nov 2024 13:31:16 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM每周速递！大模型最前沿：推理加速、模型微调/对齐、开源LLM、大模型Agent、多模态]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZ4wAuiaFiah1rJhFWH30tZvQ0XI89Ytuaz3excR787CfKx6e3kO4yicGLZCNtDvrmUiaFXcEXzzJt9Lw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言紧跟技术发展趋势，快速了解大模型最新动态。一周的时间又要结束，今天继续总结最近一周的研究动态，本片文章攻击梳理了11篇有关大模型(LLMs</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247501894&amp;idx=1&amp;sn=09fd1cb414b1559c42d7627163ebbb43&amp;chksm=fb46e7ee9651669c2c540abc2724799d9390492122823c1d5234f17fb9330158284b6017082a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 10 Nov 2024 13:32:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[哈工大 |大模型CoT任务推理优化，减少冗余步骤，提高推理效率！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZ4wAuiaFiah1rJhFWH30tZvQG2jSmxvL4G0wuKWxiciatgFGNSaYU4LD3gcpjTYX82Au4Ouk79Oec9Qw/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达一句话总结本研究提出了一个推理边界（RB）框架，系统量化并优化大语言模型（LLMs）在思维链（CoT）任务中的推理能力边界。通过定义推理边界和</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247501894&amp;idx=2&amp;sn=d72ebbce0c94c40775fd1c5aacef7f20&amp;chksm=fb34eebdf11f62e0fc49405dca0736222daeb858ddf213064fb1a58b1a95f4af010070066320&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 10 Nov 2024 13:32:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[爱丁堡 | 混合上下文学习MOICL，动态选择最优提示，LLM准确度更高，计算效率更强]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYXKkjTRUbWGL1qhKXiaO4mPibYwgoxDyptFpCyXibzCHXOjPGIKib1ibcI7fkHPqpibzDLwQPcXN8r1n3g/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言无需对大模型进行微调，上下文学习主通过给大模型（LLM）提供相关示例来实现希望的输出。面对大量的示例，大模型照单全收，随着示例越来越多，就</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247501861&amp;idx=1&amp;sn=bff248482bbf7751b3d42765cae4a8bb&amp;chksm=fbdd566396e1091d97918b87b947d1a2c5a04155955cf9150496f4944f681984ff1b9f14b006&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 07 Nov 2024 14:23:53 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[智谱 | 自我进化学习框架：WebRL：构建最先进的Web智能体]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYXKkjTRUbWGL1qhKXiaO4mPicziccLy1k47Oiaj6Lnyhr1zw9t2sRzS1fUoiaXzEHQLJOTibZEyLkK1eEw/300?wxtype=jpeg&amp;wxfrom=0"/><p>🌐使用自我进化在线课程强化学习框架，服务于 AutoGLM 性能提升大型语言模型（LLMs）不仅在人类语言理解、常识推理和知识获取方面表现出卓越的能力，而且在复杂规划和逻辑推理方面也具有巨大的潜力，这</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247501861&amp;idx=2&amp;sn=ad3738135a7cedc5c7ce88dfc0c89550&amp;chksm=fb71edb134753b488cf290b0860174948ba79312424286e23775e3663224f4bd5ea20711444a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 07 Nov 2024 14:23:53 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
