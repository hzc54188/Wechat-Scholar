<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLPer]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLPer公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_895a8687a10f.jpg</url>
      

      <title>gh_895a8687a10f</title>
      

    </image>
    






    <item>
      <title><![CDATA[从文本RAG到多模态RAG！LMU | 构建多模态RAG系统的最佳配置]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiabt0pse7twIWOBEO1psgic490bPE9kbsy6JVpN3su9fhGY3Gb5NWGU85Z2eZhxib3QFVL5e5A0UUuYQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言老生常谈：检索增强生成（RAG）主要解决的是大模型缺乏领域知识且容易产生幻觉的问题。随着当前多模态模型的发展，它可以同时处理文本和图像，那</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247501545&amp;idx=1&amp;sn=39599fef61bb411c8e5c0e74d94a8085&amp;chksm=fbb1b081e9ac669a09943a39149d8903b30884f2b05243ba112aedf81f603495250de9dcffde&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 30 Oct 2024 14:09:34 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[从此不再后训练！NeurIPS2024 &amp; CMU | 提出推理时对齐方法，解码效率最高提升32倍]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiabtHz8Az1n0mvoDGcE64D1NhdM4ZZc4owPzZ45RLzHudaYCEWYCJ3vyuIbbu6gMicjDJibhEF1uYNng/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言大模型训练主要包括两个部分，分别为Pre-Training 和 Post-Training。当我们拿到开源大模型的时候，通常会与实际场景结</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247501533&amp;idx=1&amp;sn=bf5e3f46172dbe54a63d6ef7721313fa&amp;chksm=fb03b7b0ce3adb2cc2f2bf25bcf9620cbc67b0a5183e5424e0bdb0994064aef1741354852321&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 29 Oct 2024 14:01:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[真爱！男友捐款5亿给博士女友，让她不用申请项目，安心做科研！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiabtHz8Az1n0mvoDGcE64D1N68EHJ73CWGsIyMYB1oCjfzHD5Recic41ibib0IrDPpMrthM3SJUe19xQQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达如果科研界也有“霸道总裁文”，那他的打开方式可能是这样.....杜克大学电子与计算机工程系教授、ACM/IEEE Fellow 陈怡然曾在社交</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247501533&amp;idx=2&amp;sn=aa09b9c8a3c9af334fb53cbaf501c7c7&amp;chksm=fb9c1d6d54885fdd0ac73a4f5e876c58bcd12566641a45dd2dbead4bd086f9f7092d1bd37841&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 29 Oct 2024 14:01:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每周速递！大模型前沿：涉及多模态、推理加速、模型安全、模型记忆等热点研究！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaboVS1Q3O0c3Q1YPjwMg7WCpOyuH9wU89Dric2yPibAmk4fz9U5xNzhicrwePwXicvxoV6NiaAV6YAsiciaQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言紧跟技术发展趋势，快速了解大模型最新动态。终于又有时间更新文章了，今天作者结合最近一周的研究动态，梳理了8篇有关大模型(LLMs)的最新研</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247501513&amp;idx=1&amp;sn=94fdbaf152a83ba05a154a86f6ad83ae&amp;chksm=fbebc1997c30110787eb4de0b8d9a827c0390a12a1e5b8518b9f2356dbce6fbbdc6bc51239c0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 27 Oct 2024 14:15:11 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[我发现了找顶会创新点的最强套路，真的不需要脑子]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZvK8UyFcaXMVWJleBjFObGFw2yCicHXlBgQzdKRvJEqMWsIyrYATIp8Jkiav9OBEEXU21yyaFu6bWg/640?wxtype=jpeg&amp;wxfrom=0"/><p>新手搞科研，最忌讳的就是自己埋头苦干。搞科研，只靠自己是不可能发出高区位论文的！一定要多学习那些顶会大牛“成熟的方法论”和“先进的科研思想”。站在别人的经验之上，才更容易挖掘出极具创新性的那种idea</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247501483&amp;idx=1&amp;sn=502b28400446ce11d78ee7462e379fe8&amp;chksm=fb7fe76c04a497b168e989f62440aeb88f09103143973cbfedd7497f8f237c12ae1d35077ac9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 23 Oct 2024 02:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM是否具备推理能力！？Google | 一篇论文再次掀起AI社区波澜]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZvK8UyFcaXMVWJleBjFObGaWcVNfr8c36sP0ib793qLOXiaLLoOcibxwg8yDuuQSoIiaK15z6R7fEv0Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达关于大模型推理，今年上半年的时候就曾发表过一篇文章：大模型自身无法推理/规划！ASU | 提出LLM-Modulo框架，可充分发挥LLMs潜力</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247501483&amp;idx=2&amp;sn=25af2638c324615506adfe3597da9a33&amp;chksm=fbc0a1ecc87da46c25b3f77f382f5878b78d54b034892bedf8b9de46b29d12d69fc1f3192587&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 23 Oct 2024 02:00:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
