<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLPer]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLPer公众号]]></description>
    

    <language>zh-cn</language>
    








    <item>
      <title><![CDATA[新语言模型出现！Eagle7B：基于线性Transformer，推理成本降低10-100 倍！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达Eagle 7B 可将推理成本降低 10-100 倍。在 AI 赛道中，与动辄上千亿参数的模型相比，最近，小模型开始受到大家的青睐。比如法国 </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247497734&amp;idx=1&amp;sn=a7f21d3b68a2acac0b1d4723ea820cc5&amp;chksm=fb11eca2b516c592f851ec6c03bc52f64abef8ce7e3971c671fd4a8ccf8b167b38cd417ead75&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 01 Feb 2024 13:23:45 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[PyTorch 2.2大更新！集成FlashAttention-2，性能提升2倍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达【导读】新的一年，PyTorch也迎来了重大更新，PyTorch 2.2集成了FlashAttention-2和AOTInductor等新特性</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247497734&amp;idx=2&amp;sn=f9ef1b1e0417065b1cf6809aac1bd919&amp;chksm=fbc2ae35fb76f6b0d39c8a2458078b624e43d9dd7a63d9ae030181a2d1016dc5f76f015251cd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 01 Feb 2024 13:23:45 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[（待会删）全网独一份！GPT+AI大模型资源，请低调使用！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vHQQ7qibkHrtSUZt0k1F6xTyYrs9K89Jvib8BKyuhtPZdJqZeK8rQHzEtlFdAeSpbqPicdEG2Dp6ryJHSjibOOZWHg/640?wxtype=jpeg&amp;wxfrom=0"/><p>“大模型狂热”从未停止国内巨头战队华为、百度、阿里在AIGC的厮杀中从通用大模型渗透到各垂类应用市场就连中国创投资本也独宠AIGC企业百度、科大讯飞市值分别增加27亿和45亿美元这导致AI人才缺口大、</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247497704&amp;idx=1&amp;sn=c7700322ff589bf37665c20cfaf02e4d&amp;chksm=fb5274866c73210bff2d9f1fd9bcab97cf7bba683dcc6068caa4915fc7778edcffe84486cbc3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 31 Jan 2024 13:01:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[整理了 26个多模态大模型（MM-LLM），代表了行业最高水平！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言当前 AI 领域的关注重心正从大型语言模型（LLM）向多模态转移，于是乎，让 LLM 具备多模态能力的多模态大型语言模型（MM-LLM）就</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247497704&amp;idx=2&amp;sn=46cc24e7c94d56e97b2b4a7d0e21730c&amp;chksm=fb8ef809ce096e8ca18e2cf43a14b350d3e27d267180de691c1e50c2d78e0256eb9bd8e516de&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 31 Jan 2024 13:01:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ICLR2024，微软 | 提出LLM剪枝方法-SliceGPT，参数减少25%，保持99%的性能！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYkjmzVH0kibNw1TsOlWWjwY79TJpYYrYDSa1ZG1chibjES2Vymroe6WesHrAF5rOJ8DCqrpDBF05Dw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达删除权重矩阵的一些行和列，让 LLAMA-2 70B 的参数量减少 25%，模型还能保持 99% 的零样本任务性能，同时计算效率大大提升。这就</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247497689&amp;idx=1&amp;sn=911de8625d98388718d1a627ea2e38e9&amp;chksm=fb8621a586f22e16b06a17ca0cfd7de9ad523f030aad071f1a36ea8fd3e6b72ad61e0f2adc3a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 30 Jan 2024 13:04:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[今天！Meta | 发布最大代码生成模型：Code Llama 70B，性能最好]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYkjmzVH0kibNw1TsOlWWjwY7C7dtoGIibU3OXa1orhOpS0IG12mkabY52jzVHDm7k9APWwicmNqicaLw/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达今天，Meta 正式发布 Code Llama 70B，这是 Code Llama 系列有史以来最大、性能最好的型号。我们正在开源一个全新的改</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247497689&amp;idx=2&amp;sn=222047e5a39c3c3b3665298fa51c0942&amp;chksm=fb0ae469916bc310466505d1e648b10b1d2549e3dabd60880d33a5725ca0933e78a8a75cefd5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 30 Jan 2024 13:04:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[分享10篇优秀论文，涉及LLM对齐、LLM评估、LLM隐私、RAG增强等热门话题！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaaGlVYnxYSMjYOMchzJtKDZ0MtW40KGvp9K8wNooTuwc7CdQ6D258ZibPzyWic5xnuoGAKPicK2UTopA/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言紧跟技术发展趋势，快速了解NLP领域最新动态。今天继续给大家分享10篇最新论文，其中涉及大模型幻觉、大模型对齐、大模型剪枝、大模型隐私、大</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247497639&amp;idx=1&amp;sn=8af98faee3b7d619da2965a69776f975&amp;chksm=fb28c1b6032d9ae204ac61aeda3fe8f194204331d52074ac757d3fb8c19e9b7f4f5998a76d00&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 29 Jan 2024 13:28:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[代码增强LLM！UIUC | 概述将代码数据加入LLM训练数据中的各种好处]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaY8mkQJv1tdXolV13RG6f4DZpajQibuexKVKdk4qOvMJR5n8aiaVzdrJOa2VHvdicic5CqZIBzEmCuI9w/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达大模型时代的语言模型（LLM）不仅在尺寸上变得更大了，而且训练数据也同时包含了自然语言和形式语言（代码）。作为人类和计算机之间的媒介，代码可以</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247497613&amp;idx=1&amp;sn=627115bff66a7af74260a4302872f48b&amp;chksm=fbbebc57be1f4fe611a91ecc1dffac3b68df6934708c3b1ca46b86861932d59755b5daedbaf2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 28 Jan 2024 13:29:02 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[揭秘！OpenAI新模型使用的：嵌入(Embedding)技术]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>‍点击上方“AINLPer“，设为星标更多干货，第一时间送达前几天，OpenAI 来了一波重磅更新，一口气宣布了 5 个新模型，其中就包括两个新的文本嵌入模型。我们知道，嵌入是表示自然语言或代码等内容</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247497613&amp;idx=2&amp;sn=c1fc0d492564df0e4a410c15992d259c&amp;chksm=fb8534019004d5fdca25fc5df6dc197f067400c056c57b2b5912ae4088db6e7c74ee606a8fe0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 28 Jan 2024 13:29:02 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
