<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLPer]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLPer公众号]]></description>
    

    <language>zh-cn</language>
    










    <item>
      <title><![CDATA[长文梳理！近年来GPT系列模型的发展历史：从GPT-1到GPT-4o（前世、今生）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaal1FMicd8Clsiabt7icLqaS3ybOFQP0WUvJlPKRvydibiacYyzMpeHFfnsDY1sxIjGtGPIew4QBMnRr5w/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言随着ChatGPT的发布，大语言模型的关注度和数量都在不断上升,它引领了人类进入了大模型时代，并且随着一轮一轮的迭代，最新模型已经进化到了</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247501056&amp;idx=1&amp;sn=debc8f8dcf6e9f5ba8875008df049eaa&amp;chksm=fbe50e4c21f99ef99da17f29367e37e45d393623b5f4156254f1bd73f6533afa54dc6f43d3e2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 17 Jun 2024 14:13:56 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[英伟达 | 开源最强通用模型Nemotron-4 340B，性能超越 Llama-3，可商用！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYNLm13Bf8Pb6nnfOtw9Y2HgLO4Y0oibNvpnG5uIJQp25HuhBsLHlQBEmhbFnQN0oib6oN0oCI3gh5g/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达性能超越 Llama-3，主要用于合成数据。英伟达的通用大模型 Nemotron，开源了最新的 3400 亿参数版本。本周五，英伟达宣布推出 </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247501042&amp;idx=1&amp;sn=8a78a1ea50653664e2caab3da1999c01&amp;chksm=fb03e02a10c9786d0eea7f5cb4bda4e81b9adc00eb3b6a7e8818cc81027a50fb509ecefab11f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 16 Jun 2024 15:24:40 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[荒唐！高校教授抄袭50年前的博士论文，拆分竟发了2篇SCI]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYNLm13Bf8Pb6nnfOtw9Y2HhMgsfvDomQL8TD0wz7JcB8VH3SncOVJOrecnRUa4tscBt4hu64Kf6w/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达2024年5月23日，一名来自波兰的数学教授Daria Michalik 的两篇SCI论文被撤稿！随后被调查出，这是他在2016年和2017年</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247501042&amp;idx=2&amp;sn=e532b1a3cd84678bdbfb78d81d9dbd52&amp;chksm=fbe18346f6ab45307a2bb523acacbbd9af811033670e57082b9faa37f354d04643e6839c301c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 16 Jun 2024 15:24:40 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ACL 2024 | 构建超关系知识图谱（KG），增强大模型多跳/Multi-hop QA问答能力！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYDKv0ib3UA5wsoX57mEaCjGWq3txHgZXfQNibCxOVPxHX2cMmhjBOk2mbmOsic3bYV0ZLxQPavQ8qDA/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言对于非结构化文本，大模型 (LLM) 比较擅长回答简单（单跳）问题。然而，随着问题的复杂性增加，LLM 的性能会下降。本文作者认为其主要原</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500989&amp;idx=1&amp;sn=ba0166efef33dee889aad3dd99d08aab&amp;chksm=fb06045d913a5d8d44159d9f5ab07a2c566ca1d2cae27083dd303a72f8827f4b17dbf630edb7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 13 Jun 2024 13:07:53 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[走！读个博，985高校确认：读博士年薪发20万，毕业可留校受聘]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYDKv0ib3UA5wsoX57mEaCjGcAPJANPicW12XlIr8xwodfqDGmZNBAxoOVKtT6OtzHwkt7oUUxHjib0g/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达6月8日，哈尔滨工业大学官微发文确认，哈工大可以年薪20万读博士。近日，《哈工大“未来英才”计划实施办法（试行）》一经出台便受到广泛关注。在哈</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500989&amp;idx=2&amp;sn=c2648437c9b3c43b52cfc7ef7afa348e&amp;chksm=fb66fa8ca1924d8db5dae62a01446f8a12d0220b1c3756cc87f00c080dd2873977939a6eb813&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 13 Jun 2024 13:07:53 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[港大&amp;腾讯 | 提出SELF-TUNING学习框架，让LLM自学获取新知识，表现出色！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiabiaxk4UgPoRbzr5jTIZYlE2CkNLIaT9xvwyQT6sS4J7xnBERhfaaha8D06TFL83IhfKYoOib5K83lA/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言面对快速生成的新知识，大模型存储的预训练知识往往具有滞后性。为了能够让大模型具备最新的知识，当前主要方法是对新的知识文档进行持续预训练，然</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500959&amp;idx=1&amp;sn=01a58212a60747f08c79b0beb3f02758&amp;chksm=fb44d0bedf8c9384d0231023fe9aa6968d0620eda660193b9bdc19c5303f68e6e578cab79b73&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 12 Jun 2024 15:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[复旦 | 推出通用大模型Agent平台：AgentGym，提供一条龙服务！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiabiaxk4UgPoRbzr5jTIZYlE2tFJcAoGsXpFY9wFOibUOwiazY0zXdO6nRR93bGhTA33dicFvmaibyS8GrA/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达AI通用智能体的自我进化能力，并非遥不可及。LLM-based Agent，已经不再需要人类监督者的帮助，开始实现「自我进化」！这个智能体在学</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500959&amp;idx=2&amp;sn=79c617f162b738e9841baf95fab25dfc&amp;chksm=fbce57e9b96460ce8755fd749924c7ea8caa231d3c7ef0a34584960e92cbd65fbf1e047e9a0c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 12 Jun 2024 15:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[分享几个有趣的大模型（LLMs）应用场景，涉及金融分析、物联网、招聘、战术分析等]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZxGicJb0qTwUHpH1PCialM8QcL4KXDQ0GHy1FxzzP31SFZNaOe6GAR8uicM51wZD8ORCmSACsiaxdQIw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言数字化时代，大模型以其卓越的数据处理和智能决策能力，当前应用已经渗透至了各行各业。那么，今天给大家盘点了几个比较有趣的大模型（LLMs）应</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500911&amp;idx=1&amp;sn=38bdd30beb0bece52adc00e34c8d5fef&amp;chksm=fb04fbd14734ccc5f052bfab0ca6bee04160acd7c560795b177649f211ef7d54a61b0551d61a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 10 Jun 2024 13:32:55 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[KAIST-AI | 提出Block Transformer架构，大幅提升推理速度和内存效率，20倍增益！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiabK7khmXuPBUFZ5pAVTZKX9YVsYBbXiccM2o1PNMZXRJhFqhUpxLoFdV75j8qQ3KEc3s8EHjkzbhkw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言Transformer模型虽然在NLP领域取得了巨大成功，但其Self-Attention机制在处理长序列时会导致计算和内存需求急剧增加，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500890&amp;idx=1&amp;sn=d534d9ae39fdf7e3f64f986f59263a2f&amp;chksm=fbfc45bc599c43045ef21fc20603aab346bb579c5f8e703e00235b3651cbd3b23c8b1e631137&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 06 Jun 2024 13:51:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[扎心！刚评上院士，就被曝十余篇论文造假！6篇论文已被撤]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiabK7khmXuPBUFZ5pAVTZKX9OicONGDAjeHzPXAlsVNEnB25vJV5v0JEkrfy0xPRXicsb9xlgq28axnA/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达作为自己国家领域内被引用次数最多的科学家，他被评为澳大利亚双院院士，作为科研大牛，实属荣誉满满。可戏剧是的，刚评上院士不到1年，他就被曝出论文</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500890&amp;idx=2&amp;sn=f590525617f1827225f6e93fe1fddf7e&amp;chksm=fb63dc6c06f7ca334147c4732ce5f06eec467af61438823e142319ded06747a37462729192bb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 06 Jun 2024 13:51:20 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
