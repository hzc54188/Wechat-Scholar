<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLPer]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLPer公众号]]></description>
    

    <language>zh-cn</language>
    









    <item>
      <title><![CDATA[RU | 提出手语生成大模型：SignLLM，支持8种手语生成，且均达到SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaaME8icVDlhiaBqGicqUTVwEE6AudKXZdkhkJWMYPlnvaPHVibHedibzTx0kaMNIsRiaYZlficCZibFBYljiag/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言手语对于听障人士的交流至关重要。然而，手语数据的获取和处理非常复杂，这限制了手语生成模型的发展。为推动手语生成领域的发展，本文作者提出了一</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500349&amp;idx=1&amp;sn=1e67f749642800782afc1a7fb2bd9da6&amp;chksm=fb8e89cb578a16b9be5d0ac672d1af1d6720ed00162e5392a9857035307d91e225844cca65d7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 20 May 2024 14:13:29 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[学的少，忘的少！UC | LoRA最新研究：总结LoRA最佳实践，实现LLMs高效微调！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaaYlxibia8N8dELFJSvrLxzWG1wZhs7ds5EECPVbfyIIIPBib9jJajeQ5fclBodpib6UQrIFGPS2SJJ7A/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言本文深入探讨了当前主流大模型高效微调方法——低秩适应（LoRA）。在代码编程、数学推理两个领域，对比了LoRA和全微调在不同数据规模下的性</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500339&amp;idx=1&amp;sn=1cfee1d3f99b81eb8e4bd16e43b3439d&amp;chksm=fbd6b54990ab7b419889fc6544a1e670cd5033a2e84ec2daf3a9a297c050c87a76c1b53269a7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 19 May 2024 13:02:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Google | 大模型(LLMs)对齐：为什么在线方法总是优于离线方法？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaaYlxibia8N8dELFJSvrLxzWGDUtXUFialq3t503nPFXYVJfk0ibx64tPKHlSmAz4BtdU6geoAKIucq6g/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达在线和离线对齐算法的性能差距根源何在？DeepMind实证剖析出炉在 AI 对齐问题上，在线方法似乎总是优于离线方法，但为什么会这样呢？近日，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500339&amp;idx=2&amp;sn=3d84c8566ab0968b62ecc77421727caa&amp;chksm=fb24209893832cc4757265204477f780c8645f0825cd09a54ea949f53e32e1ade1a919dc623c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 19 May 2024 13:02:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[全面开源，免费商用！腾讯| 发布混元文生图大模型，采用业内首个中文原生DiT架构！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYxfISpCagzVMxtXJWXnUwefXXvbdQ5SCneKL7tBKPsyOKSjEAicTic8NphWMf9JcEtbzicLINsHB6bQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达中文 AI 社区迎来了一个好消息：与 Sora 同架构的开源文生图大模型来了！5 月 14 日，腾讯宣布旗下混元文生图大模型全面升级并全面开源</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500289&amp;idx=1&amp;sn=2d9743c4b134223a0a6871796a561fb6&amp;chksm=fb95026b4099a673a10c39e050e6decfd27d05f8759280a9945b0287db9bab81c49550ff8754&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 15 May 2024 13:13:10 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[博士盲审挂了，不予答辩！985导师发声：遭遇“恶意评审”]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYxfISpCagzVMxtXJWXnUwe4FN0XpDuvo4pl78wb4YbqV9KdM83kicN1krhiaveMfoRUBlWkUwXNSbw/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达“一个充满敌意、极其不负责任、毫无学理依据的恶意评审，却要了断一个优秀青年学者的学术生命。试问，这合理么？”5月12日，武汉大学社会学院教授吕</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500289&amp;idx=2&amp;sn=5f8835938ca1f84477a20a964a61db55&amp;chksm=fb3d164537e783029e4202c75d35121cc814184e531d8af6ff7191f90ce30b73af6df177eeff&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 15 May 2024 13:13:10 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[剑桥 | 提出Hypernetwork，解耦LLMs分词器(Tokenizer)，提高LLMs跨语言处理性能！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYgaibOacyFA2sicvmGiaOreDBMLicwpjmYEMysT9ahEibdVicVhF3z7792z6fYAwmeanvwFIREDbD9aKvg/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言大模型（LLM）主要依赖于分词器（Tokenizer ）将文本转换为Tokens，目前主流开源大模型基本上都是基于英文数据集训练得到的，然</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500253&amp;idx=1&amp;sn=179922f53868a515242085828db6da05&amp;chksm=fb2451bf5a54d601a78ee7642412179db48e6900e7d6324474a2e526bd702f81ba38240e133c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 14 May 2024 14:03:49 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[微软&amp;清华| 提出多头混合专家方法：MH-MoE，增强专家激活率]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYgaibOacyFA2sicvmGiaOreDB4V2Q7WI3dOB0Zk3MbdeCUwLGHgbcQKlZUYGOCyZia2a4yTaElKGDtbw/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达MH-MoE 能优化几乎所有专家，实现起来非常简单。混合专家（MoE）是个好方法，支持着现在一些非常优秀的大模型，比如谷歌家的 Gemini </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500253&amp;idx=2&amp;sn=a4ef3b6f4da6420aaf1d549c5fa205d2&amp;chksm=fb899f2d95611d5da701ed5b2acb454783e739ee627ff9ca17f45764fc649bba5b5380ea1b84&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 14 May 2024 14:03:49 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[数据污染迫在眉睫！GSM8k测试基准 将不再可靠，Mistral、Phi等系列模型出现过拟合！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZcvxYgdTESt28WJsyXtGN0JHA4wog9ZhDickmUkzt5aLeRqDoiceic6H1Mvahmh7bG2DhR1GuywFMwQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言大模型数学推理评测基本上都绕不开GSM8k测试基准，当前很多大模型在该数据集上都展现出较强的性能。然而，本文作者怀疑此类模型在训练过程种可</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500198&amp;idx=1&amp;sn=aab143611fb7b9188f3c9265977855f7&amp;chksm=fbebf7b33eacf243192f31a637df2112759c31b004d353f69f6412c50e59889b524ebf4f1acd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 13 May 2024 13:52:13 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[斯坦福 | 开源全新AI加速框架：百行代码，让H100提速30%！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZcvxYgdTESt28WJsyXtGN0hlgqIsern63kkL7mV7Ihp49cUenVpBvIqVu6CrAlZBq4mZ1hqLlmVQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达提高 GPU 利用率，就是这么简单。AI 的快速发展，伴随而来的是大计算量。这就自然而然的引出了一个问题：如何减少 AI 对计算的需求，并提高</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500198&amp;idx=2&amp;sn=0086268c6f0dca4aebd0fbbed6668ecb&amp;chksm=fb416df86da36c944e8a5a253f35131bb8dde3153f8433c5cac2592935c6cc316b1c51911a09&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 13 May 2024 13:52:13 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
