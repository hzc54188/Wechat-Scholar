<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLPer]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLPer公众号]]></description>
    

    <language>zh-cn</language>
    














    <item>
      <title><![CDATA[新能源时代！看大模型（LLMs）如何助力汽车自动驾驶！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZsj2iaxrKls7B45UdtsiaB399R1OPplqcdTNsVFtQ15Fxleoo2rlJn4w8f4bHRhqDYq7bF0s0qkUxg/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言本文主要介绍大模型(LLMs)如何助力汽车自动驾驶，简单来说，作者首先带大家了解大模型的工作模式，然后介绍了自动驾驶大模型的3大应用场景，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247499358&amp;idx=1&amp;sn=bfb9a0f38d6dae3b88014c8d33322da7&amp;chksm=fb282ce04512a0af1e407b93ffc09345e150eace9955cfa42992e984f0cf247710dd0af5c122&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 09 Apr 2024 14:47:27 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[斯坦福 | 提出社交训练框架: APAM，从此不再社恐！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZsj2iaxrKls7B45UdtsiaB39GP3jr19a4TRdlDDVc2mlFZHzVKOnYTF7ukLYtB8Mt28lzral2ibZGOQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达在社交活动中，大语言模型既可以是你的合作伙伴（partner），也可以成为你的导师（mentor）。在人类的社交活动中，为了更有效地在工作和生</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247499358&amp;idx=2&amp;sn=91358ad6deaef9dcee5803f19437b1d6&amp;chksm=fbce5d0424023978cebbbe5c6cbeb11b7b2ea8f357cef48a37d46ea6cbf9afd22469987279cb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 09 Apr 2024 14:47:27 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[Google | 提出深度混合Transformer，实现计算资源动态分配，比最优基线快66%]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiabxwUdwYCicicyjc5ljTfVhkerSUt8G7rI4piauROD7quGJwCOggF9wc9XljialzHqmZh2TChKzL1dHxA/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言本研究展示了一种新型Transformer的语言模型：Mixture-of-Depths Transformer，该模型能够动态地分配计算</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247499263&amp;idx=1&amp;sn=57d1afe9d4480e9d5afd3e8d31f36994&amp;chksm=fbab87bacc1aeddc0829d3550f66a069169f27d2a561813304e7eaf7f5ac21ae38d15ec0f131&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 06 Apr 2024 13:41:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[澳门大学 | 提出神经元级高效微调方法：NeFT，秒杀LoRA，性能超全参微调（FPFT）！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaa92pMKrBxxxpVH1MgibwEbQWShrHclNl50EXd4cRvqFqrI8kbuAu2ibSSPD7SewhKJW7WLM9NAVZOw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言大模型由无数的神经元组成，不同的神经元有不同的功能，然而研究发现，并非不是所有的神经元在不同数据集上都是活跃的，而且神经元的稀疏性与特定任</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247499247&amp;idx=1&amp;sn=2fcb580949f7f462f4f6b5f193d009c1&amp;chksm=fba4ca8c8f865f98a617e2114552a7fc54ac1233e21bc9e6641a7df95b24aa235c762ab392e3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 03 Apr 2024 13:15:48 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一个专注于NLP、大模型/AIGC、学术前沿的知识社区！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYRMYt3t752ANTOmiaS3MejTzfaxGbpTe7hypEX4EScYOGSL032MhIcbDABe9OLxG5zHLmJ2WAKTCw/300?wxtype=jpeg&amp;wxfrom=0"/><p>AINLPer的星球这是ShuYini花费110多天创建的自然语言处理AI知识星球！现已有244个主题，10个专栏，涉及每日论文分享、大模型整理、热门综述、学术会议、模型实操等。AINLPer星球，旨</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247499247&amp;idx=2&amp;sn=802da47398949d4e21c0aaef6fe39dec&amp;chksm=fb0b8de30323a1c738b9bb9e1d7da827b666834aae07d8adad19c9c9e0f72258a090018e2040&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 03 Apr 2024 13:15:48 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[小红书2025届实习生招募火热进行中！（附：专属内推码）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYb0KJCia6zicGrviakuOIMOPosdeOqa5QRtOLZEiawcic7vcCpia7DCZvAgbhGksSfrQKWKr0y3xMjOCpA/640?wxtype=jpeg&amp;wxfrom=0"/><p>🚀 【小红书25届实习生招聘正式启动！】🌈 25届的国内外毕业生可千万别错过！！超多技术岗❗️海量转正机会❗️ 超多专薯福利❗️ 还在犹豫什么～～专属内推码：89C7XHN87VR6（用内推码可优先筛</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247499227&amp;idx=1&amp;sn=ec06bb527f2c92c7152449c3482614ee&amp;chksm=fbb67d0a68352b2955818b44a1bc4fc99eac6d87c20764f20fb313acf97eba0a5450c049d084&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 02 Apr 2024 13:28:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[上海AI Lab &amp; 西交 | 统一符号的开源基座大模型：Symbol-LLM]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYb0KJCia6zicGrviakuOIMOPok9U1zHcZAicHLY9cTwwianPhr5VV7p53t65Fic5326XunOd8uGdK58qFQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言当前，大模型在自然语言处理、自然语言生成方面表现相当出色，但当面对超越自然语言边界的世界知识（例如化学分子式）时则会存在局限性。可能会人有</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247499227&amp;idx=2&amp;sn=1d6cb6cdd99a63b283ad11382d361dac&amp;chksm=fb4662a9f563898821745d62c788ab4de06fb8466acae70f56f64b681f9b4a5231ba61c0378c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 02 Apr 2024 13:28:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[“抄袭”原来才是最快的写论文方法？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaaOAH9fGSwnK6ibnrYZpzzeyoawSb7WXCXHwvGT0uibbibcossH02qITQSXbicBiaPw2aibpsYktUU7Vo5g/640?wxtype=jpeg&amp;wxfrom=0"/><p>有些研究生，即使告诉他方法，也发不了顶会顶刊！因为能发顶会或者高区位会议的文章，idea必须有创新性。而一个科研新人几乎不具备独立提炼idea的能力。很多发了十几篇A会的科研大牛都在使用“简化、结合、</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247499146&amp;idx=1&amp;sn=eb438fdbf9e2c5c856da02a0dec28948&amp;chksm=fb6216b796ef87db6d31223a9358e80977c7c808f2a76b7ad9051e3d805612cc6b2ca16eba0a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Apr 2024 10:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[成立了！AINLPer星球 | 一个专注于NLP、大模型/AIGC、学术前沿的知识社区！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYRMYt3t752ANTOmiaS3MejTzfaxGbpTe7hypEX4EScYOGSL032MhIcbDABe9OLxG5zHLmJ2WAKTCw/640?wxtype=jpeg&amp;wxfrom=0"/><p>AINLPer的星球这是ShuYini花费100多天创建的自然语言处理AI知识星球！现已有244个主题，10个专栏，涉及每日论文分享、大模型整理、热门综述、学术会议、模型实操等。AINLPer星球，旨</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247499137&amp;idx=1&amp;sn=9f3434b50b45c9120662643d82bda90f&amp;chksm=fbaeb7cdf8ddd9550ce60ae9d3bba9563e70c94f8dba0bea7df1e7b2e2a2ae89789f2490d385&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 31 Mar 2024 13:54:59 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024年大模型的发力点：大模型Agent，分享6篇最新LLM Agent研究成果]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYrC5KyWTiaqbmjeXXjrMWWlEpWC2EDvqzDLOcOCaFbenuhXeGfXGadJH4rqeNjQnvmfnpqVh9tNiaQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言随着对大模型的深入研究，人们逐步开始回溯大语言模型的能力。最近，Google的一篇文章重新审视了大模型的能力，指出大模型规划并不能模拟人类</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247499126&amp;idx=1&amp;sn=64d82a74ad9fa5b62abb946200a5749a&amp;chksm=fbcba51937513c4b97390637cb31bace667b0fe924e5fb66cb767273fb468439609885491873&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Mar 2024 14:55:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[AI21 | 发布Mamba混合架构：Jamba，三倍Transformer吞吐量！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYrC5KyWTiaqbmjeXXjrMWWlibicWK899Fajz6eib3sNiaVE2D2gQpKaoicUQVwkhiaaiaia6k0WvCYBQ2vzBw/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达Mamba 时代来了？自 2017 年开创性研究论文《Attention is All You Need》问世以来，transformer 架</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247499126&amp;idx=2&amp;sn=952a08d848dd24521f8bbd9f670e199d&amp;chksm=fb6a98ab16f2e7522ccaf479382fc3e53373027d942f2afc54280dbc676b426bb9181e145791&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Mar 2024 14:55:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[浙大 &amp; 西湖 | 提出Cobra多模态大模型，整合Mamba，计算效率大幅提升！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZhhILG8yF1r9kL5MC2GjnSePLCsExIM45IUt87kcv8h9sH73Pwc6GF6qgE7U4dg7LCnshy4BH5gw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言近年来，多模态大型语言模型（MLLM）在多个领域上取得了成功，但现有MLLM主要是基于Transformer训练得到，计算效率较低。为此，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247498686&amp;idx=1&amp;sn=b5e619b441ce12637af1864cb1079fb6&amp;chksm=fb71df0789a1ffbf8bda1ef3e48fcb3da4bb8d1798bf32222bd67615df277c46fc1293bea595&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 26 Mar 2024 13:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[北航&amp;北大 | 提出统一微调框架，整合前沿微调方法，可支持100多种LLMs的微调！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZ7tsrf294iaKooK4eZERXqXJDooFBv2tBoVH4Fj43MMNNVYxxaH1BPElOwgLkJODe6OFicswaQOYAA/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言当前开源社区中有许多的大模型，为了能够将其适配至不同应用场景，基本上都需要精心的调整模型参数。为了能够实现对大模型的高效微调，本文作者提出</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247498675&amp;idx=1&amp;sn=e17752e35e688b251d1dedf410b12cdd&amp;chksm=fba82235d3100fb4801524c98616c8e35407c67c30d9778943b2dfdf3c1ca9fe866bf1d0f47f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 25 Mar 2024 13:12:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[剑桥 | 发布多模态检索器，赋能多模态大模型RAG应用]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZ7tsrf294iaKooK4eZERXqXC6MjC9yiaUCXFfmkeOgMficlowryQu002ricHwn3axREargX1BNHC8lTg/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达PreFLMR模型是一个通用的预训练多模态知识检索器，可用于搭建多模态RAG应用。模型基于发表于 NeurIPS 2023 的 Fine-gr</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247498675&amp;idx=2&amp;sn=e8ec73688f53ad74fdbcd7dc98c52ebe&amp;chksm=fb0655ef010c11893d0be4f9f7fa7a3bc1400a1c7395dd571c8649d2d3e45dc8ad6334e76c28&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 25 Mar 2024 13:12:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[UC伯克利 | 提出索增强微调(RAFT)，只需少量微调，就能大幅提升模型领域QA能力]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZSdFR4xxu2k3eicaVpYE3ribpZGAqRua1sKGyoW3d3grhdrPfDDPribsFuWRe1xcWcZPiaCvZLxvibiaaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言在整合大语言模型到应用程序时，需要添加新信息，比如专业知识或私有数据。为了有效地让模型掌握这些新知识，本文作者提出了一种名为「检索增强微调</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247498634&amp;idx=1&amp;sn=537a84d810547c19c26bbf20c9973c32&amp;chksm=fbc5c70660037e53f6de8793a421f12c3365cdbe878a94828cb7b9f72eca41b8268a00ca9185&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 22 Mar 2024 13:04:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
