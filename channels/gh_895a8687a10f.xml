<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLPer]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLPer公众号]]></description>
    

    <language>zh-cn</language>
    








    <item>
      <title><![CDATA[“抄袭”原来才是最快的写论文方法？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaaOAH9fGSwnK6ibnrYZpzzeyoawSb7WXCXHwvGT0uibbibcossH02qITQSXbicBiaPw2aibpsYktUU7Vo5g/640?wxtype=jpeg&amp;wxfrom=0"/><p>有些研究生，即使告诉他方法，也发不了顶会顶刊！因为能发顶会或者高区位会议的文章，idea必须有创新性。而一个科研新人几乎不具备独立提炼idea的能力。很多发了十几篇A会的科研大牛都在使用“简化、结合、</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247499146&amp;idx=1&amp;sn=eb438fdbf9e2c5c856da02a0dec28948&amp;chksm=fb6216b796ef87db6d31223a9358e80977c7c808f2a76b7ad9051e3d805612cc6b2ca16eba0a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 01 Apr 2024 10:00:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[成立了！AINLPer星球 | 一个专注于NLP、大模型/AIGC、学术前沿的知识社区！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYRMYt3t752ANTOmiaS3MejTzfaxGbpTe7hypEX4EScYOGSL032MhIcbDABe9OLxG5zHLmJ2WAKTCw/640?wxtype=jpeg&amp;wxfrom=0"/><p>AINLPer的星球这是ShuYini花费100多天创建的自然语言处理AI知识星球！现已有244个主题，10个专栏，涉及每日论文分享、大模型整理、热门综述、学术会议、模型实操等。AINLPer星球，旨</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247499137&amp;idx=1&amp;sn=9f3434b50b45c9120662643d82bda90f&amp;chksm=fbaeb7cdf8ddd9550ce60ae9d3bba9563e70c94f8dba0bea7df1e7b2e2a2ae89789f2490d385&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 31 Mar 2024 13:54:59 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024年大模型的发力点：大模型Agent，分享6篇最新LLM Agent研究成果]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYrC5KyWTiaqbmjeXXjrMWWlEpWC2EDvqzDLOcOCaFbenuhXeGfXGadJH4rqeNjQnvmfnpqVh9tNiaQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言随着对大模型的深入研究，人们逐步开始回溯大语言模型的能力。最近，Google的一篇文章重新审视了大模型的能力，指出大模型规划并不能模拟人类</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247499126&amp;idx=1&amp;sn=64d82a74ad9fa5b62abb946200a5749a&amp;chksm=fbcba51937513c4b97390637cb31bace667b0fe924e5fb66cb767273fb468439609885491873&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Mar 2024 14:55:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[AI21 | 发布Mamba混合架构：Jamba，三倍Transformer吞吐量！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaYrC5KyWTiaqbmjeXXjrMWWlibicWK899Fajz6eib3sNiaVE2D2gQpKaoicUQVwkhiaaiaia6k0WvCYBQ2vzBw/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达Mamba 时代来了？自 2017 年开创性研究论文《Attention is All You Need》问世以来，transformer 架</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247499126&amp;idx=2&amp;sn=952a08d848dd24521f8bbd9f670e199d&amp;chksm=fb6a98ab16f2e7522ccaf479382fc3e53373027d942f2afc54280dbc676b426bb9181e145791&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Mar 2024 14:55:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[浙大 &amp; 西湖 | 提出Cobra多模态大模型，整合Mamba，计算效率大幅提升！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZhhILG8yF1r9kL5MC2GjnSePLCsExIM45IUt87kcv8h9sH73Pwc6GF6qgE7U4dg7LCnshy4BH5gw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言近年来，多模态大型语言模型（MLLM）在多个领域上取得了成功，但现有MLLM主要是基于Transformer训练得到，计算效率较低。为此，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247498686&amp;idx=1&amp;sn=b5e619b441ce12637af1864cb1079fb6&amp;chksm=fb71df0789a1ffbf8bda1ef3e48fcb3da4bb8d1798bf32222bd67615df277c46fc1293bea595&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 26 Mar 2024 13:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[北航&amp;北大 | 提出统一微调框架，整合前沿微调方法，可支持100多种LLMs的微调！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZ7tsrf294iaKooK4eZERXqXJDooFBv2tBoVH4Fj43MMNNVYxxaH1BPElOwgLkJODe6OFicswaQOYAA/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言当前开源社区中有许多的大模型，为了能够将其适配至不同应用场景，基本上都需要精心的调整模型参数。为了能够实现对大模型的高效微调，本文作者提出</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247498675&amp;idx=1&amp;sn=e17752e35e688b251d1dedf410b12cdd&amp;chksm=fba82235d3100fb4801524c98616c8e35407c67c30d9778943b2dfdf3c1ca9fe866bf1d0f47f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 25 Mar 2024 13:12:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[剑桥 | 发布多模态检索器，赋能多模态大模型RAG应用]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZ7tsrf294iaKooK4eZERXqXC6MjC9yiaUCXFfmkeOgMficlowryQu002ricHwn3axREargX1BNHC8lTg/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达PreFLMR模型是一个通用的预训练多模态知识检索器，可用于搭建多模态RAG应用。模型基于发表于 NeurIPS 2023 的 Fine-gr</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247498675&amp;idx=2&amp;sn=e8ec73688f53ad74fdbcd7dc98c52ebe&amp;chksm=fb0655ef010c11893d0be4f9f7fa7a3bc1400a1c7395dd571c8649d2d3e45dc8ad6334e76c28&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 25 Mar 2024 13:12:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[UC伯克利 | 提出索增强微调(RAFT)，只需少量微调，就能大幅提升模型领域QA能力]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZSdFR4xxu2k3eicaVpYE3ribpZGAqRua1sKGyoW3d3grhdrPfDDPribsFuWRe1xcWcZPiaCvZLxvibiaaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言在整合大语言模型到应用程序时，需要添加新信息，比如专业知识或私有数据。为了有效地让模型掌握这些新知识，本文作者提出了一种名为「检索增强微调</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247498634&amp;idx=1&amp;sn=537a84d810547c19c26bbf20c9973c32&amp;chksm=fbc5c70660037e53f6de8793a421f12c3365cdbe878a94828cb7b9f72eca41b8268a00ca9185&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 22 Mar 2024 13:04:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
