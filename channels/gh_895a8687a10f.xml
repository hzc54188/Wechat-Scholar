<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLPer]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLPer公众号]]></description>
    

    <language>zh-cn</language>
    


















    <item>
      <title><![CDATA[分享几个有趣的大模型（LLMs）应用场景，涉及金融分析、物联网、招聘、战术分析等]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZxGicJb0qTwUHpH1PCialM8QcL4KXDQ0GHy1FxzzP31SFZNaOe6GAR8uicM51wZD8ORCmSACsiaxdQIw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言数字化时代，大模型以其卓越的数据处理和智能决策能力，当前应用已经渗透至了各行各业。那么，今天给大家盘点了几个比较有趣的大模型（LLMs）应</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500911&amp;idx=1&amp;sn=38bdd30beb0bece52adc00e34c8d5fef&amp;chksm=fb04fbd14734ccc5f052bfab0ca6bee04160acd7c560795b177649f211ef7d54a61b0551d61a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 10 Jun 2024 13:32:55 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[KAIST-AI | 提出Block Transformer架构，大幅提升推理速度和内存效率，20倍增益！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiabK7khmXuPBUFZ5pAVTZKX9YVsYBbXiccM2o1PNMZXRJhFqhUpxLoFdV75j8qQ3KEc3s8EHjkzbhkw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言Transformer模型虽然在NLP领域取得了巨大成功，但其Self-Attention机制在处理长序列时会导致计算和内存需求急剧增加，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500890&amp;idx=1&amp;sn=d534d9ae39fdf7e3f64f986f59263a2f&amp;chksm=fbfc45bc599c43045ef21fc20603aab346bb579c5f8e703e00235b3651cbd3b23c8b1e631137&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 06 Jun 2024 13:51:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[扎心！刚评上院士，就被曝十余篇论文造假！6篇论文已被撤]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiabK7khmXuPBUFZ5pAVTZKX9OicONGDAjeHzPXAlsVNEnB25vJV5v0JEkrfy0xPRXicsb9xlgq28axnA/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达作为自己国家领域内被引用次数最多的科学家，他被评为澳大利亚双院院士，作为科研大牛，实属荣誉满满。可戏剧是的，刚评上院士不到1年，他就被曝出论文</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500890&amp;idx=2&amp;sn=f590525617f1827225f6e93fe1fddf7e&amp;chksm=fb63dc6c06f7ca334147c4732ce5f06eec467af61438823e142319ded06747a37462729192bb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 06 Jun 2024 13:51:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[绝绝子！UT| 提出新型大模型微调架构：LOFIT，相比LoRA，学习参数减少200倍！！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaadhozmPhrj93Jyts7fATkcgwCV7gW8OW9t1vdYvIbOGTfj9Yg4VFf9oHZXaLXkstvvW0EVfcicnnw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言大模型可解释性的最新研究表明，通过干预LLM的表示就可以实现需求对齐，并使其快速适应下游任务，例如通过添加偏置向量来增强模型的可信度。为此</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500869&amp;idx=1&amp;sn=682681504a9b6aa7e69b2b242653ebb1&amp;chksm=fb33c5a53cf63b3ed39958ad620a37169bcfac687ff573323ebead2eefd9a072b8e38b0becfa&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 05 Jun 2024 13:31:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[腾讯混元&amp;北大| 发现「浪涌现象」，解决学习率调参难题]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaadhozmPhrj93Jyts7fATkcUnibUSC7S24rQ69iaTiaEP9GtvmxpwfXUiakdaVT84icJVckrFD6XY0IEQQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达过去十年间，基于随机梯度下降（SGD）的深度学习模型在许多领域都取得了极大的成功。与此同时各式各样的 SGD 替代品也如雨后春笋般涌现。在这些</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500869&amp;idx=2&amp;sn=e02009438b6666ac079fb27b510e3a68&amp;chksm=fb8f10fb84a087b2fce80bddb35380ce84b1a4d6d67cb26ddb61c54ccfc9f0cf2461dd9b163e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 05 Jun 2024 13:31:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型对齐到底是与谁的价值对齐？KAIST-AI | 提出大模型多价值对齐方法！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiabSa6gAvm1icsQwjONMkVUzU56jf0UvXJvtl1qo5JPDm7NNqoelXicUqrTicSs1llQUDPO7ZAH1A9ETw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言大模型（LLMs）当前的对齐方法通常会存在这么一个假设：只要与公众整体价值对齐那么就是大模型对齐的最佳选择。然而，人类价值观是多样的，为了</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500795&amp;idx=1&amp;sn=c2fa58146f0cede583814cb25b577b11&amp;chksm=fb2c75d8e7c180d77004f82469c52628e311974ce64ad9f732a8fa3e6c25d2b9ed1c65e89175&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 04 Jun 2024 14:31:54 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Mamba原班人马再出：Mamba2，性能最高可提升8倍！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiabSa6gAvm1icsQwjONMkVUzUcfSdOF4DQ0VIuXYtVLRjlyiaW1HrKy2CFLQugqwnOnwmFVGz81eRXIg/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达自 2017 年被提出以来，Transformer 已经成为 AI 大模型的主流架构，一直稳居语言建模方面 C 位。但随着模型规模的扩展和需要</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500795&amp;idx=2&amp;sn=f4292727f9c3f211133bcde0ce382462&amp;chksm=fbe96b8986290683effee36e2e72c9bca771b6319b633e59bd6bf748000fef04e899f7082044&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 04 Jun 2024 14:31:54 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[又一篇AI顶会！这个idea简直“ 杀疯了 ” ....]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaaicx4xfQn9uGmsRVicd2fnupmjjmk2Hia1azeUgNia1AQ5SiaUYu1wbADbDKQXyfMayWUXGE8lMRmBVGw/640?wxtype=jpeg&amp;wxfrom=0"/><p>一个好的idea就能决定文章是CCF A会的水平还是CCF C会的水平。所以那些科研大佬，A会、B会一年发个六七篇，靠的都是极具创新性的idea。但科研新手靠自己根本挖掘不到，最多是魔改。因此：今天分</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500758&amp;idx=1&amp;sn=e3fd1f685a4bf321ff3a112514de3623&amp;chksm=fbd33946f19abe13b0cfd9b83311f7aac38191e683424a03c3a53f97d4e42022de72b234aaa1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 03 Jun 2024 02:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[开源模型对比：Mixtral、Llama 3、Phi-3、OpenELM等有多好？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaaicx4xfQn9uGmsRVicd2fnupHToCrFYLVUnlKNGb1r5iaVoIibCddWVnqqd0dLAy7YbcqxdkaR4fa1vA/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达深度学习领域知名研究者、Lightning AI 的首席人工智能教育者 Sebastian Raschka 对 AI 大模型有着深刻的洞察，也</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500758&amp;idx=2&amp;sn=bb3f3a568de9ac764087358be47cb42a&amp;chksm=fb6c37c41dbf0b44ef512044a02e825a25668937316a15838494ed4aef3187f57095508f1086&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 03 Jun 2024 02:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024 人工智能最前沿：分享几个大模型(LLMs)的热门研究方向]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaaqTZv8CwoF0OUOQ95C1g2r6sknOxQUzibvFeSUbyF78uG1pBjEKfSV6NU0q6EhMd5BkSDpoB8r2Bg/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言在人工智能领域，大模型的研究正迅速发展，当前涵盖了很多个研究方向，每个方向都带有其独特的研究重点和挑战。下面给大家盘点几个比较热门的研究方</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500631&amp;idx=1&amp;sn=a4e888f59962ba378eae104f9bdbbe72&amp;chksm=fb715443e3ee45b8d3bfb90e7d7e59ea07e8cab2a4d22318782fe0c5cd34c1c64573411fc3ac&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 02 Jun 2024 14:37:48 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多模态LLM！谷歌 | 提出创新架构Zipper：分开训练再「压缩」]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaaqTZv8CwoF0OUOQ95C1g2rcsZiaqNPrKHhHiaGNxFsrCefvfhTWW8FAnoibbZEhxe6898lvNxaSYPuw/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达最近的一系列研究表明，纯解码器生成模型可以通过训练利用下一个 token 预测生成有用的表征，从而成功地生成多种模态（如音频、图像或状态 - </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500631&amp;idx=2&amp;sn=9ae70cda662b27ffdb5842a4a3b608d8&amp;chksm=fb09afe571bfb3c054210cc6a5d8b59143da42e81ce3d8945272f0f593082a7e4ba60006fae0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 02 Jun 2024 14:37:48 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Meta| 提出上下文位置编码：CoPE，解决当前模型「普遍存在的问题」，含GPT-4o！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaaZliaw3Lok3sL6f12bIx4Pvfa15gaUIBX9hiaHsFSwiaBJia0Ka5A2HR6a8v12yvEiaSpickMJWKl3YaRA/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言Attention机制是大模型的核心组件，但该机制并不包含顺序信息，需要进行位置编码。当前位置编码（PE）主要是通过Token计数来定位，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500578&amp;idx=1&amp;sn=8da6d8b4589c925650da952eff554612&amp;chksm=fb52afa9e1188a1e4d85269927d209d302464a6b20532ab848ed34008f3565cbffa9b6645662&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 30 May 2024 14:11:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[恐怖如斯！GSU | 提出VB-LoRA，仅需LoRA参数的0.4%，就超越了LoRA微调效果]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiabbBHNwvUBicc7BztN4TXXpdZ9XTNyv9icY3u8yORW8hoULS9ek6miaaRSMTG54Xib6h2ia1wCHicicoZ6yQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言随着大模型应用的不断推广，面对不同应用场景模型的定制化需求也不断增涨。但参数高效微调 (PEFT) 方法，比如LoRA及其变体会产生大量的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500566&amp;idx=1&amp;sn=9e0c5bedc7b08c578c34a38175e0bbee&amp;chksm=fb2fa0cac28fba140e85fcd9c9ff1f3e4b4b9bce1782e502b65284d9766c25390a803cf84a92&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 29 May 2024 14:30:42 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[哈工大 | 提出共享Attention框架：SAPT，提升LLM持续学习性能]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiabbBHNwvUBicc7BztN4TXXpdDqWh7f5BwLYlxyFOwlTp9UicS9pCCHEoueOtFw38NDz9GqKoNwtm4CQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达在大模型实际部署落地的过程中，如何赋予大模型持续学习的能力是一个至关重要的挑战。这使其能够动态适应新的任务并不断获得新的知识。大模型的持续学习</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500566&amp;idx=2&amp;sn=84f4fe99a0725c02451e10134a485048&amp;chksm=fb6a673997d776c49b2e41dc10929ec19e966143fc62aa24006eff48187d7cb08f3bb5737a48&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 29 May 2024 14:30:42 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[牛叉！UConn | 提出代码生成大模型：AutoCoder，性能超越GPT-4o！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiabicEgP6fgwpsNt7LJAyhTApP5Dp7vN2740wbiafDtOWNjgPm71IEeU8IFicjxUYECiaeQHI2WYJpM1IA/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言大模型训练需要高质量数据集，这对于代码生成任务来说尤其重要。为此本文提出了一种新型大规模代码指令数据集标注方法：AIEV-INSTRUCT</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500491&amp;idx=1&amp;sn=5f6d802b7c702aa4d924c3c608da5090&amp;chksm=fb2db2f579ba3d03ddeb74fc887f6b66f633bdc81b435db82489b2ad8a17cc699c2a4c7ac174&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 28 May 2024 14:17:48 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[自然语言、大模型/AIGC、学术前沿、行业热门应用等最新分享！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiabicEgP6fgwpsNt7LJAyhTApUe9nN0KsM4lCOibDN0ib9pQbYibIC1pg3PUNaib0JB4Tickr5ib7gctn3eicA/300?wxtype=jpeg&amp;wxfrom=0"/><p>AINLPer的星球这是ShuYini花费170多天创建的自然语言处理AI知识星球！现已有600个主题，11个专栏，涉及每日论文分享、大模型整理、热门综述、学术会议、模型实操等。AINLPer星球，旨</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500491&amp;idx=2&amp;sn=b17dc75638fdbfb9a0c3e731d8adf0a2&amp;chksm=fb74387f2b07449bc3bdd0d8fff231f1d9162aaff418ff4240ff6bd2eaeae82c7deb29ca94ac&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 28 May 2024 14:17:48 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[开源金融领域AI Agent平台：FinRobot，利用多源LLMs进行高级金融分析、市场预测]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZLWxE1bTvnlXpRQNSSkQjDsQJj7Mqu0E7yW89h82HRSmwFHWFegnHQiaicBCS18c9RLg94ibRlL7Z9w/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达引言在当今快速发展的金融领域，数据分析和决策制定的重要性日益凸显。随着人工智能技术的不断进步，尤其是大模型（LLMs）的出现，金融专业人士和普</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500473&amp;idx=1&amp;sn=8607323b644462085cf4f4d05d22657d&amp;chksm=fb1dff9aa7429698adf91452d707c3756a8f3fc1288dd7c2c7905711766cc3ebf624a3997b75&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 27 May 2024 13:35:12 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[细数：大模型评估基准的「七宗罪」]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZLWxE1bTvnlXpRQNSSkQjDCUNROS4wa2vQnQzlMYERRqloycAO1rfia7P3WcCJTFbUH6WZibpibLkvw/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击上方“AINLPer“，设为星标更多干货，第一时间送达Jason Wei 是思维链提出者，并和 Yi Tay、Jeff Dean 等人合著了关于大模型涌现能力的论文。目前他正在 OpenAI 进行</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247500473&amp;idx=2&amp;sn=cf42aed8c0d95ee7061e0a65d56f525f&amp;chksm=fb935f9a6c2611dafd5fb984bc830b78c89b2fe0f08385664707b2d39cb8a6d43efa5c0cf990&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 27 May 2024 13:35:12 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
