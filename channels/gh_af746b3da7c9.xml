<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[深度学习自然语言处理]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    

    <language>zh-cn</language>
    

























    <item>
      <title><![CDATA[SCI征稿！这些期刊，录用最快1-2月！香爆了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag8NaOXicl7iaZPic50DD7PflxV03YGwZDXsryC7y879GkdibPPxK5S14sLwKyGHq1Zx7JkF17EqOeOHg/640?wxtype=jpeg&amp;wxfrom=0"/><p>开学了，很多朋友的SCI写作计划已经提上了日程！SCI的征程，不仅是写论文的过程，更是一个期刊投稿与论文发表的过程，在文章完成之前，一定要对SCI期刊和投稿过程有一定的了解。但是，这么多期刊，甚至不同</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526745&amp;idx=1&amp;sn=b7a6c4309445323e4357d19632704017&amp;chksm=eac0edc2995e701bd59c67dd10446d121622fd786d6131c2986aa8c63f086259125103db8a54&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 19 Mar 2024 12:43:33 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[每日论文速递 | Next Token Prediction 陷阱]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag8NaOXicl7iaZPic50DD7PflxUDOv2981jHvd77dhCRTdnZcOpVjfj3gfbnyK8XyMnOvT781EPK238Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：单纯的下一个next-token predictor能否真正地模拟人类智能？我们将这一文献中支离破碎的直观问题具体化。作为出发点，我们认为必须区别对待下一个标</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526745&amp;idx=2&amp;sn=dd32529c85028177c1b73826a08bec7f&amp;chksm=eac83c032748fc9fcdd205c19a50fbd85db4c9b82c1aa7eaa04db4797fc46e5a1a151dfbb93a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 19 Mar 2024 12:43:33 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[每日论文速递 | 使用对比Reward改进RLHF]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag8NaOXicl7iaZPic50DD7PflxUDOv2981jHvd77dhCRTdnZcOpVjfj3gfbnyK8XyMnOvT781EPK238Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：来自人类反馈的强化学习（RLHF）是将大语言模型（LLM）与人类偏好相匹配的主流范式。然而，现有的 RLHF 在很大程度上依赖于准确、翔实的奖励模型，而奖励模</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526745&amp;idx=3&amp;sn=c4ccef140a34b097fb230d0a290c5cd2&amp;chksm=ea04e38d4c5b4425d3ac46a5d9bd9ad63574ae8b3cf02f452084bbd7e1abe3fc7a413c01073d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 19 Mar 2024 12:43:33 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[每日论文速递 | DeepMind提出在线偏好对齐新方法：IPO-MD]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag8NaOXicl7iaZPic50DD7PflxUDOv2981jHvd77dhCRTdnZcOpVjfj3gfbnyK8XyMnOvT781EPK238Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：确保语言模型的输出与人类偏好相一致，对于保证有用、安全和愉快的用户体验至关重要。因此，近来人们对人类对齐问题进行了广泛研究，并出现了一些方法，如人类反馈强化学</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526745&amp;idx=4&amp;sn=740b9f320a54e4f44094144b4511c638&amp;chksm=ea27eaa3dc0b4b07e3495decdadaa9130bb06aecc6daca5034b1fc12a0bfaecb16a42fc22d13&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 19 Mar 2024 12:43:33 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[大模型推理：A100/H100 太贵，何不用 4090？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagjCouMeAEPjZ1xhuth5bqOZoRv7H9mK4wxDdnnHTqWSukc9uXwzQia5HvaBx0ryMwicq8fOcg5U75A/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：李博杰， Logenic AI 联合创始人、中科大与MSRA联培计算机博士、华为天才少年主页：https://01.me/声明：本文只做分享，版权归原作者，侵权私信删除！https://zhua</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526700&amp;idx=1&amp;sn=a2798afa7c48c786883eef6bf92dc0ff&amp;chksm=eab16e905028620a6f9d05b5a08a9b4c4ffebca857c69166603290ede125ef547048c694f4b8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 18 Mar 2024 14:00:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[书生·浦语大模型实战营第二期正式启动，内容全面升级！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagjCouMeAEPjZ1xhuth5bqOSgPewy6HJiaW5TdaJl2FTR9lh9cRRzv7ggQNu28t494rgUraXsqDeuA/300?wxtype=jpeg&amp;wxfrom=0"/><p>为了帮助社区用户高效掌握和广泛应用大模型技术，我们重磅推出书生·浦语大模型实战营系列活动，旨在为开发者们提供全面而系统的大模型技术学习课程，并建立一个友好的交流平台，便于大家在大模型实践开发中分享经验</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526700&amp;idx=2&amp;sn=3c60fb5a1daf16bc539f3624e322fef7&amp;chksm=ead82660d0e5c3c8ac9c8a429fbd2c77e469ae65e73ef731c6097ed8fbfee3f6440cfeed9503&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 18 Mar 2024 14:00:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | 苹果发文：VLMs离视觉演绎推理还有多远]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaaNF6dCVvryDiaWXTxq64gDY5icLZxqHW8K0O6J0kwBv5aaVnia4TpyyZKQaghGMnRuPNzj61ZkjoqA/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：最近，GPT-4V 等视觉语言模型（VLM）在各种视觉语言任务中取得了令人难以置信的进步。我们深入研究了基于视觉的演绎推理这一更为复杂但探索较少的领域，并发现</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526700&amp;idx=3&amp;sn=96ce3f748dbc7df4216f5e7b1d56d68d&amp;chksm=eaf1d7019562c835be207d3cea7351816f3a7e62143c682b609e3177027d5af49b7aa0e00647&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 18 Mar 2024 14:00:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | Meta提出Branch-Train-Mix 混合专家大模型训练方法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaaNF6dCVvryDiaWXTxq64gDY5icLZxqHW8K0O6J0kwBv5aaVnia4TpyyZKQaghGMnRuPNzj61ZkjoqA/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：我们研究了训练大语言模型（LLM）的高效方法，使其具备多个专业领域的能力，如coding、数学推理和世界知识。我们的方法被命名为 "分支-训练-混合Branc</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526700&amp;idx=4&amp;sn=3d20715a2a8d74ca3f799023bc0131a6&amp;chksm=ea12c210798f1625456ae9c6fcdb76f90a99b6d19b88b2cde22c7939b720386e2a77bab153df&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 18 Mar 2024 14:00:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | GEAR:高效 KV Cache 压缩框架]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaaNF6dCVvryDiaWXTxq64gDY5icLZxqHW8K0O6J0kwBv5aaVnia4TpyyZKQaghGMnRuPNzj61ZkjoqA/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：键值（KV）缓存已成为加快大语言模型（LLM）推理生成速度的事实。然而，随着序列长度的增加，缓存需求也在不断增长，这使得 LLM 推理变成了一个内存约束问题，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526700&amp;idx=5&amp;sn=f2ae434b7d275341b83a13cbd624c610&amp;chksm=eaac5d123d3343628ae55d0c42ac67a160f1c3d1ed534a539570953b0cdba150c25017a44952&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 18 Mar 2024 14:00:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【原创】一文读懂RAG的来源、发展和前沿]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaaNF6dCVvryDiaWXTxq64gDOU2fvfbCgEUPghd6Vicj7qtFqy5RMLjUbic573G2icz8PfapSlHz0yIpA/640?wxtype=jpeg&amp;wxfrom=0"/><p>检索增强生成(Retrieval Augmented Generation，RAG)结合了检索 (Retrieval) 和生成 (Generation) 两个过程，旨在提高机器生成文本的相关性、准确性</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526630&amp;idx=1&amp;sn=a4f18fba5d836ffdba2fe76d4b18f9ae&amp;chksm=ead657a32fe18157d77efb6beae4f89376d13ee0677b1a7adfc77b7f0bd50ba4583e850e009a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 15 Mar 2024 10:02:16 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | 陈丹琦新作：启发式核心-理解PLM子网络]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaaNF6dCVvryDiaWXTxq64gDY5icLZxqHW8K0O6J0kwBv5aaVnia4TpyyZKQaghGMnRuPNzj61ZkjoqA/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：之前的研究发现，使用不同随机种子进行微调的预训练语言模型（LMs）可以获得相似的域内性能，但在句法泛化测试中的泛化效果却大相径庭。在这项研究中，我们发现即使在</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526630&amp;idx=2&amp;sn=2152c2c0ebd07b11f553183d9689dd16&amp;chksm=ea3cdc53997428e296a00d7cacf6738d25e39a456ce5d55db21a9a8e11fd5d8b65a2ceebb135&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 15 Mar 2024 10:02:16 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | InterrogateLLM: 大模型幻觉检测框架]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaaNF6dCVvryDiaWXTxq64gDY5icLZxqHW8K0O6J0kwBv5aaVnia4TpyyZKQaghGMnRuPNzj61ZkjoqA/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：尽管大语言模型（LLMs）取得了许多进步，并以前所未有的速度迅速发展，但由于种种原因，它们对我们日常生活方方面面的影响和整合仍然有限。阻碍其广泛应用的一个关键</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526630&amp;idx=3&amp;sn=dc88d991312cd9185d3fdce88d3de006&amp;chksm=eaed8c92b995a1f2a1987a5acd65ca0f68135c180c9c33e1a5d55142ed927ae4837649fb34e5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 15 Mar 2024 10:02:16 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | IntactKV: 用Pivot token进行无损量化的方法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaaNF6dCVvryDiaWXTxq64gDY5icLZxqHW8K0O6J0kwBv5aaVnia4TpyyZKQaghGMnRuPNzj61ZkjoqA/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：大语言模型（LLM）在自然语言处理中表现出色，但需要密集的计算。为了缓解这一问题，人们探索了各种量化方法，但这些方法都会影响 LLM 的性能。本文揭示了 LL</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526630&amp;idx=4&amp;sn=783973e2a2d4d37f2a9537e48a18275f&amp;chksm=eab13b5876543bd644ebf55775591efaca887dd5449d08b73a1e855658debea4146fbe8079c7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 15 Mar 2024 10:02:16 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多篇综述理清知识图谱现状，这167篇论文值得一读！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagEtJ97MkdjOkXBqibxDs0vx8cW6nUNMXgaNlIoOLCSTpMvfmzfQTxcpuYamia9icIpa1GKhJSryvQWw/640?wxtype=jpeg&amp;wxfrom=0"/><p>以GPT为代表的大模型，是全新一代知识表示和调用方式，相比以往知识图谱的方式，更加高效智能可扩展等，开启通用人工智能之门。但符号化的知识图谱过时了吗？并非如此，大语言模型和知识图谱不是互相替代，而是相</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526576&amp;idx=1&amp;sn=24aff467f4e4ed7624f16dbc2cf6aa92&amp;chksm=ea3d8c7613f22c6d4af0deb26b6047cd26ecc0d0c08dbe3c9dfe3efd32fcb93a8d51d04188bc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 14 Mar 2024 09:32:02 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | 【ICLR'24 Oral】LoftQ: 更好地将LLM量化与LoRA微调结合]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagEtJ97MkdjOkXBqibxDs0vxZl0hZlU8G3ibOoTqnFvibDKIZc76Libmib7gVkwPVw0uppZdlnXPaLibP5A/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：量化是为服务大语言模型（LLMs）不可或缺的技术，最近已经应用到LoRA微调中。在这项工作中，我们关注的是在一个预训练模型上同时应用量化和LoRA微调的情景。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526576&amp;idx=2&amp;sn=42e08c0fce7172c579449f53bf2f1821&amp;chksm=ea46c06ca30f3a726736e60ca82a54eeec13cbf08abc492e1cdc509c2bcf4a31f4dcda82eb59&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 14 Mar 2024 09:32:02 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | 阿里推出Mixture-of-LoRAs，一个多任务高效微调框架]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagEtJ97MkdjOkXBqibxDs0vxZl0hZlU8G3ibOoTqnFvibDKIZc76Libmib7gVkwPVw0uppZdlnXPaLibP5A/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：指令微调有激发或增强大型语言模型（LLMs）特定能力的潜力。然而，实现正确的数据平衡对于防止灾难性遗忘和任务之间的干扰至关重要。为了解决这些限制并增强训练灵活</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526576&amp;idx=3&amp;sn=1a091b91527588e652b6caa26dc06be0&amp;chksm=ea0b4d1b6c85799778db6a710471c5e743d13f1ccef1cf0d8e004f4bcc61311f643d0e789bbd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 14 Mar 2024 09:32:02 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | MIT新作：使用多个大模型协作decode]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagEtJ97MkdjOkXBqibxDs0vxZl0hZlU8G3ibOoTqnFvibDKIZc76Libmib7gVkwPVw0uppZdlnXPaLibP5A/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：我们提出了一种方法，通过在token level交错使用多个大语言模型（LLM），让它们学会协作。我们将由哪个 LLM 生成下一个token的决定建模为一个潜</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526576&amp;idx=4&amp;sn=5c674675e21b3d7691dd62b70a85a5ba&amp;chksm=ea280cac64262f3c613c7ec3db5f26e834211d4eebadab223878b123956ccc9f22445ab2a5e9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 14 Mar 2024 09:32:02 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解Mixtral 8 * 7b推理优化原理与源码实现]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajVr9QdEkdGpuMhwkVibNSCzhCqCicVpc26jrus0iaf1ASD0icWQOAuAChpvlBlPdGMAjV2S2CTwT3PHg/640?wxtype=jpeg&amp;wxfrom=0"/><p>来自：大猿搬砖简记大家好，在写这篇文章时，本来是想打算介绍Mixtral 8 * 7b具体模型架构的。但是代码读着读着就发现：最精彩的MoE部分，其相关原理在之前的文章中已经详细介绍过整体来看Mixt</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526542&amp;idx=1&amp;sn=a739f34c9931e0f182586eb837131b17&amp;chksm=ea437e14b0a5fca6d49a9a42c9e7caeff98a48239a39cfb9cc17435919534742800901c63452&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 13 Mar 2024 12:38:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | NLP大佬们联合发文，倡导使用检索增强模型RA-LMs]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia3ZKe0HPOMSDBHOkOgRSyWBdzw3gwv3C57I4RC2pVZwmfKPZ6bdCQmBvMbSEj3lDJdhH4EmgFf6g/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：参数化语言模型（LMs）通过在大量网络数据上进行训练，展现出了显著的灵活性和能力。然而，它们仍然面临着诸如幻觉、难以适应新数据分布以及缺乏可验证性等实际挑战。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526542&amp;idx=2&amp;sn=789c8fc225671cd49366a9d858710e80&amp;chksm=ea1f7b0d4d96959d4689380792b95d2da52fd63a2dfe847861b5b6257528680036c4dd771c12&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 13 Mar 2024 12:38:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | Agent控制电脑！用多模态Agent玩荒野大镖客！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia3ZKe0HPOMSDBHOkOgRSyWBdzw3gwv3C57I4RC2pVZwmfKPZ6bdCQmBvMbSEj3lDJdhH4EmgFf6g/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：最近的研究已经证明了基础代理在特定任务或场景中的成功。然而，现有的代理无法在不同的场景中进行泛化，主要是由于它们的观察和行动空间的多样性以及语义差距，或者依赖</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526542&amp;idx=3&amp;sn=6608c7f914adae76a8db85d995452879&amp;chksm=eab7eb1cd71cd3202c3a4a8c5445c3fa0698d98cd1fe14a76178311714e5f0a11bdf9a1b20f2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 13 Mar 2024 12:38:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | GaLore: 使用梯度低秩映射进行大模型 Memory-Efficient 全参训练]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia3ZKe0HPOMSDBHOkOgRSyWBdzw3gwv3C57I4RC2pVZwmfKPZ6bdCQmBvMbSEj3lDJdhH4EmgFf6g/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：训练大型语言模型（LLMs）面临着显著的内存挑战，主要是由于权重和优化器状态的不断增大。常见的内存降低方法，如低秩适应（LoRA），在每一层中向冻结的预训练权</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526542&amp;idx=4&amp;sn=3dae740833171b32d1011634624b1ed1&amp;chksm=ead229e28b737cc43c6c1a2d9037932d35157fbf97d0a47dd6460a56620c90fb9290bda08da4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 13 Mar 2024 12:38:45 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
