<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[深度学习自然语言处理]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    

    <language>zh-cn</language>
    

















    <item>
      <title><![CDATA[LLM能否依据角色的过去预测未来？一篇有趣的研究]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagZ4XjhxR3SCryYg5IcfFPvFIwJkOLMsD6Xxsvh1dT7icwGf3hSOCHzHMNP3FbS4XZefntnNlTDusg/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：wkk深度学习自然语言处理 原创引言你是否想过，如果有一天，当你面临人生重大抉择时，有一个AI助手能够为你提供决策甚至能帮你做出决定？复旦大学和阿里巴巴的最新研究报告显示，大型语言模型（LLMs</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527642&amp;idx=1&amp;sn=e08ee0d0119233fb26e3de0054c418cb&amp;chksm=ea083f9bd4513f92e6283d027c30bfc142cb7d328a8ace093dfc3cb585fcdbcf1fa1aef8ddb3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 25 Apr 2024 06:58:25 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[小师妹我一个月进阶LLM的方法！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagxhaD5f9vWPl8mmVa708XExXaTlYUtuhs5WGA1Bqw4nATkPWyk9Z0Ax0vib4rlJ5X1yOIOD5LicvPQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>我们从2024.1月底到现在已经帮助大几十个同学进阶LLM了，课程优化了数遍，好评不断，期待你的加入~介绍下我们的小团队，分别是：23年面试近50场国内LLM大厂通过率100%拿到多个大厂人才计划of</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527642&amp;idx=2&amp;sn=9ffe3743da8d70067eac2939be98d58e&amp;chksm=ea3d546d035354d62ca9af7b8739e2fc6fab0b1a5dcd8d4d43361bb6545364cf49e095a032b7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 25 Apr 2024 06:58:25 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[100+论文与创新点！SLAM+路径规划资料合集]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagZ4XjhxR3SCryYg5IcfFPvvTiaTM7ZTZlwYicNm2o7O7VxJp5pic9NT2ichiaeWibzlnxGqibribI84fJT5A/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天分享slam+路径规划超全资料合集。无偿分享，扫码即可下载。资料包括： 103篇slam论文来自ICRA2024等顶会，分为视觉slam、语义slam、物体级slam、多机器人协作slam。 35</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527434&amp;idx=1&amp;sn=cf04277e38f050ebb3ba820434cbbda2&amp;chksm=eaf3430277976d6b0daecadb7d91cbf22fad0bec700d89424a7b6fe9f043ac49c3856996ffe8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 24 Apr 2024 06:42:13 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一文看懂 LLaMA 中的旋转式位置编码（Rotary Position Embedding）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagZ4XjhxR3SCryYg5IcfFPvZnClMpxV5mZ6VR6RPia9Qt7pfx2T8Q6b4MvHXmNnrVcEzAdGZf1iapFQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：GiantPandaCV旋转式位置编码（RoPE）最早是论文[1]提出的一种能够将相对位置信息依赖集成到 self-attention 中并提升 transformer 架构性能的位置编码方式。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527434&amp;idx=2&amp;sn=98b1d85e229648f3e717e4e02bf9a326&amp;chksm=ea6ea08abe2366895ea62054ead1397a7d00b046ddae0104dec2e51cd559f465672aa4b1edf8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 24 Apr 2024 06:42:13 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[无位置编码(NoPE)也有长度泛化问题？首个针对NoPE的长度外推方法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagZ4XjhxR3SCryYg5IcfFPvTU5Bpz7tB7QWo9CVSad8MqCqSMPTf2YA6wFzEnd9d08PUqicr2IIYIA/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：FudanNLP基于Transformer的大型语言模型（LLM）展示了强大的文本理解能力，颠覆了整个NLP领域的应用范式。然而，在长度有限文本上预训练的语言模型却无法像人类一样泛化到任意长度文</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527434&amp;idx=3&amp;sn=d285370102eb4e24473b9f7c60ebc58d&amp;chksm=ea5d01ab39410279f402962af00c5200c11a488424a2525063f9eddf0f66b1e1a78b813712d3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 24 Apr 2024 06:42:13 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024 || 将任何Decoder-only的大模型（LLM）转换为文本Embedding编码器]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagZ4XjhxR3SCryYg5IcfFPv7ku2yQM958t9KOgprUUoYNEwY3D3GDl6FN2bicSRyVlyKWAaJXTXyZg/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：深度图学习与大模型LLM深度图学习与大模型LLM(小编):今天给大家介绍一篇题为《LLM2Vec: 大型语言模型是强大的文本编码器》的论文-也就是说把LLM转为embedding 模型。这篇论文</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527434&amp;idx=4&amp;sn=e27ae5dc44c3fd596ae951949cf8b61d&amp;chksm=ea819287adbd9afae2d239b616f2c94873049e8b5a4afb93ab8a958fc4083cd13a80ca1ea872&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 24 Apr 2024 06:42:13 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[总结！大模型微调（Tuning）的常见方法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahHOxDbOnnPJMQmiak1BQqe4TXedTUBLNFr1QImyicyqVialYZ73YVCkTdo6x6Y1ylicp1wkyFL3RrKuA/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着大模型的飞速发展，在短短一年间就有了大幅度的技术迭代更新，从LoRA、QLoRA、AdaLoRa、ZeroQuant、Flash Attention、KTO、PPO、DPO、蒸馏技术到模型增量学习</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527408&amp;idx=1&amp;sn=13fd3a3b021477be3ff8682789e5da96&amp;chksm=ea09c59b19d316e0157e6fe02b42ab4d889d170534b9a560742663b193b4387ee43add78950a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 22 Apr 2024 02:02:31 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[张俊林：聊聊对LLAMA-3、大模型开源与闭源以及合成数据的看法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahHOxDbOnnPJMQmiak1BQqe4RxFia1aibZscsaia6tHbQCEdOrI3HcDhHzibb94IjckyfyLdYyVhm1UgOg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：张俊林，新浪微博新技术研发负责人声明：本文只做分享，版权归原作者，侵权私信删除！原文：https://www.zhihu.com/question/653373334/answer/347146</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527408&amp;idx=2&amp;sn=6136de81fe8a9be4984bda71e4a7d785&amp;chksm=ea695d159d9dc8fbd69f0ca139619f00268607348a9b705185fb90b439fb382a5693ee91b3a3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 22 Apr 2024 02:02:31 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Transformer本可以深谋远虑，但就是不做]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahHOxDbOnnPJMQmiak1BQqe4G0dc3UtA8K6icf60WGD5E5FWzjYrjRhf4Nh31J5t3WQnxycPaVElQ1Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道机器之心编辑部语言模型是否会规划未来 token？这篇论文给你答案。「别让 Yann LeCun 看见了。」Yann LeCun 表示太迟了，他已经看到了。今天要介绍的这篇 「LeCun </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527408&amp;idx=3&amp;sn=cd8405d237020575fe8902258a139bfc&amp;chksm=ead5fe8d885aa04c933daba458bff5bf34e81a6fe9ee9f97b2c6e540b81406cfdd3f8cf07de1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 22 Apr 2024 02:02:31 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ICLR 2024 | 鸡生蛋蛋生鸡？再论生成数据能否帮助模型训练]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahHOxDbOnnPJMQmiak1BQqe4ETlQ4I6pzxa6enIWUh5AvRKJVGvft59OsB5iavkM08ayX0Ib5oPgDicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>来源：机器之心 PaperWeekly本文从一个独特的视角解释了现有多模态大模型幻觉产生的原因。随着生成模型（如 ChatGPT、扩散模型）飞速发展，一方面，生成数据质量越来越高，到了以假乱真的程度；</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527408&amp;idx=4&amp;sn=08054e26e56d7df41ced70b4ffab94b5&amp;chksm=ea35a25538538c4da5f68f752bd57b0bbd8a6fa400d2230f8814334a5e190fac88066d53e3fd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 22 Apr 2024 02:02:31 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[前紧后松：清华读博前两年的焦虑与成长]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahoUFFEOckpumwwcibwSZ2Kr9M2YxZ0GBomDTsSCuFl8VktUXSQkfF2ZxLLSZXIAoiclYQ5PkjD3nlg/640?wxtype=jpeg&amp;wxfrom=0"/><p>来自：丁司图从清华毕业入职腾讯没多久，我上个月作为今年新晋打工人的代表参加VALSE学生论坛，跟同学们分享了一些故事。司徒笔记这个专栏本来是用来聊学术的，不够轻松，似乎缺一些用来当作下饭伴侣或者如厕读</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527380&amp;idx=1&amp;sn=164454bbc95d2b50a5cd3c36c232b3e2&amp;chksm=ea9b57a9a2cf9c067fbdd8f7703616dfc87e56a3ef59957096c6cce8495998a52077c4d3aaf3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 18 Apr 2024 14:03:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[《跨语言大模型》最新综述]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahoUFFEOckpumwwcibwSZ2KrGUaW0oM2BZTPRPyPicUGMQKoFQ3q3G1dfCQwBsjmh70JXibpz5LibjXzA/300?wxtype=jpeg&amp;wxfrom=0"/><p>大模型智能｜原创作者 | 小夏跨语言大模型（MLLMs）能够利用强大的大型语言模型处理和回应多种语言的查询，在多语言自然语言处理任务中取得了显著的成功。尽管取得了这些突破，但仍然缺乏一份全面的调查总结</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527380&amp;idx=2&amp;sn=63777e4ddef974937c66df8e22b8ec9d&amp;chksm=eabb2649e195970c88e2988d6b21f7e6abfc5e6541f43f374704e1608da75f17e2864e9dd860&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 18 Apr 2024 14:03:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Meta无限长文本大模型来了：参数仅7B，已开源]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahoUFFEOckpumwwcibwSZ2Kr1VsQTveiaicB7BxPEr7eKO1Pkd4nkCt8GlczW5EQIlLnyB3Mgm7yODfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：机器之心谷歌之后，Meta 也来卷无限长上下文。Transformers 的二次复杂度和弱长度外推限制了它们扩展到长序列的能力，虽然存在线性注意力和状态空间模型等次二次解决方案，但从以往的经验来</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527380&amp;idx=3&amp;sn=34a4b45aece8f78f47b8694c16627c33&amp;chksm=ea8a5cf6d1c8f7f103d39e62c17be18ceb6c3c1fb8dccb748a475027f5e5da0ec6a4b6ddd56e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 18 Apr 2024 14:03:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[最强MOE开源：Mixtral 8x22B 发布！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahoUFFEOckpumwwcibwSZ2Krr2x1LxeeTSM7MJiaSicraIhoh44Px1w8mRrZA4UpDTicNUrEnnjfngsHQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：包包的算法笔记权重地址：https://huggingface.co/mistral-community/Mixtral-8x22B-v0.1根据上传时间发现是一周之前，在Llama3正式放出来</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527380&amp;idx=4&amp;sn=b13c82d58d1e7b86e002a46a4a067897&amp;chksm=ea4c544b03204218c80a48a2fc0a7ae5f08f4df45311d6d67b461c2ef9ef9201bfda09f9c789&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 18 Apr 2024 14:03:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[最新大模型论文研究论文合集，包含谷歌/苹果/亚马逊/港大、阿里最新研究报告！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaBUNP9ov40cegicNJEb6caLZfpGgAmwcJJvhtcevTdGQgDClnMicNGppib4GLX0FnRazqX652XiaFDYw/640?wxtype=jpeg&amp;wxfrom=0"/><p>清华团队推出 MiniCPM：利用可扩展的训练策略挖掘小模型潜力；苹果MM1大模型：30B参数，多模态，在预训练指标上达到SOTA；亚马逊提出大规模视频语言对齐方法VidLA；英伟达参与，高效视频扩散</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527348&amp;idx=1&amp;sn=5fde9cd0b646b8cdfcc722654cd0b979&amp;chksm=eae6af97e766bd3c8184259a9c3801eafcdb02f8a66396dc9901bd374418b1726a074a427f9c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 17 Apr 2024 08:03:13 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[对谷歌最新提出的Infini-transformer模型进行代码复现]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaBUNP9ov40cegicNJEb6caL2RODmk042Eou2FY8cB0eQmYlHR2IGJ1EzNCGuFIPaDlq0Udg49JX8g/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：Lil2J（已获授权）链接：https://zhuanlan.zhihu.com/p/692848185简介这篇文章主要内容为我个人对谷歌最新提出的Infini-transformer模型的个人</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527348&amp;idx=2&amp;sn=afd77d9555e3ac6586022396189d9e18&amp;chksm=eaf27464ba87c55fb78c9910dcdc878b650521b9a3552a713a06d94d133edef3b0b9c36ae9c9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 17 Apr 2024 08:03:13 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Adaptive-RAG:根据难度自适应检索方案]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaBUNP9ov40cegicNJEb6caLncBg0FhNibwN1nJ3ySh6icRTXNuLeQu5BygIvGEWaCXOOTQFBaicl5JWQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：CS的陋室RAG的论文可谓是百花齐放，今天讲一篇有关自适应的RAG，这篇论文认为是不同难度的问题，RAG系统应该有不同的应对策略，因此搭建了这个自适应的RAG系统来适配不同难度的问题。论文：Ad</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527348&amp;idx=3&amp;sn=d36b4937e00bc0ad0ab5e5503884198e&amp;chksm=ea94e7952eb39c787c716d6e48ccfe099c892cb7f4a2489297e46c959ff8cef9b53b191b41e5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 17 Apr 2024 08:03:13 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多篇顶会一作却申博失败？斯坦福博士生亲述：AI领域太卷]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaBUNP9ov40cegicNJEb6caL3gYlicc8fibFesibibrZM1e3kF1TUD7dyMPdnpmz7wSId4PPfFTzxKPDWQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：机器之心「尽管我在顶级 ML 会议上发表了多篇一作论文，为开源项目做出了贡献，也在业界产生了影响，但我仍在为进入博士课程而苦苦挣扎。我被顶尖大学拒之门外，感到迷茫和疲惫。」「我开始怀疑自己，怀疑</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527348&amp;idx=4&amp;sn=2504bdf464743ee4dde39c72d1b208b3&amp;chksm=eab11eea32733d692aace450a1917496ec83d5099e5afb6b0fb49249bf2e8ad04854d2465c08&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 17 Apr 2024 08:03:13 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
