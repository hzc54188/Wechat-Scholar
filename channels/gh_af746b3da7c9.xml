<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[深度学习自然语言处理]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_af746b3da7c9.jpg</url>
      

      <title>gh_af746b3da7c9</title>
      

    </image>
    

















    <item>
      <title><![CDATA[小数据，大突破！揭秘仅0.3B个token如何让8B模型逼近GPT-4，长文本开源新纪元]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajRvH91Dm10DLz6oGHMlFwW0tiaJAHFS6wAHicuMThiaVibbNVgGXyI4GQN2o1WjqLzWhZvQEd1Q5ickSQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者: 汤泽成 (知乎：ZetangForward)链接: https://zhuanlan.zhihu.com/p/2993874959当前，越来越多的研究指出，长文本模型（Long-context</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533305&amp;idx=1&amp;sn=7efc5ece630a0cafa138f94281276913&amp;chksm=eaf533490197c7c84c65795f6a29cf3a15974ef0cf82d61c06c36244b843fa836845e5d77991&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 25 Oct 2024 07:29:23 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[最新70篇代码大模型论文精选]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajRvH91Dm10DLz6oGHMlFwWO5wC7kkooDmWZ81SxRnQegL2n0dPzNeiaNOOicyQGxQ41T0kAMCYDXDA/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言来自：CodeFuse本文整理 2024 年 9 月至 10 月中旬全球各大高校与科研机构发布的 70 篇代码大模型相关论文。根据论文内容，我们将这些论文整理为了基座模型、代码微调、测试基准、代码</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533305&amp;idx=2&amp;sn=310982c6033e4e70602cb695e8be11f3&amp;chksm=eac14e3072c17c41543b916a8e831671583f7661f24fffc278c869d2b1c046a661694bfe03bd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 25 Oct 2024 07:29:23 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[数据或许比算法更重要？不要轻视大模型剪枝中的校准数据]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiajOibadC0GdTKdFtrTwHcLqFkaeueoUst86zY1ow526GEHMHpk1sicdnQoB9l4pBM4wWiaZmQub8gQA/640?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，大语言模型（Large Language Model, LLM）日益强大的性能吸引了各行各业的关注，并逐步在各种领域得到了广泛应用。为了节省大模型部署的成本，降低大模型服务延迟，越来越多的研究</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533278&amp;idx=1&amp;sn=e73f70ad998d04f0c8d082dbd2b38f52&amp;chksm=eab66395d2d3943b2fb07f830f3db40c5a66de80d05fb52505e02487791166f86491e002ffb7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 24 Oct 2024 12:33:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[（徒手搓LLM）逐行代码从0构造一个LLM——LlaMa篇]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiajOibadC0GdTKdFtrTwHcLqxkUyrRohEVUSM002bl6Kp9IdcTwicib3HezakOcMuHU8cCDzzJYJibQ0g/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：mc112611（已授权）链接：https://zhuanlan.zhihu.com/p/1674261485本篇为：面向人群：觉得LLM很多复杂的结构和层级，懂很多原理，但是不知道怎么结合到一</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533278&amp;idx=2&amp;sn=5f4d450ae4359fa69a8dfd07fc9f3c1c&amp;chksm=ea33fa90be40dba1820c225476c56ea1b59dbe9027113465d13c0661077b5b6b0826ee7d4172&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 24 Oct 2024 12:33:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[EMNLP2024分享会下半场！有Agent、模型/推理加速等主题]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiajOibadC0GdTKdFtrTwHcLqw64lsFWauIiaHPfXMdZn77jxic1jwfWsDq2VMFrHeQvoBsrEYUNY8wMA/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，欢迎来参加我们NICE-苏大AI Lab举办的EMNLP2024分享会，在本周六(10.26)，我们邀请到多位EMNLP2024中稿的同学来分享交流他们的工作，每篇分享都有5mins问答环节，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533278&amp;idx=3&amp;sn=223f602a33b808f5ddb70253c92ad171&amp;chksm=ea5c9370c1aad1eb51b8b1a03dae9cef09302ca50b4130ac88ce639681ae428f9ded5de0813d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 24 Oct 2024 12:33:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型评测的真正难点：内在精细决策逻辑与人认知的对齐]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baguSjMTwLCUXQOqxqfNicfyFyEQ0YVHQ1k4eajYwHHY6ibPtxx5YVnFmxaHsCic7J8cxrzUxiaibn5F6og/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：Qs.Zhang张拳石链接：https://zhuanlan.zhihu.com/p/2092355900陈鹭，张拳石Lu Chen, Yuxuan Huang, Yixing Li, Yaoh</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533042&amp;idx=1&amp;sn=b65b41a1fa5931eac86ea247f3100104&amp;chksm=eadf3d362c60b1bbde78b9334673f96f985776cf590a752f5fb05993b582d0d6bfa656281b53&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 21 Oct 2024 15:44:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM在Reranker任务上的最佳实践？A simple experiment report（with code）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baguSjMTwLCUXQOqxqfNicfyFzS4tl5jONszDQMILVsowCO48kEYIiadhtkcsx3X8P9OcIws004LzjCA/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：车中草同学(已授权)链接：https://zhuanlan.zhihu.com/p/987727357引言在BERT时代，对于Reranker任务，我们使用encoder-only的BERT为基</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533042&amp;idx=2&amp;sn=d640662c4dda381b41dbc63047480dbc&amp;chksm=ea09ed6b1ab74fc2e21cbe8c3a65dffcda8f46a3aa5843e3f95d5ca05bc8b875641eb5b50fec&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 21 Oct 2024 15:44:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[RMB: 这是一个Reward Model Benchmark]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baguSjMTwLCUXQOqxqfNicfyFmJ7gwUX55YuMNLmacIVfgl4WIUtTtQRUOJkj5SS4V5HQkMT4rrO0Ig/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：FudanNLP 我们提出了一个全面、细粒度的奖励模型评估基准，涵盖了超过 49 个现实世界场景，包含了超过三千条现实世界的用户问题。在pairwise 比较之外，我们还提出了 Best-of-</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533042&amp;idx=3&amp;sn=ac55f8aaeb192fe9e4d221215c139270&amp;chksm=eaf8717db5dc2c32d4150105518c6c6700d32e9e925d2c90ccdbe3b9ef0ac2e4d35b736da6ca&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 21 Oct 2024 15:44:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[哈工深、微信：“慢思考”超长文档翻译智能体]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiadVkMPXdicKibQ5NDyBxtnI4bBSwx75crwUpoAMVDmufKvBXaibiaZnNYljHfWVqsCy2YHPJxBxBBsWA/640?wxtype=jpeg&amp;wxfrom=0"/><p>如今，大语言模型已经成为机器翻译任务（Machine Translation）上的新型强大工具。
然而，多数在机器翻译大语言模型（MT-LLM）上开展的研究工作都是句子层面的，每一句话都被独立进行翻译</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247532980&amp;idx=1&amp;sn=91a01462cfa1c6e2089fb562675dec5e&amp;chksm=ea309f0372c80f9eded1484c3f037d92985762db58423960dae12b67d684a7865abef603dc32&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 20 Oct 2024 15:59:28 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[解构DPO：从RLHF推导到多偏好对齐的简化之道]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiadVkMPXdicKibQ5NDyBxtnI4raSeibXQZYFOUoyELWQdxaV0AnXIYX57dR0OQJLOicOkiaeWMQ43GaIog/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：克鲁斯卡OpenAI发布了 o1之后，LLM领域又掀起了Inference Scaling Law的热潮，此次推理能力的大幅提升其中就有强化学习的参与，其利用 RL 改进模型思维链的中间步骤，得</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247532980&amp;idx=2&amp;sn=9a1620d0edfde345e79904997c3b6ae2&amp;chksm=eae6fb028b21872ec54b30517375297667945b7cba395d36069f0a2071dafc8c3ca145365fb1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 20 Oct 2024 15:59:28 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[训练VLM(视觉语言模型)的经验]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaJxicwG8EkXRY90uWS9TK4nBOGt87n6W6w81Nlia9noBxfB0EnpRib9JheKXeEOicWqKezEUgQZZYIGw/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：lym链接：https://zhuanlan.zhihu.com/p/890327005如果可以用prompt解决，尽量用prompt解决，因为训练（精调）的模型往往通用能力会下降，训练和长期部</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247532929&amp;idx=1&amp;sn=87c65d444448db50484fcc074254b342&amp;chksm=ea6447ccf146ffe10bbd32a8adffba13092a2d2caa8ae868cadf1f8b24817675bb063199402f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 19 Oct 2024 15:16:54 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[MoE实验性工作Upcycling Large Language Models into Mixture of Experts]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaJxicwG8EkXRY90uWS9TK4nlSiaF9qqQHNjHtmr8hBTNLDJZgCnHXibS7UKkw7NHuldxx4pWDo2BnxA/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：LLM迷思(已授权）链接：https://zhuanlan.zhihu.com/p/1431483173Zijie大佬的最新工作，拜读了一下，对于我之前一些工作很有启发。包括之前"介绍LLM迷思</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247532929&amp;idx=2&amp;sn=5bab6bf564687845247841aff78476cd&amp;chksm=eae38280777f142a1a413f324befb53c18039f68e51372297bcb173a471f4893d1d84ebd30f5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 19 Oct 2024 15:16:54 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[可怕！llm训练的bug，梯度累计设置过大，会导致最终loss过大。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajTTVxWXOl5ZlKtyqBbfibZV33GlHqCSb1ibhrT7IhDEfNqYc2TQX0YaEMIyFfZeJxZ0jk5gHRJXzZA/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：车中草同学(已授权）链接：https://zhuanlan.zhihu.com/p/1485465898范围：该问题影响所有使用梯度累计的库，包括hf的等。（hf的人在修复中了）10.18日更新</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247532873&amp;idx=1&amp;sn=79ba187b1f1d225cd17edfc189aa0e37&amp;chksm=ea8a1cc4cc97e2f3ffe691d79d2b1f9f77ec47f27cf8b673a3588bc5a1bd3ef8dd1d7a73c101&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 18 Oct 2024 15:58:49 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[EMNLP2024分享会要开始啦！6大主题、2多主题，快来预约不错过]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajTTVxWXOl5ZlKtyqBbfibZVtWNFSJhtJfw0loI5fW8awIsMFQfGlicmkPibovkglFvibGxCBd7DKSecg/300?wxtype=jpeg&amp;wxfrom=0"/><p>文末进群~大家好，欢迎来参加我们NICE-苏大AI Lab举办的EMNLP2024分享会，在接下来的两个周六(10.19和10.26)，我们邀请到多位EMNLP2024中稿的同学来分享交流他们的工作，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247532873&amp;idx=2&amp;sn=2268ad826f9e5bf3f46370cf344e60e3&amp;chksm=eabf84658dd7b4574bdf2f16fa2c9915ff83fa29a670e751ec4d89e88ab956bc35c3ea64600f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 18 Oct 2024 15:58:49 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[关于LLM+RL(HF)的片面脉络梳理]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajTTVxWXOl5ZlKtyqBbfibZVX5KR511EcibQWymGXMNia70EfzibqvNl6UaPu3a2pgdZSyMHPYdYZO5kA/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：王小惟 Weixun链接：https://zhuanlan.zhihu.com/p/1686790674片面的脉络梳理，主要是希望能帮助大家建立一个更全局的视角，因为篇幅有限，仅包含了支撑脉络的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247532873&amp;idx=3&amp;sn=a9d776dfe943fffefe40947b811fd670&amp;chksm=ea8cfdfe103665fcbfe1d926fc217dd19d7d3ebd1836cd1633eb5898bc59fdb1fbde1d6120fd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 18 Oct 2024 15:58:49 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[BWArea Model: 决策视角下的可控语言生成]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajTTVxWXOl5ZlKtyqBbfibZVZeqgXOnrbzfxptZo626k19eewjAsicicXl2FCgVjHmsZQUIoKCZAFyDA/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：j0229链接：https://zhuanlan.zhihu.com/p/721464986前言在前段时间，在俞老师 @俞扬 的指导下，和鹏远师弟、子牛师兄 @李子牛 以及组内其他师弟一起做了可</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247532873&amp;idx=4&amp;sn=0bdf2b782aa80066bc5bb65596de0160&amp;chksm=eaafde846d5bab9698f22dfe0a00b5b472c45561f2430bb4a6417cbf58a4f94d3be9fa0d2fa0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 18 Oct 2024 15:58:49 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[合成数据用于AI训练的艺术与科学]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bah6P7uLqYMqFSangHNBAFVs6xq33RSILDQ2osQUibTRsk3bDYJ2RAXcsbia7aQzKPAdfauqO9AwiavxQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：Nathan Cooper链接：https://www.answer.ai/posts/2024-10-15-how-to-synthesize-data.html引言合成数据已经成为大规模语言</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247532765&amp;idx=1&amp;sn=5dde12b93d5256fda251b5e94d387f59&amp;chksm=eac9a9d966b621bdf253de3347a3b0173620860243044ea74b1a798830d49ce41eb0d40c2c6f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 17 Oct 2024 15:55:17 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM实践--支线：拯救Continue Pretrain的数据]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bah6P7uLqYMqFSangHNBAFVsX3TaEJNdGvWNtthrXKKfT3j2WwqM3jWibynichcBNaEpmVlF68KZyYcg/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：真中合欢链接：https://zhuanlan.zhihu.com/p/721492096打分清洗的文章难产，写起来没有思路，就换换脑子写写旁门左道，探讨一下common数据质量不理想的情况下，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247532765&amp;idx=2&amp;sn=04542c1fc0ede232218dc97011bd2d8b&amp;chksm=ea94689564078c31d0f1271e783f39861948b031d0df0d6df04a97c669801f22ba413af34f45&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 17 Oct 2024 15:55:17 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
