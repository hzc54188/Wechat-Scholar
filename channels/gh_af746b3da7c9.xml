<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[深度学习自然语言处理]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    

    <language>zh-cn</language>
    





















    <item>
      <title><![CDATA[多篇综述理清知识图谱现状，这167篇论文值得一读！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagEtJ97MkdjOkXBqibxDs0vx8cW6nUNMXgaNlIoOLCSTpMvfmzfQTxcpuYamia9icIpa1GKhJSryvQWw/640?wxtype=jpeg&amp;wxfrom=0"/><p>以GPT为代表的大模型，是全新一代知识表示和调用方式，相比以往知识图谱的方式，更加高效智能可扩展等，开启通用人工智能之门。但符号化的知识图谱过时了吗？并非如此，大语言模型和知识图谱不是互相替代，而是相</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526576&amp;idx=1&amp;sn=24aff467f4e4ed7624f16dbc2cf6aa92&amp;chksm=ea3d8c7613f22c6d4af0deb26b6047cd26ecc0d0c08dbe3c9dfe3efd32fcb93a8d51d04188bc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 14 Mar 2024 09:32:02 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[每日论文速递 | 【ICLR'24 Oral】LoftQ: 更好地将LLM量化与LoRA微调结合]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagEtJ97MkdjOkXBqibxDs0vxZl0hZlU8G3ibOoTqnFvibDKIZc76Libmib7gVkwPVw0uppZdlnXPaLibP5A/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：量化是为服务大语言模型（LLMs）不可或缺的技术，最近已经应用到LoRA微调中。在这项工作中，我们关注的是在一个预训练模型上同时应用量化和LoRA微调的情景。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526576&amp;idx=2&amp;sn=42e08c0fce7172c579449f53bf2f1821&amp;chksm=ea46c06ca30f3a726736e60ca82a54eeec13cbf08abc492e1cdc509c2bcf4a31f4dcda82eb59&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 14 Mar 2024 09:32:02 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[每日论文速递 | 阿里推出Mixture-of-LoRAs，一个多任务高效微调框架]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagEtJ97MkdjOkXBqibxDs0vxZl0hZlU8G3ibOoTqnFvibDKIZc76Libmib7gVkwPVw0uppZdlnXPaLibP5A/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：指令微调有激发或增强大型语言模型（LLMs）特定能力的潜力。然而，实现正确的数据平衡对于防止灾难性遗忘和任务之间的干扰至关重要。为了解决这些限制并增强训练灵活</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526576&amp;idx=3&amp;sn=1a091b91527588e652b6caa26dc06be0&amp;chksm=ea0b4d1b6c85799778db6a710471c5e743d13f1ccef1cf0d8e004f4bcc61311f643d0e789bbd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 14 Mar 2024 09:32:02 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[每日论文速递 | MIT新作：使用多个大模型协作decode]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagEtJ97MkdjOkXBqibxDs0vxZl0hZlU8G3ibOoTqnFvibDKIZc76Libmib7gVkwPVw0uppZdlnXPaLibP5A/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：我们提出了一种方法，通过在token level交错使用多个大语言模型（LLM），让它们学会协作。我们将由哪个 LLM 生成下一个token的决定建模为一个潜</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526576&amp;idx=4&amp;sn=5c674675e21b3d7691dd62b70a85a5ba&amp;chksm=ea280cac64262f3c613c7ec3db5f26e834211d4eebadab223878b123956ccc9f22445ab2a5e9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 14 Mar 2024 09:32:02 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[图解Mixtral 8 * 7b推理优化原理与源码实现]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajVr9QdEkdGpuMhwkVibNSCzhCqCicVpc26jrus0iaf1ASD0icWQOAuAChpvlBlPdGMAjV2S2CTwT3PHg/640?wxtype=jpeg&amp;wxfrom=0"/><p>来自：大猿搬砖简记大家好，在写这篇文章时，本来是想打算介绍Mixtral 8 * 7b具体模型架构的。但是代码读着读着就发现：最精彩的MoE部分，其相关原理在之前的文章中已经详细介绍过整体来看Mixt</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526542&amp;idx=1&amp;sn=a739f34c9931e0f182586eb837131b17&amp;chksm=ea437e14b0a5fca6d49a9a42c9e7caeff98a48239a39cfb9cc17435919534742800901c63452&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 13 Mar 2024 12:38:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | NLP大佬们联合发文，倡导使用检索增强模型RA-LMs]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia3ZKe0HPOMSDBHOkOgRSyWBdzw3gwv3C57I4RC2pVZwmfKPZ6bdCQmBvMbSEj3lDJdhH4EmgFf6g/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：参数化语言模型（LMs）通过在大量网络数据上进行训练，展现出了显著的灵活性和能力。然而，它们仍然面临着诸如幻觉、难以适应新数据分布以及缺乏可验证性等实际挑战。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526542&amp;idx=2&amp;sn=789c8fc225671cd49366a9d858710e80&amp;chksm=ea1f7b0d4d96959d4689380792b95d2da52fd63a2dfe847861b5b6257528680036c4dd771c12&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 13 Mar 2024 12:38:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | Agent控制电脑！用多模态Agent玩荒野大镖客！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia3ZKe0HPOMSDBHOkOgRSyWBdzw3gwv3C57I4RC2pVZwmfKPZ6bdCQmBvMbSEj3lDJdhH4EmgFf6g/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：最近的研究已经证明了基础代理在特定任务或场景中的成功。然而，现有的代理无法在不同的场景中进行泛化，主要是由于它们的观察和行动空间的多样性以及语义差距，或者依赖</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526542&amp;idx=3&amp;sn=6608c7f914adae76a8db85d995452879&amp;chksm=eab7eb1cd71cd3202c3a4a8c5445c3fa0698d98cd1fe14a76178311714e5f0a11bdf9a1b20f2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 13 Mar 2024 12:38:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | GaLore: 使用梯度低秩映射进行大模型 Memory-Efficient 全参训练]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia3ZKe0HPOMSDBHOkOgRSyWBdzw3gwv3C57I4RC2pVZwmfKPZ6bdCQmBvMbSEj3lDJdhH4EmgFf6g/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：训练大型语言模型（LLMs）面临着显著的内存挑战，主要是由于权重和优化器状态的不断增大。常见的内存降低方法，如低秩适应（LoRA），在每一层中向冻结的预训练权</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526542&amp;idx=4&amp;sn=3dae740833171b32d1011634624b1ed1&amp;chksm=ead229e28b737cc43c6c1a2d9037932d35157fbf97d0a47dd6460a56620c90fb9290bda08da4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 13 Mar 2024 12:38:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[太强了！斯坦福继Flash Attention V1和V2又推出Flash Decoding]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia3ZKe0HPOMSDBHOkOgRSyWuR4BYvsZ9r5QSj5iaY3NOVibWG0Qq4n99vRw9EjTricMcDXibsdicGmMb3w/640?wxtype=jpeg&amp;wxfrom=0"/><p>斯坦福大学此前提出的FlashAttention算法，能够在BERT-large训练中节省15%，将GPT训练速度提高2/3。此后又提出FlashAttention V2，拥有了更好的并行性和工作分区</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526503&amp;idx=1&amp;sn=26d0ff4f94e2500ad90770821fad6bb5&amp;chksm=ea2e6216d4f6609a07db598f01929c398df28c4afbb597c283345bdfe1c36926f4ff75c95793&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 12 Mar 2024 09:48:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[聊一聊Transformer中的FFN]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia3ZKe0HPOMSDBHOkOgRSyWPUPh1CNeNcicqyNtOzCUN1UhOdClYxuvicUgyJS294I6QSj6ARQ2EV3g/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：潘梓正，莫纳什大学博士生主页：zizhengpan.github.io来自：青稞AI最近看到有些问题[1]说为什么Transformer中的FFN一直没有大的改动。21年刚入学做ViT的时候就想</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526503&amp;idx=2&amp;sn=951f40100ab92e6dc16555de8e7df138&amp;chksm=ea9c10e2a3bc23797cdf69e3ab0b43837d3fc54818949dd80fdb637134290a849db146c1b082&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 12 Mar 2024 09:48:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型的模型融合方法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia3ZKe0HPOMSDBHOkOgRSyWNx7VQabHPRQRgm5EPMnYBxYNmU5ohBtOib9ibr07vDkibxE2lNueTtGIA/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：包包算法笔记今天来讲一下大模型中的模型融合，并给出大模型融合的有效方法的原理和实现。模型融合大家以前用的很多，特别是在判别模型里，属于永远都能稳定提升的那一类方法。但是生成语言模型，因为解码的过</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526503&amp;idx=3&amp;sn=ed84fa266ad3d89f5b8e4300dfef0d75&amp;chksm=ea7e6e3594df5048d3893827ff099156929b1c2ccf65d75f9a4bbc7eee3577e714d85d8783bc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 12 Mar 2024 09:48:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[自我分治解决复合问题: 详解Self Divide-and-Conquer]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagsiatDXqyD6gicicgak1zFNiaQ5hWiat4U8IsKNL7ZRFpCicZJ3w9UiaTOjvxqnpReZMUlbx4KtQZHJQnzA/640?wxtype=jpeg&amp;wxfrom=0"/><p>来自：老刘说NLP（稍作修改）今天介绍下最近特别热的利用LLM评估啥时候使用内部知识和外部知识的论文。现有的工作非常关注大模型本身的知识边界，以达成对于大模型known和unknown的问题能够进行不</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526465&amp;idx=1&amp;sn=763ff2ea8bb2acd0b1da23274f085f24&amp;chksm=eaff9e14f22f05c8af1d613e675ac53e91b066c3c4636ffacf3eef5373e1a321e2cc99867b8e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 11 Mar 2024 14:24:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | 邱锡鹏团队新作：In-Memory Learning 智能体声明式学习]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaib1eqoBLXn1CnTHo40DzRN674yM5mpsIKycCdblHWDgGhArlslOiaMGnA8wnhKxSHoQwYumCI2AaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：探索agent是否可以在不依赖于人工标记数据的情况下与其环境保持一致，提出了一个有意思的研究课题。从智能生物观察到的对齐过程中汲取灵感，我们提出了一种新颖的学</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526465&amp;idx=2&amp;sn=4d9b5e368ae429930d150665cfd3f411&amp;chksm=eaab022756ac1bd19a0b76fd3ca1bee05052d3b9f1de721effcfacfc1faeafab602c5cab49ac&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 11 Mar 2024 14:24:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | 【ICLR24】用语言模型预测表格Tabular]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaib1eqoBLXn1CnTHo40DzRN674yM5mpsIKycCdblHWDgGhArlslOiaMGnA8wnhKxSHoQwYumCI2AaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：深度神经网络（DNNs）的可迁移性在图像和语言处理领域取得了显著进展。然而，由于表格之间的异构性，这种DNN的优势在表格数据预测（例如回归或分类任务）方面仍未</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526465&amp;idx=3&amp;sn=6844426fa9113bdc09bcd23878f0c37b&amp;chksm=ea49671d83f80e78d6b55d10f2bc46e32a14e38dba519355ef7428cbe01a688a7a8363a3d90c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 11 Mar 2024 14:24:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | 使用LoRA微调也会过拟合？探索LoRA中的Dropout]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaib1eqoBLXn1CnTHo40DzRN674yM5mpsIKycCdblHWDgGhArlslOiaMGnA8wnhKxSHoQwYumCI2AaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：以显著的能力，大语言模型（LLMs）已成为许多自然语言处理应用中不可或缺的元素，而参数高效的微调，特别是 LoRA，已经因其轻量级的模型定制方法而备受青睐。与</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526465&amp;idx=4&amp;sn=ce0f9884cf2e2712b4d710782bd60ec3&amp;chksm=ea598ca21652f10132b46f849df4e72887fb4a01af6fd6f25c71b6b0024bc3615b4d0ff6fce5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 11 Mar 2024 14:24:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[详解大模型微调全流程]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahLjMAw7j7vftz4diaIVEoNUjnMLeGvF33jna3HEmjibOabPaWBk5CYL5gVhnibTcdmj3D6KFCStFvXA/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：1050Ti全量微调.，东北大学软件工程原文：https://zhuanlan.zhihu.com/p/684691249声明：本文只做分享，版权归原作者，侵权私信删除！编辑：青稞AI微调实战经</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526390&amp;idx=1&amp;sn=f0ac8f5ab500013ed63a385533436145&amp;chksm=ea82267dc8c402c11f706deb78bea5421c087665bea13104db199249f24462bc46fe1b369c5b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 09 Mar 2024 12:21:11 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | Self-Retrieval:内化检索信息到llm的权重中]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagHDOSxibvHyV7fNXMAiaLtT69uaFuK0kslPAAFstUtlg0w8dYWxiblIiaNIZUibbllIoYkiapjXPvzPWuw/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：Dense Retrieval（DR）现在被认为是一种很有前途的工具，可以通过结合外部记忆来增强大型语言模型（LLM）（如 GPT3 和 GPT-4）的记忆能</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526390&amp;idx=2&amp;sn=95b45b5383601bc169ff9f78d9a52168&amp;chksm=ea177d1e7ac747d0855822c9605875c3015ca3f3fd21d4df51035279792f99d8fe0864f31f0a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 09 Mar 2024 12:21:11 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | Meta新作GLoRe：让大模型识别何时何处需要对推理进行改进]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagHDOSxibvHyV7fNXMAiaLtT69uaFuK0kslPAAFstUtlg0w8dYWxiblIiaNIZUibbllIoYkiapjXPvzPWuw/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：最先进的语言模型可以在数学、科学或代码任务中表现出令人印象深刻的推理提炼能力。然而，最近的研究表明，即使是最好的模型，在没有外部反馈的情况下，也很难确定在何时</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526390&amp;idx=3&amp;sn=37ac468ca65670f25916aff5ec2959fd&amp;chksm=ea01ae58b4621321d7775a26f48d10d8707655de153b07e0d8ec8ebab6d5066b6b286fa0bd8a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 09 Mar 2024 12:21:11 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | 对比偏好优化（CPO）帮助提升LLM的翻译能力]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagHDOSxibvHyV7fNXMAiaLtT69uaFuK0kslPAAFstUtlg0w8dYWxiblIiaNIZUibbllIoYkiapjXPvzPWuw/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：中等规模的大语言模型（LLM）--参数为 7B 或 13B 的模型--表现出良好的机器翻译（MT）性能。然而，即使是基于 13B LLM 的顶级翻译模型（如 </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526390&amp;idx=4&amp;sn=80da05ed9fe3f05d8bc305610639d2a2&amp;chksm=ea7411a92d51bb5992dd1b4ab0db9cc2ef0180e7248f1ec377081ba8e8049cab648a352082bb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 09 Mar 2024 12:21:11 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | 深入分析RLAIF与SFT对大模型alignment的影响]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagHDOSxibvHyV7fNXMAiaLtT69uaFuK0kslPAAFstUtlg0w8dYWxiblIiaNIZUibbllIoYkiapjXPvzPWuw/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：Reinforcement learning with AI feedback（RLAIF）是一种流行的范式，用于提高强大的预训练语言模型的指令跟踪能力。RL</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526390&amp;idx=5&amp;sn=ed0f24062041197af36b13067270fd23&amp;chksm=eabab9ad83fa3890d1937be95678de850053ec382c2ce1479180243420493160604e382c1a46&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 09 Mar 2024 12:21:11 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
