<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[深度学习自然语言处理]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    

    <language>zh-cn</language>
    




















    <item>
      <title><![CDATA[OpenAI o1 self-play RL 技术路线推演]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahC5sVyq22FnFhRA7M8giclFGPlpedxxvnY7yef3r6EnNTiasFjpty6NH5M2hh7yicID69FO0jro3qMw/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：曹宇链接：https://zhuanlan.zhihu.com/p/720106482OpenAI的self-play RL新模型o1最近交卷，直接引爆了关于对于self-play的讨论。在数理</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247530405&amp;idx=1&amp;sn=85cd8225d04ab219de8f9076d4332026&amp;chksm=ea7d896e29c51411f9c8006b3dda639f7290e0f4898ef931e1adae4c02aa18a602c6241e2377&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 17 Sep 2024 12:55:15 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[“博士级”模型GPT-o1折戟中学数学“陷阱”问题，准确率仅为24.3%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahC5sVyq22FnFhRA7M8giclF8dfmicKSicDY3yLUzE7b6aqx2Z5Tls1rbuH9PjUuicdo4mhFQ723m8RUw/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：FudanNLP北京时间9月13日凌晨，OpenAI正式推出最新模型GPT-o1，一时间引发学界与工业界的广泛讨论，相较于先前版本GPT-4o，新模型在各大评测指标上显著提升，号称已达"博士级"</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247530405&amp;idx=2&amp;sn=c8da89dbb6ff58f2e88a0ec893dc5688&amp;chksm=eac2b4dfd2de307041be7c3fc4817c24b4407b423f7dd3c2299453ba643fff39c84bcd4d73dc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 17 Sep 2024 12:55:15 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[简单图解一下线性注意力机制]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajAZKOjhFTYnMhorwBnjxZIn02hTRdtqvslmSvhBD7KVaARkeyISxnEj1QNXgScL1Xug9qkicFrauA/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：刀刀宁链接：https://zhuanlan.zhihu.com/p/718156896线性注意力机制的文章有很多了，在本篇笔记中，我们简单地对各种方法进行一下图解比较，串一下当前的线性注意力机</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247530369&amp;idx=1&amp;sn=5091dc77081b6cdaa2c4aa09061edf81&amp;chksm=ea227fe3c2fa12f683fc208a9ba6cbeb5ff4b60bd71577f90baea0af5f0e374a831ae1fe42b9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 16 Sep 2024 15:49:02 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[人人都能看懂的DPO数学原理]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajAZKOjhFTYnMhorwBnjxZImYouQCutlZm4fY9sOmNDMdjfWcXssXCDGOTiaJ7HEUNUVpXlAjZGKjA/300?wxtype=jpeg&amp;wxfrom=0"/><p>一、DPO在做一件什么事来自：大猿搬砖简记在文章的开始，我们来思考一个问题：如果想让你训练一个能听得懂人类问题，并给出人类满意答案的模型，你会怎么设计大致的训练步骤？一口吃成一个大胖子是困难的，所以不</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247530369&amp;idx=2&amp;sn=cf08c105ba7bfdb6983263416f7af62f&amp;chksm=eaaaf7a08444ceb75f5831a40f41d424591c1de579b27c0d9a8b4643c197f32600cd30ad28ca&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 16 Sep 2024 15:49:02 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[技术上，如何复现 o1?]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagGZenX4LXy3M8yoliboFIq47tFTI2cOzXB0SiaguXcKfTb7pfU0NZric8iaEqw2NUD8pOwRjgZ8ia1xBA/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：周舒畅链接：https://zhuanlan.zhihu.com/p/720127190基础模型搞 o1 首先需要一个基模，这个基模必须是：能进行“长”生成。注意这和“长 context”不是一</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247530330&amp;idx=1&amp;sn=243a8ae021c7252d644a2b8aa56cf481&amp;chksm=eac5d6c78f789052b34a71811accf35f5e6d4b4d9e8add81658615d59f09094eb34cb191e90d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 15 Sep 2024 13:22:55 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OpenAI o1背后的技术：LLM的快思考与慢思考路线之MCTS]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagGZenX4LXy3M8yoliboFIq4UUJzJoxgfP0Fxuic0d9JC3drUzY8QYib2MQDuHRAtZk4e8y58UkSiagHQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：皓天 链接：https://zhuanlan.zhihu.com/p/659230417在上一篇文章[1]中，我们初步探索了基于EBM-MCTS的方法，并在多个数学数据集上完成实验验证。相比使用</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247530330&amp;idx=2&amp;sn=073985546d01e00231278970ca43b1c3&amp;chksm=ea84e3c9061117516838fcf0a84c610a6a8ce903a87aca61edb059944649c2aafd011b1ece5a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 15 Sep 2024 13:22:55 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2025智谱AI校园招聘正式启动！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagGZenX4LXy3M8yoliboFIq4a7vMNqEaGxBN7S7CeYhozzeJibdj5xoAb2k74I4DEUA2HES2ribQicGhg/300?wxtype=jpeg&amp;wxfrom=0"/><p></p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247530330&amp;idx=3&amp;sn=7362f2bc6293855289eb172edbb82a53&amp;chksm=eab0cfb60daf15300b657d2eb35b6d44c5a44853922005f00b245cb2ee641e7033bbafe5ab5a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 15 Sep 2024 13:22:55 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[如何用1024张显卡训练一个模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bah9yWXAm1bx4425eIiaUwIiaiaTkzKCzuWC9rI609Kst9S5OMSFMRJXyibNPDOY8IJW5Jd9YHppUEZAtw/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：你的真实姓名链接：https://www.zhihu.com/question/650979052最近看到知乎一个回答，把千卡训练的难度吹上天了。但其实真正用过千卡就会发现也就那么几个点。于是想</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247530294&amp;idx=1&amp;sn=15cfd3cbc240394bec555231c4f991d8&amp;chksm=ea4606c1d9776b5be562e1895eeff98b96cd6b7c7eb2afdd21cb187d1317d720b93be5483b0d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 14 Sep 2024 14:03:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[黄哲威与丁霄汉为初学者撰写AI会议论文写作手册，独具一格！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bah9yWXAm1bx4425eIiaUwIiaiaiaBjvWq8LUxvgqmJlZlpStapdpBM7x5Y7DfJQu985XOalBGo7TXhMKw/300?wxtype=jpeg&amp;wxfrom=0"/><p> 作者: 黄哲威、丁霄汉知乎：https://www.zhihu.com/question/438031462/answer/3624649447链接：https://github.com/hzwer</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247530294&amp;idx=2&amp;sn=6d9419cb01cc9296990623f9f205d2ad&amp;chksm=eaeb68f117b0a480605d5568d851269a19f865126086d626565a40f1c0f199e86e9c71bea568&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 14 Sep 2024 14:03:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[RWKV作者对OpenAI 发布 o1 系列模型的看法，很深刻]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahc1TuMYrLVjlQwkfY7LK4TWiateDR5bGRUqtrE1I2OC5j32AJxE4cYdTrKxGwv1vBNmicQnQe9wDKA/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：PENG Bo链接：https://www.zhihu.com/question/666991594/answer/3624168868大家都知道长期CoT可以提升性能，而且很快我们会看到其它家</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247530267&amp;idx=1&amp;sn=f4af702820978a91f17c4be7d35988b7&amp;chksm=ea664fccb2c72032b85b7b8dc263f311277c44f056bc4a86315d4b0b9571013464fee913802b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 13 Sep 2024 04:18:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[小模型在大型语言模型时代的角色：一项全面调查]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahc1TuMYrLVjlQwkfY7LK4TDaibr8ibgbStr5VzLjTqkqgyp7Oicj3gvicCt6eiaeACgMYY9N6icCpwqkjg/300?wxtype=jpeg&amp;wxfrom=0"/><p>这篇论文探讨了在大型语言模型（LLMs）时代小型模型（SMs）的角色，特别是它们在协作和竞争中的表现。论文：What is the Role of Small Models in the LLM Er</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247530267&amp;idx=2&amp;sn=c31c1fec72c3bb62dfa598263bb568c2&amp;chksm=ea0c3d8bffb7f3b18e843aeeef27ebb01864c57cb81e71116a9559d69a9c6dfab71c6b98fe08&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 13 Sep 2024 04:18:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2万字的SFT for Alignment 总结纪要]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiafc1RFGJeZhbYvLsCcpcFM8JqFEAWibGnNGPKLYqxtICxrO63Dczq2qBl0jtMZClMNYEFkbAlcCDQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：张峻旗链接：https://zhuanlan.zhihu.com/p/717553974本文是个人大模型学习笔记的第二十五篇，以18K再次刷新了单篇字符记录，感兴趣的话可以点击专栏阅读其余笔记，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247530233&amp;idx=1&amp;sn=d76435f1541362dc7df3d77f2b56dc18&amp;chksm=ea0694f6d1068a42e6a8fc3ab380f645ffa5f12a56e4a7590aac190b62d0fcfd64b55fe38843&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 12 Sep 2024 15:05:16 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[中科院提出GPT-4o实时语音交互的开源对手：Llama-Omni]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiafc1RFGJeZhbYvLsCcpcFMVg8vrcmb34fURUWYibmWVutJRt5AYmvKR2tRdedRusatklCJ7VyC2bQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：LLaMA-Omni: Seamless Speech Interaction with Large Language Models地址：https://arxiv.org/pdf/2409.0</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247530233&amp;idx=2&amp;sn=231c7b5f293ddd570e0ca3f102d8907f&amp;chksm=ea4f80dd2e4f816f8a7448283a6b66a221dbe733bfb6a705fbe7c36720cc2e85162fdd2174c8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 12 Sep 2024 15:05:16 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[研究表明，LLMs的幻觉问题是我们永远无法逃避的...]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiafc1RFGJeZhbYvLsCcpcFMvBUicggtY0C2whDBbjSS0uyUbMALTfebSib89ECtkmPfjB3KkFfI181A/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：LLMs Will Always Hallucinate, and We Need to Live With This地址：https://arxiv.org/abs/2409.05746研究背</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247530233&amp;idx=3&amp;sn=a2148b4e87c9018df8561bade19d5bd2&amp;chksm=eac43c44490b6a848e6719c67ceec8645026d836fece3d62c7b7c37d2d9e5261f3ba90c25024&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 12 Sep 2024 15:05:16 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[探究大模型微调 Lora 的不同形态(上篇): AdaLora、 AsLora、 PiSSA、 DoRA]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahxGzA2ppWZrRV8IEAYiaU3FW4qrWQibzyEib2vGkNibkQFfx7HlCkZNgMibohyfJ06RZIOmBuHch6fe4g/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：周星星链接：https://zhuanlan.zhihu.com/p/719438707排版：AI椰青@深度学习自然语言处理 公众号前言最近本人一直在研究 SFT 的落地工作，其中 LoRA 是</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247530186&amp;idx=1&amp;sn=e61e2f3a3f64e075a94824a0c30f73c3&amp;chksm=eab5dc6bee13e9ede0e52ec9e5be505420323b1ccb0cb9efb924447cd07d8eb0d057bbad6501&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 11 Sep 2024 14:49:38 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[AnyGPT | 基于离散表示统一多模态理解与生成：把一种新模态当作一门外语 -- NICE27期]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahxGzA2ppWZrRV8IEAYiaU3FGT1OkdPwzgEJKPEiaQO5ibk2qnB8GwicPzSkTkAuhUCDBwfTj3dnrbUjA/300?wxtype=jpeg&amp;wxfrom=0"/><p>主题基于离散表示统一多模态理解与生成：把一种新模态当作一门外语时间2024.9.14 20:00-21:00 周六入群论文：AnyGPT: Unified Multimodal LLM with Di</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247530186&amp;idx=2&amp;sn=4076ce39610f66d44afec4115f0a4413&amp;chksm=eae45b90731034ea50dff645548bcefae18c86129c81591ed1dece3052a0c6380a9392ca4181&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 11 Sep 2024 14:49:38 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[“晚期分块”：用长上下文嵌入模型拯救文本检索]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahxGzA2ppWZrRV8IEAYiaU3F5kArxSSjpCmgCZRibvt2AWK8jR7A8vzbaCZB1iabz87cEJRnBPmGtctw/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：Late Chunking: Contextual Chunk Embeddings Using Long-Context
Embedding Models地址：https://arxiv.or</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247530186&amp;idx=3&amp;sn=e71a090979cbf36c86bd62e054c2e981&amp;chksm=ea0ec863a2a5ee64faa97632e701b3f207de155364e284e86314c795499233972acdab5d22e2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 11 Sep 2024 14:49:38 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Sirius：一种高效的上下文稀疏性校正方法，恢复稀疏模型在推理任务上的性能]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahxGzA2ppWZrRV8IEAYiaU3FwT441jyWr08n4kldUKU64nBQulqXJdWmFETmpLLU8tZWPtqs9iabo2w/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：Sirius: Contextual Sparsity with Correction for Efficient LLMs地址：https://www.arxiv.org/abs/2409.0</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247530186&amp;idx=4&amp;sn=ab78bc470146524ec3761d9e8c31c298&amp;chksm=ea60c3909ece491de7ade3fc15d54d6865c9f05f3248e3050e588bc843914d88dcef33958d27&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 11 Sep 2024 14:49:38 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
