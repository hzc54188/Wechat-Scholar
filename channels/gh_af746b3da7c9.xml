<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[深度学习自然语言处理]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    

    <language>zh-cn</language>
    


















    <item>
      <title><![CDATA[全面解析LoRA、QLoRA、RLHF，PPO，DPO，Flash Attention、增量学习等大模型算法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagWo55Xn4teoF7yT93rwpicOoS9b7j62Xe1s04eVP0YlXAC5J9EicHZYTVbmRbsEBUw5XKI9a6GQIYg/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着大模型的飞速发展，在短短一年间就有了大幅度的技术迭代更新，从LoRA、QLoRA、AdaLoRa、ZeroQuant、Flash Attention、KTO、蒸馏技术到模型增量学习、数据处理、开源</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527194&amp;idx=1&amp;sn=e9439999d46eb2c4987061d8d53c275a&amp;chksm=ea0df41f1cdd732cb15061e3ed4bca93b94545693c6ba646bfc14ec4336a08abe5f1ec8b2dd2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 07 Apr 2024 02:33:50 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[RAG实践中的关键模块解析]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagWo55Xn4teoF7yT93rwpicOBEBqTuhfvWh8HYqOkxvibFCxaXdctZhl0QLtUfep34M0Y8ZQunpF0ibA/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：孙鹏飞，南京大学 · 计算机科学与技术，互联网行业从业人员声明：本文只做分享，版权归原作者，侵权私信删除！原文：https://zhuanlan.zhihu.com/p/682253496编辑：</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527194&amp;idx=2&amp;sn=aef77d67acbd9cc7db697711f4ad21f6&amp;chksm=ea224ac74e2715aedf6c6dbd47cb098afd3ac3aeff44ba65db3a7951d29ead130906e61c5e36&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 07 Apr 2024 02:33:50 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[复旦MOSS团队：数据配比的scalinglaw]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagWo55Xn4teoF7yT93rwpicOiaOGs9EdqqFQM2rYic4ItPJaCE4oGLJvyZiaVafMf6Cd8eWJqMrv6ppJQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：包包算法笔记在前文我们提到过，大模型训练中数据的多样性和质量是最重要的两个维度，并且在结尾挖了一个大坑，希望有大佬愿意研究多样性的scaling laws。这次，复旦MOSS团队带着数据配比sc</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527194&amp;idx=3&amp;sn=e49f6c0aaaddd6d1c89001e1f84eae32&amp;chksm=eaff9e2a54ba6ddbb2e10ee2f8016a24aeb93970fd4854203cf99fec84ef5def3e2544a18ca6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 07 Apr 2024 02:33:50 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[长文本之罪：Claude团队新越狱技术，Llama 2到GPT-4无一幸免]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagWo55Xn4teoF7yT93rwpicOicp314zx0hiaURDrGSglDvr5bibQQm12TYogNHnqpZ94rDJgPEtOAaaeg/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道作者：杜伟、陈萍Anthropic 发现一种新型越狱漏洞并给出了高效的缓解方案，可以将攻击成功率从 61% 降至 2%。刚刚，人工智能初创公司 Anthropic 宣布了一种「越狱」技术（</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527194&amp;idx=4&amp;sn=9fe5a5dea900cc4bfb000ebc9acefe35&amp;chksm=ea2e69ec2929bc4a6cd45bc752d0e060d34b8329211651118fbb7430fe1b1eacd6bed640f569&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 07 Apr 2024 02:33:50 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[从 大模型接受弱智吧再教育 谈指令微调对齐]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahgLwWzwMYxDNvdjWDfcofTrmk0LnGnGAcmLLO8sEgPaZKHMmjLQ6LzW1S67oTEjwthXEdYgH1RHA/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：hzwer原文链接：https://zhuanlan.zhihu.com/p/690667537仅学术分享，侵删这两天一篇论文以离谱方式火了：CQIA：“用弱智吧数据训练的 AI 爆杀了所有中文</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527163&amp;idx=1&amp;sn=6c2d6bf3594b5201c52881630044ecb2&amp;chksm=ea2aa0c5959e97c86265cbcea09b58a4a33178d163671a9a671b23c65cc5fe822d79c242effa&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 04 Apr 2024 10:01:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | RLRF: 从反思反馈中不断迭代进行强化学习对齐]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahgLwWzwMYxDNvdjWDfcofTvFIQJ5VKDGrr016eIX7XwOcT1BbtM95hfvHjxa6OvQUt1B1EiaBGia1Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：尽管 RLHF 在使 LLM 与人类偏好相一致方面大有可为，但它往往会导致表面上的一致，优先考虑风格上的变化，而不是改善 LLM 的下游性能。不明确的偏好可能</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527163&amp;idx=2&amp;sn=ec0cfedef98843c710d3420d61f52b43&amp;chksm=ea1d70b19a543682530b3cdca5f5c5502a2dc214070ba02f7222deca5ebc9ee74f648e4900b9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 04 Apr 2024 10:01:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | 一次编码平行解码：高效Transformer解码]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahgLwWzwMYxDNvdjWDfcofTaJcsKibBMYNsK1NgowaS7syPCl3snNZU2kssSP3U5dHvFWs07Qhfsmg/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：基于Transformer的 NLP 模型功能强大，但计算成本较高，限制了应用场景。经过微调的编码器-解码器模型在专业领域很受欢迎，其性能优于 GPT-4 等</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527163&amp;idx=3&amp;sn=114cf4ec777732490531ab76845c637d&amp;chksm=ea42d2342e3183b712c87cdc87f38c5ae29cd6447da94b62ac79283903da5cbf6d21b148b65f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 04 Apr 2024 10:01:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | NAACL'24：自生成翻译记忆缓解翻译持续学习遗忘问题]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahgLwWzwMYxDNvdjWDfcofTVpa9Rlt2sUtSKKnSAq8QUvgZCsDydzX3ks4libtavx0HribfsGq7xyKQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：现代神经机器翻译系统在几种不同的语言中表现出强劲的性能，并在不断改进。然而，它们的持续学习能力仍然受到灾难性遗忘问题的严重限制。在这项工作中，我们利用enco</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527163&amp;idx=4&amp;sn=fc226988e6685cee9941423d8bdd1270&amp;chksm=eaa699a9b6fd4ea5e31732682fc45c5296a957bbf5251997a03743d54452b8064cbbb2442700&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 04 Apr 2024 10:01:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[整理了2000篇2024年顶会论文合集【附下载】]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaiby9gaSjXhibiarawTzXCF7zrkTZH6ylVyyYK0nc7UxjEKkUVM71ibFaGcBsmpmYF3Ac9ic0rlbLlr6g/640?wxtype=jpeg&amp;wxfrom=0"/><p>众所周知，论文是人工智能学习的基石，因为论文展示了不同方向最新的研究成果，了解并且掌握这些学习成果，会对自己写论文助力不少。这次我整理了AAAI 2024 / CVPR 2024 / ICLR 202</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527113&amp;idx=1&amp;sn=339259dab1976710f52157bfbfa612cb&amp;chksm=eadd4fe8b65caa36cfa5df6ca655303fb06dafe1b12c799a6bf436057f4f7a8b9bccf9a43ba0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 03 Apr 2024 07:43:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[首个符号大模型！Symbol- LLM：探索自然语言与符号之间的能力平衡]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaiby9gaSjXhibiarawTzXCF7zHyQuHFrx339cJxnAHmOlUUicBUMQw2gYIkywmy1EEznflwPo41Tibgibw/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享导读当前，大型语言模型 (Large Language Model, LLM) 大多强调以自然语言 (Natural Language, NL)为媒介进行交互、推理以及反馈修</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527113&amp;idx=2&amp;sn=0a47ee91b67348b1504f5514be7a98f3&amp;chksm=eac5c5e4d5d8300dbee227e16e2d6e9eabb726ce7988eb1cd68f2200f31bc428afa1066d176f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 03 Apr 2024 07:43:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[近期RAG技术总结和串讲（4w字RAG文章纪念）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaiby9gaSjXhibiarawTzXCF7zb3XPkwXjLQWSwxOMMyVOL0nf7SsVSgD5YbMBOql43F3oSTHqOdUTbQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：CS的陋室最近写的RAG内容已经挺多了，然而内容逐渐变得零散，我今天给大家总结一下RAG的有关内容，同时给大家把有关内容串起来。当然，串起来的更多是概述和摘记，让大家对RAG的基础有更整体的了解</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527113&amp;idx=3&amp;sn=8f2de0a2226307e3c34fab4620a2ec91&amp;chksm=eaefbf13bf29923b26d1fe5b71185dee28b27fbdc48a6017ea609f135138ddefd7f0c3542c73&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 03 Apr 2024 07:43:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LA-Light：大语言模型开始接管城市交通了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahuhGEqWa1WMCwpZgX2YPhnVKUY8vmARu8S8YribsSMX3SlNGeVTRIKCI7StfAGYzhCna2WmiaabPmA/640?wxtype=jpeg&amp;wxfrom=0"/><p>LA-Light：大语言模型开始接管城市交通了来着：大语言模型论文跟踪LLM应用 交通管理 信号控制摘要面对大都市交通拥堵这一牵涉广泛且棘手的问题，解决之道在于有效管理，而交通信号控制系统在此举足轻重</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527077&amp;idx=1&amp;sn=ec124e02eecfa87da2d9367f0d359a29&amp;chksm=ea76778f3eedcc53a4a488733e13334727c64716003b3faaa1789d33f4dbc458f0eaaec53311&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 02 Apr 2024 15:31:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[聊聊 MOE + LoRA 微调新方式]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahuhGEqWa1WMCwpZgX2YPhnUj2Vib96CoCZBb8oFpGhibUJZZ7JR9qia6FJ1icGav1wRFCefKIJ1OWxtw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：无恶不作，华为2012实验室 · 软件开发声明：本文只做分享，版权归原作者，侵权私信删除！原文：https://zhuanlan.zhihu.com/p/686851113编辑：青稞AI1.背景</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527077&amp;idx=2&amp;sn=ea2ce0154a6c428b6c68a1ea1e1cc4ab&amp;chksm=ea8baf85fa23f15fa4164e602318a1ac6e54bfb12623f25f5c19ff7efb7ac5b71a8636e43a81&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 02 Apr 2024 15:31:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | InsCL: Data-efficient 持续指令学习]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahuhGEqWa1WMCwpZgX2YPhnLoiaefgfa0yNicT2bW944ILkeR3yzdHIBYwMvY4MfXibOLwcJUFkJpibQw/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：Instruction tuning 可有效优化大型语言模型（LLM），使其适用于下游任务。由于实际应用中的环境不断变化，LLMs 需要在不发生灾难性遗忘的情</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527077&amp;idx=3&amp;sn=014aabad2f75281ec2068a25f2cd0db3&amp;chksm=ea06aa51315190600d0004ac1a693ad5c3ac343a3cfc964b33bdefa76b8245dbfb7930ecee50&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 02 Apr 2024 15:31:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | AFLoRA: 自适应冻结权重进行PEFT]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahuhGEqWa1WMCwpZgX2YPhnLoiaefgfa0yNicT2bW944ILkeR3yzdHIBYwMvY4MfXibOLwcJUFkJpibQw/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：我们提出了一种新颖的参数高效微调（PEFT）方法，被称为自适应冻结低阶自适应Adaptive Freezing of Low Rank Adaptation </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527077&amp;idx=4&amp;sn=54dcb43cee7029ee2770d2ed5ff331e3&amp;chksm=ea7ef667ae94c18b1e3e0f9134692d1fefcdbe700b1fa07e36fda658905a3e3d75cb86edec26&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 02 Apr 2024 15:31:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[基于LLM的多Agent框架在金融市场数据的应用]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahuhGEqWa1WMCwpZgX2YPhnS3Zuok7d3gouycrCx79F0HPPVBkcDic1n23Vwdyh8D8rznZ8vW2CyZg/300?wxtype=jpeg&amp;wxfrom=0"/><p>基于LLM的多Agent框架在金融市场数据的应用来着：大语言模型论文跟踪Agent 金融市场 异常检测Enhancing Anomaly Detection in Financial Markets </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527077&amp;idx=5&amp;sn=5bf33f8324be9d4a9f3b829caaae1d72&amp;chksm=eaca378c6687ff2a7b3203a639b7d7825e704f0c61510733406e87da73cc417c350053695dac&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 02 Apr 2024 15:31:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解大模型计算加速系列之：vLLM核心技术PagedAttention原理]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiahichdmLG8icTCIsoe8OyicESMsOqCNej6ezqknosR8H4AbOutpxAJfGiaDtZh8OiaN5SkZ22HV7DibLgQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>来自：大猿搬砖简记大家好，今天想来介绍下当红推理框架vLLM的核心技术PagedAttention。PagedAttention的设计灵感来自操作系统的虚拟内存分页管理技术。vLLM的论文是在假设读者</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527028&amp;idx=1&amp;sn=27b2dadb681be9764288ee78ee734280&amp;chksm=ea557647263cb634fbe82fb5fb8c17b7851223e4651f4f6d6255ca19332f1f196cf72ff87296&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Apr 2024 10:10:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | BiLoRA: 基于双极优化消除LoRA过拟合]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajtgYnjwHsznpBEHSEKPkZH2MCobV4YAcAwycVFP3tZNNpc6oxffiaGf7QxaHpouhqIxFGKxClEEFQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：低秩适应（LoRA）是在下游任务中通过学习低秩增量矩阵对大规模预训练模型进行微调的一种流行方法。虽然与完全微调方法相比，LoRA 及其变体能有效减少可训练参数</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527028&amp;idx=2&amp;sn=552f8fea486c67d2a0ed4fa2ac8a9e66&amp;chksm=ea2eab2322828dafbef56884583902043a8a4e85bbbc7cfdb597adc8e3f0bd5a286fcfd995b2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Apr 2024 10:10:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | [COLING'24] 探索数据多样性对LLM对齐的影响]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajtgYnjwHsznpBEHSEKPkZH2MCobV4YAcAwycVFP3tZNNpc6oxffiaGf7QxaHpouhqIxFGKxClEEFQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：与人类偏好对齐可以防止大型语言模型（LLMs）产生误导性或有毒内容，但同时需要高成本的人类反馈。假设人工标注的资源有限，可以考虑两种不同的分配方式：标注更多样</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527028&amp;idx=3&amp;sn=9e564696a9ae71563ab2718bcf910524&amp;chksm=eaa43585c4a7218c078161ea13d6b68fd487c4a44226b3e641d68de99f6cfacfa370357ce8ee&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Apr 2024 10:10:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | ReAct Meets ActRe: Agent规划自主解释]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajtgYnjwHsznpBEHSEKPkZH2MCobV4YAcAwycVFP3tZNNpc6oxffiaGf7QxaHpouhqIxFGKxClEEFQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：语言代理通过对基础模型进行推理，展示了自主决策能力。最近，人们开始利用多步骤推理和行动轨迹作为训练数据，努力训练语言代理以提高其性能。然而，收集这些轨迹仍然需</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527028&amp;idx=4&amp;sn=fac7786436364768cdcd538b3253e9b2&amp;chksm=ea9ea28fe7ae026b08079be222fafd364c0ae4a065ddabe712c168cfe22a4f6ab4fce6ef7b9b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Apr 2024 10:10:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[6行代码，1行命令！轻松实现多模态（视觉）模型离线推理&amp;在线服务]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiahichdmLG8icTCIsoe8OyicESVelR20mUou5DicoLfcPibHz7ictjr4KM5MRVyZqOz04tNgjxyhKZK58Hw/300?wxtype=jpeg&amp;wxfrom=0"/><p>早在去年年底，LMDeploy 已经悄悄地支持了多模态（视觉）模型（下文简称 VLM）推理，只不过它静静地躺在仓库的 examples/vl 角落里，未曾与大家正式照面。LMDeploy 开源链接：h</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527028&amp;idx=5&amp;sn=dcdb478001765f5277215be999ff9c16&amp;chksm=eae0d5267959bbdd873569a77d79a99c370cc5070ebafac3fefa19ffc531f535c3ad384b14aa&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Apr 2024 10:10:41 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
