<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[深度学习自然语言处理]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    

    <language>zh-cn</language>
    























    <item>
      <title><![CDATA[详解大模型微调全流程]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahLjMAw7j7vftz4diaIVEoNUjnMLeGvF33jna3HEmjibOabPaWBk5CYL5gVhnibTcdmj3D6KFCStFvXA/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：1050Ti全量微调.，东北大学软件工程原文：https://zhuanlan.zhihu.com/p/684691249声明：本文只做分享，版权归原作者，侵权私信删除！编辑：青稞AI微调实战经</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526390&amp;idx=1&amp;sn=f0ac8f5ab500013ed63a385533436145&amp;chksm=ea82267dc8c402c11f706deb78bea5421c087665bea13104db199249f24462bc46fe1b369c5b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 09 Mar 2024 12:21:11 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[每日论文速递 | Self-Retrieval:内化检索信息到llm的权重中]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagHDOSxibvHyV7fNXMAiaLtT69uaFuK0kslPAAFstUtlg0w8dYWxiblIiaNIZUibbllIoYkiapjXPvzPWuw/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：Dense Retrieval（DR）现在被认为是一种很有前途的工具，可以通过结合外部记忆来增强大型语言模型（LLM）（如 GPT3 和 GPT-4）的记忆能</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526390&amp;idx=2&amp;sn=95b45b5383601bc169ff9f78d9a52168&amp;chksm=ea177d1e7ac747d0855822c9605875c3015ca3f3fd21d4df51035279792f99d8fe0864f31f0a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 09 Mar 2024 12:21:11 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[每日论文速递 | Meta新作GLoRe：让大模型识别何时何处需要对推理进行改进]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagHDOSxibvHyV7fNXMAiaLtT69uaFuK0kslPAAFstUtlg0w8dYWxiblIiaNIZUibbllIoYkiapjXPvzPWuw/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：最先进的语言模型可以在数学、科学或代码任务中表现出令人印象深刻的推理提炼能力。然而，最近的研究表明，即使是最好的模型，在没有外部反馈的情况下，也很难确定在何时</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526390&amp;idx=3&amp;sn=37ac468ca65670f25916aff5ec2959fd&amp;chksm=ea01ae58b4621321d7775a26f48d10d8707655de153b07e0d8ec8ebab6d5066b6b286fa0bd8a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 09 Mar 2024 12:21:11 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[每日论文速递 | 对比偏好优化（CPO）帮助提升LLM的翻译能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagHDOSxibvHyV7fNXMAiaLtT69uaFuK0kslPAAFstUtlg0w8dYWxiblIiaNIZUibbllIoYkiapjXPvzPWuw/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：中等规模的大语言模型（LLM）--参数为 7B 或 13B 的模型--表现出良好的机器翻译（MT）性能。然而，即使是基于 13B LLM 的顶级翻译模型（如 </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526390&amp;idx=4&amp;sn=80da05ed9fe3f05d8bc305610639d2a2&amp;chksm=ea7411a92d51bb5992dd1b4ab0db9cc2ef0180e7248f1ec377081ba8e8049cab648a352082bb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 09 Mar 2024 12:21:11 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[每日论文速递 | 深入分析RLAIF与SFT对大模型alignment的影响]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagHDOSxibvHyV7fNXMAiaLtT69uaFuK0kslPAAFstUtlg0w8dYWxiblIiaNIZUibbllIoYkiapjXPvzPWuw/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：Reinforcement learning with AI feedback（RLAIF）是一种流行的范式，用于提高强大的预训练语言模型的指令跟踪能力。RL</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526390&amp;idx=5&amp;sn=ed0f24062041197af36b13067270fd23&amp;chksm=eabab9ad83fa3890d1937be95678de850053ec382c2ce1479180243420493160604e382c1a46&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 09 Mar 2024 12:21:11 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[马斯克回应OpenAI："Change your name"]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahCpdz8a0wshPcPvlk9vkjqyiclNAExE7buPoPUBEiaGuQonoMZ5ichQIaysqJ1x5GibFLUxfvBNiaqzbA/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近，整个AI圈都在关注OpenaAI和SpaceX首席执行官埃隆·马斯克的官司。继OpenAI驳回“埃隆的所有主张”（dismiss "all of Elon's claims"）之后，今日马斯克在</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526302&amp;idx=1&amp;sn=61774958b69a404b464ab27c1b9b891e&amp;chksm=ea8747cc79cd001abd28537481766769637c307e4d8b05c2ecb4d6b17ff745c76d0ef6026634&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 06 Mar 2024 12:22:57 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | “A是B的dad”<=>“B是A的son"，大模型的“逆转诅咒”]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahCpdz8a0wshPcPvlk9vkjqdCVq2EnF5RMUiaRgrkgdJbxgvw9cXBoI8g9ajicQQNntsiczHVVUBG8Ww/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：虽然大语言模型 (LLM) 在不同的任务中取得了令人印象深刻的表现，但最近的研究表明，因果 LLM 遭受着“逆转诅咒”。 一个典型的例子，模型知道“A的父亲是</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526302&amp;idx=2&amp;sn=eced688699bbab8db091d0346b09487c&amp;chksm=eafac9bd8176674512dad596fb4d9f76425c756e49b18fa73c0130c154fee316aa37b51c7176&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 06 Mar 2024 12:22:57 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | VisionLLaMA: 视觉生成和理解的新基准模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahCpdz8a0wshPcPvlk9vkjqdCVq2EnF5RMUiaRgrkgdJbxgvw9cXBoI8g9ajicQQNntsiczHVVUBG8Ww/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：大语言模型建立在基于transformer的架构之上，用于处理文本输入。LLaMA 在众多开源实现中脱颖而出。同样的transformer能否用于处理二维图像</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526302&amp;idx=3&amp;sn=201d05d5c7afa49129d5a4a14fefed7f&amp;chksm=eae5393048d3a06a8ec53e997588322d5ec2c73e1863afe5a9ee545e65b21d73b1b45541b21a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 06 Mar 2024 12:22:57 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | ICLR'24：Transformer能捕捉物体间的空间关系吗？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahCpdz8a0wshPcPvlk9vkjqdCVq2EnF5RMUiaRgrkgdJbxgvw9cXBoI8g9ajicQQNntsiczHVVUBG8Ww/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp【ICLR2024】Can Transformers Capture Spatial Relations between Objects?摘要：物体之间的空间关系是</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526302&amp;idx=4&amp;sn=7b8025f4554b50b9931d89d5d41ecd49&amp;chksm=ea25c06ffaa752dcd5bcdd66598d68ece1958a5be545aa02c951011bc5379503741f3bf5bbff&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 06 Mar 2024 12:22:57 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Llama 2 高调开源，大模型微调我已经上手了(附99个大模型微调模型/数据/工具)!]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia5B8nlrH1E3yxIkqWYt6xkE3qUQywQyX30WxkEtFWkXLt0V36yIicrogmYMhSvAHo8lYWlib1DicsQw/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近出现了一系列令人激动的开源大语言模型，如meta的LLaMA、清华的ChatGLM等。伴随大模型一起爆火的，还有大模型的微调方法。然而随着模型规模和任务数量的增加，对整个Transformer模型</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526210&amp;idx=1&amp;sn=47a5bf39cdc319e6c111fa59548b5d4a&amp;chksm=ea7cbc236855625f46aeb6ae5a73c2aa5a952222845ce30f639ce5de66e9a33cfad6d24f0518&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 05 Mar 2024 06:22:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | I-LoRA：解决PEFT中的灾难性遗忘问题]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia5B8nlrH1E3yxIkqWYt6xk5q7V9BwibnDlv7uRR3BIibzDciaXhs0ibW42cQfnrZ5LMyxreLRQibbticNA/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp师姐1个月攻下LLM的所有知识的捷径Analyzing and Reducing Catastrophic Forgetting in Parameter Effi</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526210&amp;idx=2&amp;sn=c8079e53ef2770ede1c0d72ade8c1599&amp;chksm=ea65b205f307023aad09b1bed717ed43498b8e2c6ed599297f44ffcefb21df509d65075abe6f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 05 Mar 2024 06:22:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | 检索是更准确的生成（RAG相关）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia5B8nlrH1E3yxIkqWYt6xk5q7V9BwibnDlv7uRR3BIibzDciaXhs0ibW42cQfnrZ5LMyxreLRQibbticNA/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp师姐1个月攻下LLM的所有知识的捷径Retrieval is Accurate Generation摘要：标准语言模型通过从固定、有限和独立的词汇表中选择token</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526210&amp;idx=3&amp;sn=b977d47d9c0449167171979e2b0a99ff&amp;chksm=ea34ae8538310ec8845ef0db02bdbac940eb87bc1aaaab2f52078f2985a2bf375b8ad256d956&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 05 Mar 2024 06:22:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | 持续学习会给大模型带来什么？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia5B8nlrH1E3yxIkqWYt6xk5q7V9BwibnDlv7uRR3BIibzDciaXhs0ibW42cQfnrZ5LMyxreLRQibbticNA/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp师姐1个月攻下LLM的所有知识的捷径Investigating Continual Pretraining in Large Language Models: In</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526210&amp;idx=4&amp;sn=61e268f0910bcc6dc9bb8747143d8f7d&amp;chksm=ead0923a0aa133c0f158896f6f9ad9dc124d64b19fa7ddb1f30dc281fbb3da7ceecc894bae54&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 05 Mar 2024 06:22:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | 大模型是如何处理multilingual场景的？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia5B8nlrH1E3yxIkqWYt6xk5q7V9BwibnDlv7uRR3BIibzDciaXhs0ibW42cQfnrZ5LMyxreLRQibbticNA/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp师姐1个月攻下LLM的所有知识的捷径How do Large Language Models Handle Multilingualism?摘要：大语言模型（LLM</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526210&amp;idx=5&amp;sn=c8ef3580d71eb22fd971729332244b26&amp;chksm=eac85623b0ffd00b070a049e1b5e60eba24796b23afd1a1ba46990407d4c33ba4cdb1adfec21&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 05 Mar 2024 06:22:20 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[全栈大模型微调框架LLaMA Factory：从预训练到RLHF的高效实现]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaSWUfBaqRzXFEf3QHaOF4jiamLIvrtv3y0b9Jh5zEW3ic3qwVzrSjgicY0Qrg2JJ5ZFe4d5GThZuRjg/640?wxtype=jpeg&amp;wxfrom=0"/><p>主题全栈大模型微调框架LLaMA Factory：从预训练到RLHF的高效实现个人简介郑耀威，北京航空航天大学博士生。以第一作者在CVPR、AAAI、WWW等国际会议发表多篇论文，担任AAAI、EMN</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526170&amp;idx=1&amp;sn=b6a46827c8487e79cd30a9a4cdb8d6c4&amp;chksm=ea76e2133fbdb2a537dde5e844c1a8b9410d4ff358045c44063459baddaa6a9ba19c0ccd22ca&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 04 Mar 2024 15:26:05 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[从0开始预训练1.4b中文大模型实践]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagkKMfGIPj1sxLHv1ibfqzGlpeeHnYa2wN2g99173g9SibWB2ZD4HoSiay4ia0zh9UtWvtdBcrCXGp7NA/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：Lil2J@知乎（已授权）链接：https://zhuanlan.zhihu.com/p/684946331简介这篇文章主要记录了我个人对1.4b中文大模型的实践复现过程。我选择了QWEN作为基</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526159&amp;idx=1&amp;sn=5c9de926bc62fdcac8e227e3d392827a&amp;chksm=ea81e2c8da39f61b6f986d42ffa5ebeac8ba31913715a15f1ed909ffad4f8a8a08f38b4c7c23&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 02 Mar 2024 12:25:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[合成数据(Synthetic data)微调大语言模型实战指南：背景、方案、案例、代码、评估]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagkKMfGIPj1sxLHv1ibfqzGlxfZkbNtCqicLbR5ynhTL1lbaLsWMpygnWTiaicYKDGRbJMfWE6fPbFrOA/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：旺知识应该微调自己的模型还是使用公开大语言服务接口(LLM API)？创建自己的模型可以完全掌控，但需要数据收集、培训和部署方面的专业知识。LLM API更易于使用，但会迫使将数据发送给第三方，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526159&amp;idx=2&amp;sn=34e9830656726ceb81f15bd3ecfca77e&amp;chksm=eabc8e812e6ce0e24c7cf50c2e7a95b1f4c80de67dbd47d469582f6e861c532903d5f931c79c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 02 Mar 2024 12:25:34 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
