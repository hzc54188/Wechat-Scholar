<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[深度学习自然语言处理]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_af746b3da7c9.jpg</url>
      

      <title>gh_af746b3da7c9</title>
      

    </image>
    








    <item>
      <title><![CDATA[微软提出ICAE：从上下文压缩的角度看待推理加速]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaDfmm8v5c78M5cgVsb2XpGe3IkaSTscwGVk8AYtdKwGFMzuh62nnsUYso2mRXeqeSbBlsy31zClQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：难赋由于目前主流的注意力机制依然是二次复杂度，对长上下文的语言建模仍是目前Transformer模型的一大挑战。之前的工作主要放在对模型架构的改进，如注意力模块稀疏化在注意力中引入记忆信息对外部</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247534206&amp;idx=1&amp;sn=fce02234571138f1c9777380e568f437&amp;chksm=ea71d5d9db2b8bc31152107edcd00e793a99677975ff66812e7e7482406a947feda572c9b527&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 06 Dec 2024 11:41:06 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[从答案到问题：一种新的学习目标让LLM更擅长推理]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaDfmm8v5c78M5cgVsb2XpGsDClO025hEy1wwDkZpfKRlJ9Hfu9CCwQXxnCTYAGUtibAxic80WWmKmQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>整理：深度学习自然语言处理 公众号这篇文章介绍了REVTHINK框架，通过数据增强和学习目标来增强大型语言模型（LLMs）的反向推理能力。研究表明，REVTHINK在常识推理、数学推理和逻辑推理等12</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247534206&amp;idx=2&amp;sn=0fa464f55cc83a71eda8197847617ae4&amp;chksm=ea47adf190ac68cd8257c7bbaadff2bc6e36e81352bb549213bd7874be22fd5bac5b29911ff4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 06 Dec 2024 11:41:06 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[二战字节大模型算法岗，拿下70K offer！！！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagWf2hHnKAd9nBNkIoAuXZh8IZUfQ1NOLnytWQqCg2Lr2lsbQ3p5vGoTYUHgHxFtfS4tVL6FtdicKw/640?wxtype=jpeg&amp;wxfrom=0"/><p>在牛客网看到有同学211本电气专业大三面试字节实习，连简历初筛都没过，毕业后因为kaggle金牌经历，成功二战拿下offer。其实无论是互联网还是传统行业，招聘软件上但凡是头部大厂的算法相关岗位，基本</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247534150&amp;idx=1&amp;sn=616d03cbd2644f943ddd5fad73c47565&amp;chksm=ea6b3352a1aad0ae301e20e610e632a810651a6cf7bca788a3e310e2137ccbc8d829df398a74&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 04 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[盘点 2024 年的视觉语言模型VLMs]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagWf2hHnKAd9nBNkIoAuXZhmlIa0M81LibPNSIrQLFurGZrELFNWia2DyZHoErNplFNxqA0Ph9TL00Q/300?wxtype=jpeg&amp;wxfrom=0"/><p> 作者：AI椰青原文：https://zhuanlan.zhihu.com/p/7827587018编辑：青稞AI1 引言视觉语言模型（Vision Language Models, VLMs）是一类</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247534150&amp;idx=2&amp;sn=565767dabc308b02d0ce01e9110dfc6a&amp;chksm=ead536732668a767c0a2ac7b8185eed793e61aaa2d995fdf290a12162d76d7d7e3f490578a1e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 04 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型时代的科研之路：写给过去的自己]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagGbtKhPK0Y9HNmNy5K43smJ3tnP9RA16oKIZdaXXYicjXHrXjc7uEHvN6B9xCpic5cBrBmtuSkicpsA/640?wxtype=jpeg&amp;wxfrom=0"/><p>主题大模型时代的科研之路：写给过去的自己 时间2024.12.08 10:30-11:30 周日引言假如时光可以倒流，回到大语言模型刚刚兴起的时刻，你是否依然会选择这条研究之路？如果会，你最想告诉当时</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247534134&amp;idx=1&amp;sn=1d49b9b766ccf1cd578e39e096ffeb03&amp;chksm=eae17a3185993adb355c6a560c9cd634665e38310c3dd96d0511601cb3169ebefdda27182bbc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 03 Dec 2024 06:35:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[VL-RewardBench: 通往多模态 self-play 的试金石]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagGbtKhPK0Y9HNmNy5K43smwocxIYiaEr5vmL7JPj5xjtGHRCSJYDzTy0GWq9icn67TtH0H4UxalWibQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：Lei Li地址：https://zhuanlan.zhihu.com/p/9426034901随着模型能力的不断强化，合成数据 + Self-Play 已经成为 LLMs 和 VLMs Pos</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247534134&amp;idx=2&amp;sn=e7df91206731ef15e86b3229c531a0c5&amp;chksm=eaff2202d5f7fb5937a8f4625fb059c92ee48a35a700ca22594c4740c8b2d751f53ab6021d6b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 03 Dec 2024 06:35:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[浙江大学刘佐珠/吴健课题组 6篇论文被EMNLP 2024主会/Findings录用]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaQCsNRqkrRJyiak6MMBKGfvarBN0Cw595AqGPQXDUVx6LCaBpwUQWNrHIAicRkWAabwic8VPBJC65Mg/640?wxtype=jpeg&amp;wxfrom=0"/><p>2024年EMNLP会议于2024年11月12日-16日在美国迈阿密召开，浙江大学研究员刘佐珠、浙江大学求是特聘教授吴健课题组，联合新加坡国立大学、新加坡A*Star、北京大学、时代天使公司等单位，共</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247534111&amp;idx=1&amp;sn=62a533d49e7cc77f23ce45d80542925a&amp;chksm=ea5dd167ebc39b5a4613128113b6116a0a021af07c9fa9149a76338350a2b9e4b6a99e2cf0c2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 01 Dec 2024 14:01:04 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM不会CoT隐性推理，只会显性推理！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bah8ia2Tb5tVvK9Vq6sua8bMZfa43eE7HAwtmGymzZ9T36HzeEfriaSrlibAfkic7Yh9vibzJXle48ic8ohw/300?wxtype=jpeg&amp;wxfrom=0"/><p>这篇文章探讨了大型语言模型（LLMs）在隐式推理中的表现，发现尽管隐式推理理论上更为高效，但实际上并不等同于显式推理链（CoT）。研究表明，LLMs在进行隐式推理时并未真正进行逐步计算，而是依赖于经验</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247534111&amp;idx=2&amp;sn=5536dab237bf4274d69e9224007ad377&amp;chksm=ea0c2386c8611d2192b3efbf0435c502362da3e28fd6707d40d65b80c79d5bf9a15e705e137d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 01 Dec 2024 14:01:04 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[本科生大作业给8分，iclr评审机制的失灵？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baj9UNxfkzBKLNYMPCJOArsQnHQ7VHTrAIbYBkIE9d8qp1ndN80Wnqca5XdysNT62XiaXtia693Nzo5w/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：难赋——以前看见个评论说ai的十分制会议中的10分指的是“如何这篇文章没有中，我将断绝与该会议的一切联系”，要是今天讲的这篇论文中了iclr的话，没准这句话对于iclr来说可以改成对8分的评价了</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247534079&amp;idx=1&amp;sn=9e43cdc345f2f0d424a9690715916746&amp;chksm=eacb2d7df51c493cc89d5833fcde5d8559e5556ed19c0adc9eaf08c81f474fe20d5887484568&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 29 Nov 2024 15:58:45 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
