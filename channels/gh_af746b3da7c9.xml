<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[深度学习自然语言处理]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    

    <language>zh-cn</language>
    




















    <item>
      <title><![CDATA[2024年大模型Alignment偏好优化技术PPO,DPO, SimPO,KTO,Step-DPO, MCTS-DPO,SPO]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia9l9AcgGZtGgl2zib28uNApkRn3Wq4NB0M6aUeJsgwSC7iaA3f0TnrEpDibtYofOOmwuTt852xLqygw/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：是念链接：https://zhuanlan.zhihu.com/p/710021282学术分享，侵删今年做过一段时间的alignment工作，做得有点不开心，各种social的原因，觉得自己的发</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529712&amp;idx=1&amp;sn=141763b569a7fe274261545c6c25deb9&amp;chksm=ea6ce00b713ba37e9918c528b750aaa9a09e299487374388d444fbb212624eefcc7d790c2658&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 09 Sep 2024 12:09:35 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[探索自然语言中的计划搜索：提升大型语言模型代码生成性能的新方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia9l9AcgGZtGgl2zib28uNAp1uGMAvD60GVRq5EFVElVia1ziblec5IicUep6wZ5HjUNiaSdg4llccuYqA/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：Planning In Natural Language Improves LLM Search For Code Generation 链接：https://arxiv.org/pdf/240</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529712&amp;idx=2&amp;sn=9636b9860ce3959aa37a335f93b7a6a1&amp;chksm=eafaa3d431cd9d03fe054738d831e26105a492abbf81170e0dadf1db504aa4bbf137b4dfafe3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 09 Sep 2024 12:09:35 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[揭秘MagicDec：如何推测解码让长文本处理不再纠结于延迟与吞吐？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia9l9AcgGZtGgl2zib28uNApoFZib61IIxR6Ku93abAEmL5UzVYc4rGiakgicV769UCKXTnXRloGCYJicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：MagicDec-part2: Breaking the Latency-Throughput Tradeoff for Long Contexts with Speculative Decod</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529712&amp;idx=3&amp;sn=178cdbb2485c5e43f8376bf1f37eaf8e&amp;chksm=eaf9379a84965ee2a86e3bb3a52b667c666200e55aed6606665d62c94219e3b6bfdf3d815643&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 09 Sep 2024 12:09:35 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[关于如何做科研的一些个人经验 -- 清华AP、Mooncake作者]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahfcMKOVo1DH2AsU1CHEzEDLzJ9ASGsjOh5zxiadrHEhtBQib3icRU8x9iaceUB6micGicDWeibumt73Ge0A/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：ZHANG Mingxing链接：https://zhuanlan.zhihu.com/p/718156903最近开学季，被抓来给研究生新生们做个关于“如何做研究的”的入学教育报告。会后大家希望</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529635&amp;idx=1&amp;sn=daa01cb6a383800378b0c0b1e88b7f06&amp;chksm=ea9ffe2e7973981f315a3ddd92ab0e9decb72de9eac96344879cb5f0d300785049db20e19e3a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 06 Sep 2024 11:36:07 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[重复采样魔法：用更多样本击败单次尝试的最强模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahfcMKOVo1DH2AsU1CHEzED5eNEANHGY7JvYxGhbCbibjVbHKNDP826qORM5bjG7ib33sG0qicxt4q0A/300?wxtype=jpeg&amp;wxfrom=0"/><p>这篇文章探讨了通过增加生成样本的数量来扩展大型语言模型（LLMs）在推理任务中的表现。研究发现，重复采样可以显著提高模型的覆盖率，特别是在具有自动验证工具的任务中。研究还发现，覆盖率与样本数量之间的关</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529635&amp;idx=2&amp;sn=0af2dc8dd1a157e41fe4f1681f24d26a&amp;chksm=eac1ee2013daffd4fc327c3cf9e5ea30ae540adb0d6782953952a6d88cfbb8a3850e30fc111e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 06 Sep 2024 11:36:07 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[你真的了解GPT4o吗？连续发CCFA的博士方法介绍]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahWFWp46tGnsB6cfictLicFicjJcm9aeE95EQPqWLG3cgGOjKyLOyTgwySHJp75GFk4gJWRnRnssWH6g/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言    相信大家都听过ChatGPT，但很少有人能真正解锁这个地表最强AI模型的真实能力。其实是在数据分析、编程代码、文献检索等多方面都能大幅提升工作效率。我们一起来看看：GPT在科研中，到底能帮</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529586&amp;idx=1&amp;sn=f8e0c6ab3b11fab73a7f92a05656571e&amp;chksm=eabc6766d0ea4dfe7ac748de7ee3a47d691996bc47d58c554a6068e6ffbceed49940f1e709d7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 05 Sep 2024 05:32:02 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Alignment下一站：合成数据]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajibLy5jXZAK6bMMImqrDvotj3hAIpkKplTSfOFTy2LqVmUXdPOXPTb5tzzDOSzvmGvibrWoC1Uy0nA/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：李rumorNICE26期 | 大语言模型多选题评估的偏见与鲁棒性大模型训练中，数据质量已经是所有人的共识了。在23年开始接触Alignment之后，我一直是人工标注流派，深信InstructG</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529586&amp;idx=2&amp;sn=2b20138a341d7948ebc9efceb8260183&amp;chksm=ea5e179b8c2df4f8ebc8deac534e9ccc145676427191355cedc50bf8d9490762966317d07790&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 05 Sep 2024 05:32:02 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[MemLong: 长文本的新记忆大师，可将上下文长度从4k提升到80k！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahWFWp46tGnsB6cfictLicFicj8a45tph06aWT4QKxkspewdg4S6MDVibemsMx0yUT69cjLBdNEPEOR7g/640?wxtype=jpeg&amp;wxfrom=0"/><p>这篇文章介绍了一个名为MemLong的模型，它通过使用外部检索器来增强长文本建模的能力。MemLong结合了一个不可微的检索-记忆模块和一个部分可训练的解码器-仅语言模型，并引入了一种细粒度、可控的检</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529579&amp;idx=1&amp;sn=f9993383eee80c22ef55eb229f4c9258&amp;chksm=eaf371e937a23ba7c561085879fa3cb431dfa14d1ac26f6d59a4b81d3e4dd0059300d0f10ece&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 04 Sep 2024 13:45:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[最强MoE完全开源模型发布啦~]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahWFWp46tGnsB6cfictLicFicjsTTpnXXwnDSiamqSY2azoJatqrfFNnlNqSoSC4fEMjLras8WHfJ3MZg/300?wxtype=jpeg&amp;wxfrom=0"/><p>这篇文章介绍了OLMOE（Open Mixture-of-Experts Language Models）系列模型，这是一款开源的稀疏混合专家模型。OLMOE-1B-7B拥有70亿参数，但每个输入令牌</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529579&amp;idx=2&amp;sn=3af092a56e4c84437928122c2df9d147&amp;chksm=ea8209139602ae7228567b2043bd8b5cfaff036986e70840ed9be8fbf035935d8cb359221bf4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 04 Sep 2024 13:45:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大语言模型多选题评估的偏见与鲁棒性]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahU80vrTaqdePtC23BeScz94hU1LxhAVyUccHTH1On8FzlTt3U9aKXxH4ZC3BUx951dRDjMo301eA/640?wxtype=jpeg&amp;wxfrom=0"/><p>主题大语言模型多选题评估的偏见与鲁棒性   On the bias and robustness of LLM Multiple Choice Question Evaluation时间2024.9.</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529480&amp;idx=1&amp;sn=77fc7cdf9564600ab2dcef991135ecd0&amp;chksm=ea94f90ec4d17d1308927680e598e8581d8a34fc6e0eaf20561e2cd1808c597b609f995bea2b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 03 Sep 2024 11:50:38 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[情境化逻辑：LLMs推理能力的真正试金石]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahU80vrTaqdePtC23BeScz9woWiaCjcMLpuPGBFnhd0fNkq5FM7icqxKXKBAf58gSUtiae2rH18lzYEA/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：Disentangling Logic: The Role of Context in Large Language Model Reasoning Capabilities地址：https:/</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529480&amp;idx=2&amp;sn=be6414f70170b8f601762593dc945e3d&amp;chksm=eac8feda8c189227d96da3f72cfb5e07bdc5df36f689d0de8bbb09d40b6cb104d8d1270dbcd3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 03 Sep 2024 11:50:38 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
