<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[深度学习自然语言处理]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    

    <language>zh-cn</language>
    










    <item>
      <title><![CDATA[LA-Light：大语言模型开始接管城市交通了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahuhGEqWa1WMCwpZgX2YPhnVKUY8vmARu8S8YribsSMX3SlNGeVTRIKCI7StfAGYzhCna2WmiaabPmA/640?wxtype=jpeg&amp;wxfrom=0"/><p>LA-Light：大语言模型开始接管城市交通了来着：大语言模型论文跟踪LLM应用 交通管理 信号控制摘要面对大都市交通拥堵这一牵涉广泛且棘手的问题，解决之道在于有效管理，而交通信号控制系统在此举足轻重</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527077&amp;idx=1&amp;sn=ec124e02eecfa87da2d9367f0d359a29&amp;chksm=ea76778f3eedcc53a4a488733e13334727c64716003b3faaa1789d33f4dbc458f0eaaec53311&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 02 Apr 2024 15:31:22 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[聊聊 MOE + LoRA 微调新方式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahuhGEqWa1WMCwpZgX2YPhnUj2Vib96CoCZBb8oFpGhibUJZZ7JR9qia6FJ1icGav1wRFCefKIJ1OWxtw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：无恶不作，华为2012实验室 · 软件开发声明：本文只做分享，版权归原作者，侵权私信删除！原文：https://zhuanlan.zhihu.com/p/686851113编辑：青稞AI1.背景</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527077&amp;idx=2&amp;sn=ea2ce0154a6c428b6c68a1ea1e1cc4ab&amp;chksm=ea8baf85fa23f15fa4164e602318a1ac6e54bfb12623f25f5c19ff7efb7ac5b71a8636e43a81&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 02 Apr 2024 15:31:22 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[每日论文速递 | InsCL: Data-efficient 持续指令学习]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahuhGEqWa1WMCwpZgX2YPhnLoiaefgfa0yNicT2bW944ILkeR3yzdHIBYwMvY4MfXibOLwcJUFkJpibQw/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：Instruction tuning 可有效优化大型语言模型（LLM），使其适用于下游任务。由于实际应用中的环境不断变化，LLMs 需要在不发生灾难性遗忘的情</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527077&amp;idx=3&amp;sn=014aabad2f75281ec2068a25f2cd0db3&amp;chksm=ea06aa51315190600d0004ac1a693ad5c3ac343a3cfc964b33bdefa76b8245dbfb7930ecee50&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 02 Apr 2024 15:31:22 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[每日论文速递 | AFLoRA: 自适应冻结权重进行PEFT]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahuhGEqWa1WMCwpZgX2YPhnLoiaefgfa0yNicT2bW944ILkeR3yzdHIBYwMvY4MfXibOLwcJUFkJpibQw/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：我们提出了一种新颖的参数高效微调（PEFT）方法，被称为自适应冻结低阶自适应Adaptive Freezing of Low Rank Adaptation </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527077&amp;idx=4&amp;sn=54dcb43cee7029ee2770d2ed5ff331e3&amp;chksm=ea7ef667ae94c18b1e3e0f9134692d1fefcdbe700b1fa07e36fda658905a3e3d75cb86edec26&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 02 Apr 2024 15:31:22 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[基于LLM的多Agent框架在金融市场数据的应用]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahuhGEqWa1WMCwpZgX2YPhnS3Zuok7d3gouycrCx79F0HPPVBkcDic1n23Vwdyh8D8rznZ8vW2CyZg/300?wxtype=jpeg&amp;wxfrom=0"/><p>基于LLM的多Agent框架在金融市场数据的应用来着：大语言模型论文跟踪Agent 金融市场 异常检测Enhancing Anomaly Detection in Financial Markets </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527077&amp;idx=5&amp;sn=5bf33f8324be9d4a9f3b829caaae1d72&amp;chksm=eaca378c6687ff2a7b3203a639b7d7825e704f0c61510733406e87da73cc417c350053695dac&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 02 Apr 2024 15:31:22 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[图解大模型计算加速系列之：vLLM核心技术PagedAttention原理]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiahichdmLG8icTCIsoe8OyicESMsOqCNej6ezqknosR8H4AbOutpxAJfGiaDtZh8OiaN5SkZ22HV7DibLgQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>来自：大猿搬砖简记大家好，今天想来介绍下当红推理框架vLLM的核心技术PagedAttention。PagedAttention的设计灵感来自操作系统的虚拟内存分页管理技术。vLLM的论文是在假设读者</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527028&amp;idx=1&amp;sn=27b2dadb681be9764288ee78ee734280&amp;chksm=ea557647263cb634fbe82fb5fb8c17b7851223e4651f4f6d6255ca19332f1f196cf72ff87296&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Apr 2024 10:10:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | BiLoRA: 基于双极优化消除LoRA过拟合]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajtgYnjwHsznpBEHSEKPkZH2MCobV4YAcAwycVFP3tZNNpc6oxffiaGf7QxaHpouhqIxFGKxClEEFQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：低秩适应（LoRA）是在下游任务中通过学习低秩增量矩阵对大规模预训练模型进行微调的一种流行方法。虽然与完全微调方法相比，LoRA 及其变体能有效减少可训练参数</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527028&amp;idx=2&amp;sn=552f8fea486c67d2a0ed4fa2ac8a9e66&amp;chksm=ea2eab2322828dafbef56884583902043a8a4e85bbbc7cfdb597adc8e3f0bd5a286fcfd995b2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Apr 2024 10:10:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | [COLING'24] 探索数据多样性对LLM对齐的影响]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajtgYnjwHsznpBEHSEKPkZH2MCobV4YAcAwycVFP3tZNNpc6oxffiaGf7QxaHpouhqIxFGKxClEEFQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：与人类偏好对齐可以防止大型语言模型（LLMs）产生误导性或有毒内容，但同时需要高成本的人类反馈。假设人工标注的资源有限，可以考虑两种不同的分配方式：标注更多样</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527028&amp;idx=3&amp;sn=9e564696a9ae71563ab2718bcf910524&amp;chksm=eaa43585c4a7218c078161ea13d6b68fd487c4a44226b3e641d68de99f6cfacfa370357ce8ee&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Apr 2024 10:10:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | ReAct Meets ActRe: Agent规划自主解释]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajtgYnjwHsznpBEHSEKPkZH2MCobV4YAcAwycVFP3tZNNpc6oxffiaGf7QxaHpouhqIxFGKxClEEFQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：语言代理通过对基础模型进行推理，展示了自主决策能力。最近，人们开始利用多步骤推理和行动轨迹作为训练数据，努力训练语言代理以提高其性能。然而，收集这些轨迹仍然需</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527028&amp;idx=4&amp;sn=fac7786436364768cdcd538b3253e9b2&amp;chksm=ea9ea28fe7ae026b08079be222fafd364c0ae4a065ddabe712c168cfe22a4f6ab4fce6ef7b9b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Apr 2024 10:10:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[6行代码，1行命令！轻松实现多模态（视觉）模型离线推理&amp;在线服务]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiahichdmLG8icTCIsoe8OyicESVelR20mUou5DicoLfcPibHz7ictjr4KM5MRVyZqOz04tNgjxyhKZK58Hw/300?wxtype=jpeg&amp;wxfrom=0"/><p>早在去年年底，LMDeploy 已经悄悄地支持了多模态（视觉）模型（下文简称 VLM）推理，只不过它静静地躺在仓库的 examples/vl 角落里，未曾与大家正式照面。LMDeploy 开源链接：h</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527028&amp;idx=5&amp;sn=dcdb478001765f5277215be999ff9c16&amp;chksm=eae0d5267959bbdd873569a77d79a99c370cc5070ebafac3fefa19ffc531f535c3ad384b14aa&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 01 Apr 2024 10:10:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Kimi.ai与ChatGPT：长文本理解与科研辅助的比较研究]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baj9Oh9nRlrO7824k3ibUoBcb8BKaicdXHVgAqWJekXHE55p7sJHmr8KNUVdMF0mzicnE0aVic4ShLSia8A/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：张逸霄音乐人工智能博士生在读纯学术分享，侵删TL; DRKimi.ai能很好地解决ChatGPT无法应对的长文本理解和知识整合任务。最近Kimi在内测2M上下文的新模型（之前是200k，新版本翻</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526918&amp;idx=1&amp;sn=b09a9ff8ebcb786fb087b9812560e953&amp;chksm=ea81ffc3a0a8e6c06e625dc34a79f629a0d10009bad3c91bd6289afd84d58a7a58bffc7bd5c7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 25 Mar 2024 15:24:48 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | Google提出PERL：将PEFT与RLHF结合起来]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagsTZkXZtLQWJzQebQjziaEEibwmxk7Zh6lIp8mG9gdMzGw8U66aA2McKYMhIrL0PbJ2Pnq04g3CVicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：从人类反馈中强化学习（RLHF）已被证明是将预训练的大型语言模型（LLM）与人类偏好相匹配的有效方法。但是，使用 RLHF 训练模型的计算成本很高，而且整个过</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526918&amp;idx=2&amp;sn=bb5b58255d4f4b699a0e8225bf961307&amp;chksm=ea8e71ead44c48089427bc5b4650f12ef31e14f0e251bf192bf819580fdd2dc75c203a70a83f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 25 Mar 2024 15:24:48 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | Agent-FLAN: Agent指令训练让开源大模型Agent能力更进一步]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagsTZkXZtLQWJzQebQjziaEEibwmxk7Zh6lIp8mG9gdMzGw8U66aA2McKYMhIrL0PbJ2Pnq04g3CVicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：开源的大型语言模型（LLM）在各种 NLP 任务中取得了巨大成功，但在作为代理时，它们仍然远远不如基于 API 的模型。如何将代理能力整合到开源 LLM 中成</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526918&amp;idx=3&amp;sn=26f21ead13a2f39988621215a6abcf33&amp;chksm=ea879b57d73a660f150282aea940176627e7c769e18d98360fb0fe1ce516195100364d3469bf&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 25 Mar 2024 15:24:48 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[每日论文速递 | 通过Token-level的Feedback进行强化学习控制文本生成]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagsTZkXZtLQWJzQebQjziaEEibwmxk7Zh6lIp8mG9gdMzGw8U66aA2McKYMhIrL0PbJ2Pnq04g3CVicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 分享整理：pp摘要：为了满足实际应用的要求，控制大型语言模型（LLM）的生成至关重要。之前的研究试图将强化学习（RL）引入可控文本生成，而大多数现有方法都存在过拟合问题（基于微调</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247526918&amp;idx=4&amp;sn=7a68ff5f3bf4b130fb1f7d46c75d7e5b&amp;chksm=ea5008e2b17185fc67190282eeb15415488510b1b1a88e6d3f70eb779e8daa937f5dc7e8c67d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 25 Mar 2024 15:24:48 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
