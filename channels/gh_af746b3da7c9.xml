<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[深度学习自然语言处理]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_af746b3da7c9.jpg</url>
      

      <title>gh_af746b3da7c9</title>
      

    </image>
    





















    <item>
      <title><![CDATA[遇上博大精深的中华文化，多模态大模型还能行吗？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajrjk193zib0Q1RG5e8pZ9uPiafVEAzd6U1ibpH16ibljQhtVOkWXW7VYu5HmRF5TVbibqoibqv5hYX4upw/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：张辰皓随着多模态大模型（MLLMs）能力的不断提升，对其高阶能力的评估需求也在增加。然而，目前缺乏对MLLMs在理解中文特色视觉内容方面的高阶感知和推理能力的评估工作。为了探讨多模型大模型与人类</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533374&amp;idx=1&amp;sn=561e7bda3afeb7c11d6d09d8eed886ff&amp;chksm=ea3086a63186ab7290ad2f5cb1a0fcc851463bcfc41632a0bf0a4968b45b86ea07a11533ed2c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 27 Oct 2024 13:51:14 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[突破数据合成scaling瓶颈！7B模型可以赶超GPT4-Turbo]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiadajiaUXzVycYU8KRuovOZ2CDY2tWfIUG8DPDKRfOmK2XlSvutmibNKWYR0YLs5oktticG0iaMXcOBDA/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者: 丁誉洋 项目链接: https://scalequest.github.io/复杂任务的推理能力已成为当前大语言模型的核心竞争力，也是各大厂商争相角逐的关键领域。OpenAI将其 o1 模型定</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533350&amp;idx=1&amp;sn=fe56709dcb1a6c1902a26746cbbd7c2d&amp;chksm=ea1f974bcf8ace44454dfaa6bd1891beae6efc2089fed45b7ffdd66e0ec04e8e32e5ec540442&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 26 Oct 2024 13:05:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多模态大语言模型教程 | MLLM Tutorial @ ACM MM 2024]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiadajiaUXzVycYU8KRuovOZ2ngGxwynwrg7zeJwuaMBd4jgTVTfK7Yl6ARanTJ7JGTeia4ziaA9W36Iw/300?wxtype=jpeg&amp;wxfrom=0"/><p>教程网页MLLM Tutorial@ACM-MM2024: https://mllm2024.github.io/ACM-MM2024时间墨尔本时间 2024年10月28日星期一，上午9点到中午12:</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533350&amp;idx=2&amp;sn=803ae14d057181505ab2b0e9034804b5&amp;chksm=ea34fe97ad854651bcb10efc5d4429a9442ee050d68b47b7cee145551e97ddbbbd3969a178c4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 26 Oct 2024 13:05:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[小数据，大突破！揭秘仅0.3B个token如何让8B模型逼近GPT-4，长文本开源新纪元]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajRvH91Dm10DLz6oGHMlFwW0tiaJAHFS6wAHicuMThiaVibbNVgGXyI4GQN2o1WjqLzWhZvQEd1Q5ickSQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者: 汤泽成 (知乎：ZetangForward)链接: https://zhuanlan.zhihu.com/p/2993874959当前，越来越多的研究指出，长文本模型（Long-context</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533305&amp;idx=1&amp;sn=7efc5ece630a0cafa138f94281276913&amp;chksm=eaf533490197c7c84c65795f6a29cf3a15974ef0cf82d61c06c36244b843fa836845e5d77991&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 25 Oct 2024 07:29:23 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[最新70篇代码大模型论文精选]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajRvH91Dm10DLz6oGHMlFwWO5wC7kkooDmWZ81SxRnQegL2n0dPzNeiaNOOicyQGxQ41T0kAMCYDXDA/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言来自：CodeFuse本文整理 2024 年 9 月至 10 月中旬全球各大高校与科研机构发布的 70 篇代码大模型相关论文。根据论文内容，我们将这些论文整理为了基座模型、代码微调、测试基准、代码</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533305&amp;idx=2&amp;sn=310982c6033e4e70602cb695e8be11f3&amp;chksm=eac14e3072c17c41543b916a8e831671583f7661f24fffc278c869d2b1c046a661694bfe03bd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 25 Oct 2024 07:29:23 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[数据或许比算法更重要？不要轻视大模型剪枝中的校准数据]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiajOibadC0GdTKdFtrTwHcLqFkaeueoUst86zY1ow526GEHMHpk1sicdnQoB9l4pBM4wWiaZmQub8gQA/640?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，大语言模型（Large Language Model, LLM）日益强大的性能吸引了各行各业的关注，并逐步在各种领域得到了广泛应用。为了节省大模型部署的成本，降低大模型服务延迟，越来越多的研究</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533278&amp;idx=1&amp;sn=e73f70ad998d04f0c8d082dbd2b38f52&amp;chksm=eab66395d2d3943b2fb07f830f3db40c5a66de80d05fb52505e02487791166f86491e002ffb7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 24 Oct 2024 12:33:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[（徒手搓LLM）逐行代码从0构造一个LLM——LlaMa篇]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiajOibadC0GdTKdFtrTwHcLqxkUyrRohEVUSM002bl6Kp9IdcTwicib3HezakOcMuHU8cCDzzJYJibQ0g/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：mc112611（已授权）链接：https://zhuanlan.zhihu.com/p/1674261485本篇为：面向人群：觉得LLM很多复杂的结构和层级，懂很多原理，但是不知道怎么结合到一</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533278&amp;idx=2&amp;sn=5f4d450ae4359fa69a8dfd07fc9f3c1c&amp;chksm=ea33fa90be40dba1820c225476c56ea1b59dbe9027113465d13c0661077b5b6b0826ee7d4172&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 24 Oct 2024 12:33:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[EMNLP2024分享会下半场！有Agent、模型/推理加速等主题]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiajOibadC0GdTKdFtrTwHcLqw64lsFWauIiaHPfXMdZn77jxic1jwfWsDq2VMFrHeQvoBsrEYUNY8wMA/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，欢迎来参加我们NICE-苏大AI Lab举办的EMNLP2024分享会，在本周六(10.26)，我们邀请到多位EMNLP2024中稿的同学来分享交流他们的工作，每篇分享都有5mins问答环节，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533278&amp;idx=3&amp;sn=223f602a33b808f5ddb70253c92ad171&amp;chksm=ea5c9370c1aad1eb51b8b1a03dae9cef09302ca50b4130ac88ce639681ae428f9ded5de0813d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 24 Oct 2024 12:33:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型评测的真正难点：内在精细决策逻辑与人认知的对齐]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baguSjMTwLCUXQOqxqfNicfyFyEQ0YVHQ1k4eajYwHHY6ibPtxx5YVnFmxaHsCic7J8cxrzUxiaibn5F6og/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：Qs.Zhang张拳石链接：https://zhuanlan.zhihu.com/p/2092355900陈鹭，张拳石Lu Chen, Yuxuan Huang, Yixing Li, Yaoh</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533042&amp;idx=1&amp;sn=b65b41a1fa5931eac86ea247f3100104&amp;chksm=eadf3d362c60b1bbde78b9334673f96f985776cf590a752f5fb05993b582d0d6bfa656281b53&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 21 Oct 2024 15:44:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM在Reranker任务上的最佳实践？A simple experiment report（with code）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baguSjMTwLCUXQOqxqfNicfyFzS4tl5jONszDQMILVsowCO48kEYIiadhtkcsx3X8P9OcIws004LzjCA/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：车中草同学(已授权)链接：https://zhuanlan.zhihu.com/p/987727357引言在BERT时代，对于Reranker任务，我们使用encoder-only的BERT为基</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533042&amp;idx=2&amp;sn=d640662c4dda381b41dbc63047480dbc&amp;chksm=ea09ed6b1ab74fc2e21cbe8c3a65dffcda8f46a3aa5843e3f95d5ca05bc8b875641eb5b50fec&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 21 Oct 2024 15:44:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[RMB: 这是一个Reward Model Benchmark]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baguSjMTwLCUXQOqxqfNicfyFmJ7gwUX55YuMNLmacIVfgl4WIUtTtQRUOJkj5SS4V5HQkMT4rrO0Ig/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：FudanNLP 我们提出了一个全面、细粒度的奖励模型评估基准，涵盖了超过 49 个现实世界场景，包含了超过三千条现实世界的用户问题。在pairwise 比较之外，我们还提出了 Best-of-</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533042&amp;idx=3&amp;sn=ac55f8aaeb192fe9e4d221215c139270&amp;chksm=eaf8717db5dc2c32d4150105518c6c6700d32e9e925d2c90ccdbe3b9ef0ac2e4d35b736da6ca&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 21 Oct 2024 15:44:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[哈工深、微信：“慢思考”超长文档翻译智能体]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiadVkMPXdicKibQ5NDyBxtnI4bBSwx75crwUpoAMVDmufKvBXaibiaZnNYljHfWVqsCy2YHPJxBxBBsWA/640?wxtype=jpeg&amp;wxfrom=0"/><p>如今，大语言模型已经成为机器翻译任务（Machine Translation）上的新型强大工具。
然而，多数在机器翻译大语言模型（MT-LLM）上开展的研究工作都是句子层面的，每一句话都被独立进行翻译</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247532980&amp;idx=1&amp;sn=91a01462cfa1c6e2089fb562675dec5e&amp;chksm=ea309f0372c80f9eded1484c3f037d92985762db58423960dae12b67d684a7865abef603dc32&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 20 Oct 2024 15:59:28 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[解构DPO：从RLHF推导到多偏好对齐的简化之道]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiadVkMPXdicKibQ5NDyBxtnI4raSeibXQZYFOUoyELWQdxaV0AnXIYX57dR0OQJLOicOkiaeWMQ43GaIog/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：克鲁斯卡OpenAI发布了 o1之后，LLM领域又掀起了Inference Scaling Law的热潮，此次推理能力的大幅提升其中就有强化学习的参与，其利用 RL 改进模型思维链的中间步骤，得</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247532980&amp;idx=2&amp;sn=9a1620d0edfde345e79904997c3b6ae2&amp;chksm=eae6fb028b21872ec54b30517375297667945b7cba395d36069f0a2071dafc8c3ca145365fb1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 20 Oct 2024 15:59:28 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
