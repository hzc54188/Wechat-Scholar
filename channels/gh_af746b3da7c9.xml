<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[深度学习自然语言处理]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_af746b3da7c9.jpg</url>
      

      <title>gh_af746b3da7c9</title>
      

    </image>
    

















    <item>
      <title><![CDATA[NICE31期 | 微软+罗格斯大学提出：使用交互式推测解码赋能Agent，将智能体规划速度提高一倍！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajoPhwmzhz2MKHGiatibtaZPbckB5aNibwwkxnJaYqaEAAevBDz49hLG1KBjpo8SVzZaYLLkgLe0SoMA/640?wxtype=jpeg&amp;wxfrom=0"/><p>主题微软+罗格斯大学提出：使用交互式推测解码赋能Agent，将智能体规划速度提高一倍！ 时间2024.11.3 10:00-11:00 周日入群内容论文：Interactive Speculative</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533527&amp;idx=1&amp;sn=00d4c16b6a7907149c48f911ca2aa94f&amp;chksm=ea1298399b024ece51131ca12a8d984e9b989e6d2cd41d984367c35fea1fb37e16943c6fe18e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 01 Nov 2024 15:27:24 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[ElectionSim：首个大模型智能体驱动的大规模人口选举仿真框架，实现美国总统大选高精度模拟]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajoPhwmzhz2MKHGiatibtaZPbrcbk5X5icAUu51ToTujGNGiaIaTvUFlFBLFYN1bEIVjj8JUAOclXibiaXg/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：复旦DISC2020美国大选模拟结果01内容简介✦基于大规模人口的选举模拟旨在建模特定群体对候选政党和候选人的偏好，在预测现实社会趋势方面有重要意义。当前的主流方法是 agent-based m</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533527&amp;idx=2&amp;sn=a53f93cdc62c85d9ee5a5d4da8e1461e&amp;chksm=eadf195c35ffcdda5e7825bd955e16896824c58cc7d5d69de0c1504009bb19e124034717389c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 01 Nov 2024 15:27:24 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[EMNLP 2024 Oral | CoBa：均衡多任务收敛之道]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajoPhwmzhz2MKHGiatibtaZPb7dYtASA65aj6hOjeibTNKicBSrC9D3pmldQWAqzFaMCZn4sal5qjmmnw/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：CodeFuse多任务学习（MTL）通过给单个模型提供更优的性能和跨任务的泛化能力，从而促进了大语言模型（LLMs）的微调。这是一种资源高效的替代方案，避免了针对每个任务单独训练一个模型而带来的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533527&amp;idx=3&amp;sn=10a8bc1b11c294770afb009cf0097d93&amp;chksm=eac99e368a63b69808a875842939e02e9799c71356c337eba35084c753099401b539375f4f12&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 01 Nov 2024 15:27:24 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[LLaMA系列一直在假装开源...]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaicIBIUssIcCjsIPmK1RtiatngJF99y8902ia9bB09Wx8yvh9KSO5RwwLBdmIE8ek0FwZo73UicUMAiaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>伙伴们，很奇怪~ 关于LLM的开源与闭源模型的竞争又开始愈发激烈。众所周知，开源模型以其开放性和社区驱动的特点受到一部分用户的青睐，而闭源模型则因其专业性和性能优化被广泛应用于商业领域。由于大模型最近</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533509&amp;idx=1&amp;sn=50bbac26f73d97ea2d874b07718e45f7&amp;chksm=eaaf6b65934084fcd0a3a19a661cb664b088021aa58a00c622d1120b2a2f22e52e063f4188b7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 31 Oct 2024 12:54:04 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[EMNLP2024 | 解锁Apple Intelligence：用AppBench一键评测你的手机智能]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagXCAPkU6TwVGSuaVgyJHdUGDxPB33A2SdUhu8fSmYMbPpMZnCzKTTNmmibneribTJtKzLkQKn0UliaA/640?wxtype=jpeg&amp;wxfrom=0"/><p>这篇论文介绍了AppBench，一个评估大型语言模型在复杂用户指令下规划和执行来自多个应用的多项API的新基准。论文: AppBench: Planning of Multiple APIs from</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533466&amp;idx=1&amp;sn=e35aa71c0ca5aa0e705dbc8d6b4405f9&amp;chksm=ea49194c32b63ea67bd0077837442ab6e9630c9c24ad95ff3c34fa7e090aaba6605fa7149df7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 29 Oct 2024 15:53:25 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[从鼠标点击到自然语言：LLM based 文件管理系统怎么样]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaEoZB98J8rvHibVv0UCB75MsMZniblY1o9egA12ZXSrwSXxWrrSNeY2e9mB9ichq3lCzK4VZlFbZ4TQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>这篇论文提出了一种基于大型语言模型的语义文件系统（LSFS），通过自然语言提示实现了更智能和高效的文件管理。论文: From Commands to Prompts:
LLM-based Semant</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533390&amp;idx=1&amp;sn=c7beb1219568e8e40b7bbceded6b9685&amp;chksm=ea24d22e16a19a2d542375573319a4d90b14d4d0bd7c139cd69e3658139b3728d7052a1c5e82&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 28 Oct 2024 14:07:56 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[遇上博大精深的中华文化，多模态大模型还能行吗？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajrjk193zib0Q1RG5e8pZ9uPiafVEAzd6U1ibpH16ibljQhtVOkWXW7VYu5HmRF5TVbibqoibqv5hYX4upw/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：张辰皓随着多模态大模型（MLLMs）能力的不断提升，对其高阶能力的评估需求也在增加。然而，目前缺乏对MLLMs在理解中文特色视觉内容方面的高阶感知和推理能力的评估工作。为了探讨多模型大模型与人类</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533374&amp;idx=1&amp;sn=561e7bda3afeb7c11d6d09d8eed886ff&amp;chksm=ea3086a63186ab7290ad2f5cb1a0fcc851463bcfc41632a0bf0a4968b45b86ea07a11533ed2c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 27 Oct 2024 13:51:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[突破数据合成scaling瓶颈！7B模型可以赶超GPT4-Turbo]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiadajiaUXzVycYU8KRuovOZ2CDY2tWfIUG8DPDKRfOmK2XlSvutmibNKWYR0YLs5oktticG0iaMXcOBDA/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者: 丁誉洋 项目链接: https://scalequest.github.io/复杂任务的推理能力已成为当前大语言模型的核心竞争力，也是各大厂商争相角逐的关键领域。OpenAI将其 o1 模型定</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533350&amp;idx=1&amp;sn=fe56709dcb1a6c1902a26746cbbd7c2d&amp;chksm=ea1f974bcf8ace44454dfaa6bd1891beae6efc2089fed45b7ffdd66e0ec04e8e32e5ec540442&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 26 Oct 2024 13:05:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多模态大语言模型教程 | MLLM Tutorial @ ACM MM 2024]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiadajiaUXzVycYU8KRuovOZ2ngGxwynwrg7zeJwuaMBd4jgTVTfK7Yl6ARanTJ7JGTeia4ziaA9W36Iw/300?wxtype=jpeg&amp;wxfrom=0"/><p>教程网页MLLM Tutorial@ACM-MM2024: https://mllm2024.github.io/ACM-MM2024时间墨尔本时间 2024年10月28日星期一，上午9点到中午12:</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533350&amp;idx=2&amp;sn=803ae14d057181505ab2b0e9034804b5&amp;chksm=ea34fe97ad854651bcb10efc5d4429a9442ee050d68b47b7cee145551e97ddbbbd3969a178c4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 26 Oct 2024 13:05:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[小数据，大突破！揭秘仅0.3B个token如何让8B模型逼近GPT-4，长文本开源新纪元]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajRvH91Dm10DLz6oGHMlFwW0tiaJAHFS6wAHicuMThiaVibbNVgGXyI4GQN2o1WjqLzWhZvQEd1Q5ickSQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者: 汤泽成 (知乎：ZetangForward)链接: https://zhuanlan.zhihu.com/p/2993874959当前，越来越多的研究指出，长文本模型（Long-context</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533305&amp;idx=1&amp;sn=7efc5ece630a0cafa138f94281276913&amp;chksm=eaf533490197c7c84c65795f6a29cf3a15974ef0cf82d61c06c36244b843fa836845e5d77991&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 25 Oct 2024 07:29:23 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[最新70篇代码大模型论文精选]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajRvH91Dm10DLz6oGHMlFwWO5wC7kkooDmWZ81SxRnQegL2n0dPzNeiaNOOicyQGxQ41T0kAMCYDXDA/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言来自：CodeFuse本文整理 2024 年 9 月至 10 月中旬全球各大高校与科研机构发布的 70 篇代码大模型相关论文。根据论文内容，我们将这些论文整理为了基座模型、代码微调、测试基准、代码</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533305&amp;idx=2&amp;sn=310982c6033e4e70602cb695e8be11f3&amp;chksm=eac14e3072c17c41543b916a8e831671583f7661f24fffc278c869d2b1c046a661694bfe03bd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 25 Oct 2024 07:29:23 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[数据或许比算法更重要？不要轻视大模型剪枝中的校准数据]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiajOibadC0GdTKdFtrTwHcLqFkaeueoUst86zY1ow526GEHMHpk1sicdnQoB9l4pBM4wWiaZmQub8gQA/640?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，大语言模型（Large Language Model, LLM）日益强大的性能吸引了各行各业的关注，并逐步在各种领域得到了广泛应用。为了节省大模型部署的成本，降低大模型服务延迟，越来越多的研究</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533278&amp;idx=1&amp;sn=e73f70ad998d04f0c8d082dbd2b38f52&amp;chksm=eab66395d2d3943b2fb07f830f3db40c5a66de80d05fb52505e02487791166f86491e002ffb7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 24 Oct 2024 12:33:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[（徒手搓LLM）逐行代码从0构造一个LLM——LlaMa篇]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiajOibadC0GdTKdFtrTwHcLqxkUyrRohEVUSM002bl6Kp9IdcTwicib3HezakOcMuHU8cCDzzJYJibQ0g/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：mc112611（已授权）链接：https://zhuanlan.zhihu.com/p/1674261485本篇为：面向人群：觉得LLM很多复杂的结构和层级，懂很多原理，但是不知道怎么结合到一</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533278&amp;idx=2&amp;sn=5f4d450ae4359fa69a8dfd07fc9f3c1c&amp;chksm=ea33fa90be40dba1820c225476c56ea1b59dbe9027113465d13c0661077b5b6b0826ee7d4172&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 24 Oct 2024 12:33:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[EMNLP2024分享会下半场！有Agent、模型/推理加速等主题]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiajOibadC0GdTKdFtrTwHcLqw64lsFWauIiaHPfXMdZn77jxic1jwfWsDq2VMFrHeQvoBsrEYUNY8wMA/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，欢迎来参加我们NICE-苏大AI Lab举办的EMNLP2024分享会，在本周六(10.26)，我们邀请到多位EMNLP2024中稿的同学来分享交流他们的工作，每篇分享都有5mins问答环节，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533278&amp;idx=3&amp;sn=223f602a33b808f5ddb70253c92ad171&amp;chksm=ea5c9370c1aad1eb51b8b1a03dae9cef09302ca50b4130ac88ce639681ae428f9ded5de0813d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 24 Oct 2024 12:33:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型评测的真正难点：内在精细决策逻辑与人认知的对齐]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baguSjMTwLCUXQOqxqfNicfyFyEQ0YVHQ1k4eajYwHHY6ibPtxx5YVnFmxaHsCic7J8cxrzUxiaibn5F6og/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：Qs.Zhang张拳石链接：https://zhuanlan.zhihu.com/p/2092355900陈鹭，张拳石Lu Chen, Yuxuan Huang, Yixing Li, Yaoh</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533042&amp;idx=1&amp;sn=b65b41a1fa5931eac86ea247f3100104&amp;chksm=eadf3d362c60b1bbde78b9334673f96f985776cf590a752f5fb05993b582d0d6bfa656281b53&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 21 Oct 2024 15:44:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM在Reranker任务上的最佳实践？A simple experiment report（with code）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baguSjMTwLCUXQOqxqfNicfyFzS4tl5jONszDQMILVsowCO48kEYIiadhtkcsx3X8P9OcIws004LzjCA/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：车中草同学(已授权)链接：https://zhuanlan.zhihu.com/p/987727357引言在BERT时代，对于Reranker任务，我们使用encoder-only的BERT为基</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533042&amp;idx=2&amp;sn=d640662c4dda381b41dbc63047480dbc&amp;chksm=ea09ed6b1ab74fc2e21cbe8c3a65dffcda8f46a3aa5843e3f95d5ca05bc8b875641eb5b50fec&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 21 Oct 2024 15:44:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[RMB: 这是一个Reward Model Benchmark]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baguSjMTwLCUXQOqxqfNicfyFmJ7gwUX55YuMNLmacIVfgl4WIUtTtQRUOJkj5SS4V5HQkMT4rrO0Ig/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：FudanNLP 我们提出了一个全面、细粒度的奖励模型评估基准，涵盖了超过 49 个现实世界场景，包含了超过三千条现实世界的用户问题。在pairwise 比较之外，我们还提出了 Best-of-</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533042&amp;idx=3&amp;sn=ac55f8aaeb192fe9e4d221215c139270&amp;chksm=eaf8717db5dc2c32d4150105518c6c6700d32e9e925d2c90ccdbe3b9ef0ac2e4d35b736da6ca&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 21 Oct 2024 15:44:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[哈工深、微信：“慢思考”超长文档翻译智能体]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiadVkMPXdicKibQ5NDyBxtnI4bBSwx75crwUpoAMVDmufKvBXaibiaZnNYljHfWVqsCy2YHPJxBxBBsWA/640?wxtype=jpeg&amp;wxfrom=0"/><p>如今，大语言模型已经成为机器翻译任务（Machine Translation）上的新型强大工具。
然而，多数在机器翻译大语言模型（MT-LLM）上开展的研究工作都是句子层面的，每一句话都被独立进行翻译</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247532980&amp;idx=1&amp;sn=91a01462cfa1c6e2089fb562675dec5e&amp;chksm=ea309f0372c80f9eded1484c3f037d92985762db58423960dae12b67d684a7865abef603dc32&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 20 Oct 2024 15:59:28 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[解构DPO：从RLHF推导到多偏好对齐的简化之道]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiadVkMPXdicKibQ5NDyBxtnI4raSeibXQZYFOUoyELWQdxaV0AnXIYX57dR0OQJLOicOkiaeWMQ43GaIog/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：克鲁斯卡OpenAI发布了 o1之后，LLM领域又掀起了Inference Scaling Law的热潮，此次推理能力的大幅提升其中就有强化学习的参与，其利用 RL 改进模型思维链的中间步骤，得</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247532980&amp;idx=2&amp;sn=9a1620d0edfde345e79904997c3b6ae2&amp;chksm=eae6fb028b21872ec54b30517375297667945b7cba395d36069f0a2071dafc8c3ca145365fb1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 20 Oct 2024 15:59:28 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
