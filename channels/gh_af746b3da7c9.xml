<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[深度学习自然语言处理]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    

    <language>zh-cn</language>
    

















    <item>
      <title><![CDATA[单卡3小时训练专属大模型Agent-基于LLaMA Factory实战]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag71uVOwHxZGIK64N7QGiaAv5722z37KOhoxUXic5SUabfdjwx33b4KbiciasK5VQrvicM3KVnMxxzicQxQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面编辑：NLP工作站今天给大家带来一篇Agent微调实战文章-《单卡 3 小时训练专属大模型 Agent：基于 LLaMA Factory 实战》，来自知乎@hiyouga（已授权）。知乎：ht</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247525761&amp;idx=1&amp;sn=884edcd90fc0cfcfc64f15eab131540f&amp;chksm=ea4c946f83cb47922ef30611f4600d29c4227b8f06a5e9762ffa5a16d9bb0c629782c9269abe&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 07 Feb 2024 10:18:11 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[2023年大语言模型融合技术调研与实践指南]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>来自：旺知识人类渴望通过吸收获得额外能力的愿望由来已久。超级马里奥就是人类这一梦想的体现，它可以通过收集物品获得额外的技能，如投掷火球和暂时无敌。假设有几个大语言模型：一位擅长解决数学问题，另一位擅长</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247525761&amp;idx=2&amp;sn=a2c7b2fd1450313b583ee3d27bd5083b&amp;chksm=ea395c0c4cc2f9fa20f8da7123f5fe9b780dc03f67471c22236799f7bb608a9a07195c71febe&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 07 Feb 2024 10:18:11 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[8个图神经网络论文创新点汇总【附161篇论文PDF】]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>图神经网络GNN是现在各大深度学习顶会的研究热点，与CV和NLP领域交叉，容易有创新点，是发论文的好方向。本文系统整理了8个图神经网络好发论文的方向，及48篇相关论文。此外还有GNN基础入门知识合集，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247525750&amp;idx=1&amp;sn=37c2b457108951bf259a736a8a2f0a0b&amp;chksm=eabf3e84c887ef90d3ab487ab5a3f85bf9870c46ecb8ac9dbf366ad8aa3fadf3c0b966625b73&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 04 Feb 2024 09:33:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[生成式AI的下一站：更有趣还是更有用？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>作者：李博杰@知乎https://www.zhihu.com/question/637090810/answer/3386191009编辑：包包算法笔记 （本文是 2024 年 1 月 6 日笔者在知</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247525750&amp;idx=2&amp;sn=ffe881e3f5d9adc682a97d1e263e3fba&amp;chksm=ea295ddba586d30dbfb62e581947498d8bff2e0bd8bf9e57b79f03088146d8f5ee116770425d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 04 Feb 2024 09:33:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[不分割成token，直接从字节中高效学习，Mamba原来还能这样用]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>来自：机器之心给出一句「Hello, world!」你要怎么把它喂给 AI 模型？目前常见的方法是利用某种算法将它分为若干 token，比如 ["Hello", ",", "world", "!"]。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247525750&amp;idx=3&amp;sn=5186639d0b8984b0f1824ad3c3b90ec8&amp;chksm=ea5343aba58d29efba1657b0b1c27e0ab22866dff292e6ef3d4ad182772b7d8aabd108027c29&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 04 Feb 2024 09:33:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[详解多模态大模型：LLaVA+LLaVA1.5+LLaVA-Med]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>作者：凯恩博，香港城市大学计算机科学博士编辑：青稞AILLaVA repo：https://github.com/haotian-liu/LLaVA/LLaVA 1.0：Visual Instruct</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247525750&amp;idx=4&amp;sn=50ed9fc56142ab304456e74f021d32c8&amp;chksm=ea376fdb20ad57166d0c127fd25e901e02a1b7a5e873b911c18e4fa482bfea90cc6ce2103e88&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 04 Feb 2024 09:33:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[年终汇总​！ICLR24、AAAI24、ACL23、EMNLP23、NIPS23、ICML23论文合集]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>AAAI2024放榜后，今年的主要顶会的录用结果基本全部发布。我花了3个月的时间整理了包括AAAI2024、ICLR2024、CVPR 2023、ECCV 2023、ICML 2023、ICLR 20</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247525738&amp;idx=1&amp;sn=7cf24fc39771f8db58bb6643ed2ce13d&amp;chksm=ea311b7b2bfdea41482713f9c60703041ee0d22e6a2f8cd6bdfdce037ff94e0fcedd2cbb41d5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 02 Feb 2024 09:23:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[MiniCPM：揭示端侧大语言模型的无限潜力]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagUJsAjQywFEE3ZiaAEBNkwW7CF8z790Pnm4a0flTPphnk6eibCtf2dWxibQXGTwBeoQw9OVDzr4MKPQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：胡声鼎、涂宇鸽、韩旭、崔淦渠、贺超群、赵威霖、龙翔、郑直、方晔玮、张开活、黄宇翔、戴振宁、龚柏涛、王崇屹、姚远、周界、蔡杰、张新荣、翟忠武、丁宁、贾超、曾国洋、李大海、刘知远、孙茂松等机构：面壁</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247525738&amp;idx=2&amp;sn=7f3ed90a569f9af4b0f7b9f56b47089a&amp;chksm=ea2ba863cb6fcc293e32343715f908273ed927a337ab32d466a78b10993d36f87c9f7ef9929c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 02 Feb 2024 09:23:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[生成式 AI 的发展方向，是 Chat 还是 Agent？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>作者：北方的郎@知乎编辑：青稞AI现在看，应该是Agent。前一段时间，比尔.盖茨在他的博客上发表了：《AI is about to completely change how you use com</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247525738&amp;idx=3&amp;sn=e7f4a6b395b1ee4ea8742fd1606c2747&amp;chksm=ea95bb5acfa09eec3861eca43eb75284157d268274e811c2f036bdda11b7f6a65334eddec1f6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 02 Feb 2024 09:23:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OpenAI新的向量技术(embedding)-俄罗斯套娃表征学习]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagibUlaPib0jILnNhGohIXXKXQ9pNHKeoGOryvOb2ZjsZQ3ib2SI09ELcZbxCSiaD9EgbibU12mkon42EA/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：车中草同学@知乎链接：https://zhuanlan.zhihu.com/p/680273451openai2024年1月25日更新了他们新的向量模型，比上一代openai的向量模型更强大。值</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247525700&amp;idx=1&amp;sn=33a0b1b929edb0f34de5f18902184449&amp;chksm=eabbcf5258b3c77d75407ea9f198febbfbb954a58aeb72e7d469212b28dc526eab9ba2ea0b48&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 01 Feb 2024 13:36:17 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[年轻人的第一个多模大模型!1080Ti轻松运行]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>作者：孔令宇，中国科学院大学直博在读。个人主页：https://www.kppkkp.top编辑：青稞AI在工作 Vary 中，我们第一次提出了CLIP视觉词表在密集感知能力上的不足，并给出了一种简单</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247525700&amp;idx=2&amp;sn=5cc63b1fef3fbc2c2ee9d6bc134b3de4&amp;chksm=ea927f37dea4144facfa5860d15ef41b9e99b42f9d7f37253a26228cbca333d992911798784c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 01 Feb 2024 13:36:17 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型也能切片，微软SliceGPT让LLAMA-2计算效率大增]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>机器之心报道编辑：张倩、佳琪删除权重矩阵的一些行和列，让 LLAMA-2 70B 的参数量减少 25%，模型还能保持 99% 的零样本任务性能，同时计算效率大大提升。这就是微软 SliceGPT 的威</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247525700&amp;idx=3&amp;sn=8f80d15ea4ec2f381234080ae6231892&amp;chksm=eaad89d75134d793ca6af37f1c45b3e1484a11a54c45cdfb6f08c7445ced921b906025e3d953&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 01 Feb 2024 13:36:17 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[（待会删）全网独一份！GPT+AI大模型资源，请低调使用！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>“大模型狂热”从未停止国内巨头战队华为、百度、阿里在AIGC的厮杀中从通用大模型渗透到各垂类应用市场就连中国创投资本也独宠AIGC企业百度、科大讯飞市值分别增加27亿和45亿美元这导致AI人才缺口大、</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247525648&amp;idx=1&amp;sn=ce4e11ff3076c67a4fe377b7bcf4f5fb&amp;chksm=ea6ca733499c145b3f36c85389de232d895cf30230186a20f83ed404a636ce75429228c86c2d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 30 Jan 2024 09:09:38 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[FuseLLM：大语言模型的知识融合！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag0csA4rM7FRINcm0mAcuqGicQpPFDaicovfs8Ric2KAliasSQmp1GvDQ3mNqQXYrMpiaIISnlkS0F7G5A/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 原创作者：wkk论文：KNOWLEDGE FUSION OF LARGE LANGUAGE MODELS地址：https://arxiv.org/pdf/2401.10491.p</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247525648&amp;idx=2&amp;sn=5c7f70b7865c1ff903468577b50e3b1e&amp;chksm=ea180df154f46b27b363b8cbd9ca07fd7a1aa610bc134ba333b0db26897a8d0150bb0d9835d1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 30 Jan 2024 09:09:38 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[哈工大联合快手提出CogGPT：大模型也需要认知迭代]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>来自：机器之心在认知科学领域，人类通过持续学习改变认知的过程被称为认知迭代（Cognitive Dynamics）。形象地说，认知迭代就像是我们大脑的「软件更新」过程，手机应用通过不断的更新来修复 b</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247525648&amp;idx=3&amp;sn=20dc022fd852f1d41b2731cf3c4463f0&amp;chksm=ea86ae0cf34b759f193d50f7fd9b4d5a0c3d4ce577b6dd5a8a3e5442038d61cfd370afe80fe2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 30 Jan 2024 09:09:38 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[写在跨年之前：聊聊LLM Agents的现状，问题与未来]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagJMJM6ZIRnaGMe8iahNHKXTDg8lHhib19dRjNwOoTQhT9qqmE5vG5xvlWqNH2LKVliaic8y4hNyQPuXQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：hadiii@知乎链接：https://zhuanlan.zhihu.com/p/679177488跨年之前，想总结一下去年上半年以来关于LLM Agents的学习经历，同时记录一下我在其中过程</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247525623&amp;idx=1&amp;sn=6fe357d66e630c732bb9fdf2c47f86fa&amp;chksm=ead171732f513c7ea27d4789143a73537ec6cca9198e8f316f1b99611657ac5f0fb1da1afe0a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 29 Jan 2024 13:37:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解大模型推理优化之KV Cache]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>来自：YeungNLP此前，我们更多专注于大模型训练方面的技术分享和介绍，然而在完成模型训练之后，上线推理也是一项非常重要的工作。后续，我们将陆续撰写更多关于大模型推理优化的技术文章，包括但不限于KV</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247525623&amp;idx=2&amp;sn=01980ca372f538a6201652f6aad22a1b&amp;chksm=ea4753e8bdd321e5ce4d1cd5314dd04b80047a204bab01d20af5702fb73f72563bb5a4128d8d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 29 Jan 2024 13:37:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[百川智能上新超千亿大模型Baichuan 3，冲榜成绩：若干中文任务超车GPT-4]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>来自：量子位走月更路线的百川智能，在年前猛地加速，变成了半月更：发布了超千亿参数的最新版本大模型Baichuan 3，是百川智能基础模型第三代——就在20天前，这家由王小川创办的大模型公司，刚刚发布过</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247525623&amp;idx=3&amp;sn=c38e0631a56c82231b0a709220a03da7&amp;chksm=eac5bccef26b36fca04056d5330338217a2d2a59c37bce95f6dd3e7b3e373bf01d86872eed2c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 29 Jan 2024 13:37:46 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
