<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[深度学习自然语言处理]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    

    <language>zh-cn</language>
    




















    <item>
      <title><![CDATA[前紧后松：清华读博前两年的焦虑与成长]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahoUFFEOckpumwwcibwSZ2Kr9M2YxZ0GBomDTsSCuFl8VktUXSQkfF2ZxLLSZXIAoiclYQ5PkjD3nlg/640?wxtype=jpeg&amp;wxfrom=0"/><p>来自：丁司图从清华毕业入职腾讯没多久，我上个月作为今年新晋打工人的代表参加VALSE学生论坛，跟同学们分享了一些故事。司徒笔记这个专栏本来是用来聊学术的，不够轻松，似乎缺一些用来当作下饭伴侣或者如厕读</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527380&amp;idx=1&amp;sn=164454bbc95d2b50a5cd3c36c232b3e2&amp;chksm=ea9b57a9a2cf9c067fbdd8f7703616dfc87e56a3ef59957096c6cce8495998a52077c4d3aaf3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 18 Apr 2024 14:03:18 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[《跨语言大模型》最新综述]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahoUFFEOckpumwwcibwSZ2KrGUaW0oM2BZTPRPyPicUGMQKoFQ3q3G1dfCQwBsjmh70JXibpz5LibjXzA/300?wxtype=jpeg&amp;wxfrom=0"/><p>大模型智能｜原创作者 | 小夏跨语言大模型（MLLMs）能够利用强大的大型语言模型处理和回应多种语言的查询，在多语言自然语言处理任务中取得了显著的成功。尽管取得了这些突破，但仍然缺乏一份全面的调查总结</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527380&amp;idx=2&amp;sn=63777e4ddef974937c66df8e22b8ec9d&amp;chksm=eabb2649e195970c88e2988d6b21f7e6abfc5e6541f43f374704e1608da75f17e2864e9dd860&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 18 Apr 2024 14:03:18 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Meta无限长文本大模型来了：参数仅7B，已开源]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahoUFFEOckpumwwcibwSZ2Kr1VsQTveiaicB7BxPEr7eKO1Pkd4nkCt8GlczW5EQIlLnyB3Mgm7yODfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：机器之心谷歌之后，Meta 也来卷无限长上下文。Transformers 的二次复杂度和弱长度外推限制了它们扩展到长序列的能力，虽然存在线性注意力和状态空间模型等次二次解决方案，但从以往的经验来</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527380&amp;idx=3&amp;sn=34a4b45aece8f78f47b8694c16627c33&amp;chksm=ea8a5cf6d1c8f7f103d39e62c17be18ceb6c3c1fb8dccb748a475027f5e5da0ec6a4b6ddd56e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 18 Apr 2024 14:03:18 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[最强MOE开源：Mixtral 8x22B 发布！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahoUFFEOckpumwwcibwSZ2Krr2x1LxeeTSM7MJiaSicraIhoh44Px1w8mRrZA4UpDTicNUrEnnjfngsHQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：包包的算法笔记权重地址：https://huggingface.co/mistral-community/Mixtral-8x22B-v0.1根据上传时间发现是一周之前，在Llama3正式放出来</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527380&amp;idx=4&amp;sn=b13c82d58d1e7b86e002a46a4a067897&amp;chksm=ea4c544b03204218c80a48a2fc0a7ae5f08f4df45311d6d67b461c2ef9ef9201bfda09f9c789&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 18 Apr 2024 14:03:18 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[最新大模型论文研究论文合集，包含谷歌/苹果/亚马逊/港大、阿里最新研究报告！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaBUNP9ov40cegicNJEb6caLZfpGgAmwcJJvhtcevTdGQgDClnMicNGppib4GLX0FnRazqX652XiaFDYw/640?wxtype=jpeg&amp;wxfrom=0"/><p>清华团队推出 MiniCPM：利用可扩展的训练策略挖掘小模型潜力；苹果MM1大模型：30B参数，多模态，在预训练指标上达到SOTA；亚马逊提出大规模视频语言对齐方法VidLA；英伟达参与，高效视频扩散</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527348&amp;idx=1&amp;sn=5fde9cd0b646b8cdfcc722654cd0b979&amp;chksm=eae6af97e766bd3c8184259a9c3801eafcdb02f8a66396dc9901bd374418b1726a074a427f9c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 17 Apr 2024 08:03:13 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[对谷歌最新提出的Infini-transformer模型进行代码复现]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaBUNP9ov40cegicNJEb6caL2RODmk042Eou2FY8cB0eQmYlHR2IGJ1EzNCGuFIPaDlq0Udg49JX8g/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：Lil2J（已获授权）链接：https://zhuanlan.zhihu.com/p/692848185简介这篇文章主要内容为我个人对谷歌最新提出的Infini-transformer模型的个人</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527348&amp;idx=2&amp;sn=afd77d9555e3ac6586022396189d9e18&amp;chksm=eaf27464ba87c55fb78c9910dcdc878b650521b9a3552a713a06d94d133edef3b0b9c36ae9c9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 17 Apr 2024 08:03:13 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Adaptive-RAG:根据难度自适应检索方案]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaBUNP9ov40cegicNJEb6caLncBg0FhNibwN1nJ3ySh6icRTXNuLeQu5BygIvGEWaCXOOTQFBaicl5JWQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：CS的陋室RAG的论文可谓是百花齐放，今天讲一篇有关自适应的RAG，这篇论文认为是不同难度的问题，RAG系统应该有不同的应对策略，因此搭建了这个自适应的RAG系统来适配不同难度的问题。论文：Ad</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527348&amp;idx=3&amp;sn=d36b4937e00bc0ad0ab5e5503884198e&amp;chksm=ea94e7952eb39c787c716d6e48ccfe099c892cb7f4a2489297e46c959ff8cef9b53b191b41e5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 17 Apr 2024 08:03:13 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多篇顶会一作却申博失败？斯坦福博士生亲述：AI领域太卷]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaBUNP9ov40cegicNJEb6caL3gYlicc8fibFesibibrZM1e3kF1TUD7dyMPdnpmz7wSId4PPfFTzxKPDWQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：机器之心「尽管我在顶级 ML 会议上发表了多篇一作论文，为开源项目做出了贡献，也在业界产生了影响，但我仍在为进入博士课程而苦苦挣扎。我被顶尖大学拒之门外，感到迷茫和疲惫。」「我开始怀疑自己，怀疑</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527348&amp;idx=4&amp;sn=2504bdf464743ee4dde39c72d1b208b3&amp;chksm=eab11eea32733d692aace450a1917496ec83d5099e5afb6b0fb49249bf2e8ad04854d2465c08&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 17 Apr 2024 08:03:13 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[1个月快速迈入AI大模型黄金赛道！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahVBKLfGdLUVY5TUVViaOwUr3cbH6AictYyOeoeLpCbYT2AgrLc59jS6YrHF4icMgXHLLqyrRhlq5L4Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>听说你想快速转行人工智能？企业想要快速落地大模型应用到现有业务？身边缺少真正懂AI技术的大佬带你学习？由清华大学顶尖人工智能博士专家组成的Llama中文社区授课团队将会助你一臂之力！！不仅有靠谱的课程</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527312&amp;idx=1&amp;sn=40e37fff5405541969ab5ebbc5777dfb&amp;chksm=ea6f7fb9d3b9885f2a07b333dcd6214e7db187895a5eecdb706a4887022dcda4ad619c4965a4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 16 Apr 2024 09:06:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型综述出书了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahVBKLfGdLUVY5TUVViaOwUrz8IYib0DgTLic3ibdQO5Jib6gUIpVkXlsUw1NMJPTklEG8a1Eyqd9MgCow/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：RUC AI Box在2023年3月，我们发表了大语言模型综述文章《A Survey of Large Language Models》。这篇综述文章已经更新到第13个版本，包含了83页的正文内</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527312&amp;idx=2&amp;sn=74ce209cc48bafad83750fc51c26725c&amp;chksm=eaf15d134462fe4ad2837f3f3d02c326ad160440374abd70ee2408682a47fb1acee98c335f78&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 16 Apr 2024 09:06:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型训练加速之FlashAttention系列：爆款工作背后的产品观]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahVBKLfGdLUVY5TUVViaOwUrzsQp9GxusXoGCd3XU6N8ic8Rm65TAp103pgtGpceuDX1gm2OpXv7UhA/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：方佳瑞原文：https://zhuanlan.zhihu.com/p/664061672纯学术分享，侵删FlashAttention（FA）是一系列针对Transformer模型训练和推理加速方</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527312&amp;idx=3&amp;sn=bb19d0d35825d0e912b8c1cb5e48ae8a&amp;chksm=eae4ba052e34dd8147fd9e1c54c7a0d4441889bcc0dc27a42601038f0dd98305b63cd2e0226c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 16 Apr 2024 09:06:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[清华开源RepoAgent：大模型驱动的项目级代码文档生成框架]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahVBKLfGdLUVY5TUVViaOwUryAfLG6HtIy9pJbwaHHia6FPbzonibu1MHpTpPrsgqaltZm4jWOzh9zIw/300?wxtype=jpeg&amp;wxfrom=0"/><p>来源：TsinghuaNLP@公众号声明：本文只做分享，版权归原作者，侵权私信删除！编辑：青稞AI在软件工程领域，代码文档的质量直接关系到开发效率和软件质量。然而，文档的生成和维护往往耗费大量的时间和</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527312&amp;idx=4&amp;sn=585201593d7345d9ac6bcc2a987d18fc&amp;chksm=ea912ab16834b154342962f76d2ef30d327cff102bb1fff532ec42c5492ba44478af7c207847&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 16 Apr 2024 09:06:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一文全面盘点算法工程师大模型微调技能图谱]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaotYYdfgU4rUOxdaTnNhWvVrnaHddlQ5agfcxaicyCRq0N5Qta0ErBWTj1ww0Ia3ynN3K5KZz1n9w/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着大模型的飞速发展，在短短一年间就有了大幅度的技术迭代更新，从LoRA、QLoRA、AdaLoRa、ZeroQuant、Flash Attention、KTO、PPO、DPO、蒸馏技术到模型增量学习</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527281&amp;idx=1&amp;sn=6d7e8808feddba3b6233623576e21fd5&amp;chksm=eac412c935c3a39642218e8e6236f5429598c5e7b9801c98d13badf02a8c2d05d440bbf6be21&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 15 Apr 2024 10:09:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[魔改RNN挑战Transformer，RWKV上新：推出2种新架构模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaotYYdfgU4rUOxdaTnNhWvYx615HbE5A5xN4ia5JCBPpibrsVWgQXjqQhoic6sDaaVphWzTNAJkJwuQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>RWKV 投稿量子位 | 公众号 QbitAI不走Transformer寻常路，魔改RNN的国产新架构RWKV，有了新进展：提出了两种新的RWKV架构，即Eagle (RWKV-5) 和Finch（R</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527281&amp;idx=2&amp;sn=7bdb38ae001b4759fdf760f836f383a2&amp;chksm=ea519f3ad20528ca1316c0943ca80ae37673e88db9c18f50affeb917144408b27b41150797cb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 15 Apr 2024 10:09:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多模态大模型的最优预训练范式]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaotYYdfgU4rUOxdaTnNhWvtu6g16fuZcribibyg179ZSTNohmFApggUK3K1avnqVBnCbyhzckBrwcQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：AI小飞侠，CV算法工程师/多模态声明：本文只做分享，版权归原作者，侵权私信删除！原文：https://zhuanlan.zhihu.com/p/685586296编辑：青稞AI目前主流的多模态</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527281&amp;idx=3&amp;sn=fa7c2429946e45c58094508d42189c25&amp;chksm=ea907edaecff7f5fc443b4dddd69818532fbaa16167f1838be48b4167aece1ed1d6bc2ecf733&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 15 Apr 2024 10:09:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[HADES: 利用视觉弱点越狱多模态大语言模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaotYYdfgU4rUOxdaTnNhWvzKDcrbjZskfrib0JmKkQkLia9JGsZV6CbLOxIZj9P22Jiak3iaacNicicmFA/300?wxtype=jpeg&amp;wxfrom=0"/><p>© 作者｜李依凡机构｜中国人民大学研究方向｜多模态大语言模型来自 | RUC AI Box本文提出了一种针对多模态大语言模型的越狱方法HADES，使用精心设计的图片隐藏和放大原有有害意图，利用图像侧是</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527281&amp;idx=4&amp;sn=bbcfe62c44ddada545f138fedb889cf4&amp;chksm=ea3a0f5b5a872eb0f4a2a2cd190af399ce7402681887055ab610978cd374c6920decdd3da850&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 15 Apr 2024 10:09:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[MOE vs MOT 让LLM更加有效]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajf3mibiauPpz0VfpyQNB8QejUjyvPrvicerFvcbJhWLqQ7LpAfyM6Uxf9009ibuZEGfibxhtjwa7PLrXw/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：北方的郎链接：https://zhuanlan.zhihu.com/p/691070810翻译自：https://www.superannotate.com/blog/mixture-of-ex</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527253&amp;idx=1&amp;sn=67ac3f80e022164ebc00ad14a7b39300&amp;chksm=ead7cc9f18491a4632891a5d38e5c1e7be8a5d27dddde617237dbedb319b05c1322a770e3a00&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 14 Apr 2024 15:04:08 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[国内20家公司大模型岗位面试经验汇总]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajf3mibiauPpz0VfpyQNB8QejnxWu9jHgmee4Xw6DiaZvHe0MJctgJZE1oKicTqh0WhtOajkxP4DTyE7w/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：林夕，阿里巴巴集团高级算法工程师，专注多模态大模型研究。声明：本文只做分享，版权归原作者，侵权私信删除！原文：https://zhuanlan.zhihu.com/p/690801254编辑：青</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527253&amp;idx=2&amp;sn=73abf1bb10d41b4300629f74fa8624e9&amp;chksm=ea05c3e9eb480cec11979ee9334b419c67bc5d05d432a199e60516fa0980f79148d1217b215f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 14 Apr 2024 15:04:08 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[RAG系统中答案无关的片段对LLMs生成结果有何影响？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajf3mibiauPpz0VfpyQNB8Qejw5SRZicD2TPAubUbDiaDPMx7xbQFAAYcpSjR0do1gKa9McRu1glU7WFg/300?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面来自：NLP工作站RAG（检索增强生成）通过检索系统找到用户问题相关的信息片段，利用大模型综合生成一个答案，极大解决了大模型幻觉、信息更新不及时等问题，已经成为了大模型落地的重要手段。但在检索</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527253&amp;idx=3&amp;sn=0e8acc3643fd1880bcf63fba30b40966&amp;chksm=ea5978e4bd6313afd2946445b93adda87128333de166f634806aff3037697b6c2986d112f50c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 14 Apr 2024 15:04:08 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
