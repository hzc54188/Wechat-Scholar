<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[深度学习自然语言处理]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    

    <language>zh-cn</language>
    


















    <item>
      <title><![CDATA[MemLong: 长文本的新记忆大师，可将上下文长度从4k提升到80k！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahWFWp46tGnsB6cfictLicFicj8a45tph06aWT4QKxkspewdg4S6MDVibemsMx0yUT69cjLBdNEPEOR7g/640?wxtype=jpeg&amp;wxfrom=0"/><p>这篇文章介绍了一个名为MemLong的模型，它通过使用外部检索器来增强长文本建模的能力。MemLong结合了一个不可微的检索-记忆模块和一个部分可训练的解码器-仅语言模型，并引入了一种细粒度、可控的检</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529579&amp;idx=1&amp;sn=f9993383eee80c22ef55eb229f4c9258&amp;chksm=eaf371e937a23ba7c561085879fa3cb431dfa14d1ac26f6d59a4b81d3e4dd0059300d0f10ece&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 04 Sep 2024 13:45:44 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[最强MoE完全开源模型发布啦~]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahWFWp46tGnsB6cfictLicFicjsTTpnXXwnDSiamqSY2azoJatqrfFNnlNqSoSC4fEMjLras8WHfJ3MZg/300?wxtype=jpeg&amp;wxfrom=0"/><p>这篇文章介绍了OLMOE（Open Mixture-of-Experts Language Models）系列模型，这是一款开源的稀疏混合专家模型。OLMOE-1B-7B拥有70亿参数，但每个输入令牌</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529579&amp;idx=2&amp;sn=3af092a56e4c84437928122c2df9d147&amp;chksm=ea8209139602ae7228567b2043bd8b5cfaff036986e70840ed9be8fbf035935d8cb359221bf4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 04 Sep 2024 13:45:44 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[大语言模型多选题评估的偏见与鲁棒性]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahU80vrTaqdePtC23BeScz94hU1LxhAVyUccHTH1On8FzlTt3U9aKXxH4ZC3BUx951dRDjMo301eA/640?wxtype=jpeg&amp;wxfrom=0"/><p>主题大语言模型多选题评估的偏见与鲁棒性   On the bias and robustness of LLM Multiple Choice Question Evaluation时间2024.9.</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529480&amp;idx=1&amp;sn=77fc7cdf9564600ab2dcef991135ecd0&amp;chksm=ea94f90ec4d17d1308927680e598e8581d8a34fc6e0eaf20561e2cd1808c597b609f995bea2b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 03 Sep 2024 11:50:38 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[情境化逻辑：LLMs推理能力的真正试金石]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahU80vrTaqdePtC23BeScz9woWiaCjcMLpuPGBFnhd0fNkq5FM7icqxKXKBAf58gSUtiae2rH18lzYEA/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：Disentangling Logic: The Role of Context in Large Language Model Reasoning Capabilities地址：https:/</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529480&amp;idx=2&amp;sn=be6414f70170b8f601762593dc945e3d&amp;chksm=eac8feda8c189227d96da3f72cfb5e07bdc5df36f689d0de8bbb09d40b6cb104d8d1270dbcd3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 03 Sep 2024 11:50:38 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[千问团队tech lead解读Qwen2-VL：让我们先把视觉理解干上去！（一）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajx2W5iciboKvJicT1rGVWkuYoN3dIshnl0M7VzEwaiaacibOZwHlnJib8NX9FoqejgJuChOxg485ufQebA/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：林俊旸链接：https://zhuanlan.zhihu.com/p/717704002编辑：AI椰青正值前几天发布Qwen2-VL，大家应该在我们的博客或者各个公众号看到我们模型的表现，并且看</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529429&amp;idx=1&amp;sn=88234f6be39005bcfc95b05e679915d4&amp;chksm=ea9288195c3d0c54257d84b6d5016e9a9a27da6563d8063f6a39b295b650bf80d2514cc2b443&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 02 Sep 2024 05:30:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ACL2024 | LLM+RAG可能要毁了信息检索，一份深入研究]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajx2W5iciboKvJicT1rGVWkuYoYZDCcrwGR8OQTickc18vRHss6OM3d915tpI7tZ6tJ2yU9mMWPvcxciaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：[ACL2024] Spiral of Silence: How is Large Language Model Killing Information Retrieval?—A Case St</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529429&amp;idx=2&amp;sn=f37ef1b38b8a77924bcc3bfe991c200a&amp;chksm=eaaf5008af99548f94e9266c0f4f9659fa55ada4f27542f94116e79e3016e51def725a5d1749&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 02 Sep 2024 05:30:39 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型领域，你心目中 idea 最惊艳的论文是哪篇？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiacs3wOoAu29m8s9DFL55DcEic1KteF6JjtOZ49df6j0fOBCbN1J3w4tgEswOqZ5iax2vslj9WmZTEQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：Beyond Hsueh链接：https://www.zhihu.com/question/665735775/answer/3611972970推荐一篇 ICLR 2023 的文章：Seman</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529407&amp;idx=1&amp;sn=389d20bc6bcb690bea856ff3cf28c167&amp;chksm=eae651667c64cc2a2b21a07c331e74eba24ea64fbf852051bbb596b9cd6d8a4a195864d00c83&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 01 Sep 2024 14:33:29 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[入坑大模型18个月的反思与贩私]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiacs3wOoAu29m8s9DFL55DcIbdNqXEicgB2ZXhhHOmhlfD2NyB3dlWox6S1Gm2lDcxHEo9fiauiaSQIw/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎: Minogame链接: https://zhuanlan.zhihu.com/p/717402693编辑：包包算法笔记前几天开完一个有高层参加的会议，会后组里的技术大佬直接就开喷“要规划没规划</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529407&amp;idx=2&amp;sn=a0a026af84edf98625592f37305c5cbf&amp;chksm=eabd2b06ee51966d351723f3f36fdcecb4cc24f7733715935c74794ce73863ed5739050c7590&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 01 Sep 2024 14:33:29 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一周打完1000场官司，中科院发布首个AI法庭AgentCourt！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiacs3wOoAu29m8s9DFL55DcdAiaicpIJoH92dSUKH8WVialPzLu5S46u0HnQ91YGhjZ8cY8YogTvoQYQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>编辑：LRST来自：新智元在人工智能重塑各个行业的今天,法律界也迎来了前所未有的变革。传统的法律实践面临着效率低下、成本高昂等挑战，而AI技术的出现为解决这些问题提供了新的可能。从最初斯坦福小镇火遍全</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529407&amp;idx=3&amp;sn=1c410330c388fbddf813e6177de9d4cc&amp;chksm=eac38bb256dc524e0a245a68fda7e2db32039a4df32655ee65fa1cd05c148a2c737f155e8fc0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 01 Sep 2024 14:33:29 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM的范式转移：RL带来新的 Scaling Law]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajBLl5SltLUyttT3j67qAo9JeJKicMm9dTonKJ4RTia4Zm82V4xjiaBElBfmedltibyibIVuRJCcSviaEUA/640?wxtype=jpeg&amp;wxfrom=0"/><p>来自：海外独角兽作者：Cage从几周前 Sam Altman 在 X 上发布草莓照片开始，整个行业都在期待 OpenAI 发布新模型。根据 The information 的报道，Strawberry</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529378&amp;idx=1&amp;sn=fff2afb33393f0bbe797176aeb599f13&amp;chksm=ea1ae624d0ed56dffd1d6e48094cd3e2e39e827a00ef3c60a66aa83147c1c3cfbd165e784212&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 31 Aug 2024 09:06:35 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[揭秘LLMs不确定性背后的隐患：后门攻击的悄然兴起]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajBLl5SltLUyttT3j67qAo9NHibQTBWsoX3VZrtRR76EudSR4nyc3ubXiaA4TmoLzJVByJhjvttoVAQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：Uncertainty is Fragile: Manipulating Uncertainty
in Large Language Models链接：https://arxiv.org/pdf</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529378&amp;idx=2&amp;sn=b286cdb0c4aee358cc4821a24b1e21e3&amp;chksm=eaa971bd9cee36bc90d8794529c8ce528e7d1b6534a2a9843eb44c1ddf4350d0718383be8aa3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 31 Aug 2024 09:06:35 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[vllm代码更新太频繁，我该怎么办？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajBLl5SltLUyttT3j67qAo9pNVibGic5hyQZBRNY3OEGjgByJljdVlCiaegg7ZziaibSov1kG0WRQPe2Rw/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：大猿搬砖简记大家好，大家在读vllm源码解读系列时，肯定会有以下疑惑：“vllm仓库当前主分支的代码，好像和当前文章中展示的代码，存在许多不同之处，这是为什么呢？”这是因为vllm的开源社区非常</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529378&amp;idx=3&amp;sn=fe853ad92ffa461e46bb026acc27402a&amp;chksm=ea47e7092172e86de15156c255c7b89dc9e664fae8d099417157771b2f8ef6dd6eb58c0be44b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 31 Aug 2024 09:06:35 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Concise Thoughts：仅通过长度限制，获取更简明的CoT能大幅度提升效果]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaDVwQm4MoPzagh9RFKrHOFDWBuAiae3dKy2IicKEe5ZDEzhcsrS8lfjwJU7TNmjNibEffTsd3Wic7WVg/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文：Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost地址：https://arxiv.org/pdf/2407.</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529318&amp;idx=1&amp;sn=ab30fd1618261cdd15e513025bb13c6e&amp;chksm=ea024875b56d743e8d91c49990bb87b3f7c49ee592d09197f4992660df6667c865b0624d6fa5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 30 Aug 2024 11:59:02 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[校招生做大模型，选预训练还是SFT？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaDVwQm4MoPzagh9RFKrHOFlKibSiaJAeYxl02WJ87rcZ7sbQBVAj1KA5SmLZhNrvsjQDjkvVmQukAg/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎: ybq链接: https://www.zhihu.com/question/635761315/answer/3608088928我推荐选 pretrain，理由如下：pretrain 提高工</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529318&amp;idx=2&amp;sn=a861858641f35f356f109f4ea8d8ac87&amp;chksm=ea5835d57ac335d91f0ac1de7fd5087750d6272d97d2d685562fb7c685222f95a9f9745d0fb1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 30 Aug 2024 11:59:02 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[情感分析的终极形态：全景式细粒度多模态对话情感分析基准PanoSent]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaDVwQm4MoPzagh9RFKrHOF4Hw8y9uJXo48Ju6Uic7PTpFicQzvbSTowbmX0WjAAib4HFWnPElJibkMoQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：机器之心罗盟，本工作的第一作者。新加坡国立大学（NUS）人工智能专业准博士生，本科毕业于武汉大学。主要研究方向为多模态大语言模型和 Social AI、Human-eccentric AI。‍情</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529318&amp;idx=3&amp;sn=966e58907a6a84f7fad9aba8289f4771&amp;chksm=ea30814a66c76c9359858eca4603bc9c83d145727febaccc7baaaa570a7866d6fc78ec484595&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 30 Aug 2024 11:59:02 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OpenRLHF：大规模分布式RLHF训练系统介绍]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagF7vOVhF7zsTulJhE1yuQqibZkN63WpibrfPMg7ZI8QZfQkLHHbicM6qskdibIE2ILFcyAM7ZWOuuASQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>主题大规模分布式RLHF训练系统介绍时间2024.9.1 10:30-11:30 周日入群大纲1. RLHF背景知识2. RLHF性能分析3. 基于DeepSpeed的TRLX/TRL/LMF4. 基</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529101&amp;idx=1&amp;sn=dafb1342af7932b5c1153b72a9383949&amp;chksm=ea093157743e62ec282c18b8f68161a4eba40f06844f2d615976fbe417a24b7cc6d3529bf062&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 29 Aug 2024 07:27:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[如何看待 Show-o 和 Transfusion 等 AR+Diffusion 的工作？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagF7vOVhF7zsTulJhE1yuQq3ZTRaV3b8nNyDXdJ0BMVUJruhibwGCQ0uHibddn8GyicdYkMrpACuotiag/300?wxtype=jpeg&amp;wxfrom=0"/><p>Show-o大致如下：作者：Mike Shou链接：https://www.zhihu.com/question/665151133/answer/3608387516来源：知乎好久没来知乎了，简单总</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529101&amp;idx=2&amp;sn=62b96defafc7a89a2a336a855d66e1dd&amp;chksm=ea4abd5fbac4b4ef5af83693f46491bd2db5b8d417a7a5713e5279e973398b951ab8054b1e3e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 29 Aug 2024 07:27:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[微解读 | 到底要不要使用Code？探索Code对pre-training的影响]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagF7vOVhF7zsTulJhE1yuQq78IEhicMo3j5lZKibonoicTRBEKxU0fq7Iae2xHmsaxFAtDRsQZVsTXBQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：李磊 香港大学To Code, or Not To Code?Exploring Impact of Code in Pre-traininghttps://arxiv.org/pdf/2408</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529101&amp;idx=3&amp;sn=0d3fcf8ae500b94799649cca2953a4e2&amp;chksm=ea06aa77370b4800bd3df15bb37587ed1865c8d714ddb36b492d0faa5b5179d26b465e660b16&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 29 Aug 2024 07:27:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[当心环境内容的干扰：大模型GUI智能体的忠实度研究]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahPP2qia6PeP50RxGWyJ0xIw8l0eIh2OoPL6S1wYA4rfBHGBzB8UwBwkZj4peAqla3Hj1td4MGQJdQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>主题当心环境内容的干扰：大模型GUI智能体的忠实度研究时间2024.8.31 10:30-11:30 周六入群论文：Caution for the Environment:
Multimodal Ag</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247529076&amp;idx=1&amp;sn=587a7e753aa7b7350c0a4586b85e6a9d&amp;chksm=ea70e0657cbf77ef4fabf24aabc9c96164b945c3973b0cccac9da0da892c973fee1d8389f24e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 28 Aug 2024 06:37:36 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
