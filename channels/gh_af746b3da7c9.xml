<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[深度学习自然语言处理]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    

    <language>zh-cn</language>
    
















    <item>
      <title><![CDATA[全面解析RLHF，PPO，DPO，Flash Attention，增量学习等大模型算法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag8iczq8AU4ylR3PtXez8v3ejPlV6eR4udurACxhNlzibQnnIEQK2NL2RoXtYWbRnibUUp2OS0iaCmUKw/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着大模型的飞速发展，在短短一年间就有了大幅度的技术迭代更新，从LoRA、QLoRA、AdaLoRa、ZeroQuant、Flash Attention、KTO、PPO、DPO、蒸馏技术到模型增量学习</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527724&amp;idx=1&amp;sn=243f23560c0097eec41f9d71af2a2831&amp;chksm=ea3bc37d448266f8aa0e3800201de27a35aeb0f3d933fe13981f9386d6fd45e61403da171e2f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 30 Apr 2024 09:19:26 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[MSRA联合清华在LoRA相关工作最新进展—混合LoRA专家 (MoLE)]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baj3wdQg6zr7nIpf0B5icHhkEVKLjCSiae8jAFM4ZiaGKWXOyuCVM1wOHP6SxBjQ2Oic6boNpQjCd8wL0w/300?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 原创作者：fanmetasy引言2022年提出的LoRA（Low-Rank Adaptation）已成为微调大型预训练模型的关键技术，其在多种任务中均展现了有效性。LoRA的模块</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527724&amp;idx=2&amp;sn=3255f64fb1d82e871ee2d0d52605e2b4&amp;chksm=eab014bf5aca6235b9dcf8c3283515fc77f2c8ccaeb6b5f2c224658a37dd5a3cc080033f7c8e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 30 Apr 2024 09:19:26 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[OpenAI最新研究——利用指令层次结构应对LLM攻击]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baj3wdQg6zr7nIpf0B5icHhkEU25XX1RsrJSgZVjOE6Gcxib7iaUa5QxAUtyl8JqnQe7Zogg8DSpz5cQw/640?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 原创作者：无穷小敏今天要给大家介绍一篇OpenAI的在今年4月19日发表的一篇研究，该研究提出了一种指令层次结构（instruction hierarchy），以减少LLM被攻击</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527711&amp;idx=1&amp;sn=47cd37f1e941f2cd2785f94f2245ae01&amp;chksm=eab1a88f59a2f655a13e7f18b951bb4e58164adfb8d224db0d09c1a5f7e18a07c9bf43ff637b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 27 Apr 2024 08:19:52 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[COLING24 ｜ GFaiR：基于归结反演的大语言模型逻辑推理系统]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagugAm5wBsSbqBU0szInXQKpv3XoPTzc8FhDMQukyhYUhRGiakODrcWo9oFaUA023gRIKsAbPQz8wQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名称：Towards Generalizable and Faithful Logic Reasoning over Natural Language via Resolution Refutat</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527711&amp;idx=2&amp;sn=32b5d242ed9ca45ce2fe31af417cacf4&amp;chksm=ea1a2cc3295279b241dca5bdd17ca3846b29783a03d8fe9545794ceec0eca82a1b2e33862324&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 27 Apr 2024 08:19:52 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Bert类模型也具备指令遵循能力吗？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baj3wdQg6zr7nIpf0B5icHhkEudOWPu7g63zU6KFXve1C8YUZzIgNdpqdwaNuxnAHoqUMSt4LENdN1w/640?wxtype=jpeg&amp;wxfrom=0"/><p>深度学习自然语言处理 原创作者：WinnieBERT模型，依托Transformer架构及其大规模预训练，为自然语言处理领域带来了深远的影响。BERT模型架构包含多层双向Transformer编码器，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527690&amp;idx=1&amp;sn=a8ff415944e3bfebd6e11b4d9a5c0eda&amp;chksm=ea5d306c3fda2ccf6c77cde1919fa965b3ea73ba8255497a2071bd4597234c9142a5bdba34c8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 26 Apr 2024 10:13:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[TIVE: 数据高效的视觉指令微调]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baj3wdQg6zr7nIpf0B5icHhkEp0SGib8jNno1sOVGzpx4c95mJ7NN873CibVxqkIzdFkHgRESKkWIq2mw/300?wxtype=jpeg&amp;wxfrom=0"/><p>© 作者｜刘子康机构｜中国人民大学研究方向｜多模态大语言模型来自：RUC AI Box视觉指令微调是构建多模态大语言模型(MLLM)的核心步骤。现有的视觉指令构造方法主要有两类：基于大语言模型自动化构</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527690&amp;idx=2&amp;sn=1b1d987aa55f52cb92803737e1efff5a&amp;chksm=ea85f07eb6bf1e68b59f9cd628321a0672588e0f5f95d4113f2d399423f7bf47cc8fbd35db8a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 26 Apr 2024 10:13:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[微软发布Phi-3大模型，3.8B击败chatgpt]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baj3wdQg6zr7nIpf0B5icHhkEmwA17psEVcJASYLv9RZGQJCXXB9cQHfVWPM1TfMb5kdbR7UeRV6zUg/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：包包的算法笔记微软在4月23日发布了Phi-3，Phi-3用 3.8B 的小版本做到了 Mixtral-8x7B 一样的效果，换算到dense大约等于一个14B的水平。量化后大小约1.8G， 在</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527690&amp;idx=3&amp;sn=dc85cb69201d83d2fa4f257746985870&amp;chksm=ea8a758ca91ac6c8639bb7ac64a838409cee6dce5ce344628c1cbd53cd4b04a05326b7ded51d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 26 Apr 2024 10:13:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM能否依据角色的过去预测未来？一篇有趣的研究]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagZ4XjhxR3SCryYg5IcfFPvFIwJkOLMsD6Xxsvh1dT7icwGf3hSOCHzHMNP3FbS4XZefntnNlTDusg/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：wkk深度学习自然语言处理 原创引言你是否想过，如果有一天，当你面临人生重大抉择时，有一个AI助手能够为你提供决策甚至能帮你做出决定？复旦大学和阿里巴巴的最新研究报告显示，大型语言模型（LLMs</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527642&amp;idx=1&amp;sn=e08ee0d0119233fb26e3de0054c418cb&amp;chksm=ea083f9bd4513f92e6283d027c30bfc142cb7d328a8ace093dfc3cb585fcdbcf1fa1aef8ddb3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 25 Apr 2024 06:58:25 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[小师妹我一个月进阶LLM的方法！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagxhaD5f9vWPl8mmVa708XExXaTlYUtuhs5WGA1Bqw4nATkPWyk9Z0Ax0vib4rlJ5X1yOIOD5LicvPQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>我们从2024.1月底到现在已经帮助大几十个同学进阶LLM了，课程优化了数遍，好评不断，期待你的加入~介绍下我们的小团队，分别是：23年面试近50场国内LLM大厂通过率100%拿到多个大厂人才计划of</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527642&amp;idx=2&amp;sn=9ffe3743da8d70067eac2939be98d58e&amp;chksm=ea3d546d035354d62ca9af7b8739e2fc6fab0b1a5dcd8d4d43361bb6545364cf49e095a032b7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 25 Apr 2024 06:58:25 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[100+论文与创新点！SLAM+路径规划资料合集]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagZ4XjhxR3SCryYg5IcfFPvvTiaTM7ZTZlwYicNm2o7O7VxJp5pic9NT2ichiaeWibzlnxGqibribI84fJT5A/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天分享slam+路径规划超全资料合集。无偿分享，扫码即可下载。资料包括： 103篇slam论文来自ICRA2024等顶会，分为视觉slam、语义slam、物体级slam、多机器人协作slam。 35</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527434&amp;idx=1&amp;sn=cf04277e38f050ebb3ba820434cbbda2&amp;chksm=eaf3430277976d6b0daecadb7d91cbf22fad0bec700d89424a7b6fe9f043ac49c3856996ffe8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 24 Apr 2024 06:42:13 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一文看懂 LLaMA 中的旋转式位置编码（Rotary Position Embedding）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagZ4XjhxR3SCryYg5IcfFPvZnClMpxV5mZ6VR6RPia9Qt7pfx2T8Q6b4MvHXmNnrVcEzAdGZf1iapFQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：GiantPandaCV旋转式位置编码（RoPE）最早是论文[1]提出的一种能够将相对位置信息依赖集成到 self-attention 中并提升 transformer 架构性能的位置编码方式。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527434&amp;idx=2&amp;sn=98b1d85e229648f3e717e4e02bf9a326&amp;chksm=ea6ea08abe2366895ea62054ead1397a7d00b046ddae0104dec2e51cd559f465672aa4b1edf8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 24 Apr 2024 06:42:13 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[无位置编码(NoPE)也有长度泛化问题？首个针对NoPE的长度外推方法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagZ4XjhxR3SCryYg5IcfFPvTU5Bpz7tB7QWo9CVSad8MqCqSMPTf2YA6wFzEnd9d08PUqicr2IIYIA/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：FudanNLP基于Transformer的大型语言模型（LLM）展示了强大的文本理解能力，颠覆了整个NLP领域的应用范式。然而，在长度有限文本上预训练的语言模型却无法像人类一样泛化到任意长度文</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527434&amp;idx=3&amp;sn=d285370102eb4e24473b9f7c60ebc58d&amp;chksm=ea5d01ab39410279f402962af00c5200c11a488424a2525063f9eddf0f66b1e1a78b813712d3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 24 Apr 2024 06:42:13 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024 || 将任何Decoder-only的大模型（LLM）转换为文本Embedding编码器]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagZ4XjhxR3SCryYg5IcfFPv7ku2yQM958t9KOgprUUoYNEwY3D3GDl6FN2bicSRyVlyKWAaJXTXyZg/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：深度图学习与大模型LLM深度图学习与大模型LLM(小编):今天给大家介绍一篇题为《LLM2Vec: 大型语言模型是强大的文本编码器》的论文-也就是说把LLM转为embedding 模型。这篇论文</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527434&amp;idx=4&amp;sn=e27ae5dc44c3fd596ae951949cf8b61d&amp;chksm=ea819287adbd9afae2d239b616f2c94873049e8b5a4afb93ab8a958fc4083cd13a80ca1ea872&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 24 Apr 2024 06:42:13 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[总结！大模型微调（Tuning）的常见方法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahHOxDbOnnPJMQmiak1BQqe4TXedTUBLNFr1QImyicyqVialYZ73YVCkTdo6x6Y1ylicp1wkyFL3RrKuA/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着大模型的飞速发展，在短短一年间就有了大幅度的技术迭代更新，从LoRA、QLoRA、AdaLoRa、ZeroQuant、Flash Attention、KTO、PPO、DPO、蒸馏技术到模型增量学习</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527408&amp;idx=1&amp;sn=13fd3a3b021477be3ff8682789e5da96&amp;chksm=ea09c59b19d316e0157e6fe02b42ab4d889d170534b9a560742663b193b4387ee43add78950a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 22 Apr 2024 02:02:31 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[张俊林：聊聊对LLAMA-3、大模型开源与闭源以及合成数据的看法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahHOxDbOnnPJMQmiak1BQqe4RxFia1aibZscsaia6tHbQCEdOrI3HcDhHzibb94IjckyfyLdYyVhm1UgOg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：张俊林，新浪微博新技术研发负责人声明：本文只做分享，版权归原作者，侵权私信删除！原文：https://www.zhihu.com/question/653373334/answer/347146</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527408&amp;idx=2&amp;sn=6136de81fe8a9be4984bda71e4a7d785&amp;chksm=ea695d159d9dc8fbd69f0ca139619f00268607348a9b705185fb90b439fb382a5693ee91b3a3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 22 Apr 2024 02:02:31 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Transformer本可以深谋远虑，但就是不做]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahHOxDbOnnPJMQmiak1BQqe4G0dc3UtA8K6icf60WGD5E5FWzjYrjRhf4Nh31J5t3WQnxycPaVElQ1Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道机器之心编辑部语言模型是否会规划未来 token？这篇论文给你答案。「别让 Yann LeCun 看见了。」Yann LeCun 表示太迟了，他已经看到了。今天要介绍的这篇 「LeCun </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527408&amp;idx=3&amp;sn=cd8405d237020575fe8902258a139bfc&amp;chksm=ead5fe8d885aa04c933daba458bff5bf34e81a6fe9ee9f97b2c6e540b81406cfdd3f8cf07de1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 22 Apr 2024 02:02:31 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ICLR 2024 | 鸡生蛋蛋生鸡？再论生成数据能否帮助模型训练]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahHOxDbOnnPJMQmiak1BQqe4ETlQ4I6pzxa6enIWUh5AvRKJVGvft59OsB5iavkM08ayX0Ib5oPgDicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>来源：机器之心 PaperWeekly本文从一个独特的视角解释了现有多模态大模型幻觉产生的原因。随着生成模型（如 ChatGPT、扩散模型）飞速发展，一方面，生成数据质量越来越高，到了以假乱真的程度；</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247527408&amp;idx=4&amp;sn=08054e26e56d7df41ced70b4ffab94b5&amp;chksm=ea35a25538538c4da5f68f752bd57b0bbd8a6fa400d2230f8814334a5e190fac88066d53e3fd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 22 Apr 2024 02:02:31 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
