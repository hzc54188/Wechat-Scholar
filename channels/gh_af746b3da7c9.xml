<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[深度学习自然语言处理]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_af746b3da7c9.jpg</url>
      

      <title>gh_af746b3da7c9</title>
      

    </image>
    

















    <item>
      <title><![CDATA[很荣幸邀请两位研究员分享：大模型数据合成和增强技术]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiawoO2e9AiaNmibUvQL2GOsN0mb2KFB4dzfbT2gpqV6OV0lLpXsyp2SRRicY09JBMWtXSxuianqFVJ9zA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注NICE，不错过每周分享~主题大模型数据合成和增强技术时间2024.11.27 周三 20:00-21:00论文：A Survey on Data Synthesis and Augmentati</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247534068&amp;idx=1&amp;sn=88a5af0264962e393519e01a1a702270&amp;chksm=eaf44600431011fa0a4af1d3e93f00251f2ec7e2340cfa279b0471d0bffd1d58b88ed2b77e14&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Mon, 25 Nov 2024 14:41:38 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[投机解码中高质量draft tokens不该被拒绝]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaJ1z6xvIXpgHC2eibAwFeRVpVDdcvia74Yiagupia6H70B2KPtocCTnMqDh5HibM7UY6VL2FYhqickOVIQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>💡ICLR25的8/8/10/5的高分工作，确实值得读一下！论文：Judge Decoding: Faster Speculative Sampling Requires Going Beyond M</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247534062&amp;idx=1&amp;sn=a2f24cff43adea2cbd0f4271189e8726&amp;chksm=ea73ff0100488724de407a29033e167deacd50538cc2fcfff912978ee81cf2bfe007d2b7070e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 24 Nov 2024 14:19:26 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一网打尽大模型长文本训练技术]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaJ1z6xvIXpgHC2eibAwFeRVHzTtibo7tZ7mRtoib0OEMiaIUPYjjvY7ib5pdRH107Rsl6xibrwSgBZm5EQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>注：作者 wangs，毕业于985高校，曾在中国科学院国家重点实验室开展科研工作。从学期间，发表了1篇SCI论文、1篇EI论文，并申请了若干项专利。主要研究方向集中在大模型（LLM)和（RAG）等领域</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247534062&amp;idx=2&amp;sn=1591b8a4fc10364141b4b15614d4a182&amp;chksm=ea334e37211f8ecd46e110e1865ccbff268679d32305b38f803d2cb19d79a02f6609fafdce7d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 24 Nov 2024 14:19:26 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[什么是人生的最顶级享受？DeepMind上班，年薪120万磅，研究AI的深层次的推理和思考]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaZRDfyeBy1dejj1uPPiamY1kq4ouUknG7vKM2Pgeibqjdn9rD1w5ia0Fsv4CFEaRPQxCqaPia8GibuVIA/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家周末好呀，今天知乎刷到《什么是人生的最顶级享受？》的一个回答，这简直就是所有人的理想生活啊，我的天。这里分享给大家~知乎：多崎作链接：https://www.zhihu.com/question/</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247534027&amp;idx=1&amp;sn=51b58fd69a96d59a20f50f3648c538bf&amp;chksm=ea324914845dfdc35849ff50d81bf34bf4a72789f725d0318f07a6fb881bd0159d21ff13197c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 23 Nov 2024 14:43:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ICLR 高分：深入研究多模态大模型的对齐策略]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaZRDfyeBy1dejj1uPPiamY1qDkpY3sUf7FffzSwZgUxlDxvqCjYnibqw4ffzicW3mvZIdJpGPg9ddVQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：yearn原文：https://zhuanlan.zhihu.com/p/6762892397编辑：青稞AI多模态大模型（MLLMs）虽然在视觉与语言理解任务上取得了显著进展，但仍面临“幻觉”现</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247534027&amp;idx=2&amp;sn=a7280fdc8f2178de996c12f07f1d7930&amp;chksm=ea71a7bf64bc899d4a424d72b692d0a24ea93a91494762b96a3b8dadd911c3df00a7ea58b6c6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 23 Nov 2024 14:43:22 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[探索 OpenAI O1 模型复现：从 Kimi K0-Math 到 DeepSeek R1 Lite]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagYMeVbsIFQQ9miatD9Gic6xTm9QhyGESWYBJemg1F8kiaEqPP8oul8sJjicxMuD5BZBc6PCZuic607wpA/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：初七123334（已授权）地址：https://zhuanlan.zhihu.com/p/8102196012最近，随着Kimi K0-Math和DeepSeek R1 Lite模型的发布，Op</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247534014&amp;idx=1&amp;sn=a75f512fc44d040dee04d7e69ec8b43a&amp;chksm=ea915e85319eeb6666ac1b7448d9db9dcf01fe71b121d59a8f27c74157633c2e68aca67da430&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 22 Nov 2024 11:51:07 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[阿里提出Marco-o1：探索开放推理模型在复杂问题解决中的应用与突破]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagYMeVbsIFQQ9miatD9Gic6xTH39czZpJRrsXAtVqV7xNWIDJE0wNE0JGUNuPYP2lMvuT1ql0wgibq2w/300?wxtype=jpeg&amp;wxfrom=0"/><p>这篇论文介绍了Marco-o1模型，旨在通过结合Chain-of-Thought（CoT）微调、蒙特卡罗树搜索（MCTS）、反思机制和创新推理策略，增强大型语言模型（LLM）在复杂现实世界问题解决任务</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247534014&amp;idx=2&amp;sn=3a21d855f626e93e2dee47ef0a94294f&amp;chksm=ea9337bd04ad644b2992a11eea817bc678eda8715913f19564026106067a9d2588cc9ad52d30&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 22 Nov 2024 11:51:07 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[提点超30%的WebAgent新方法，比树搜索更灵活！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiatl9FqiaaENGHpdpayibwAJXbKYwjkJGKPMGQCZTO3icFfs3O5qEOTzr5jhiasZ5UeuD0usjGRVibuiafw/640?wxtype=jpeg&amp;wxfrom=0"/><p>这篇论文探讨了如何利用大型语言模型（LLM）作为世界模型来增强网络代理的基于模型的规划能力。作者提出的WebDreamer方法通过使用LLM模拟每个候选动作的自然语言描述结果，并评估这些想象中的结果来</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533978&amp;idx=1&amp;sn=fcf87146f2824961a68e4dbbdf1c8d30&amp;chksm=ea5807f102f1a4060367bc513fe0fb6154ce0afad0005522b3802666bf454c492ab3a6fb572f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 21 Nov 2024 14:48:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[MEMO-Bench揭示现有多模态在负面情绪图片识别与生成上存在巨大缺陷]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiatl9FqiaaENGHpdpayibwAJXsNKWwkBFGSldcgAib5LxenQUXDicaFwAu0KsNJk3ncvk9UTnRchvVs0Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文介绍了MEMO-Bench，这是一个针对文本到图像生成模型和多模态大型语言模型在情感分析方面能力的综合基准测试。MEMO-Bench包含7145张描绘六种不同情感的肖像画，并使用12个文本到图像模</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533978&amp;idx=2&amp;sn=74536c73f54efa85f11e2072a9591f04&amp;chksm=eaf8ad0dafa8682d3f57f8584028d07d47806273341fcf813a55d84680644a5cd64bf53121c8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 21 Nov 2024 14:48:14 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM是如何将信息检索杀死的？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajLsl29NStdniafdxKESfiagswHK4RacpKkm0E4XZpzjFglBVJuuicctbH5p6A7HfhH8b07c31yuZ93g/640?wxtype=jpeg&amp;wxfrom=0"/><p>主题信任密码：探索LLM文本的长远影响 时间2024.11.23 10:30-11:30 周六入群欢迎加入NICE每周分享交流群，在群内与分享嘉宾和观众进行深入交流讨论，并且可第一时间收到后续NICE</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533948&amp;idx=1&amp;sn=60fd5fcade6f9c4f4866ff34c9a16515&amp;chksm=ea3eea855c4bd74ffc9eca9c2ee5cca21982d5acba03340a2891354e9189d72d8fa5c9508504&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 20 Nov 2024 14:49:37 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[微软发现不同prompt模版会导致最大40%性能差距！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajLsl29NStdniafdxKESfiagskzBFVnB8fBYZ4bWvWJLibBj1gCvFQdMX0Hmzic2tsKYL9qSqvRUZM1Qg/300?wxtype=jpeg&amp;wxfrom=0"/><p>这篇文章研究了提示格式对大型语言模型（LLM）性能的影响。通过将相同的上下文格式化为纯文本、Markdown、JSON和YAML等不同模板，并在自然语言推理、代码生成和翻译等任务中使用OpenAI的G</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533948&amp;idx=2&amp;sn=a86e41e76320d068a76c212b2b6056ba&amp;chksm=eaf9f9df4b1b8eed6437cd9e35dc79c76c89666242de1ac4f88993a38fce26ff5b4d302d6122&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 20 Nov 2024 14:49:37 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DeepSeek 推理模型预览版上线，解密 o1 推理过程]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajLsl29NStdniafdxKESfiags65CsS5MibhvpNNubcCpxzJAZhJryT6uBjBdQSyic4nMuWuyHnRia98fAw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天，DeepSeek 全新研发的推理模型 DeepSeek-R1-Lite 预览版正式上线。所有用户均可登录官方网页 （chat.deepseek.com），一键开启与 R1-Lite 预览版模型的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533948&amp;idx=3&amp;sn=b2af14907db9c76d49e589c5541a5079&amp;chksm=ea07c498803ca0bdc2fc853766d55babc645803f84e4c6dad6445569652566fff4a80a2164a7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 20 Nov 2024 14:49:37 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型也有侧脑？揭秘WISE如何带来终生学习新突破]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaHO0PdInkbhA7ppFsq7vqPkBazibwibnD5UCXNXiaicwk50icUTEKJOjhcqBx02icPRib3vaZ4HSaY97XQw/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者: bhn论文：https://arxiv.org/abs/2405.14768代码：https://github.com/zjunlp/EasyEdit人类的学习能力是独特而强大的。我们不仅能够</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533916&amp;idx=1&amp;sn=b568869c922e23706c1d57ebfafc7c00&amp;chksm=ea58d189f12b15b84bbc06753bad3bfdbd0a162c4d95c1429888492025e0763001509471572a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 19 Nov 2024 13:40:09 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM也怕你妈叫你回家吃饭这种模糊请求，纽大提出指导LLM澄清问题]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaHO0PdInkbhA7ppFsq7vqPSTNlNheH35bJxkicviaxXotK3AvwyMcckbkY4adNtHa1d2XvpDe4joAg/300?wxtype=jpeg&amp;wxfrom=0"/><p>这篇论文让我发现，原来机器人也怕小明的你妈叫你回家吃饭这种模糊请求啊！-- 小红书巴比龙在大模型任我行下的评论论文：Modeling Future Conversation Turns to Teac</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533916&amp;idx=2&amp;sn=b1d0c7aceff1dcc46af248114abc5d0a&amp;chksm=ea6a7de20bba1fb3fb57eaeb80e802d892ccd49cad451d8d2480bc015515f5dbeb0c63418512&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 19 Nov 2024 13:40:09 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[最值得参加的LLM盛会！多模态/Agent/具身智能/安全/评估等15个论坛！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagDpSvaHDTtC7ZW78FJE9Raw3mknnIiaHXsh1FIvYbz8RUnJc09tG2YMbVibricrYSic0vnL3TicibowY1A/640?wxtype=jpeg&amp;wxfrom=0"/><p>会议简介中国中文信息学会（CIPS）是中国中文信息处理及其相关领域的学术团体，大模型与生成专业委员会（LMG）是中国中文信息学会旗下的专业委员会，全国大模型智能生成大会（LMG）是该专委会的旗舰学术会</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533861&amp;idx=1&amp;sn=7dc16f68636f96cc0b0d63756a4b184e&amp;chksm=eaabcfa971b723a741f6b7b2b6c7d9e3c6010e974ef21f70b33e43d25cec70e6ec2f7af04e69&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 18 Nov 2024 07:08:17 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[人人都能看懂的RL-PPO理论知识]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagDpSvaHDTtC7ZW78FJE9RaGXIiaXxFJ3URSB47qpqBlpZ3pPIWLLia18hljC8ibGV4D8Sl0e05Y2lhw/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自：大猿搬砖简记在去年的这个时候，我以deepspeed-chat的代码为例，解读了rlhf运作的流程。当时写这篇文章的目的，主要是想让读者在没有强化学习知识的情况下，能从直觉上快速理解这份代码，以</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533861&amp;idx=2&amp;sn=113ac3b2a5b213c88bd3c43f59e82eac&amp;chksm=ea67765efc9575693cd0d944447003184906fc3b5a6eb85bc3790f563c9aff4ef0ed7d1519fc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 18 Nov 2024 07:08:17 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[最新多模态大模型综述｜连续还是离散？多模态大模型的进化之路]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagDpSvaHDTtC7ZW78FJE9Ra6p0VWeBEw30JG5cGGrwGsvw6w78DZMMRQeLorFeARcOAFJzqkudBZQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>，复旦大学数据智能与社会计算实验室Fudan DISC近年来，多模态大模型（LMM）相关的研究百花齐放。然而，现有的综述缺乏对LMM构建中各方面的研究问题的全面讨论。为此，来自复旦大学的研究团队尝试从</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247533861&amp;idx=3&amp;sn=fee75e5dfc4bb7551ec6414d0ff1702c&amp;chksm=ea34b53ed9317cc849c51e1c7d3228040ab630ee66d42da34c8ba1a7ed3924515fd787d63ce1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 18 Nov 2024 07:08:17 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
