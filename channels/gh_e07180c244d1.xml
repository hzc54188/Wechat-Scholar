<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[我爱计算机视觉]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[我爱计算机视觉公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_e07180c244d1.jpg</url>
      

      <title>gh_e07180c244d1</title>
      

    </image>
    
















    <item>
      <title><![CDATA[MMRel | 多模态大模型时代的评测物体间关系理解新基准]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvZ0oPQL3j6xPZicFmj4plLXDzHEvW1kUicsuzjPvnoMJrWFZI6ic3ALnz5PIsJEGOTzHMnmWoE9XEcQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美针对目前多模态大模型（MLLMs）对于物体间关系理解的不足，我们贡献了一个大规模、高质量、多领域的专注于物体间关系理解的数据集 MMRel。相比于其他数据集，MMRel 具</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247625702&amp;idx=1&amp;sn=8a8510468c3dc96bf6baed7bc2752994&amp;chksm=973d1b93cd81606ed35b790a1282e875550132b4c6c6118e9c6e4b7d20ed4c92171bd96f892d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 20 Nov 2024 14:01:22 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[NeurIPS 2024｜单步生成：让扩散模型实现高速无损的内容生成]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtI1DBz0HtmLpVIia80JJNicrwQU9jGqp3vQudfrzOnQS9yf5hc0ewf7tbEY7SfEY3VDRYLo76xkq2A/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享 NeurIPS 2024 论文One-Step Diffusion Distillation through Score Implicit Matching，单步</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247625681&amp;idx=1&amp;sn=84163ba78b70427faab482f1e4921bf2&amp;chksm=971808cd6ecd375e2494e131fc64d05195a930fba49978f4a5cb5cea8eb1b58025eb72765af7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 19 Nov 2024 09:23:25 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[喜提 TPAMI 顶刊！！！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvahGG7oh8Xib7YRerRKEDJpt3nrCk0UH6nwyywU8rqKXpmgkebHnQFiakEz3lMCT5fU2XzaYOXy3qQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近经常收到读者的留言 ：说从研三上学期，就焦虑得厉害，论文不仅要大改，投的SCI还没有接收。害怕延毕，不停地熬夜，但是并不知道要去做什么。成宿成宿的失眠，每天晚上噩梦不断，导师对我是放养型，和导师、</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247625667&amp;idx=1&amp;sn=82a88bc73323ef86e08c920d3bb1cd1d&amp;chksm=97ca6e91dfe941a8f69d7089cd06fb3e9c280ef9287b91fa0f60041aac84214a8a31da0fc78f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 15 Nov 2024 06:03:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NeurIPS 2024 ｜ 北大&amp;华为提出扩散架构U-DiT，六分之一算力即可超越DiT]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsrariaB5RbF53Q7t9rH1wQIuiagU5znehZNlz5ufnv4icEib1rHcV8snibr91dGY3NZHffCgQoNpQ4n0g/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美Sora 的发布让广大研究者及开发者深刻认识到基于 Transformer 架构扩散模型的巨大潜力。作为这一类的代表性工作，DiT 模型抛弃了传统的 U-Net 扩散架构，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247625667&amp;idx=2&amp;sn=80afd75547378b277d7e87abef165211&amp;chksm=97dac4676e8c2d9d39b5c45e41a19fe68e22343ea6183ea0948909129ec36922cc39a5985b25&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 15 Nov 2024 06:03:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[TNNLS24｜动态网络！同一个模型走不同路径，就能生成不同的图像描述结果！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv5dZqq5LOdc1QoMP5aIQt2ibVNhrUFu42ekKyfJwibOib3waLctMsSMgu5JzoUr4mwQnpFWjeqXY0QA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本文探讨了一种用于视觉和语言任务的新型动态网络，其中推理结构针对不同的输入动态定制。之前大多数最先进的方法都是静态的和手工制作的网络，它们不仅严重依赖于专家知识，而且忽略了</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247625641&amp;idx=1&amp;sn=29065bb2450dce2ab509370fe6cd8e88&amp;chksm=97f2df91ad706b8c3d16a93c58293f9e876701fadda6fe8ed8f770550c8bb9aca4eaeace6c12&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 14 Nov 2024 06:58:04 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[突破大模型，经典著作！！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsPmIxNarBx80gib1uAvg5oibfYQ776G1agtccjuAPqyNczRDm8P9qGRqGEgLk9MkKMiaqEWZGWwbuhg/640?wxtype=jpeg&amp;wxfrom=0"/><p>介绍《大语言模型基础与前沿》是由美国明尼苏达大学双城分校电子与计算机工程博士熊涛所著。熊博士曾在多家中美知名高科技公司担任高级管理职位和首席科学家，在人工智能的多个领域，包括大语言模型、图神经网络等从</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247625640&amp;idx=1&amp;sn=112e67e4d00e1561955c5d883973df85&amp;chksm=97549b238e9cffca7a6b4256a9e72a5c030ffb1ac1faf0a757a242fa27c666de45a34e640b5f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 13 Nov 2024 04:12:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[革命性突破！UltrAvatar: 逼真的3D虚拟可驱动人物生成，纹理引导生成打造极致完美]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvuh8SWdnChKutwM4iaG3GMhzpcWC0Tt1Wm3TMKhU8V8fLUj6hZxorSVdIGpq3NSrssW1Q2x3JUKXQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>UltrAvatar: A Realistic Animatable 3D Avatar Diffusion Model with Authenticity Guided TexturesCVPR 2</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247625640&amp;idx=2&amp;sn=49f7f09155089929e9b1156f95637338&amp;chksm=97a9c2c5bc997bb2d869c9be60138a0c8480a2878c225535d874a6cc0f8eb15a12d3afe921e8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 13 Nov 2024 04:12:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[打破多模态检索的瓶颈，OmniSearch实现智能动态规划！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv5dZqq5LOdc1QoMP5aIQt27eKeib0wylBJsE6UCXgB2CFYbHNawxL6huszQzxricK5flepALzcTWHA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美随着多模态大语言模型（MLLM）的广泛应用，模型在理解复杂问题时经常会出现“幻觉”现象，即模型生成的内容与事实不符。多模态检索增强生成（mRAG）技术旨在通过外部知识库的检</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247625621&amp;idx=1&amp;sn=8485122b5917ddbb396e6a069e2aad34&amp;chksm=97716e481e4bd8454eb286ce567b2ea9b2cdf756d5323d4e8f3cefe2729b5bfd304dc3757e16&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 12 Nov 2024 04:03:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[R-CoT: 利用反向思维链弥补合成数据与实际数据之间的GAP，实现多模态几何数据生成能力突破]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtAk9vkBaibyyACHBGwFk8XAyBmPZG18crgAkktMtIAbFVkl9R9R2gEl58tbXuAbCymjDupJsOA8sQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本文简要介绍多模态数学几何数据生成论文R-CoT: Reverse Chain-of-Thought Problem Generation for Geometric Re</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247625551&amp;idx=1&amp;sn=d6ea544a75f6da72dcc37fcbd3f9926b&amp;chksm=9765366674ce6242335e239d601e3b1991266287e51a9e2daabc529ca32daa67f49a023809e8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 11 Nov 2024 07:50:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CVPR 2024 | OmniMotionGPT：突破有限数据限制，实现无限动物动作生成！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTs4lGCyZSgGcDibNFMa9NQwtCURU9Xv8K8tzMVf9937YhNF5yv0ica33FR5pYial86ctqr73vUcXSpyw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享 CVPR 2024 论文OmniMotionGPT: Animal Motion Generation with Limited Data，该项工作由西湖大学 M</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247625529&amp;idx=1&amp;sn=d912f3d0d6c9af2055af0e0408563a71&amp;chksm=97d0fb90d6d6b6c469b80002054480e73375ab91ea60ac3f1f8291ca30c16a728ba5a74bb176&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 08 Nov 2024 06:47:46 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Pattern Recognition | 同时关注局部和全局信息，利用注意力抓取不同粒度的视觉信息来描述图片]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvKJMa0qIicPrZVYsoshHaJvWDa2Js1hcRn6EnBsd1oUoFWpBb1vLFibutMLUmfbU0W2QibfJb8QibRCA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本文研究了利用网格特征进行图像字幕的局部视觉建模，这对生成准确且详细的字幕至关重要。为了实现这一目标，我们提出了一种具有两种新颖设计的局部敏感Transformer网络（L</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247625501&amp;idx=1&amp;sn=49163e9b0f9482508e4e6f1de2e4e96f&amp;chksm=970f8242dca1358344cd480ec618693684ea8eb17cb6faaefa9bba286e9b7b36927ba95dc9c3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 07 Nov 2024 13:29:07 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[综述 | JSTARS 2024 利用深度学习技术监测无人机和卫星影像中的废弃物]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTt9OBMnvs9lYdvQsAL9h0mLkibtmgQptw1Pp3oG78SUvGXVt3lYf9PPAyK9hwrnxowgPIuVdVjWHjA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享论文Monitoring Waste from Unmanned Aerial Vehicle and Satellite Imagery Using Deep L</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247625419&amp;idx=1&amp;sn=c56fd0cdfabd0af2a9c938439cb0c178&amp;chksm=97874f4b547ae724b1e92f28ce1f12af32dad8350d22614e0ad1b47e2c40351461ce8e9867ed&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 06 Nov 2024 15:01:23 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[PointGST：点云分析精度卷到99%了，还只用了2M训练参数]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuC3VxicvVjWWgY75q4tLSfT7wY9LicqLRhLVByT8iaV0pxLPX01iaibxF9ADZ7FPM55kyLVnTzUeDQVDQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美近年来，点云分析技术在自动驾驶、虚拟现实、三维重建等领域得到了广泛应用。尽管点云预训练模型展现出了优越的性能，但随着模型参数量的急剧增加，对其进行微调的内存和存储开销也同步</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247625395&amp;idx=1&amp;sn=2514aed21a184c7eeaeab42c7f67d106&amp;chksm=9724a96cd12eac584a0ce975f94c672c6b90400bd70f387ebff52a518b7febf940aab88381e1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 05 Nov 2024 14:32:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NeurIPS 2024 | 观物取象，穷理尽性：从视觉观测中推理物理运动规律]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuC3VxicvVjWWgY75q4tLSfTAdffHqe77fqaPHdIOlg9vmWsoyEuNPOvb5g9iaukibounqA8plCK7a9w/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本文分享 NeurIPS 2024 论文NeuMA: Neural Material Adaptor for Visual Grounding of Intrinsic D</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247625387&amp;idx=1&amp;sn=bdf97b9b0837c9a193b097862f94bd28&amp;chksm=970670e32504c7ab521dea55f32f3ca2e629f23d1b2c321ea272bc1c559dbf8d4dfdd2138735&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 04 Nov 2024 12:45:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[E.T. Bench，一个大规模，高质量，场景开放的事件级视频时序理解测试基准，专注于长视频和多事件视频的细粒度时序理解]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuVbyAvyQhsugz3eMKDE7rlYeibPRCaCuhmQt90wOljQDwmz9IwoTosK80ibeC3dXuVTvWHm3v3H4sg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享论文E.T. Bench: Towards Open-Ended Event-Level Video-Language Understanding，提出E.T. B</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247625340&amp;idx=1&amp;sn=cd48fd443c82effd1214ffc82efc85fb&amp;chksm=971b855bc487781d651bb99e4a56c4fb7e637461cd7e64438b61b64ab7bf6481c56e7f35d525&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 01 Nov 2024 04:36:47 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NeurIPS2024 | 提高专业生产力，让你的AI画作布局可控，360 AI Research开源新模型HiCo]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtyG7OviaXZDqC0JhiaLuMILzZVXSXibjOkojMZ4zwVtn0476xBSSyc96edrgnmbImFfGG1yaqzlibFWg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美AI绘画模型一直以来被概括为“文生图”模型，究其原因，是因为当前的主流图像生成模型基本都只提供了基于文本条件生成图像的能力，各家的AI绘画产品也主要在生成画质和文本理解能力</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247625339&amp;idx=1&amp;sn=74efc1389ec3190b6f3ccecab0df5bf1&amp;chksm=970a21105f7bd9b9b27c58978d242e6a8cadbeb48879e487a21540ee9cce9e483b6a84b2ece5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 31 Oct 2024 05:58:26 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
